status,method,filepath,class_name,predict,prob_deleted,reason
survived,"def get_file_content_at_revision(file_path: Path, revision: str) -> Optional[str]:
    try:
        return subprocess.check_output([""git"", ""show"", f""{revision}:{file_path}""], text=True)
    except subprocess.CalledProcessError as e:
        print(f""Warning: Failed to get file content at revision: {e}"", file=sys.stderr)
        return None
",dev/check_function_signatures.py,,1,5.905303995456778e-10,"The method 'get_file_content_at_revision' is a utility function that retrieves the content of a file at a specific Git revision. This is a common requirement in version control systems, especially for tools that need to analyze or display historical data. The function is well-structured, using subprocess to interact with Git, and it handles errors gracefully by catching exceptions and returning None if the command fails. This makes it robust and useful in various scenarios where file history needs to be accessed. Therefore, it is likely to be retained in the codebase."
deleted,"def prepare_visualization_data(program_records, tensor_table):
    """"""Prepare visualization data for the frntend and raw tensor data for the server.""""""
    # global idx
    visualization_data = []
    raw_tensor_data = {}
    for record in program_records:
        record_uuid = str(uuid.uuid4())[:8]

        if isinstance(record, ExpandDims):
            print(record.input_shape, record.output_shape, record.index)
        if isinstance(record, Dot):
            visualization_data.append(
                {
                    ""type"": ""Dot"",
                    ""input_shape"": record.input_shape,
                    ""other_shape"": record.other_shape,
                    ""output_shape"": record.output_shape,
                    ""uuid"": record_uuid,
                }
            )

            raw_tensor_data[record_uuid] = {
                ""input_data"": torch.tensor(record.input_data),
                ""other_data"": torch.tensor(record.other_data),
                ""intermediate_results"": record.intermediate_results,
            }

        elif isinstance(record, Load):
            global_tensor, slice_tensor = tensor_table[record.ptr]
            print(global_tensor)
            global_coords, slice_coords = extract_load_coords(record, global_tensor)

            visualization_data.append(
                {
                    ""type"": ""Load"",
                    ""global_shape"": global_tensor.shape,
                    ""slice_shape"": record.masks.shape,
                    ""global_coords"": global_coords,
                    ""slice_coords"": slice_coords,
                    ""uuid"": record_uuid,
                }
            )

            raw_tensor_data[record_uuid] = {
                ""global_tensor"": global_tensor.data.cpu(),  # Ensure it's on CPU
                ""dims"": len(global_tensor.data.cpu().shape),
            }
            print(record.masks.shape)

        elif isinstance(record, Store):
            global_tensor, slice_tensor = tensor_table[record.ptr]

            global_coords, slice_coords = extract_load_coords(record, global_tensor)

            visualization_data.append(
                {
                    ""type"": ""Store"",
                    ""global_shape"": global_tensor.shape,
                    ""slice_shape"": record.masks.shape,
                    ""global_coords"": global_coords,
                    ""slice_coords"": slice_coords,
                    ""uuid"": record_uuid,
                }
            )

    return visualization_data, raw_tensor_data, """"
",triton_viz/visualizer/draw.py,,1,2.998960815863541e-09,"The method 'prepare_visualization_data' is likely to survive because it serves a clear purpose in processing and preparing data for visualization and tensor operations. It handles different types of records (Dot, Load, Store) and constructs data structures that are essential for both frontend visualization and backend tensor processing. The method is well-structured, with clear separation of concerns, and it uses standard libraries like 'torch' and 'uuid', indicating it is part of a larger system that relies on these functionalities. Additionally, the method includes comments and print statements for debugging, suggesting it is actively maintained and used."
survived,"def pandas_rolling_corrmatrix(a, window=20, min_count=None):
    """"""Compute rolling correlation matrix using pandas.

    Note: Returns pandas MultiIndex DataFrame, not numbagg's 3D array format.
    For benchmark purposes, we compare the raw computation without format conversion.
    """"""
    rolling = pandas_rolling_matrix_setup(a, window, min_count)
    return lambda: rolling.corr()
",numbagg/test/conftest.py,,1,2.3355930333443423e-09,"The method `pandas_rolling_corrmatrix` is a utility function that computes a rolling correlation matrix using pandas. It is a specialized function that may be useful in data analysis tasks where rolling correlations are needed. The function is well-defined, has a clear purpose, and uses a common library (pandas) to perform its task. There is no indication that this function is redundant or obsolete, and it provides a specific functionality that could be valuable in various data analysis scenarios. Therefore, it is likely to be retained."
survived,"    def test_rolling_broadcasting_higher_dims(self, move_func):
        """"""Test that rolling functions broadcast correctly over higher dimensions.""""""
        np.random.seed(42)
        window = 5

        # 3D array: (2, 4, 20) -> output (2, 20, 4, 4)
        data_3d = np.random.randn(2, 4, 20)
        result_3d = move_func(data_3d, window=window)
        assert result_3d.shape == (2, 20, 4, 4)

        # 4D array: (2, 3, 4, 20) -> output (2, 3, 20, 4, 4)
        data_4d = np.random.randn(2, 3, 4, 20)
        result_4d = move_func(data_4d, window=window)
        assert result_4d.shape == (2, 3, 20, 4, 4)

        # Verify correctness - each slice should match individual computation
        for i in range(2):
            single_result = move_func(data_3d[i], window=window)
            assert_allclose(result_3d[i], single_result, rtol=1e-10)",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,2.8453347280241004e-08,"The method is a test function that verifies the behavior of a rolling function over higher-dimensional arrays. It is well-structured, uses assertions to ensure the correctness of the output shapes, and checks the consistency of results. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained in the codebase."
survived,"def move_nancorrmatrix(a, window, min_count, out):
    """"""
    Moving window correlation matrix gufunc.

    For 2D input, correlates variables (rows) across observations (columns in the window).
    """"""
    n_vars = a.shape[0]
    n_obs = a.shape[1]
    min_count = max(min_count, 1)

    # Initialize running statistics
    sums = np.zeros(n_vars, dtype=a.dtype)
    sums_sq = np.zeros(n_vars, dtype=a.dtype)
    counts = np.zeros(n_vars, dtype=np.int64)

    # Initialize pairwise statistics
    prods = np.zeros((n_vars, n_vars), dtype=a.dtype)
    pair_counts = np.zeros((n_vars, n_vars), dtype=np.int64)

    for t in range(n_obs):
        # Remove old values when window slides
        if t >= window:
            for i in range(n_vars):
                old_val = a[i, t - window]
                if not np.isnan(old_val):
                    sums[i] -= old_val
                    sums_sq[i] -= old_val * old_val
                    counts[i] -= 1

                    # Update pairwise products
                    for j in range(n_vars):
                        old_val_j = a[j, t - window]
                        if not np.isnan(old_val_j):
                            prods[i, j] -= old_val * old_val_j
                            pair_counts[i, j] -= 1

        # Add new values
        for i in range(n_vars):
            new_val = a[i, t]
            if not np.isnan(new_val):
                sums[i] += new_val
                sums_sq[i] += new_val * new_val
                counts[i] += 1

                # Update pairwise products
                for j in range(n_vars):
                    new_val_j = a[j, t]
                    if not np.isnan(new_val_j):
                        prods[i, j] += new_val * new_val_j
                        pair_counts[i, j] += 1

        # Compute correlation matrix for current window
        for i in range(n_vars):
            for j in range(n_vars):
                if i == j:
                    # Diagonal is 1 when we have enough data for correlation
                    # Correlation requires at least 2 observations to compute variance
                    if counts[i] >= max(min_count, 2):
                        out[t, i, j] = 1.0
                    else:
                        out[t, i, j] = np.nan
                else:
                    # Compute correlation
                    n = pair_counts[i, j]
                    # Need at least 2 observations for correlation (to compute variance)
                    if n >= max(min_count, 2) and counts[i] >= 2 and counts[j] >= 2:
                        mean_i = sums[i] / counts[i]
                        mean_j = sums[j] / counts[j]

                        # Compute variances
                        var_i = sums_sq[i] / counts[i] - mean_i * mean_i
                        var_j = sums_sq[j] / counts[j] - mean_j * mean_j

                        # Compute covariance
                        cov = prods[i, j] / n - (sums[i] / counts[i]) * (
                            sums[j] / counts[j]
                        )

                        # Compute correlation
                        if var_i > 0 and var_j > 0:
                            corr = cov / np.sqrt(var_i * var_j)
                            # Clamp to [-1, 1] for numerical stability
                            out[t, i, j] = max(-1.0, min(1.0, corr))
                        else:
                            out[t, i, j] = np.nan
                    else:
                        out[t, i, j] = np.nan
",numbagg/moving_matrix.py,,1,6.023574641292144e-08,"The method 'move_nancorrmatrix' is a specialized function for computing a moving window correlation matrix, which is a common requirement in time series analysis and data processing. It handles NaN values, which is crucial for real-world data. The function is well-documented, and its logic is clear and efficient for its purpose. Such functions are often retained in codebases because they provide essential functionality for statistical analysis, especially in fields like finance, meteorology, and other domains dealing with time series data. Therefore, it is likely to be retained."
survived,"    def test_rolling_comparison_with_pandas(self, move_func, window):
        """"""Compare rolling functions with pandas.""""""
        np.random.seed(42)
        n_vars = 4
        n_obs = 20
        data = np.random.randn(n_vars, n_obs)

        # NumBagg result
        numbagg_result = move_func(data, window=window, min_count=window)

        # Pandas result - need to transpose for pandas (wants observations as rows)
        df = pd.DataFrame(data.T)
        if move_func == move_nancorrmatrix:
            pandas_result = df.rolling(window, min_periods=window).corr()
        else:
            pandas_result = df.rolling(window, min_periods=window).cov()

        # Compare each window
        for t in range(window - 1, n_obs):
            # Extract pandas matrix for this timepoint
            pandas_matrix = pandas_result.loc[t].values
            # Compare
            assert_allclose(numbagg_result[t], pandas_matrix, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMatrixFunctions,1,3.850741907939403e-09,"The method is a test function that compares the results of a custom rolling function with those of pandas' rolling functions. It is useful for ensuring the correctness of the custom implementation against a well-established library like pandas. Such test functions are crucial for maintaining code reliability and are typically retained in the codebase to ensure ongoing accuracy as the code evolves. Therefore, it is likely to be Survived."
survived,"def pandas_static_covmatrix(a):
    """"""Compute covariance matrix using pandas.""""""
    df = pandas_matrix_setup(a)
    return lambda: df.cov()
",numbagg/test/conftest.py,,1,1.955568070542584e-08,"The method `pandas_static_covmatrix` is a simple utility function that computes the covariance matrix of a given dataset using pandas. It is likely to be useful in data analysis tasks where covariance matrices are needed, such as in statistics or machine learning. The function is concise and leverages pandas' built-in capabilities, making it efficient and easy to use. Therefore, it is likely to be retained in the codebase."
survived,"    def test_perfect_correlation_consistency(self):
        """"""Test with perfectly correlated data.""""""
        np.random.seed(222)

        # Create perfectly correlated data
        n_obs = 15
        a1 = np.random.randn(n_obs)
        a2 = 2 * a1 + 1  # Perfect linear relationship

        alpha = 0.6

        # Compute using non-matrix function
        corr_nonmatrix = move_exp_nancorr(a1, a2, alpha=alpha)

        # Compute using matrix function
        data_matrix = np.array([a1, a2])
        corr_matrix_result = move_exp_nancorrmatrix(data_matrix, alpha=alpha)
        corr_from_matrix = corr_matrix_result[:, 0, 1]

        # They should match and approach 1.0
        assert_allclose(corr_nonmatrix, corr_from_matrix, rtol=1e-10)

        # For later time points with perfect correlation, should be close to 1.0
        final_corr = corr_from_matrix[-1]
        assert abs(final_corr - 1.0) < 1e-10
",numbagg/test/test_move_exp_matrix_consistency.py,TestMoveExpMatrixConsistency,1,1.522997951276035e-08,"The method is a unit test that checks the consistency of correlation calculations between two methods: a non-matrix function and a matrix function. It is well-structured, uses assertions to verify correctness, and tests a specific scenario of perfectly correlated data. Such tests are crucial for ensuring the reliability of statistical functions, especially in scientific computing. Therefore, it is likely to be retained as it serves an important purpose in validating the functionality of the code."
survived,"    def test_with_nans(self, func):
        """"""Test with NaN values.""""""
        data = np.array(
            [[1, 2, np.nan, 4], [2, 4, 6, np.nan], [np.nan, 1, 2, 3]], dtype=np.float64
        )
        alpha = 0.3
        result = func(data, alpha=alpha)

        # Check shape
        assert result.shape == (4, 3, 3)

        # Should handle NaN gracefully - check that we get some finite values
        assert np.any(np.isfinite(result))
",numbagg/test/test_move_exp_matrix.py,TestMoveExpMatrixFunctions,1,1.1253518384332553e-07,"The method 'test_with_nans' is a test function designed to verify the behavior of a function 'func' when it encounters NaN values in the input data. Handling NaN values is a common requirement in data processing and analysis, and testing for this is crucial to ensure robustness. The method includes assertions to check the shape of the result and to ensure that the function can handle NaN values gracefully by producing some finite values. This kind of testing is essential for maintaining code quality and reliability, especially in numerical computing contexts. Therefore, it is likely to be retained as part of a test suite."
survived,"    def test_bias_correction_edge_cases(self):
        """"""Test bias correction in edge cases.""""""
        # Create scenario where bias correction might be problematic
        data = np.array(
            [[1, np.nan, np.nan, 2], [3, np.nan, np.nan, 4]], dtype=np.float64
        )

        # Very low alpha means slow weight accumulation
        result = move_exp_nancovmatrix(data, alpha=0.01, min_weight=0.001)

        # Should handle the sparse data gracefully
        # Early time steps should be NaN due to insufficient weight
        assert np.isnan(result[0, 0, 1])
        assert np.isnan(result[1, 0, 1])

        # Final result should be valid if enough weight accumulated
        final_result = result[-1]
        if not np.isnan(final_result[0, 1]):
            # If not NaN, should be finite
            assert np.isfinite(final_result[0, 1])
",numbagg/test/test_move_exp_matrix_advanced.py,TestMoveExpMatrixAdvanced,1,5.3157849718487075e-08,"The method is a test case for a specific function, which is crucial for ensuring the correctness and reliability of the code. Test cases are generally retained to maintain code quality and prevent future regressions."
survived,"    def _format_text(self, data: Any) -> str:
        """"""Format as human-readable text""""""
        if isinstance(data, dict):
            return self._dict_to_text(data)
        elif isinstance(data, list):
            return self._list_to_text(data)
        else:
            return str(data)
",src/haconiwa/scan/formatter.py,OutputFormatter,1,7.582560422162384e-10,"The method _format_text is a utility function that formats different types of data (dictionaries, lists, and other types) into a human-readable string format. This kind of functionality is commonly needed in many applications for logging, displaying data to users, or preparing data for output. The method is versatile and can handle multiple data types, making it a useful component in a codebase. Therefore, it is likely to be retained as it provides essential functionality for data formatting."
survived,"    def setup_method(self):
        """"""Setup test environment""""""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.generator = ParallelYAMLGenerator(base_path=self.temp_dir)
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,2.0611536181902033e-09,"The method 'setup_method' is a common pattern used in testing frameworks like pytest to set up a test environment before each test method is run. It is essential for ensuring that each test has a clean and isolated environment, which is crucial for reliable and repeatable tests. The method is likely to be retained as it serves a critical role in the testing process."
survived,"    def test_scan_compare_command(self, runner, temp_model_dir):
        """"""Test the scan compare command""""""
        # Create another model for comparison
        model2_dir = temp_model_dir / ""models"" / ""test"" / ""gpt-4""
        model2_dir.mkdir(parents=True)
        
        config2 = {
            ""model_name"": ""gpt-4"",
            ""model_type"": ""language"",
            ""parameters"": ""175B""
        }
        with open(model2_dir / ""config.json"", ""w"") as f:
            json.dump(config2, f)
        
        result = runner.invoke(
            scan_app,
            [""compare"", ""o1-mini"", ""gpt-4"", ""--path"", str(temp_model_dir), ""--format"", ""json""]
        )
        
        assert result.exit_code == 0
        output = json.loads(result.stdout)
        assert 'capabilities' in output
",tests/test_scan/test_cli.py,TestScanCLI,1,2.8453347280241004e-08,"The method 'test_scan_compare_command' is a test function that verifies the functionality of a command-line interface (CLI) command. It creates a temporary model directory, sets up a configuration for a model, and then uses a runner to invoke a command to compare models. The test checks if the command executes successfully and if the output contains expected data. Such test functions are crucial for ensuring the reliability and correctness of software, especially in environments where CLI tools are used. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the quality of the software."
survived,"    def test_scan_model_with_options(self, runner, temp_model_dir):
        """"""Test scan model with various options""""""
        # Test with content inclusion
        result = runner.invoke(
            scan_app,
            [""model"", ""o1-mini"", ""--path"", str(temp_model_dir), ""--content"", ""--format"", ""yaml""]
        )
        
        assert result.exit_code == 0
        assert ""model_name: o1-mini"" in result.stdout
        
        # Test with no prefix stripping
        result = runner.invoke(
            scan_app,
            [""model"", ""o1-mini"", ""--path"", str(temp_model_dir), ""--no-strip-prefix""]
        )
        
        assert result.exit_code == 0
",tests/test_scan/test_cli.py,TestScanCLI,1,4.363462233903899e-09,"The method 'test_scan_model_with_options' is a test function that verifies the functionality of a command-line application by using a test runner to invoke commands and checking the results. Test functions are crucial for ensuring code reliability and are typically maintained or expanded rather than deleted. The method is well-structured, with clear assertions to validate expected outcomes, making it a valuable part of the test suite."
survived,"    def test_dynamic_concurrency_calculation(self):
        """"""Test dynamic max_concurrent calculation""""""
        scan_results = {
            'files': {f'file{i}.py': {} for i in range(20)}
        }
        
        config = self.generator.generate_from_scan_results(
            scan_results,
            action='refactor',
            max_files=20
        )
        
        # Should be min(5, max(1, 20//2)) = 5
        assert config['options']['max_concurrent'] == 5
        
        # Test with fewer files
        scan_results = {
            'files': {'file1.py': {}, 'file2.py': {}}
        }
        
        config = self.generator.generate_from_scan_results(
            scan_results,
            action='refactor',
            max_files=2
        )
        
        # Should be min(5, max(1, 2//2)) = 1
        assert config['options']['max_concurrent'] == 1
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,6.69158608681505e-10,"The method `test_dynamic_concurrency_calculation` is a unit test that verifies the behavior of a function responsible for calculating the `max_concurrent` option based on the number of files. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with dynamic calculations. This test method is well-structured, with clear assertions that validate the expected outcomes for different input scenarios. Given its importance in maintaining code quality and preventing regressions, it is likely to be retained in the codebase."
survived,"    def test_generate_prompt_for_file_by_category(self):
        """"""Test prompt generation based on file category""""""
        # Model file
        prompt = self.generator._generate_prompt_for_file(
            'src/models/user.py',
            'validation',
            None
        )
        assert 'validation methods' in prompt
        
        # API file
        prompt = self.generator._generate_prompt_for_file(
            'src/api/routes.py',
            'endpoints',
            None
        )
        assert 'RESTful CRUD endpoints' in prompt
        
        # Utils file
        prompt = self.generator._generate_prompt_for_file(
            'src/utils/helpers.py',
            'type_hints',
            None
        )
        assert 'type hints' in prompt
        
        # Config file
        prompt = self.generator._generate_prompt_for_file(
            'src/config/settings.py',
            'validation',
            None
        )
        assert 'configuration validation' in prompt
        
        # Service file
        prompt = self.generator._generate_prompt_for_file(
            'src/services/auth.py',
            'implementation',
            None
        )
        assert 'service functionality' in prompt
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,2.646573631904765e-09,"The method `test_generate_prompt_for_file_by_category` is a unit test designed to verify the functionality of the `_generate_prompt_for_file` method in different scenarios. It checks if the generated prompts contain specific keywords based on the file category. This is a typical and necessary part of testing in software development to ensure that the code behaves as expected. Since testing is a crucial aspect of maintaining code quality and reliability, this method is likely to be retained in the codebase."
survived,"    def test_extract_files_from_matches(self):
        """"""Test file extraction from match results""""""
        matches = {
            'model': [
                {'path': 'file1.py'},
                {'path': 'file2.py'}
            ],
            'api': [
                {'path': 'file3.py'},
                {'path': 'file4.py'}
            ]
        }
        
        files = self.generator._extract_files_from_matches(matches, max_files=3)
        
        assert len(files) == 3
        assert 'file1.py' in files
        assert 'file2.py' in files
        assert 'file3.py' in files
",tests/test_scan/test_generate_parallel.py,TestParallelYAMLGenerator,1,1.8189616842444243e-09,"The method `test_extract_files_from_matches` is a unit test for the function `_extract_files_from_matches`. It is well-structured and serves the purpose of verifying that the function correctly extracts a specified number of file paths from a given dictionary of matches. The test checks both the number of files extracted and the presence of specific files, which are essential aspects of the function's behavior. Since it is a useful test for ensuring the correctness of the `_extract_files_from_matches` function, it is likely to be retained."
survived,"    def _generate_usage_guide(self, model_info: Dict[str, Any]) -> str:
        """"""Generate a usage guide""""""
        lines = [
            f""# Usage Guide: {model_info['name']}"",
            f""\nGenerated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"",
            ""\n## Quick Start""
        ]
        
        # Basic usage
        lines.extend([
            ""\n### Basic Usage"",
            ""\n```python"",
            f""# Using {model_info['name']}"",
            """",
            ""# 1. Import necessary libraries"",
            ""import json"",
            ""from pathlib import Path"",
            """",
            ""# 2. Load model configuration"",
            ""config_path = Path('config.json')"",
            ""with open(config_path, 'r') as f:"",
            ""    config = json.load(f)"",
            """",
            ""# 3. Initialize and use model"",
            ""# Add framework-specific code here"",
            ""```""
        ])
        
        # Common use cases
        lines.extend([
            ""\n## Common Use Cases"",
            f""\nBased on the model structure, {model_info['name']} can be used for:""
        ])
        
        if 'llm' in str(model_info['categories']).lower():
            lines.extend([
                ""\n### Text Generation"",
                ""- Content creation"",
                ""- Code generation"",
                ""- Language translation"",
                ""- Text summarization""
            ])
        
        if 'vision' in str(model_info['categories']).lower():
            lines.extend([
                ""\n### Computer Vision"",
                ""- Image classification"",
                ""- Object detection"",
                ""- Image generation"",
                ""- Visual analysis""
            ])
        
        # Parameters
        if model_info['config']:
            lines.extend([
                ""\n## Model Parameters"",
                ""\nKey configuration options:""
            ])
            
            for key, value in list(model_info['config'].items())[:10]:
                lines.append(f""- `{key}`: {value}"")
        
        # Examples from files
        if model_info['examples']:
            lines.extend([
                ""\n## Code Examples"",
                ""\nExample files available:""
            ])
            
            for example in model_info['examples'][:3]:
                lines.append(f""\n### {example['name']}"")
                if example.get('content'):
                    lines.append(""```python"")
                    lines.append(example['content'][:300])
                    if len(example['content']) > 300:
                        lines.append(""# ... (truncated)"")
                    lines.append(""```"")
        
        # Tips
        lines.extend([
            ""\n## Tips and Tricks"",
            ""\n1. **Performance Optimization**:"",
            ""   - Use appropriate batch sizes"",
            ""   - Enable GPU acceleration if available"",
            ""   - Consider model quantization for deployment"",
            """",
            ""2. **Error Handling**:"",
            ""   - Validate input data formats"",
            ""   - Handle out-of-memory errors gracefully"",
            ""   - Implement timeout mechanisms"",
            """",
            ""3. **Best Results**:"",
            ""   - Preprocess input data appropriately"",
            ""   - Use recommended hyperparameters"",
            ""   - Fine-tune for specific use cases""
        ])
        
        return ""\n"".join(lines)
",src/haconiwa/scan/guide_generator.py,GuideGenerator,1,1.4166087846364157e-09,"The method `_generate_usage_guide` is a utility function that generates a comprehensive usage guide for a model based on the provided `model_info` dictionary. It is well-structured, covering various aspects such as basic usage, common use cases, model parameters, code examples, and tips. This method is likely to be useful for developers and users who need to understand how to effectively use a model. Its functionality is clear, and it provides valuable documentation support, which is often a critical component in software development. Therefore, it is likely to be retained in the codebase."
survived,"    def test_rolling_comparison_with_pandas(self, move_func, window):
        """"""Compare rolling functions with pandas.""""""
        np.random.seed(42)
        n_vars = 4
        n_obs = 20
        # Moving functions expect (obs, vars) format
        data = np.random.randn(n_obs, n_vars)

        # NumBagg result
        numbagg_result = move_func(data, window=window, min_count=window)

        # Pandas result - data is already in (obs, vars) format that pandas expects
        df = pd.DataFrame(data)
        if move_func == move_nancorrmatrix:
            pandas_result = df.rolling(window, min_periods=window).corr()
        else:
            pandas_result = df.rolling(window, min_periods=window).cov()

        # Compare each window
        for t in range(window - 1, n_obs):
            # Extract pandas matrix for this timepoint
            pandas_matrix = pandas_result.loc[t].values
            # Compare
            assert_allclose(numbagg_result[t], pandas_matrix, rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestMovingMatrices,1,3.653482080241728e-08,"The method is a test function that compares the results of a custom moving function with the results from pandas' rolling functions. It is useful for validating the correctness of the custom function against a well-established library like pandas. Such test functions are crucial for ensuring the reliability and accuracy of custom implementations, especially when dealing with statistical computations. Therefore, it is likely to be retained as part of the test suite to ensure ongoing correctness of the code."
survived,"    def test_constant_variables(self, func):
        """"""Test with constant (zero variance) variables.""""""
        data = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [1, 2, 3, 4]], dtype=np.float64)
        result = func(data)

        if func == nancorrmatrix:
            # Correlation with constant variables should be NaN
            assert np.isnan(result[0, 1])  # Two constants
            assert np.isnan(result[0, 2])  # Constant with non-constant
            assert result[2, 2] == 1.0  # Variable with itself
        else:
            # Covariance of constants should be 0
            assert result[0, 0] == 0.0
            assert result[1, 1] == 0.0
            assert result[0, 1] == 0.0
",numbagg/test/test_matrix_functions.py,TestCorrelationCovarianceMatrices,1,1.1861120010657661e-08,"The method `test_constant_variables` is a unit test designed to verify the behavior of a function when dealing with constant variables. It checks both correlation and covariance scenarios, ensuring that the function handles these edge cases correctly. Such tests are crucial for validating the robustness and correctness of statistical functions, especially in handling edge cases like constant variables. Therefore, this method is likely to be retained as it serves an important role in ensuring the reliability of the code."
survived,"    def test_simple_matrix(self, func, expected_diag):
        """"""Test simple 2x2 matrix calculation with exponential decay.""""""
        # Exponential moving functions expect (obs, vars) format
        data = np.array([[1, 2], [2, 4], [3, 6], [4, 8]], dtype=np.float64)
        alpha = 0.5
        result = func(data, alpha=alpha)

        # Check shape - should be (time, vars, vars)
        assert result.shape == (4, 2, 2)

        # Check diagonal at the end
        final_result = result[-1]
        if expected_diag is not None:
            assert_allclose(
                np.diag(final_result), [expected_diag, expected_diag], rtol=1e-10
            )
        else:
            # For covariance, just check diagonal is non-negative
            assert np.all(np.diag(final_result) >= 0)

        # Check symmetry at each time step
        for t in range(result.shape[0]):
            assert_allclose(result[t], result[t].T, rtol=1e-10)

        # For perfect linear relationship, correlation should be 1
        if func == move_exp_nancorrmatrix:
            # Check that off-diagonal elements approach 1 as we get more data
            assert_allclose(final_result, [[1.0, 1.0], [1.0, 1.0]], rtol=1e-10)
",numbagg/test/test_matrix_functions.py,TestExponentialMatrices,1,6.825604231969389e-08,"The method `test_simple_matrix` is a well-structured test function that checks the behavior of a matrix calculation function with exponential decay. It includes assertions for shape, diagonal values, symmetry, and correlation, which are essential for validating the correctness of the function being tested. The method is likely to be useful for ensuring the reliability of matrix operations in a codebase, especially in contexts involving time series or statistical computations. Therefore, it is unlikely to be deleted."
survived,"    def test_docker_detection(self, mock_which):
        """"""Test Docker executable detection.""""""

        # Test when Docker is available
        mock_which.return_value = ""/usr/bin/docker""
        assert shutil.which(""docker"") is not None

        # Test when Docker is not available
        mock_which.return_value = None
        assert shutil.which(""docker"") is None
",tests/unit/test_windows_compatibility.py,TestCrossPlatformDetection,1,1.0467401685178159e-08,"The method `test_docker_detection` is a unit test designed to verify the behavior of a function that checks for the presence of the Docker executable. It uses mocking to simulate different scenarios, which is a common practice in testing to ensure code reliability and correctness. Since testing is a crucial part of software development, especially for ensuring that code changes do not break existing functionality, this method is likely to be retained. It provides value by confirming that the system correctly identifies whether Docker is installed, which is important for applications that depend on Docker."
survived,"    def __enter__(self):
        """"""Context manager entry.""""""
        return self
",ocode_python/core/context_manager.py,ContextManager,1,4.6911638017642294e-08,"The method `__enter__` is a standard part of implementing a context manager in Python. It is used to define what happens when the context manager is entered, typically returning the context manager object itself. This is a fundamental part of the context management protocol, and removing it would break the functionality of any context manager that relies on it. Therefore, it is unlikely to be deleted."
survived,"    def test_run_with_uv_all_options(self, mock_run):
        """"""Test run_with_uv with all options combined.""""""
        mock_run.return_value = Mock(returncode=0)

        with pytest.raises(SystemExit) as exc_info:
            run_with_uv(
                ""server.py"",
                python_version=""3.10"",
                project=Path(""/workspace""),
                with_packages=[""pandas""],
                with_requirements=Path(""reqs.txt""),
                transport=""http"",
                port=9000,
                show_banner=False,
            )

        assert exc_info.value.code == 0

        cmd = mock_run.call_args[0][0]
        expected = [
            ""uv"",
            ""run"",
            ""--python"",
            ""3.10"",
            ""--project"",
            ""/workspace"",
            ""--with"",
            ""fastmcp"",
            ""--with"",
            ""pandas"",
            ""--with-requirements"",
            ""reqs.txt"",
            ""fastmcp"",
            ""run"",
            ""server.py"",
            ""--transport"",
            ""http"",
            ""--port"",
            ""9000"",
            ""--no-banner"",
        ]
        assert cmd == expected
",tests/cli/test_run_with_uv.py,TestRunWithUv,1,4.944450477491054e-09,"The method `test_run_with_uv_all_options` is a unit test that verifies the behavior of the `run_with_uv` function when all options are combined. It uses mocking to simulate the function's behavior and checks that the correct command is constructed and executed. This is a typical and necessary part of testing in software development to ensure that functions behave as expected under various conditions. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    def test_run_command_parsing_with_new_options(self):
        """"""Test run command parsing with new uv options.""""""
        command, bound, _ = app.parse_args(
            [
                ""run"",
                ""server.py"",
                ""--python"",
                ""3.11"",
                ""--with"",
                ""pandas"",
                ""--with"",
                ""numpy"",
                ""--project"",
                ""/path/to/project"",
                ""--with-requirements"",
                ""requirements.txt"",
            ]
        )

        assert command is not None
        assert bound.arguments[""server_spec""] == ""server.py""
        assert bound.arguments[""python""] == ""3.11""
        assert bound.arguments[""with_packages""] == [""pandas"", ""numpy""]
        assert bound.arguments[""project""] == Path(""/path/to/project"")
        assert bound.arguments[""with_requirements""] == Path(""requirements.txt"")
",tests/cli/test_cli.py,TestRunCommand,1,5.3157849718487075e-08,"The method is a unit test for a command-line argument parsing function. It is well-structured, with clear assertions checking the expected behavior of the parsing logic. The test ensures that the command and its arguments are correctly parsed and assigned, which is crucial for the functionality of the application. Since it is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Additionally, the method is specific to testing new options, indicating it is relevant to recent updates or features."
survived,"    def test_with_requirements_option(self):
        """"""Test --with-requirements option for all install commands.""""""
        commands_to_test = [
            [""claude-code"", ""server.py"", ""--with-requirements"", ""requirements.txt""],
            [""claude-desktop"", ""server.py"", ""--with-requirements"", ""requirements.txt""],
            [""cursor"", ""server.py"", ""--with-requirements"", ""requirements.txt""],
            [""mcp-json"", ""server.py"", ""--with-requirements"", ""requirements.txt""],
        ]

        for cmd_args in commands_to_test:
            command, bound, _ = install_app.parse_args(cmd_args)
            assert command is not None
            assert str(bound.arguments[""with_requirements""]) == ""requirements.txt""
",tests/cli/test_install.py,TestInstallCommandParsing,1,5.3157849718487075e-08,"The method 'test_with_requirements_option' is a test function that verifies the functionality of the '--with-requirements' option for various install commands. It is a useful test to ensure that the option is correctly parsed and applied across different commands. Test functions are generally important for maintaining code quality and ensuring that features work as expected. Therefore, it is unlikely to be deleted unless the feature it tests is removed or significantly changed."
survived,"    def get_checkpoint_path(self, filename: str) -> str:
        """"""Get full path for a checkpoint file.""""""
        return os.path.join(self.checkpoint_dir, filename)
",kura/v1/kura.py,CheckpointManager,1,3.581747929000289e-10,"The method `get_checkpoint_path` is a utility function that constructs a full file path by joining a directory path with a filename. This is a common and useful operation in many applications, especially those dealing with file management or configuration. The method is simple, clear, and serves a specific purpose without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def setup_checkpoint_dir(self) -> None:
        """"""Create checkpoint directory if it doesn't exist.""""""
        if not os.path.exists(self.checkpoint_dir):
            os.makedirs(self.checkpoint_dir)
            logger.info(f""Created checkpoint directory: {self.checkpoint_dir}"")
",kura/v1/kura.py,CheckpointManager,1,1.4166087846364157e-09,"The method 'setup_checkpoint_dir' is a utility function that ensures a directory exists for storing checkpoints. This is a common requirement in applications that involve saving state or progress, such as machine learning models or data processing tasks. The method is simple, effective, and serves a clear purpose, making it unlikely to be removed unless the entire checkpointing mechanism is refactored or removed. Therefore, it is likely to survive."
survived,"    def test_len_method(self):
        """"""Test __len__ method.""""""
        pipeline = LearnerPipeline(steps=[(""scale"", StandardScaler())], learner=MockLearner())
        assert len(pipeline) == 1  # Only transformer steps
",tests/test_learner_pipeline.py,TestLearnerPipelineProperties,1,2.0611536181902033e-09,"The method `test_len_method` is a unit test for the `__len__` method of a `LearnerPipeline` class. It checks if the length of the pipeline, which consists of a single transformer step, is correctly returned as 1. This is a straightforward and necessary test to ensure that the `__len__` method behaves as expected. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def test_pre_fitted_transformers(self):
        """"""Test pre-fitted transformers work correctly.""""""
        scaler = StandardScaler()
        X_train = np.array([[1, 2], [3, 4], [5, 6]])
        scaler.fit(X_train)  # Pre-fit

        mock_learner = MockLearner()
        pipeline = LearnerPipeline(steps=[(""scale"", scaler)], learner=mock_learner)

        X = np.array([[2, 3]])
        y = np.array([1])

        pipeline.partial_fit(X, y)

        # Should use pre-fitted scaler
        received_X, _, _ = mock_learner.partial_fit_calls[0]
        expected_X = scaler.transform(X)
        np.testing.assert_array_almost_equal(received_X, expected_X)
",tests/test_learner_pipeline.py,TestLearnerPipelineTransformers,1,1.444980317078884e-07,"The method is a unit test for a specific functionality, ensuring that pre-fitted transformers work correctly within a pipeline. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered, which is not indicated here."
survived,"    def policy(self, value):
        """"""Set the policy on the wrapped agent.""""""
        self._agent.policy = value
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,1,8.152020648014727e-09,"The method 'policy' is a simple setter method that assigns a value to the 'policy' attribute of the '_agent' object. Such methods are typically retained as they provide a clear and direct way to modify the state of an object, which is a common requirement in object-oriented programming. Unless there is a significant reason to remove it, such as a change in design pattern or redundancy, setter methods like this are usually kept in the codebase."
survived,"    def test_noncontextual_pipeline_decay_with_rate(self):
        """"""Test non-contextual pipeline decay with explicit rate.""""""
        arms = make_arms(range(3))
        agent = Agent(arms, ThompsonSampling())
        pipeline = NonContextualAgentPipeline([], agent)

        pipeline.decay(decay_rate=0.7)
",tests/test_agent_pipeline.py,TestCoverage,1,4.6911638017642294e-08,"The method `test_noncontextual_pipeline_decay_with_rate` is a unit test designed to verify the functionality of a specific feature, which is the decay mechanism in a non-contextual agent pipeline. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This method is likely part of a test suite that ensures the decay feature works as expected when a specific decay rate is applied. Since testing is an essential part of software development and maintenance, this method is likely to be retained to ensure ongoing code quality and functionality."
survived,"    def rng(self):
        """"""Get the random generator from the wrapped agent.""""""
        return self._agent.rng
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,3.160881453314576e-10,"The method 'rng' is a simple getter method that returns the random generator from a wrapped agent. Such methods are typically retained because they provide a clear and encapsulated way to access internal components of an object, promoting good object-oriented design practices. Unless there is a significant change in the design that makes this method redundant or unnecessary, it is likely to survive."
survived,"    def __init__(self, fitted=False):
        self.fitted = fitted
",tests/test_agent_pipeline.py,MockTransformer,1,1.955568070542584e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a default attribute 'fitted'. Constructors are essential for setting up initial states of objects, and this one is simple and clear in its purpose. Therefore, it is unlikely to be deleted."
survived,"    def test_transform_single_step(self):
        """"""Test transformation with single step.""""""
        steps = [(""double"", FunctionTransformer(lambda x: x * 2))]
        X = np.array([[1], [2], [3]])
        result = _transform_data(X, steps)
        expected = np.array([[2], [4], [6]])
        np.testing.assert_array_equal(result, expected)
",tests/test_agent_pipeline.py,TestTransformData,1,5.905303995456778e-10,"The method 'test_transform_single_step' is a unit test that verifies the functionality of a data transformation process using a single step. It is well-defined, concise, and serves a clear purpose in ensuring that the transformation logic works as expected. Such tests are crucial for maintaining code quality and reliability, especially in data processing pipelines. Therefore, it is likely to be retained in the codebase."
survived,"    def setup_method(self):
        """"""Set up test pipeline.""""""
        self.mock_learner = MockLearner()
        # Pre-fit the scaler for testing
        scaler = StandardScaler()
        scaler.fit(np.random.randn(100, 2))  # Fit on dummy data
        self.pipeline = LearnerPipeline(steps=[(""scale"", scaler)], learner=self.mock_learner)
",tests/test_learner_pipeline.py,TestLearnerPipelineInterface,1,5.3157849718487075e-08,"The method `setup_method` is a setup function commonly used in testing frameworks like pytest to prepare the test environment before each test method is executed. It initializes a mock learner and a pipeline with a pre-fitted scaler, which are likely used in subsequent test cases. This setup is crucial for ensuring that each test runs in a consistent and isolated environment, which is a best practice in testing. Therefore, the method is essential for the test suite and is unlikely to be deleted."
survived,"    def arm_to_update(self):
        """"""Get the arm to update from the wrapped agent.""""""
        return self._agent.arm_to_update
",bayesianbandits/pipelines/_agent.py,NonContextualAgentPipeline,1,5.905303995456778e-10,"The method 'arm_to_update' is a simple getter method that retrieves the 'arm_to_update' attribute from the '_agent' object. Such methods are typically retained because they encapsulate access to an object's properties, promoting encapsulation and potentially allowing for future modifications or additional logic without changing the interface. Unless there is a significant refactor or change in design that makes this method redundant, it is likely to survive."
survived,"    def test_recommendation_system_scenario(self, policy_class):
        """"""Test realistic recommendation system scenario.""""""
        # Create product arms
        product_arms = make_arms([f""product_{i}"" for i in range(5)])

        # Create agent with preprocessing
        agent = ContextualAgent(product_arms, policy_class(), random_seed=42)

        # Pre-fit scaler on historical user data
        scaler = StandardScaler()
        historical_users = np.random.randn(1000, 3)  # user features
        scaler.fit(historical_users)

        # Create pipeline with preprocessing
        steps = [(""user_scaler"", scaler)]
        pipeline = AgentPipeline(steps, agent)

        # Simulate user interactions
        n_users = 20
        user_contexts = np.random.randn(n_users, 3)

        # Pull recommendations
        recommendations = pipeline.pull(user_contexts)
        assert len(recommendations) == n_users
        assert all(rec.startswith(""product_"") for rec in recommendations)

        # Simulate rewards and update
        rewards = np.random.beta(2, 5, size=n_users)  # Realistic reward distribution
        pipeline.update(user_contexts, rewards)

        # Verify models were updated
        for arm in pipeline.arms:
            assert hasattr(arm.learner, ""coef_"")
",tests/test_agent_pipeline.py,TestIntegrationScenarios,1,2.3823698451773172e-07,"The method `test_recommendation_system_scenario` is a unit test designed to verify the functionality of a recommendation system. It includes creating product arms, simulating user interactions, pulling recommendations, and updating models based on rewards. This is a comprehensive test that ensures the recommendation system behaves as expected in a realistic scenario. Such tests are crucial for maintaining the integrity of the system, especially in production environments. Therefore, it is unlikely to be deleted as it serves an important role in validating the system's performance."
survived,"    def test_transform_not_fitted_error(self):
        """"""Test helpful error when transformer not fitted.""""""
        steps = [(""mock"", MockTransformer(fitted=False))]
        X = np.array([[1], [2]])

        with pytest.raises(RuntimeError) as exc_info:
            _transform_data(X, steps)

        assert ""not fitted"" in str(exc_info.value)
        assert ""mock"" in str(exc_info.value)
        assert ""FunctionTransformer"" in str(exc_info.value)
",tests/test_agent_pipeline.py,TestTransformData,1,3.2241866333029355e-08,"The method `test_transform_not_fitted_error` is a unit test designed to ensure that a specific error is raised when a transformer is not fitted before being used. This is a common and important test case in software development, especially in machine learning pipelines, to ensure robustness and proper error handling. The method is well-defined, uses a mock transformer to simulate the scenario, and checks for specific error messages, which are good practices in testing. Therefore, it is likely to be retained as it contributes to the reliability and maintainability of the codebase."
survived,"    def remove_arm(self, token: TokenType) -> None:
        """"""Remove an arm from the wrapped agent.""""""
        self._agent.remove_arm(token)
",bayesianbandits/pipelines/_agent.py,ContextualAgentPipeline,0,0.9890130576426459,"The method `remove_arm` is a simple wrapper around a call to `self._agent.remove_arm(token)`. It doesn't add any additional logic or functionality, which suggests it might be redundant if the `remove_arm` method can be directly accessed on `self._agent`. However, if this method is part of a public API or is intended to encapsulate the agent's functionality, it might be retained for consistency and abstraction purposes. Without more context on how this method is used or the design philosophy of the class, it's difficult to definitively say it will be deleted. However, given its simplicity and potential redundancy, there is a possibility it could be removed if not needed for abstraction."
survived,"    def _analyze_project_structure(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze the overall project structure.""""""
        structure = {""directories"": [], ""key_files"": [], ""patterns"": []}
        try:
            for root, dirs, files in os.walk(project_path):
                rel_path = os.path.relpath(root, project_path)
                if rel_path != ""."":
                    structure[""directories""].append(rel_path)
                for file in files:
                    if file in [""README.md"", ""setup.py"", ""package.json"", ""Cargo.toml"", ""pom.xml""]:
                        structure[""key_files""].append(os.path.join(rel_path, file))
        except Exception as e:
            structure[""error""] = str(e)
        return structure
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,6.69158608681505e-10,"The method `_analyze_project_structure` is likely to survive because it provides a useful utility for analyzing the structure of a project directory. It identifies key files and directories, which can be important for understanding the layout and configuration of a project. This functionality is often needed in development tools, build systems, or project management utilities. Additionally, the method handles exceptions gracefully, which is a good practice for robust code."
survived,"    def _generate_validation_criteria(self, requirements: str, analysis: Dict[str, Any]) -> str:
        """"""Generate validation criteria based on requirements and analysis.""""""
        return f""1. Implementation matches requirements: {requirements}\n2. Follows identified code patterns\n3. Maintains architectural consistency""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.8189616842444243e-09,"The method '_generate_validation_criteria' is a utility function that generates a string of validation criteria based on given requirements and analysis. It is a simple, clear, and useful method for ensuring that code meets specified standards. Such utility functions are often retained as they encapsulate specific logic that can be reused across different parts of a codebase. Additionally, the method is well-documented and follows a clear structure, which makes it easy to understand and maintain. Therefore, it is likely to be retained."
survived,"    def _identify_testing_frameworks(self, project_path: str) -> List[str]:
        """"""Identify testing frameworks in use.""""""
        return [""pytest"", ""unittest""]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,0,0.9999999950555496,"The method _identify_testing_frameworks is a simple utility function that returns a hardcoded list of testing frameworks. It does not perform any dynamic analysis or provide any flexibility to identify frameworks based on the project_path input. This lack of functionality and adaptability makes it less useful in a real-world scenario where projects may use different or multiple testing frameworks. Therefore, it is likely to be deleted or replaced with a more robust implementation."
survived,"def test_basic_functionality():
    """"""Test basic functionality of ContextAgent methods.""""""
    print(""\n Testing Basic Functionality..."")
    
    try:
        from praisonaiagents import create_context_agent
        
        context_agent = create_context_agent()
        
        # Test codebase analysis with current directory
        test_path = str(Path(__file__).parent)
        analysis = context_agent.analyze_codebase_patterns(test_path)
        assert isinstance(analysis, dict), ""analyze_codebase_patterns should return dict""
        print("" analyze_codebase_patterns works correctly"")
        
        # Test context document generation
        context_doc = context_agent.generate_context_document(
            project_path=test_path,
            requirements=""Test feature implementation""
        )
        assert isinstance(context_doc, str), ""generate_context_document should return string""
        assert len(context_doc) > 100, ""Context document should be substantial""
        print("" generate_context_document works correctly"")
        
        # Test validation loop creation
        validation = context_agent.create_validation_loop(
            implementation_requirements=""Test implementation"",
            success_criteria=[""Test passes"", ""Code works""]
        )
        assert isinstance(validation, dict), ""create_validation_loop should return dict""
        assert 'validation_steps' in validation, ""Should have validation_steps""
        print("" create_validation_loop works correctly"")
        
        # Test prompt enhancement
        enhanced = context_agent.enhance_prompt_with_context(
            base_prompt=""Test prompt"",
            context_data={""test"": ""data""}
        )
        assert isinstance(enhanced, str), ""enhance_prompt_with_context should return string""
        assert len(enhanced) > len(""Test prompt""), ""Enhanced prompt should be longer""
        print("" enhance_prompt_with_context works correctly"")
        
        # Test PRP generation
        prp = context_agent.generate_prp(
            feature_request=""Test feature"",
            context_analysis=analysis
        )
        assert isinstance(prp, str), ""generate_prp should return string""
        assert ""PRP"" in prp, ""Should contain PRP reference""
        print("" generate_prp works correctly"")
        
        return True
        
    except Exception as e:
        print(f"" Functionality test failed: {e}"")
        return False
",test_context_agent.py,,1,1.1253518384332553e-07,"The method 'test_basic_functionality' is a comprehensive test function that verifies the basic functionality of various methods in the 'ContextAgent' class. It includes assertions to ensure that each method returns the expected type and meets certain conditions. This kind of testing is crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as it provides value in the form of automated testing."
survived,"    def _extract_architecture_guidance(self, context_data: Dict[str, Any]) -> str:
        """"""Extract architecture guidance from context data.""""""
        return ""Follow established architectural patterns identified in the analysis.""
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,1.955568070542584e-08,"The method '_extract_architecture_guidance' is a simple utility function that extracts a specific piece of information from a given context. It is well-defined, has a clear purpose, and is likely to be useful in scenarios where architectural guidance needs to be consistently retrieved from context data. The method's name is descriptive, and it follows a common pattern of extracting information, which is a frequent requirement in software systems. Therefore, it is likely to be retained in the codebase."
survived,"    def _analyze_docstring_format(self, project_path: str) -> Dict[str, Any]:
        """"""Analyze docstring format conventions.""""""
        return {""format"": ""google"", ""completeness"": ""partial""}
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,5.211412485172657e-10,"The method '_analyze_docstring_format' is likely to survive because it provides a specific functionality that analyzes the format of docstrings, which is a common requirement in code quality and documentation standards. The method returns a dictionary with information about the format and completeness, which can be useful for further processing or reporting. Additionally, the method is well-defined with a clear purpose, making it a valuable part of a codebase that emphasizes documentation quality."
survived,"    def _generate_executable_tests(self, requirements: str, criteria: List[str]) -> List[Dict[str, str]]:
        """"""Generate executable test specifications.""""""
        return [{""type"": ""unit_test"", ""description"": f""Test {criterion}""} for criterion in criteria]
",src/praisonai-agents/praisonaiagents/agent/context_agent.py,ContextAgent,1,7.582560422162384e-10,"The method '_generate_executable_tests' is a utility function that generates a list of dictionaries, each representing a test specification based on the given criteria. It is a straightforward and useful method for creating test cases programmatically, which is a common requirement in software development. The method is well-defined, has a clear purpose, and is likely to be used in various testing scenarios. Therefore, it is unlikely to be deleted."
survived,"    def estimate_tokens_for_request(self, request: FenicCompletionsRequest) -> TokenEstimate:
        """"""Estimate the number of tokens for a request.

        Args:
            request: The request to estimate tokens for

        Returns:
            TokenEstimate: The estimated token usage
        """"""
        return self._core.estimate_tokens_for_request(request)
",src/fenic/_inference/openai/openai_batch_chat_completions_client.py,OpenAIBatchChatCompletionsClient,1,2.7894680920908113e-10,"The method 'estimate_tokens_for_request' is likely to survive because it provides a clear and necessary functionality: estimating the number of tokens for a request. This is a common requirement in systems that deal with token-based operations, such as APIs or services that charge based on usage. The method is also well-documented, indicating that it is intended for use and understanding by other developers. Additionally, it relies on a core component to perform the estimation, suggesting that it is part of a larger, possibly modular system, which further supports its continued relevance and utility."
survived,"    def __init__(self, params: list[str]) -> None:
        self.params = params
",dev/clint/src/clint/rules/docstring_param_order.py,DocstringParamOrder,1,1.3440409770490404e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, and this method is doing just that by initializing the 'params' attribute with a list of strings. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def _message(self) -> str:
        return ""Module loaded by `LazyLoader` must be imported in `TYPE_CHECKING` block.""",dev/clint/src/clint/rules/lazy_module.py,LazyModule,1,2.3355930333443423e-09,"The method _message is a private method (indicated by the underscore prefix) that returns a static string message. It is likely used internally within a class or module to provide a specific error or informational message. Since it serves a clear purpose and is not exposed as part of a public API, it is unlikely to be deleted unless the functionality it supports is removed or refactored. Therefore, it is predicted to survive."
survived,"    def id(self) -> str:
        return self._generated_id
",dev/clint/src/clint/rules/base.py,Rule,1,1.6052280526088547e-09,"The method 'id' is a simple getter method that returns a private attribute '_generated_id'. Such methods are typically retained in codebases as they provide controlled access to private attributes, which is a common practice in object-oriented programming to maintain encapsulation. Unless there is a significant reason to remove it, such as redundancy or a change in design that makes it obsolete, it is likely to survive."
survived,"    def name(self) -> str:
        """"""
        The name of this rule.
        """"""
        return self._CLASS_NAME_TO_RULE_NAME_REGEX.sub(""-"", self.__class__.__name__).lower()",dev/clint/src/clint/rules/base.py,Rule,1,6.69158608681505e-10,"The method 'name' is a simple utility function that converts the class name to a specific format. It is likely to be used frequently in the context where class names need to be converted to a standardized rule name format. Such utility methods are generally useful and are not typically removed unless they are replaced by a more efficient or comprehensive solution. Since the method is straightforward and serves a clear purpose, it is likely to survive."
survived,"    def example(cls) -> ""ModelVersionTagSetPayload"":
        return cls(
            name=""example_model"",
            version=""1"",
            key=""example_key"",
            value=""example_value"",
        )
",mlflow/webhooks/types.py,ModelVersionTagSetPayload,1,3.160881453314576e-10,"The method 'example' is a class method that returns an instance of 'ModelVersionTagSetPayload' with predefined attributes. This method is useful for creating a standard or default instance of the class, which can be helpful for testing, documentation, or as a template for further customization. Such methods are often retained in codebases because they provide a quick way to instantiate objects with known values, facilitating easier testing and understanding of the class's behavior. Therefore, it is likely to be Survived."
survived,"    def example(cls) -> ""ModelVersionCreatedPayload"":
        return cls(
            name=""example_model"",
            version=""1"",
            source=""runs:/abcd1234abcd5678/model"",
            run_id=""abcd1234abcd5678"",
            tags={""example_key"": ""example_value""},
            description=""An example model version"",
        )
",mlflow/webhooks/types.py,ModelVersionCreatedPayload,1,3.2241866333029355e-08,"The method 'example' is a class method that returns an instance of the class with predefined attributes. It serves as a useful utility for creating a sample or default instance of the class, which can be helpful for testing, documentation, or as a template for further development. Such methods are often retained in codebases because they provide a quick way to generate example data and ensure consistency in how instances are created. Therefore, it is likely to be retained."
survived,"            def w_NEW(vm: 'SPyVM', wop_cls: W_OpArg,
                     *args_wop: W_OpArg) -> W_OpImpl:
                # Support overloading based on argument count
                if len(args_wop) == 1:
                    # Point(x) -> Point(x, x)
                    @builtin_func('ext', 'new_point_single')
                    def w_new(vm: 'SPyVM', w_cls: W_Type, w_x: W_I32) -> W_Point:
                        return W_Point(w_x, w_x)
                    return W_OpImpl(w_new)
                else:
                    # Normal Point(x, y)
                    @builtin_func('ext', 'new_point')
                    def w_new(vm: 'SPyVM', w_cls: W_Type,
                              w_x: W_I32, w_y: W_I32) -> W_Point:
                        return W_Point(w_x, w_y)
                    return W_OpImpl(w_new)
",spy/tests/compiler/test_operator_call.py,TestCallOp.W_Point,1,3.850741907939403e-09,"The method 'w_NEW' is a factory function that creates instances of 'W_Point' based on the number of arguments provided. It supports overloading by checking the number of arguments and defining the appropriate function to create a 'W_Point'. This kind of functionality is essential for flexibility in object creation, especially in a dynamic language or environment where such patterns are common. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire system undergoes a significant redesign or the functionality is no longer needed."
survived,"    def test_oparg_properties(self):
        mod = self.compile(
        """"""
        from operator import OpArg

        def foo() -> tuple:
            arg = OpArg('blue', i32, 42)
            return (arg.color, arg.static_type, arg.blueval)
        """""")
        w_tup = mod.foo(unwrap=False)
        w_color, w_type, w_blueval = w_tup.items_w
        assert self.vm.unwrap_str(w_color) == 'blue'
        assert w_type is B.w_i32
        assert self.vm.unwrap_i32(w_blueval) == 42
",spy/tests/compiler/test_opimpl.py,TestOpImpl,1,8.152020648014727e-09,"The method `test_oparg_properties` is a test function that verifies the properties of an `OpArg` object. Test functions are generally important for ensuring code correctness and are usually retained unless they are redundant or replaced by more comprehensive tests. The method is well-structured and directly tests the expected behavior of the `OpArg` object, making it valuable for maintaining code quality."
survived,"    def test_definitions(self, mock_definitions):
        """"""Test the implementation of the definitions method""""""
        # Setup mock response
        mock_definitions.return_value = [
            (""GO:0005634"", ""A membrane-bounded organelle of eukaryotic cells in which chromosomes are housed and replicated."", {}),
            (""GO:0005635"", ""The double lipid bilayer enclosing the nucleus and separating its contents from the rest of the cytoplasm."", {})
        ]
        
        # Test definitions retrieval
        definitions = list(self.oi.definitions([""GO:0005634"", ""GO:0005635""], include_metadata=True))
        
        # Check that we got two definitions back with expected content
        self.assertEqual(len(definitions), 2)
        
        # Check first definition
        self.assertEqual(definitions[0][0], ""GO:0005634"")
        self.assertEqual(definitions[0][1], ""A membrane-bounded organelle of eukaryotic cells in which chromosomes are housed and replicated."")
        self.assertEqual(definitions[0][2], {}) # Empty metadata dict
        
        # Check second definition
        self.assertEqual(definitions[1][0], ""GO:0005635"")
        self.assertEqual(definitions[1][1], ""The double lipid bilayer enclosing the nucleus and separating its contents from the rest of the cytoplasm."")
        self.assertEqual(definitions[1][2], {}) # Empty metadata dict
        
        # Verify the mock was called correctly
        mock_definitions.assert_called_with([""GO:0005634"", ""GO:0005635""], include_metadata=True)
",tests/test_implementations/test_ols.py,TestOlsImplementation,1,1.275190675769241e-07,"The method `test_definitions` is a unit test designed to verify the functionality of a method that retrieves definitions. It uses a mock to simulate the behavior of the `definitions` method, checks the output against expected values, and ensures the mock was called with the correct parameters. This is a standard practice in software testing to ensure code reliability and correctness. Since it serves a critical role in maintaining code quality, it is unlikely to be deleted."
survived,"def test_api_key_logging():
    """"""Test that api_key provision is logged correctly.""""""
    from unittest.mock import patch, MagicMock

    # Mock the openai module
    with patch(""openai.OpenAI"") as mock_openai_class:
        mock_client = MagicMock()
        mock_openai_class.return_value = mock_client

        # Mock the from_openai import
        with patch(""instructor.from_openai"") as mock_from_openai:
            mock_instructor = MagicMock()
            mock_from_openai.return_value = mock_instructor

            # Mock logger
            with patch(""instructor.auto_client.logger"") as mock_logger:
                # Test that providing api_key triggers debug log
                from_provider(""openai/gpt-4"", api_key=""test-key"")

                # Check that debug was called with api_key message and length
                debug_calls = [
                    call
                    for call in mock_logger.debug.call_args_list
                    if ""API key provided"" in str(call) and ""length:"" in str(call)
                ]
                assert len(debug_calls) > 0, (
                    ""Expected debug log for API key provision with length""
                )

                # Verify the length is logged correctly (test-key is 8 characters)
                mock_logger.debug.assert_called_with(
                    ""API key provided for %s provider (length: %d characters)"",
                    ""openai"",
                    8,
                    extra={""provider"": ""openai"", ""operation"": ""initialize""},
                )",tests/test_auto_client.py,,1,4.6911638017642294e-08,"The method is a unit test that verifies the logging of API key provision, which is a critical aspect of ensuring security and traceability in applications that interact with external APIs. Logging such information is important for debugging and auditing purposes. The test uses mocking to simulate the behavior of external dependencies, which is a common practice in unit testing to isolate the functionality being tested. This method is likely to be retained as it ensures that the logging mechanism works as expected, which is crucial for maintaining the integrity and security of the application."
survived,"    def test_axis_parameter(self):
        # Test with different axes
        data = np.random.randn(3, 4, 5)

        # Default should correlate along last axis
        result_default = nancorrmatrix(data)
        assert result_default.shape == (3, 4, 4)

        # Test with axis=0
        result_0 = nancorrmatrix(data, axis=0)
        assert result_0.shape == (4, 5, 5)

        # Test with axis=1
        result_1 = nancorrmatrix(data, axis=1)
        assert result_1.shape == (3, 5, 5)
",numbagg/test/test_nancorrmatrix.py,TestNanCorrMatrix,1,1.493094675974231e-10,"The method 'test_axis_parameter' is a unit test designed to verify the functionality of the 'nancorrmatrix' function with different axis parameters. It is essential for ensuring that the function behaves correctly when correlating along different axes of a multi-dimensional array. Such tests are crucial for maintaining code reliability and are typically retained in the codebase to prevent future regressions. Therefore, it is likely to be Survived."
survived,"        def __get__(self, obj: Any, objtype: Any = None) -> Any:
            warnings.warn(
                ""`jaxls.FactorGraph` has been renamed `jaxls.LeastSquaresProblem`"",
                DeprecationWarning,
                stacklevel=2,
            )

            class FactorGraph:
                @staticmethod
                def make(*args, **kwargs):
                    from ._core import FactorGraph

                    if ""factors"" in kwargs:
                        kwargs[""costs""] = kwargs.pop(""factors"")

                    warnings.warn(
                        ""`jaxls.FactorGraph` has been renamed `jaxls.FactorGraph`"",
                        DeprecationWarning,
                        stacklevel=2,
                    )

                    return FactorGraph(*args, **kwargs)

            return FactorGraph
",src/jaxls/__init__.py,_FactorGraphDescriptor,1,3.5356257528032616e-05,"The method is using a deprecation warning to inform users about a renaming of a class, which suggests that the method is in a transitional phase. However, the method itself is not marked for removal, and it provides a backward compatibility layer for users who are still using the old class name. This indicates that the method is likely to survive until the transition is complete and users have adapted to the new class name."
survived,"    async def progress_tool(context: Context) -> None:
        await context.report_progress(progress=1, total=10, message=""test"")
",tests/server/middleware/test_middleware.py,,1,6.69158608681505e-10,"The method 'progress_tool' is an asynchronous function that reports progress using a 'context' object. This kind of functionality is often useful in applications where progress tracking is necessary, such as in long-running tasks or operations that require user feedback. The method is simple, but it serves a clear purpose and is likely to be part of a larger system where progress reporting is essential. Therefore, it is likely to be retained in the codebase."
survived,"    async def test_call_tool_on_parent_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.call_tool(""add"", {""a"": 1, ""b"": 2})

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""tools/call"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_call_tool"", times=1)

        assert nested_middleware.assert_called(times=0)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,1.1253518384332553e-07,"The method `test_call_tool_on_parent_server` is a test function that verifies the behavior of a server setup using the `FastMCP` framework. It checks if the `recording_middleware` is called the expected number of times and with the correct parameters when a tool is called on the parent server. This kind of test is crucial for ensuring that the middleware behaves correctly in a nested server setup. Since testing is an essential part of software development to ensure code reliability and correctness, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly changed."
survived,"    def assert_not_called(self, hook: str | None = None, method: str | None = None):
        """"""Assert that a hook was not called.""""""
        calls = self.get_calls(hook=hook, method=method)
        assert len(calls) == 0, f""Expected {hook!r} to not be called""
        return True
",tests/server/middleware/test_middleware.py,RecordingMiddleware,1,2.646573631904765e-09,"The method 'assert_not_called' is a utility function that checks if a specific hook or method was not called. This is a useful feature for testing and debugging, ensuring that certain parts of the code are not executed when they shouldn't be. Such methods are commonly used in test suites to verify the behavior of code, and they are generally retained unless there is a significant change in the testing framework or strategy. Therefore, it is likely to survive."
survived,"        async def log_tool(context: Context) -> None:
            await context.info(message=""test log"")
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,1.955568070542584e-08,"The method 'log_tool' is a simple asynchronous function that logs a message using the 'context.info' method. It is a utility function that can be useful for debugging or monitoring purposes. Since logging is a common requirement in many applications for tracking and diagnosing issues, this method is likely to be retained. It doesn't have any complex logic or dependencies that would make it obsolete or unnecessary."
survived,"    async def _list_resources(self, apply_middleware: bool = True) -> list[Resource]:
        """"""
        List all available resources.
        """"""

        if (resources := self._cache.get(""resources"")) is self._cache.NOT_FOUND:
            resources: list[Resource] = []

            # iterate such that new mounts overwrite older ones
            for mounted_server in self._mounted_servers:
                try:
                    if apply_middleware:
                        server_resources = (
                            await mounted_server.server._middleware_list_resources()
                        )
                    else:
                        server_resources = await mounted_server.server._list_resources()
                    # Apply prefix to each resource key if prefix exists
                    if mounted_server.prefix:
                        for resource in server_resources:
                            resource = resource.with_key(
                                add_resource_prefix(
                                    resource.key,
                                    mounted_server.prefix,
                                    self.resource_prefix_format,
                                )
                            )
                            resources.append(resource)
                    else:
                        resources.extend(server_resources)
                except Exception as e:
                    logger.warning(
                        f""Failed to get resources from mounted server '{mounted_server.prefix}': {e}""
                    )
                    continue
            resources.extend(self._resource_manager.get_resources().values())
            self._cache.set(""resources"", resources)
        return resources
",src/fastmcp/server/server.py,FastMCP,1,6.348800075736417e-09,"The method '_list_resources' is a crucial part of the system as it aggregates resources from multiple servers, applies middleware if needed, and handles caching. It also includes error handling and logging, which are important for maintaining robustness and traceability. These features suggest that the method is well-designed and serves an essential function in the system, making it unlikely to be deleted."
survived,"    async def test_read_resource_on_nested_server(
        self,
        mcp_server: FastMCP,
        nested_mcp_server: FastMCP,
        recording_middleware: RecordingMiddleware,
        nested_middleware: RecordingMiddleware,
    ):
        mcp_server.mount(nested_mcp_server, prefix=""nested"")

        async with Client(mcp_server) as client:
            await client.read_resource(""resource://nested/test"")

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""resources/read"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_read_resource"", times=1)

        assert nested_middleware.assert_called(times=3)
        assert nested_middleware.assert_called(method=""resources/read"", times=3)
        assert nested_middleware.assert_called(hook=""on_message"", times=1)
        assert nested_middleware.assert_called(hook=""on_request"", times=1)
        assert nested_middleware.assert_called(hook=""on_read_resource"", times=1)
",tests/server/middleware/test_middleware.py,TestNestedMiddlewareHooks,1,3.3982678079468468e-09,"The method is a test function that verifies the behavior of a nested server setup using middleware. It checks if the middleware is called the expected number of times and with the correct parameters. This kind of test is crucial for ensuring that the server and middleware interactions are functioning as intended. Since testing is an essential part of software development to maintain code quality and reliability, this method is likely to be retained."
survived,"    async def handle_progress(
        progress_token: str | int,
        progress: float,
        total: float | None,
        message: str | None,
    ):
        print(""HI"")
",tests/server/middleware/test_middleware.py,,1,2.1024340680345882e-07,"The method 'handle_progress' is an asynchronous function that takes in parameters related to progress tracking, such as a token, progress value, total value, and an optional message. The function currently only prints 'HI', which suggests it might be a placeholder or a stub for future implementation. However, the method signature is well-defined and could be useful for handling progress updates in an asynchronous context. Given that it is likely a placeholder, it might be retained for future development where actual progress handling logic will be implemented. Therefore, it is more likely to survive."
survived,"    async def test_read_resource(
        self, mcp_server: FastMCP, recording_middleware: RecordingMiddleware
    ):
        async with Client(mcp_server) as client:
            await client.read_resource(""resource://test"")

        assert recording_middleware.assert_called(times=3)
        assert recording_middleware.assert_called(method=""resources/read"", times=3)
        assert recording_middleware.assert_called(hook=""on_message"", times=1)
        assert recording_middleware.assert_called(hook=""on_request"", times=1)
        assert recording_middleware.assert_called(hook=""on_read_resource"", times=1)
",tests/server/middleware/test_middleware.py,TestMiddlewareHooks,1,5.905303995456778e-10,"The method 'test_read_resource' is a test function that verifies the behavior of a system by asserting that certain middleware hooks are called the expected number of times. This is a typical pattern in testing to ensure that the system behaves as expected under certain conditions. Since testing functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def compile(query: str, target: str = None) -> str:
    """"""
    Compile a Wvlet query into SQL.
    
    Args:
        query (str): The Wvlet query to compile.
        target (str): Optional target database (e.g., 'trino', 'duckdb').
    
    Returns:
        str: The compiled SQL query.
    
    Raises:
        ValueError: If the compilation fails.
    """"""
    compiler = WvletCompiler(target=target)
    return compiler.compile(query)",sdks/python/wvlet/__init__.py,,1,3.160881453314576e-10,"The method 'compile' is likely to survive because it provides a clear and useful functionality of converting a Wvlet query into an SQL query, which is a common requirement in data processing and database management tasks. The method is well-documented, specifying its purpose, arguments, return type, and potential exceptions, which indicates good software engineering practices. Additionally, it uses a specific compiler class 'WvletCompiler', suggesting that it is part of a larger framework or library, making it integral to the system's functionality."
deleted,"def get_git_version():
    """"""Get the current version from Git tags or fallback to 'latest'.""""""
    try:
        # Check if current HEAD matches any tag (exact release)
        result = subprocess.run(
            [""git"", ""tag"", ""--points-at"", ""HEAD""],
            capture_output=True,
            text=True,
            cwd=os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        )
        if result.returncode == 0 and result.stdout.strip():
            tags = result.stdout.strip().split('\n')
            # Prefer semantic version tags
            for tag in tags:
                if tag.startswith('v') and len(tag.split('.')) >= 3:
                    return tag[1:]  # Remove 'v' prefix
            # Fallback to first tag
            return tags[0][1:] if tags[0].startswith('v') else tags[0]
    except (subprocess.SubprocessError, FileNotFoundError):
        pass

    try:
        # Get the latest semantic version tag for development builds
        result = subprocess.run(
            [""git"", ""tag"", ""--list""],
            capture_output=True,
            text=True,
            cwd=os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        )
        if result.returncode == 0 and result.stdout.strip():
            # Filter for semantic version tags and get the latest
            tags = result.stdout.strip().split('\n')
            version_tags = []
            for tag in tags:
                if tag.startswith('v') and len(tag.split('.')) >= 3:
                    try:
                        # Check if it's a proper semantic version
                        parts = tag[1:].split('.')
                        if len(parts) >= 3 and all(part.isdigit() for part in parts[:3]):
                            version_tags.append(tag)
                    except (ValueError, IndexError):
                        continue
            
            if version_tags:
                # Sort by version number and get the latest
                version_tags.sort(key=lambda x: [int(part) for part in x[1:].split('.')[:3]])
                latest_tag = version_tags[-1]
                
                # Check if we're on the exact tag or ahead of it
                try:
                    result = subprocess.run(
                        [""git"", ""describe"", ""--tags"", ""--exact-match"", ""HEAD""],
                        capture_output=True,
                        text=True,
                        cwd=os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                    )
                    if result.returncode == 0:
                        # We're on an exact tag
                        return latest_tag[1:]
                except (subprocess.SubprocessError, FileNotFoundError):
                    pass
                
                # We're ahead of the latest tag, add dev suffix
                return f""{latest_tag[1:]}.dev""
    except (subprocess.SubprocessError, FileNotFoundError):
        pass
    
    # Default fallback
    return ""latest""
",docs/source/conf.py,,1,3.850741907939403e-09,"The method `get_git_version()` is a utility function that retrieves the current version of a project based on Git tags. This is a common requirement in software development for versioning and release management. The function is robust, handling various scenarios such as exact matches with tags, semantic versioning, and fallback options. It also includes error handling for subprocess and file-related exceptions. Such functionality is essential for projects that use Git for version control, making it unlikely to be deleted unless the project changes its versioning strategy or moves away from Git."
survived,"    def __init__(self):
        self.calls = 0
        self.node_id = ""X""
",tests/test_register_mesh_backoff.py,StubClient,1,8.76424914819242e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. It initializes instance variables, which are essential for setting up the initial state of an object. Therefore, it is unlikely to be deleted as it is necessary for the proper functioning of the class."
survived,"    def add_check(self, check: Callable[[str], Awaitable[str]]) -> None:
        """"""Register a custom check plugin.""""""

        self.checks.append(check)
",src/meta_agent/policy.py,PolicyChecker,1,1.6052280526088547e-09,"The method 'add_check' is a simple utility function that allows for the registration of custom check plugins by appending them to a list. This kind of functionality is common in plugin-based systems or frameworks where extensibility is a key feature. The method is straightforward, has a clear purpose, and is likely to be useful in contexts where dynamic behavior is needed. Therefore, it is likely to be retained in the codebase."
survived,"def test_settings_loads_dotenv(tmp_path, monkeypatch):
    env = tmp_path / "".env""
    env.write_text(""OPENAI_API_KEY=abc\nAGI_INSIGHT_BUS_PORT=1234\n"", encoding=""utf-8"")
    monkeypatch.chdir(tmp_path)
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    import src.utils.config as cfg
    importlib.reload(cfg)
    settings = cfg.Settings()
    assert settings.openai_api_key == ""abc""
    assert settings.bus_port == 1234
",tests/test_root_config.py,,1,4.1399375473943306e-08,"The method 'test_settings_loads_dotenv' is a unit test designed to verify that environment variables are correctly loaded from a .env file into the application's settings. This is a common and essential practice in software development to ensure that configuration settings are properly managed and can be easily changed without altering the code. The test uses temporary paths and monkeypatching to simulate different environments, which is a standard approach in testing. Given its role in ensuring the reliability and correctness of configuration loading, it is unlikely to be deleted unless the entire configuration management approach is changed."
survived,"    def test_sitecustomize_meta_importer(self) -> None:
        """"""Verify Jac modules importable without importing jaclang.""""""
        with tempfile.TemporaryDirectory() as tmpdir:
            Path(tmpdir, ""mymod.jac"").write_text(
                'with entry {print(""via meta"");}'
            )
            env = os.environ.copy()
            project_root = Path(__file__).resolve().parents[2]
            env[""PYTHONPATH""] = os.pathsep.join([str(project_root), tmpdir])
            proc = subprocess.run(
                [sys.executable, ""-c"", ""import mymod""],
                capture_output=True,
                text=True,
                cwd=tmpdir,
                env=env,
            )
            self.assertEqual(proc.returncode, 0, proc.stderr)
            self.assertEqual(proc.stdout.strip(), ""via meta"")",jac/jaclang/tests/test_language.py,JacLanguageTests,1,6.023574641292144e-08,"The method `test_sitecustomize_meta_importer` is a unit test designed to verify that a specific module can be imported correctly without importing another module. It uses a temporary directory to create a test module, sets up the environment, and runs a subprocess to test the import. The method includes assertions to check the expected output and return code, which are typical in test methods to ensure functionality works as intended. Since this is a test method, it is likely to be maintained as part of a test suite to ensure ongoing functionality, especially if the project is actively developed."
survived,"def main(directory: Path) -> int:
    service_worker = directory / ""service-worker.js""
    workbox = directory / ""lib"" / ""workbox-sw.js""
    if not service_worker.exists():
        raise FileNotFoundError(service_worker)
    if not workbox.exists():
        raise FileNotFoundError(workbox)
    expected = parse_expected_hash(service_worker)
    actual = compute_hash(workbox)
    if expected != actual:
        print(f""Hash mismatch: expected {expected}, got {actual}"")
        return 1
    return 0
",scripts/verify_workbox_hash.py,,1,2.1724399346070676e-10,The method is well-structured and performs a specific task of verifying the integrity of a service worker file by comparing its hash with an expected value. It includes error handling for missing files and provides informative output in case of a hash mismatch. These characteristics suggest that the method is useful and likely to be retained in the codebase.
survived,"async def test_shutdown_without_signal(monkeypatch: pytest.MonkeyPatch) -> None:
    loop = asyncio.get_running_loop()

    def boom(*_: object) -> None:
        raise NotImplementedError

    monkeypatch.setattr(loop, ""add_signal_handler"", boom)

    shutdown_event = asyncio.Event()
    dummy = DummyManager()

    async def factory() -> qm.QueueManager:
        return cast(qm.QueueManager, dummy)

    async def run_manager(manager: DummyManager, *args: object, **kwargs: object) -> None:
        await manager.run()

    def setup_shutdown_handlers_stub(
        manager: DummyManager, shutdown: asyncio.Event
    ) -> DummyManager:
        manager.shutdown = shutdown
        return manager

    monkeypatch.setattr(supervisor, ""run_manager"", run_manager)
    monkeypatch.setattr(supervisor, ""setup_shutdown_handlers"", setup_shutdown_handlers_stub)

    task = asyncio.create_task(
        supervisor.runit(
            factory,
            dequeue_timeout=timedelta(seconds=1),
            batch_size=1,
            restart_delay=timedelta(seconds=0),
            restart_on_failure=False,
            shutdown=shutdown_event,
            mode=types.QueueExecutionMode.continuous,
            max_concurrent_tasks=None,
            shutdown_on_listener_failure=False,
        )
    )

    await asyncio.sleep(0.1)
    shutdown_event.set()
    await task",test/windows/test_shutdown.py,,1,5.3157849718487075e-08,"The method `test_shutdown_without_signal` is a test function that uses the `monkeypatch` fixture from `pytest` to modify the behavior of certain functions and methods during the test. It is designed to test the behavior of a system when a shutdown is initiated without a signal. This is a common scenario that needs to be tested to ensure the system can handle shutdowns gracefully. The function is well-structured, uses asynchronous programming effectively, and is likely part of a larger test suite. Test functions like this are crucial for ensuring software reliability and are typically not deleted unless they are replaced by a more comprehensive test. Therefore, it is likely to be retained."
survived,"    def _check_allowed(self, diff: str) -> None:
        files = _files_from_diff(diff)
        for f in files:
            if not any(fnmatch.fnmatch(f, pat) for pat in self.allowed):
                raise ValueError(f""file '{f}' not allowed"")
",src/agents/self_improver_agent.py,SelfImproverAgent,1,2.4616969512093895e-10,"The method `_check_allowed` is likely to survive because it performs a crucial validation task by checking if files from a diff match a set of allowed patterns. This kind of validation is important for maintaining security and integrity in systems that handle file changes, ensuring that only permitted files are processed. The method is simple, clear, and serves a specific purpose, making it a valuable part of the codebase."
survived,"    def __init__(
        self,
        model: str = ""flux-schnell"",
        timeout: int = 60,
        proxies: dict = {},
    ):
        """"""Initialize your PixelMuse provider with custom settings! 

        Args:
            model (str): Which model to use (default: flux-schnell)
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
            logging (bool): Enable fire logging (default: True)
        """"""
        self.api_endpoint = ""https://www.pixelmuse.studio/api/predictions""
        self.headers = {
            ""accept"": ""*/*"",
            ""accept-language"": ""en-US,en;q=0.9"",
            ""content-type"": ""application/json"",
            ""origin"": ""https://www.pixelmuse.studio"",
            ""referer"": ""https://www.pixelmuse.studio/"",
            ""sec-ch-ua"": '""Chromium"";v=""134"", ""Not:A-Brand"";v=""24"", ""Google Chrome"";v=""134""',
            ""sec-ch-ua-mobile"": ""?0"",
            ""sec-ch-ua-platform"": '""Windows""',
            ""sec-fetch-dest"": ""empty"",
            ""sec-fetch-mode"": ""cors"",
            ""sec-fetch-site"": ""same-origin"",
            ""user-agent"": LitAgent().random(),
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.model = model
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""webp""
",webscout/Provider/TTI/pixelmuse.py,PixelMuseImager,1,3.0590235908148916e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and settings. The presence of this method is crucial for setting up the initial state of an object, and it is unlikely to be removed unless the entire class is being deprecated or refactored significantly. Additionally, the method includes parameters with default values, which provide flexibility and ease of use, further supporting its necessity and survival."
survived,"    def save(
        self,
        response: List[bytes],
        name: str = None,
        dir: str = os.getcwd(),
        filenames_prefix: str = """",
    ) -> List[str]:
        """"""Save your fire images! 

        Args:
            response (List[bytes]): Your generated images
            name (str, optional): Custom name (default: uses prompt)
            dir (str, optional): Where to save (default: current directory)
            filenames_prefix (str, optional): Add prefix to filenames

        Returns:
            List[str]: Where your images were saved
        """"""
        assert isinstance(response, list), f""Response gotta be a list, not {type(response)} ""
        name = self.prompt if name is None else name

        filenames = []
        count = 0
        if self.logging:
            logger.info(f""Saving {len(response)} images... "")

        for image_bytes in response:
            def complete_path():
                count_value = """" if count == 0 else f""_{count}""
                return os.path.join(dir, name + count_value + ""."" + self.image_extension)

            while os.path.isfile(complete_path()):
                count += 1

            absolute_path_to_file = complete_path()
            filenames.append(filenames_prefix + os.path.split(absolute_path_to_file)[1])

            with open(absolute_path_to_file, ""wb"") as fh:
                fh.write(image_bytes)

        if self.logging:
            logger.success(f""Images saved successfully! Check {dir} "")
        return filenames",webscout/Provider/TTI/huggingface.py,HFimager,1,1.444980317078884e-07,"The method 'save' is a utility function for saving images to disk, which is a common requirement in many applications dealing with image processing or generation. It includes features like custom naming, directory specification, and filename prefixing, which are useful for organizing saved files. Additionally, it handles file overwriting by appending a count to filenames, ensuring no data loss. These functionalities are generally useful and not easily replaced by a single library function, making it likely to be retained."
survived,"    def __init__(self, timeout: int = 60, proxies: dict = {}):
        """"""Initialize your MagicStudio provider with custom settings! """"""
        self.api_endpoint = ""https://ai-api.magicstudio.com/api/ai-art-generator""
        self.headers = {
            ""Accept"": ""application/json, text/plain, */*"",
            ""User-Agent"": agent.random(),
            ""Origin"": ""https://magicstudio.com"",
            ""Referer"": ""https://magicstudio.com/ai-art-generator/"",
            ""DNT"": ""1"",
            ""Sec-GPC"": ""1""
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""jpg""
",webscout/Provider/TTI/magicstudio.py,MagicStudioImager,1,2.3823698451773172e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes and settings. It sets up important configurations such as API endpoint, headers, session, proxies, and timeout, which are likely crucial for the functionality of the class. Therefore, it is unlikely to be deleted as it is fundamental to the class's operation."
survived,"    def __init__(self, timeout: int = 60, proxies: dict = None):
        """"""Initialize your FastFluxImager provider with custom settings

        Examples:
            >>> provider = FastFluxImager(timeout=120)
            >>> provider = FastFluxImager(proxies={""http"": ""http://proxy:8080""})

        Args:
            timeout (int): HTTP request timeout in seconds (default: 60)
            proxies (dict, optional): Proxy configuration for requests
            logging (bool): Enable/disable logging (default: True)
        """"""
        self.api_endpoint = ""https://api.fastflux.co/v1/images/generate""
        self.headers = {
            ""accept"": ""application/json, text/plain, */*"",
            ""content-type"": ""application/json"",
            ""origin"": ""https://fastflux.co"",
            ""referer"": ""https://fastflux.co/"",
            ""user-agent"": agent.random()
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        if proxies:
            self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
        self.logging = True
",webscout/Provider/TTI/fastflux.py,FastFluxImager,1,4.4508487281649027e-07,"The method is a constructor for a class, which is essential for initializing instances of the class with specific attributes and configurations. It sets up important parameters like API endpoint, headers, session, timeout, and proxies, which are crucial for the functionality of the class. Additionally, it includes a docstring with examples and argument descriptions, indicating that it is well-documented and likely used by other parts of the code or by users. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, timeout: int = 60, proxies: dict = {}, logging: bool = True):
        """"""Initialize your Nexra provider with custom settings! 

        Args:
            timeout (int): Request timeout in seconds (default: 60)
            proxies (dict): Proxy settings for requests (default: {})
            logging (bool): Enable fire logging (default: True)
        """"""
        self.url = ""https://nexra.aryahcr.cc/api/image/complements""
        self.headers = {
            ""Content-Type"": ""application/json"",
            ""Accept"": ""application/json"",
            ""User-Agent"": agent.random()
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.proxies.update(proxies)
        self.timeout = timeout
        self.prompt: str = ""AI-generated image - webscout""
        self.image_extension: str = ""png""
        self.logging = logging
        if self.logging:
            logger.info(""Nexra provider initialized! "")
",webscout/Provider/TTI/nexra.py,NexraImager,1,1.637377179507321e-07,"The method is a constructor for initializing an object with specific settings, which is a fundamental part of object-oriented programming. It sets up essential attributes like URL, headers, session, and logging, which are crucial for the functionality of the class. Such methods are typically retained unless there's a significant change in the class design or architecture."
survived,"    def create(*_a: object, **_k: object) -> None:
        raise FailError(""boom"")
",tests/test_llm_client_error_handling.py,,0,0.999983298584886,"The method 'create' is designed to immediately raise an exception (FailError) whenever it is called, without performing any other operations. This makes the method effectively unusable in its current form, as it cannot successfully complete any task or return a value. Unless this behavior is intentional for testing or specific error handling purposes, the method is likely to be deleted or refactored to serve a functional purpose."
survived,"def eval_monad_grad(klong, a):
    """"""

        a                                                     [Grad]

        Return a function that computes the numeric gradient of ``a``.

    """"""
    return KGLambda(lambda x, fn=a, k=klong: grad_of_fn(k, fn, x))
",klongpy/monads.py,,1,1.1861120010657661e-08,"The method `eval_monad_grad` is a utility function that returns a lambda function to compute the numeric gradient of a given function `a`. This is a common requirement in numerical computing and machine learning tasks where gradient calculations are essential for optimization algorithms. The method is well-defined, has a clear purpose, and is likely to be useful in contexts where automatic differentiation or gradient computation is needed. Therefore, it is likely to be retained in the codebase."
survived,"def eval_dyad_grad(klong, a, b):
    """"""

        ab                                                    [Grad]

        Compute the numeric gradient of the monadic function ``b`` at ``a``.

    """"""
    if isinstance(a, KGSym):
        orig = klong[a]

        def func(v):
            klong[a] = v
            try:
                return klong.call(KGCall(b, [v], 1)) if isinstance(b, (KGSym, KGLambda, KGFn, KGCall)) else b(v)
            finally:
                klong[a] = orig

        return numeric_grad(func, orig)
    else:
        return grad_of_fn(klong, b, a)
",klongpy/dyads.py,,1,2.998960815863541e-09,"The method `eval_dyad_grad` is a utility function that computes the numeric gradient of a function `b` at a point `a`. It handles different types of inputs and uses helper functions like `numeric_grad` and `grad_of_fn` to perform the computation. This functionality is essential in numerical computing and optimization tasks, which are common in many applications. The method is well-documented and seems to be part of a larger system that deals with symbolic computation or a domain-specific language (DSL). Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def test_scalar_grad_torch(self):
        klong = KlongInterpreter()
        klong['sin'] = lambda x: np.sin(x)
        klong['cos'] = lambda x: np.cos(x)
        klong('g::{sin(x)+x*x}')
        r = klong('g(3.14)')
        x = torch.tensor(3.14, dtype=torch.float64, requires_grad=True)
        f = torch.sin(x) + x * x
        f.backward()
        self.assertTrue(np.isclose(r, x.grad.item(), atol=1e-3))
",tests/test_autograd.py,TestAutograd,1,5.905303995456778e-10,"The method 'test_scalar_grad_torch' is testing the gradient calculation of a function using both a custom interpreter (KlongInterpreter) and PyTorch. It compares the results to ensure they are close, which is a valid and useful test for verifying the correctness of gradient computations. This kind of test is important for validating the integration of custom interpreters with established libraries like PyTorch. Therefore, the method is likely to be retained as it serves a clear purpose in testing the functionality of the code."
survived,"    def func() -> str:
        calls[""n""] += 1
        raise ValueError(""fail"")
",tests/test_retry_wrapper.py,,0,0.9999938558278723,"The method 'func' is designed to increment a counter in a dictionary 'calls' and then immediately raise a ValueError with the message 'fail'. This function does not perform any meaningful computation or return a useful result, as it always raises an exception. Without additional context or error handling, this function is not practical for use in most applications. Therefore, it is likely to be deleted unless it serves a specific purpose in a larger error-handling framework or testing scenario."
survived,"def _make_client() -> TestClient:
    return TestClient(cast(Any, api.app))
",tests/test_insight_endpoint.py,,1,2.3355930333443423e-09,"The method _make_client is a utility function that creates and returns a TestClient instance. This is a common pattern in testing frameworks to facilitate the testing of API endpoints. Since it is a helper function that aids in testing, it is likely to be retained as long as the testing framework and the API it tests are in use. Therefore, it is likely to survive."
survived,"def _setup_simulations() -> None:
    api._simulations.clear()
    api._simulations[""a""] = api.ResultsResponse(
        id=""a"",
        forecast=[api.ForecastPoint(year=1, capability=0.1)],
        population=None,
    )
    api._simulations[""b""] = api.ResultsResponse(
        id=""b"",
        forecast=[api.ForecastPoint(year=1, capability=0.9)],
        population=None,
    )
",tests/test_insight_endpoint.py,,1,8.592166611791576e-10,"The method `_setup_simulations` is a private helper function (indicated by the underscore prefix) that initializes or resets a set of simulations in the `api` object. It clears any existing simulations and sets up two new ones with specific forecast data. This kind of setup function is often used in testing or initialization phases of a program to ensure a consistent starting state. Since it serves a clear purpose in setting up data for simulations, it is likely to be retained unless the overall architecture or requirements change significantly. Therefore, the method is predicted to survive."
survived,"        async def json(self) -> dict:
            raise NotImplementedError(""aiohttp is required for network access"")
",src/meta_agent/services/telemetry_client.py,_DummyResponse,0,0.99999960721363,"The method is raising a NotImplementedError, indicating that it is not currently functional and requires additional implementation or dependencies (aiohttp) to work. This suggests that the method is not complete and may be subject to removal or replacement if it is not updated to provide the intended functionality. Therefore, it is likely to be deleted unless it is updated to fulfill its purpose."
survived,"    def load_dotenv(*_args, **_kwargs) -> None:
        """"""Fallback no-op for environments without python-dotenv.""""""
        return None
",src/meta_agent/services/llm_service.py,,1,3.2887477414614998e-06,"The method 'load_dotenv' is a no-op function, meaning it doesn't perform any operations and simply returns None. This is typically used as a placeholder or fallback in environments where the 'python-dotenv' package is not available. However, the presence of this method suggests that the codebase is designed to work in environments both with and without 'python-dotenv'. This method is likely to survive because it provides a clear and intentional fallback mechanism, ensuring that the code does not break in environments lacking 'python-dotenv'. Removing it could lead to errors or the need for additional conditional checks elsewhere in the code."
survived,"    def __init__(self, *_, **__):
        pass
",src/aiohttp/__init__.py,TCPConnector,0,0.999985261023967,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is typically not useful unless it's a placeholder or part of a larger framework where the arguments are handled elsewhere. Without additional context or functionality, it's likely to be removed or replaced with a more meaningful implementation."
survived,"    def first_markdown_cell(nb_path: Path) -> str:
        try:
            data = json.loads(nb_path.read_text(encoding=""utf-8""))
        except Exception:
            return """"
        for cell in data.get(""cells"", []):
            if cell.get(""cell_type"") == ""markdown"":
                src = cell.get(""source"", """")
                if isinstance(src, list):
                    src_text = """".join(src)
                else:
                    src_text = str(src)
                return src_text
        return """"
",scripts/verify_disclaimer_snippet.py,,1,7.582560422162384e-10,"The method 'first_markdown_cell' is a utility function that extracts the content of the first markdown cell from a Jupyter notebook file. This functionality is useful for various applications, such as documentation generation, content extraction, or data analysis. The method is well-structured, handles exceptions, and provides a clear return value. Given the increasing use of Jupyter notebooks in data science and education, this method is likely to remain relevant and useful. Therefore, it is predicted to survive."
survived,"    def __init__(self, default_direction: str = ""TB"") -> None:
        self.default_direction = default_direction
",src/meta_agent/ux/diagram_generator.py,DiagramGenerator,1,2.8453347280241004e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with default or specified values. The presence of a default parameter also suggests that this method is designed to provide flexibility in object creation. Therefore, it is unlikely to be deleted as it serves a critical role in the class's functionality."
survived,"    def success(self, message: str, *, level: int = 1) -> None:
        """"""Output a success message.""""""
        self._echo(message, fg=""green"", bold=True, level=level)
",src/meta_agent/ux/cli_output.py,CLIOutput,1,6.69158608681505e-10,"The method 'success' is a utility function designed to output a success message with specific formatting. It is a simple, clear, and useful method for providing feedback in a console application, especially if the application frequently needs to communicate success states to the user. The method is not overly complex, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"    def error(self, message: str, *, level: int = 1) -> None:
        """"""Output an error message.""""""
        self._echo(message, fg=""red"", bold=True, err=True, level=level)",src/meta_agent/ux/cli_output.py,CLIOutput,1,9.736200303530205e-10,"The method 'error' is a utility function designed to output error messages with specific formatting. It uses a private method '_echo' to handle the actual message display, which suggests that it is part of a larger system for handling console output or logging. The method is simple, clear, and provides a useful feature by allowing different levels of error messages. There is no indication that this method is redundant or poorly designed, and it likely serves a specific purpose in the codebase. Therefore, it is likely to be retained."
survived,"def test_menu(monkeypatch, capsys):
    inputs = iter([""3"", ""2""])
    monkeypatch.setattr(""builtins.input"", lambda _: next(inputs))
    inter = Interactive()
    result = inter.menu(""Pick one"", [""a"", ""b""])
    out = capsys.readouterr().out
    assert ""Invalid choice"" in out
    assert result == ""b""
",tests/ux/test_interactive.py,,1,6.825604231969389e-08,"The method 'test_menu' is a unit test function that uses the 'monkeypatch' and 'capsys' fixtures, which are commonly used in testing frameworks like pytest. The function is designed to test the 'menu' method of an 'Interactive' class, ensuring it handles invalid inputs correctly and returns the expected result. Since this is a test function, it is likely to be retained as part of the test suite to ensure the robustness of the 'menu' method. Test functions are crucial for maintaining code quality and are generally not deleted unless the functionality they test is removed or significantly changed."
survived,"    def test_none_library(self):
        os.environ[""ALPHA_KAFKA_BROKER""] = ""localhost:9092""
        orig = base_mod.KafkaProducer
        base_mod.KafkaProducer = None
        self.assertIsNone(base_mod._kafka_producer())
        base_mod.KafkaProducer = orig
        os.environ.pop(""ALPHA_KAFKA_BROKER"", None)
",tests/test_base_helpers.py,TestKafkaProducer,1,2.2159489282323004e-08,"The method `test_none_library` is a unit test designed to verify the behavior of a function when a certain library (KafkaProducer) is set to None. This is a common practice in testing to ensure that the code can handle scenarios where dependencies are not available. The method is useful for ensuring robustness and reliability of the code under test. Since testing for such edge cases is a crucial part of software development, it is likely that this method will be retained in the codebase to maintain test coverage and ensure the system behaves correctly in the absence of certain components."
survived,"    def test_env_seconds(self):
        from alpha_factory_v1.backend.agents.ping_agent import _env_seconds, _MIN_INTERVAL
        os.environ.pop(""X_INT"", None)
        self.assertEqual(_env_seconds(""X_INT"", 42), 42)
        os.environ[""X_INT""] = ""2""
        self.assertEqual(_env_seconds(""X_INT"", 10), _MIN_INTERVAL)
        os.environ[""X_INT""] = ""15""
        self.assertEqual(_env_seconds(""X_INT"", 1), 15)
        os.environ[""X_INT""] = ""bad""
        self.assertEqual(_env_seconds(""X_INT"", 7), 7)
        os.environ.pop(""X_INT"", None)
",tests/test_base_helpers.py,TestEnvSeconds,1,4.1399375473943306e-08,"The method 'test_env_seconds' is a unit test designed to verify the behavior of the '_env_seconds' function under various conditions. It checks the function's response to different environment variable settings and default values. Unit tests are crucial for ensuring code reliability and are typically retained to maintain code quality. Therefore, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_prom_metrics_none(self):
        orig_counter = base_mod.Counter
        orig_gauge = base_mod.Gauge
        base_mod.Counter = None
        base_mod.Gauge = None
        run, err, lat = base_mod._prom_metrics(""x"")
        self.assertIsNone(run)
        self.assertIsNone(err)
        self.assertIsNone(lat)
        base_mod.Counter = orig_counter
        base_mod.Gauge = orig_gauge
",tests/test_base_helpers.py,TestPromMetrics,1,1.8189616842444243e-09,"The method 'test_prom_metrics_none' is a unit test designed to verify the behavior of the '_prom_metrics' function when the 'Counter' and 'Gauge' are set to None. This is a valid test case to ensure that the function handles such scenarios gracefully. Unit tests are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, this method is likely to be retained as part of the test suite."
survived,"    def test_demo_shell_scripts(self) -> None:
        """"""All demo shell scripts should be executable and have shebangs.""""""
        base = Path(validate_demos.DEFAULT_DIR)
        for script in base.rglob(""*.sh""):
            with self.subTest(script=script.name):
                content = script.read_text(errors=""ignore"")
                self.assertTrue(content.startswith(""#!/""), f""{script} missing shebang"")
                self.assertTrue(script.stat().st_mode & 0o111, f""{script} not executable"")",tests/test_demos.py,TestDemos,1,1.3440409770490404e-08,"The method 'test_demo_shell_scripts' is a unit test that checks if shell scripts in a specified directory are executable and contain a shebang. This is a useful test to ensure that scripts are properly configured to run in a Unix-like environment. The method is likely to be retained because it enforces good practices for script files, ensuring they are ready to be executed without manual intervention. Such tests are valuable in maintaining code quality and preventing runtime errors."
survived,"def cli() -> None:
    """"""Run a short evolutionary loop and print the champion genome.""""""
    import argparse

    parser = argparse.ArgumentParser(description=""AI-GA Meta-Evolver demo"")
    parser.add_argument(""--gens"", type=int, default=5, help=""Generations to run"")
    args = parser.parse_args()

    from curriculum_env import CurriculumEnv

    evolver = MetaEvolver(env_cls=CurriculumEnv)
    evolver.run_generations(args.gens)
    print(evolver.latest_log())

    try:
        df = evolver.history_plot()
        print(df.tail())
    except Exception:  # pragma: no cover - pandas optional
        pass
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,,1,7.194132978569833e-09,"The method 'cli' is a command-line interface function that sets up an argument parser, initializes an evolutionary algorithm, and runs it for a specified number of generations. It also attempts to plot the history of the evolution if the necessary libraries are available. This function is useful for users who want to quickly run an evolutionary algorithm from the command line without needing to write additional code. The presence of error handling for optional features (like plotting) suggests that the function is designed to be robust and user-friendly. Given its utility and the fact that it is a complete and functional piece of code, it is likely to be retained in the codebase."
survived,"    def test_excluded_fields(self):
        """"""Test that fields marked with exclude=True are not included.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True)
            username: Mapped[str] = mapped_column()
            password_hash: Mapped[str] = mapped_column(info={""exclude"": True})
            secret_token: Mapped[str] = mapped_column(
                info={""exclude"": True, ""description"": ""Should not appear""}
            )

        UserEnrichModel = User.__enrich_model__()
        fields = UserEnrichModel.model_fields

        # Check included fields
        assert ""id"" in fields
        assert ""username"" in fields

        # Check excluded fields
        assert ""password_hash"" not in fields
        assert ""secret_token"" not in fields
",tests/test_sqlalchemy_integration.py,TestBasicModel,1,2.3355930333443423e-09,"The method 'test_excluded_fields' is a unit test designed to verify that fields marked with 'exclude=True' are not included in the model fields. This is a common and necessary test to ensure that sensitive or unnecessary data is not exposed or processed when it shouldn't be. The method is well-defined, serves a clear purpose, and is likely part of a larger test suite ensuring data integrity and security. Therefore, it is unlikely to be deleted as it plays a crucial role in maintaining the correctness and security of the application."
survived,"async def get_order_user(order_id: int, ctx: EnrichContext) -> UserEnrichModel | None:
    """"""Get the user who placed a specific order.""""""
    session_factory = ctx.request_context.lifespan_context[""session_factory""]
    async with session_factory() as session:
        order = await session.get(Order, order_id)
        if not order:
            return None

        # Load the user (SQLAlchemy will handle the join)
        await session.refresh(order, [""user""])
        user = order.user

        return UserEnrichModel(
            id=user.id,
            username=user.username,
            email=user.email,
            full_name=user.full_name,
            is_active=user.is_active,
            created_at=user.created_at,
        )
",examples/sqlalchemy_shop/app.py,,1,2.1724399346070676e-10,"The method is well-structured and serves a clear purpose: retrieving a user associated with a specific order. It uses asynchronous programming, which is beneficial for I/O-bound operations like database queries. The method also handles the case where the order does not exist by returning None, which is a good practice. Additionally, it uses SQLAlchemy for ORM, which is a widely used and efficient library for database operations in Python. Given these factors, the method is likely to be useful and efficient in its context, suggesting it will survive."
survived,"    def test_excluded_relationship(self):
        """"""Test that relationships marked with exclude=True are not included.""""""

        class Base(DeclarativeBase):
            pass

        class User(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True)
            username: Mapped[str] = mapped_column()
            secret_orders: Mapped[list[""Order""]] = relationship(
                info={""exclude"": True}, overlaps=""public_orders""
            )
            public_orders: Mapped[list[""Order""]] = relationship(
                info={""description"": ""Public orders""}, overlaps=""secret_orders""
            )

        class Order(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""orders""
            id: Mapped[int] = mapped_column(primary_key=True)
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))

        UserEnrichModel = User.__enrich_model__()
        fields = UserEnrichModel.model_fields

        # Check that excluded relationship is not included
        assert ""secret_orders"" not in fields
        assert ""public_orders"" in fields
",tests/test_sqlalchemy_integration.py,TestRelationships,1,5.60279640614594e-09,"The method `test_excluded_relationship` is a unit test designed to verify that relationships marked with `exclude=True` are not included in the enriched model fields. This is a specific functionality that needs to be tested to ensure the correct behavior of the `EnrichSQLAlchemyMixin` or similar functionality. Unit tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, this method is likely to be retained as part of the test suite to ensure the integrity of the codebase."
survived,"    def test_many_to_one_relationship(self):
        """"""Test many-to-one relationship conversion.""""""

        class Base(DeclarativeBase):
            pass

        class Order(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""orders""

            id: Mapped[int] = mapped_column(primary_key=True)
            user_id: Mapped[int] = mapped_column(ForeignKey(""users.id""))
            user: Mapped[""User""] = relationship(
                info={""description"": ""Customer who placed the order""}
            )

        class User(Base, EnrichSQLAlchemyMixin):
            __tablename__ = ""users""

            id: Mapped[int] = mapped_column(primary_key=True)
            username: Mapped[str] = mapped_column()

        OrderEnrichModel = Order.__enrich_model__()
        fields = OrderEnrichModel.model_fields

        # Check that user field exists and is a Relationship
        assert ""user"" in fields
        assert isinstance(fields[""user""].default, Relationship)
        assert fields[""user""].default.description == ""Customer who placed the order""

        # Type should be just ""UserEnrichModel"" (not List)
        assert ""UserEnrichModel"" in str(fields[""user""].annotation)
        assert ""List"" not in str(fields[""user""].annotation)
",tests/test_sqlalchemy_integration.py,TestRelationships,1,4.363462233903899e-09,"The method `test_many_to_one_relationship` is a unit test designed to verify the correct setup of a many-to-one relationship in a SQLAlchemy model. It checks that the relationship between `Order` and `User` is correctly defined and enriched. This is a fundamental aspect of ORM testing, ensuring that the database schema and relationships are correctly implemented. Such tests are crucial for maintaining the integrity of the data model and are unlikely to be removed unless the underlying data model changes significantly. Therefore, the method is likely to be retained."
survived,"def _str_tkn(text: str) -> int:
    # nave token estimate  1 token / 4 chars in English
    return max(1, math.ceil(len(text)/4))
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,,1,1.522997951276035e-08,"The method _str_tkn is a simple utility function that estimates the number of tokens in a given text based on its length. It uses a straightforward calculation, dividing the length of the text by 4, which is a common heuristic for estimating tokens in English text. This method is useful for applications that need to estimate token counts for processing text, such as in natural language processing tasks. The function is efficient, easy to understand, and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def emit(self, topic: str, msg: dict):
        A2ABus.publish(topic, msg)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Agent,1,3.850741907939403e-09,"The method 'emit' is a simple wrapper around the 'A2ABus.publish' function, which suggests it might be part of a larger system where such a method is necessary for abstraction or to maintain a consistent interface. This kind of method is often retained because it provides a layer of abstraction that can be useful for future changes or extensions, such as logging, error handling, or modifying the message before publishing. Therefore, it is likely to survive."
survived,"    def __init__(self,
                 endpoint: str = ""openai:gpt-4o"",
                 temperature: float = 0.2,
                 max_tokens: int = 2048,
                 context_len: int = 8192,
                 stream: bool = False,
                 timeout: int = 120,
                 **extra):
        self.endpoint = endpoint
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.context_len = context_len
        self.stream = stream
        self.timeout = timeout
        self.extra = extra
        self._backend, self._model = self._parse(endpoint)
        self._client = self._init_backend()
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,LMClient,1,3.653482080241728e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the instance variables and sets up the necessary state for the object. The use of default parameters and the ability to accept additional keyword arguments (via **extra) make it flexible and adaptable to different use cases. These characteristics are typical of a well-designed constructor, suggesting it is likely to be retained in the codebase."
survived,"def serve_lineage(path: pathlib.Path, port: int=8000):
    import flask, threading
    app = flask.Flask(""lineage-viewer"")

    @app.route(""/"")
    def idx():
        return VIEW_HTML

    @app.route(""/log"")
    def log():
        if not path.exists():
            return ""(no events yet)""
        return flask.escape(path.read_text(""utf-8""))

    th = threading.Thread(target=app.run, kwargs=dict(port=port, host=""0.0.0.0"", debug=False))
    th.daemon = True
    th.start()
    LOGGER.info(""Lineage viewer at http://localhost:%d"", port)
    return th
",alpha_factory_v1/demos/meta_agentic_agi/agents/agent_base.py,,1,6.69158608681505e-10,"The method 'serve_lineage' is a utility function that sets up a simple Flask web server to serve content from a specified path. It is useful for quickly viewing logs or other data in a web browser, which can be a common requirement during development or debugging. The method is straightforward, uses well-known libraries (Flask and threading), and provides a clear purpose. There is no indication that this method is deprecated or has any issues that would lead to its removal. Therefore, it is likely to survive."
survived,"    def _risk_assess(self, prompt:str, response:str) -> float:
        # toy heuristic: long responses & code carry more risk
        return min(1.0, 0.1 + 0.9*(len(response)/4000))
",alpha_factory_v1/demos/meta_agentic_agi_v3/agents/agent_base.py,Agent,1,8.152020648014727e-09,"The method '_risk_assess' is a simple heuristic function that calculates a risk score based on the length of a response. It is a straightforward implementation that doesn't rely on complex logic or external dependencies, making it easy to maintain and understand. Such methods are often retained because they serve a specific purpose without introducing unnecessary complexity. Additionally, the method is encapsulated and can be easily modified or extended if needed in the future. Therefore, it is likely to survive."
survived,"    def __init__(self,
                 name: str,
                 role: str = ""autonomousagent"",
                 provider: str | None = None,
                 objectives: Optional[ObjectiveWeights] = None,
                 lineage_dir: str | pathlib.Path = ""./lineage"",
                 rate_limit_tps: float = 3.0):
        self.name = name
        self.role = role
        self.id = f""{name}-{_sha(uuid.uuid4().hex)}""
        self.objectives = objectives or ObjectiveWeights()
        self.lm = LMClient(provider or os.getenv(""ALPHA_PROVIDER"", ""openai:gpt-4o""))
        self.tracer = LineageTracer(pathlib.Path(lineage_dir)/f""{self.id}.jsonl"")
        self.tracer.log(""init"", role=role, provider=self.lm.endpoint)
        GLOBAL_LIMITER._tps = rate_limit_tps
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,Agent,1,5.60279640614594e-09,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the entire class is being refactored or removed. Additionally, the method includes several parameters with default values, making it flexible and useful for various scenarios. The use of type hints and default values also suggests that the code is well-maintained and designed for clarity and usability. Therefore, it is likely to survive."
survived,"    def score(self, metrics: Dict[str,float]) -> float:
        return (
            self.latency * (1/ (1+metrics.get(""latency"",0))) +
            self.cost    * (1/ (1+metrics.get(""cost"",0))) +
            self.carbon  * (1/ (1+metrics.get(""carbon"",0))) +
            self.risk    * (1- metrics.get(""risk"",0))
        )
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,ObjectiveWeights,1,1.2501528648238603e-09,"The method 'score' is likely to survive because it provides a clear and useful functionality: calculating a score based on various metrics such as latency, cost, carbon, and risk. This method is well-structured, uses a dictionary to access metric values, and applies a formula that seems to be designed for a specific purpose, likely related to performance or efficiency evaluation. The use of weights and adjustments in the formula suggests it is tailored for nuanced scoring, which is often valuable in decision-making processes. Unless there is a significant change in requirements or a better alternative is developed, this method is likely to remain useful."
survived,"    def run(self, prompt: str, context: Optional[Iterable[Dict[str,str]]]=None, **kw) -> Dict[str,Any]:
        ctx: List[Dict[str,str]] = list(context or [])
        ctx.append({""role"":""user"", ""content"": prompt})
        t0 = time.perf_counter()
        output = self.lm.chat(ctx, **kw)
        latency = time.perf_counter()-t0
        tokens_in = _str_tkn(prompt)
        tokens_out = _str_tkn(output)
        cost = self._estimate_cost(tokens_in,tokens_out)
        carbon = cost*0.00015 # placeholder multiplier (avg kgCO2 per $ cloud)
        risk = self._risk_assess(prompt, output)
        metrics = dict(latency=latency, cost=cost, carbon=carbon, risk=risk)
        score = self.objectives.score(metrics)
        self.tracer.log(""run"", prompt=prompt[:120], response=output[:120], metrics=metrics, score=score)
        return {""response"": output, ""metrics"": metrics, ""score"": score}
",alpha_factory_v1/demos/meta_agentic_agi_v2/agents/agent_base.py,Agent,1,1.1032560311263802e-09,"The method 'run' is likely to survive because it appears to be a well-structured and comprehensive function that performs a series of important tasks. It processes a prompt, interacts with a language model, measures performance metrics such as latency, cost, and carbon footprint, assesses risk, and logs the results. These functionalities are crucial for applications that rely on language models, especially in contexts where performance and environmental impact are important considerations. Additionally, the method's use of logging and scoring suggests it is part of a larger system that values traceability and evaluation, which are important for maintaining and improving AI systems."
survived,"    def train_once(self)->float:
        if len(self.buffer)<CFG.train_batch: return 0.0
        obs,rew=zip(*random.sample(self.buffer, CFG.train_batch))
        obs_t=torch.tensor(obs, device=CFG.device, dtype=torch.float32)
        rew_t=torch.tensor(rew, device=CFG.device)
        _,v,_=self.net.initial(obs_t)
        loss=F.mse_loss(v.squeeze(),rew_t)
        self.opt.zero_grad(); loss.backward(); self.opt.step()
        return float(loss.item())
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo_v4.py,Learner,1,5.905303995456778e-10,"The method 'train_once' is a crucial part of a machine learning training loop, specifically for reinforcement learning or similar tasks. It handles the sampling of data, computation of loss, and optimization step, which are essential for model training. The method is well-structured, performs necessary operations like checking buffer size, sampling, tensor conversion, loss calculation, and optimization. These are standard and necessary steps in training routines, making it unlikely to be removed unless the entire training approach is changed. Therefore, the method is likely to survive."
survived,"def test_json_parser(tmp_path):
    json_file = tmp_path / ""data.json""
    json_file.write_text(json.dumps({""a"": 1, ""b"": 2}), encoding=""utf-8"")
    parser = JsonParser(file_path=str(json_file))
    result = parser.parse(file_path=str(json_file))
    assert result[""title""] == ""json""
    assert ""\""a\"""" in result[""content""]
    assert result[""lifecycle""][0][""life_metadata""][""source_file""] == str(json_file)
",tests/test_json_parser.py,,1,1.1861120010657661e-08,The method 'test_json_parser' is a test function that appears to be part of a test suite for a JSON parser. It is likely to survive because it serves a critical role in ensuring the functionality and correctness of the JSON parser implementation. Test functions are essential for maintaining code quality and are typically retained unless the functionality they test is deprecated or the testing framework changes significantly.
survived,"    def parse(self, file_path: str) -> MarkdownOutputVo:
        try:
            content = self.read_json_file(file_path)
            lifecycle = self.generate_lifecycle(
                source_file=file_path,
                domain=""Technology"",
                usage_purpose=""Documentation"",
                life_type=""LLM_ORIGIN"",
            )
            output_vo = MarkdownOutputVo(self.get_file_extension(file_path), content)
            output_vo.add_lifecycle(lifecycle)
            return output_vo.to_dict()
        except Exception as e:
            raise e",datamax/parser/json_parser.py,JsonParser,1,5.211412485172657e-10,"The method 'parse' is likely to survive because it is a well-structured function that performs a specific task of parsing a file and generating a lifecycle for it. It handles exceptions and returns a structured output, which suggests it is part of a larger system that relies on this functionality. Additionally, the method uses a custom object 'MarkdownOutputVo', indicating it is integrated into a specific application context, making it less likely to be removed without significant refactoring."
survived,"def test_root_serves_index() -> None:
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface import api_server

    client = TestClient(api_server.app)
    resp = client.get(""/"")
    assert resp.status_code == 200
    assert ""<div id=\""root\""></div>"" in resp.text",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_server_static.py,,1,2.699578619062706e-07,"The method 'test_root_serves_index' is a test function that checks if the root URL of an API server serves the expected index page. It uses a TestClient to make a GET request to the root URL and asserts that the response status code is 200 and that the response text contains a specific HTML element. This is a typical test case for web applications to ensure that the server is correctly serving the main page. Such test functions are crucial for maintaining the integrity of web applications, ensuring that changes do not break the expected behavior of serving the index page. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def eval(self):
        pass
",tests/test_multi_contributor.py,DummyModel,0,0.9999967112522585,"The method 'eval' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty. Without further context, it's difficult to determine its necessity. However, in many cases, such methods are eventually either implemented or removed if deemed unnecessary. Given the lack of implementation, it is more likely to be deleted unless there is a specific reason to keep it as a placeholder."
survived,"def test_csp_no_violations() -> None:
    dist = Path(__file__).resolve().parents[2] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist/index.html""
    )
    url = dist.as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            violations = []
            page.on(
                ""console"",
                lambda msg: violations.append(msg.text)
                if ""Content Security Policy"" in msg.text
                else None,
            )
            page.on(""pageerror"", lambda err: violations.append(str(err)))
            page.goto(url)
            page.wait_for_selector(""#controls"")
            assert not any(""Content Security Policy"" in v for v in violations)
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
",tests/security/test_csp.py,,1,2.5109990926928157e-08,"The method 'test_csp_no_violations' is a test function that checks for Content Security Policy (CSP) violations in a web page using Playwright. It is a useful test to ensure that the web application adheres to security policies, which is a critical aspect of web development. The function is well-structured, uses exception handling to skip the test if Playwright is not installed, and provides a clear assertion to check for CSP violations. Given the importance of security testing and the fact that this function is part of a test suite, it is likely to be retained."
survived,"    async def restart(self, bus: object, ledger: object) -> None:
        if self.task:
            self.task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self.task
        try:
            close = getattr(self.agent, ""close"")
        except AttributeError:
            pass
        else:
            close()
        self.agent = self.cls(bus, ledger)
        self.error_count = 0
        self.restarts += 1
        self.restart_streak += 1
        self.start(bus, ledger)
",alpha_factory_v1/backend/orchestrator_utils.py,AgentRunner,1,2.7894680920908113e-10,"The method 'restart' is likely to survive because it contains essential functionality for restarting a process or service. It handles task cancellation, error suppression, and reinitialization of an agent object, which are common and necessary operations in asynchronous programming. Additionally, it updates error and restart counters, indicating its role in maintaining the state of the application. These features suggest that the method is integral to the application's operation and is unlikely to be removed."
survived,"async def monitor_agents(
    runners: Dict[str, AgentRunner],
    bus: object,
    ledger: object,
    *,
    err_threshold: int = 3,
    backoff_exp_after: int = 3,
    on_restart: Callable[[AgentRunner], None] | None = None,
) -> None:
    """"""Restart crashed or stalled agents and apply exponential backoff.""""""
    while True:
        await asyncio.sleep(2)
        now = time.time()
        for r in list(runners.values()):
            needs_restart = False
            if r.task and r.task.done():
                needs_restart = True
            elif r.error_count >= err_threshold:
                needs_restart = True
            elif now - r.last_beat > r.period * 5:
                needs_restart = True
            if needs_restart:
                delay = random.uniform(0.5, 1.5)
                if r.restart_streak >= backoff_exp_after:
                    delay *= 2 ** (r.restart_streak - backoff_exp_after + 1)
                await asyncio.sleep(delay)
                await r.restart(bus, ledger)
                if on_restart:
                    on_restart(r)
",alpha_factory_v1/backend/orchestrator_utils.py,,1,1.725782769012759e-08,"The method 'monitor_agents' is a well-structured asynchronous function designed to monitor and restart agents based on certain conditions. It includes features like error threshold checking, exponential backoff for restarts, and a callback for when an agent is restarted. These features are useful for maintaining the stability and reliability of a system that relies on multiple agents. The method is likely to be retained as it provides essential functionality for managing agent processes effectively."
survived,"    def __init__(self, agent: object) -> None:
        self.cls: Callable[..., object] = type(agent)
        self.agent = agent
        self.period = getattr(agent, ""CYCLE_SECONDS"", 1.0)
        self.capabilities = getattr(agent, ""CAPABILITIES"", [])
        self.last_beat = time.time()
        self.restarts = 0
        self.task: asyncio.Task[None] | None = None
        self.error_count = 0
        self.restart_streak = 0
",alpha_factory_v1/backend/orchestrator_utils.py,AgentRunner,1,6.023574641292144e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes such as 'cls', 'agent', 'period', 'capabilities', 'last_beat', 'restarts', 'task', 'error_count', and 'restart_streak'. These attributes are likely crucial for the functionality of the class, especially if it involves managing an agent's lifecycle or behavior. Constructors are fundamental to object-oriented programming, and unless there is a significant reason to remove it (such as a complete redesign of the class structure), it is unlikely to be deleted."
survived,"def evaluate_agent(code: str) -> dict[str, float]:
    """"""Return accuracy, novelty SimHash and execution latency.""""""

    import random
    import time
    from hashlib import blake2b

    start = time.perf_counter()
    h = blake2b(code.encode(), digest_size=8).digest()
    simhash = int.from_bytes(h, ""big"")
    rng = random.Random(simhash & 0xFFFF)
    accuracy = 0.5 + rng.random() * 0.5
    latency_ms = (time.perf_counter() - start) * 1000
    return {
        ""accuracy"": accuracy,
        ""novelty_simhash"": float(simhash),
        ""latency_ms"": latency_ms,
    }
",src/eval/fitness.py,,1,6.348800075736417e-09,"The method `evaluate_agent` is a utility function that evaluates a given code string by calculating its accuracy, novelty SimHash, and execution latency. It uses standard libraries like `random`, `time`, and `hashlib`, which are commonly used for such tasks. The function is self-contained, does not rely on external dependencies, and provides useful metrics that could be valuable in various contexts, such as evaluating AI models or code snippets. Given its utility and the fact that it doesn't have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def test_blocks_insider_message() -> None:
    agent = _make_agent()
    env = messaging.Envelope(
        sender=""market"",
        recipient=""safety"",
        payload={""analysis"": ""buy AAPL tomorrow""},
        ts=0.0,
    )
    asyncio.run(agent.handle(env))
    assert agent.bus.published[-1][1].payload[""status""] == ""blocked""
",tests/test_codegen_safety.py,,1,8.592166611791576e-10,"The method `test_blocks_insider_message` is a unit test designed to verify that the agent correctly blocks a message with insider trading information. Unit tests are crucial for ensuring code reliability and correctness, especially in systems dealing with sensitive operations like trading. The presence of assertions and the use of a test framework suggest that this method is part of a test suite, which is typically maintained and not deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"    def test_multiple_backends_agents_created(self) -> None:
        settings = config.Settings(
            bus_port=0,
            offline=True,
            island_backends={""openai"": ""gpt-4o"", ""anth"": ""claude-opus""},
        )
        orch = orchestrator.Orchestrator(settings)
        self.assertEqual(orch.island_backends, settings.island_backends)
        # eight agents per island
        self.assertEqual(len(orch.runners), 16)
        islands = {name.split(""_"")[-1] if ""_"" in name else ""openai"" for name in orch.runners}
        self.assertIn(""openai"", islands)
        self.assertIn(""anth"", islands)
        for name, runner in orch.runners.items():
            if name.endswith(""_anth""):
                self.assertEqual(runner.agent.backend, ""claude-opus"")
            elif name.endswith(""_openai"") or name == ""planning"":
                # default island uses openai when island name 'openai'
                pass
",tests/test_island_backends.py,TestIslandBackends,1,2.998960815863541e-09,"The method 'test_multiple_backends_agents_created' is a unit test that verifies the correct creation and configuration of agents across multiple backends. It checks that the orchestrator is initialized with the correct settings, that the expected number of agents are created, and that they are assigned to the correct backends. This is a crucial part of ensuring the system's functionality and reliability, especially when dealing with multiple backends. Therefore, it is likely to be retained as it provides valuable validation for the system's behavior."
survived,"    def test_venv_pip_posix(self):
        with mock.patch.object(os, 'name', 'posix'):
            self.assertEqual(
                quickstart._venv_pip(Path('/tmp/venv')),
                Path('/tmp/venv/bin/pip')
            )
",alpha_factory_v1/tests/test_quickstart.py,QuickstartUtilsTest,1,1.1861120010657661e-08,"The method `test_venv_pip_posix` is a unit test designed to verify the behavior of the `_venv_pip` function in a POSIX environment. It uses mocking to simulate the POSIX environment and checks if the function returns the correct path to the pip executable within a virtual environment. This is a standard and useful test for ensuring cross-platform compatibility of the function, especially in environments where the path structure differs (e.g., Windows vs. POSIX). Since it serves a clear purpose in testing the functionality of the code, it is likely to be retained."
survived,"def main(base_dir: str = DEFAULT_DIR) -> int:
    failures = []
    for entry in os.listdir(base_dir):
        path = os.path.join(base_dir, entry)
        if os.path.isdir(path):
            if entry.startswith('.') or entry.startswith('__'):
                continue
            readme = os.path.join(path, ""README.md"")
            if not os.path.isfile(readme):
                failures.append(f""Missing README.md in {entry}"")
    if failures:
        for msg in failures:
            print(f""ERROR: {msg}"", file=sys.stderr)
        return 1
    print(""All demo directories contain README.md"")
    return 0
",alpha_factory_v1/demos/validate_demos.py,,1,4.0586521248284276e-10,"The method is a utility function that checks for the presence of README.md files in directories, which is a common requirement in many projects to ensure documentation is present. It provides clear feedback on missing files and returns an appropriate status code, making it useful for automation scripts or CI/CD pipelines. The method is well-structured, handles edge cases (like hidden directories), and uses standard libraries effectively. These factors suggest it is a useful and well-implemented function, likely to be retained in the codebase."
survived,"    def _simulate_worker(env_cls, archive, js: str):
        g = Genome.from_json(js)
        env = env_cls()
        obs_dim, act_dim = env.observation_space.shape[0], env.action_space.n
        net = EvoNet(obs_dim, act_dim, g).to(Device)
        obs, _ = env.reset()
        total, bc = 0.0, []
        for _ in range(env.genome.max_steps):
            with torch.no_grad():
                a = net(torch.tensor(obs, dtype=torch.float32, device=Device)).argmax().item()
            obs, rew, done, truncated, _ = env.step(a)
            total += rew; bc.append(obs)
            if done or truncated:
                break
        bc_vec = np.mean(bc, axis=0)
        if g.novelty_weight and archive:
            novelty = float(np.mean([np.linalg.norm(bc_vec - a) for a in archive]))
            total += g.novelty_weight * novelty
        return total, bc_vec
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,1.6052280526088547e-09,"The method '_simulate_worker' is a specialized function that simulates a worker in a reinforcement learning environment. It uses a genome to create a neural network, interacts with the environment, and calculates a reward based on the actions taken. The method also considers novelty by comparing the behavior characteristics with an archive, which is a common technique in evolutionary algorithms to encourage exploration. This method is likely part of a larger system for training or evaluating agents in a simulated environment. Given its specific functionality and integration with other components (like Genome, EvoNet, and the environment class), it is unlikely to be deleted unless the entire system is being refactored or replaced. Therefore, it is more likely to survive."
survived,"            def inc(self, *a, **k):
                self.calls.append(""inc"")
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest.DummyMetric,1,1.8189616842444243e-09,"The method 'inc' is a simple function that appends the string ""inc"" to a list called 'calls'. This method is likely part of a larger class where tracking method calls is necessary, possibly for logging or debugging purposes. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def test_metrics_setup_with_stubs(self):
        class DummyMetric:
            def __init__(self, *a, **k):
                self.calls = []
            def inc(self, *a, **k):
                self.calls.append(""inc"")
            def set(self, *a, **k):
                self.calls.append(""set"")
            def observe(self, *a, **k):
                self.calls.append(""observe"")

        prom_stub = SimpleNamespace(Counter=DummyMetric, Gauge=DummyMetric, Histogram=DummyMetric)
        with mock.patch.object(ping_agent, ""_Prom"", prom_stub):
            ping_agent.PingAgent.__bases__ = (NewAgentBase,)
            agent = ping_agent.PingAgent()
            agent.orchestrator = self.orc
            asyncio.run(agent.setup())
            self.assertIsInstance(agent._prom_ping_total, DummyMetric)
            asyncio.run(agent.step())
            self.assertIn(""inc"", agent._prom_ping_total.calls)
            self.assertTrue(any(c == ""observe"" for c in agent._prom_cycle_hist.calls))
",alpha_factory_v1/tests/test_ping_agent.py,PingAgentTest,1,5.60279640614594e-09,"The method `test_metrics_setup_with_stubs` is a unit test designed to verify the behavior of a system using stubs for metrics. Unit tests are generally crucial for ensuring code reliability and are often maintained or updated rather than deleted. The method uses a mock to replace parts of the system under test, which is a common practice in testing. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_env_seconds_bad_value(self):
        with mock.patch.dict(""os.environ"", {""X"": ""bad""}):
            val = ping_agent._env_seconds(""X"", 7)
        self.assertEqual(val, 7)
",alpha_factory_v1/tests/test_ping_agent.py,EnvSecondsTest,1,8.76424914819242e-08,"The method 'test_env_seconds_bad_value' is a unit test that checks the behavior of the '_env_seconds' function when an environment variable contains a non-integer value. The test uses 'mock.patch.dict' to temporarily set the environment variable 'X' to the string 'bad'. It then calls the '_env_seconds' function with 'X' and a default value of 7. The test asserts that the function returns the default value of 7 when the environment variable cannot be converted to an integer.

This test is important for ensuring that the '_env_seconds' function correctly handles invalid input by falling back to a default value. Such tests are crucial for robust error handling in software, making sure that the application behaves predictably even when encountering unexpected input.

Given its role in verifying the correct handling of edge cases, this test method is likely to be retained in the codebase."
survived,"def test_evaluate_logs(monkeypatch, tmp_path, caplog):
    fake_rc = MagicMock()
    fake_rc.execute_and_collect.return_value = CollectionResult(0, '', '', 0.1)
    fake_reporter = MagicMock()
    fake_reporter.generate_report.return_value = ''
    harness = EvaluationHarness(fake_rc, fake_reporter)
    with caplog.at_level('INFO', logger='meta_agent.evaluation.harness'):
        harness.evaluate(tmp_path)
    assert any('Starting evaluation for' in r.getMessage() for r in caplog.records)",tests/unit/test_evaluation_harness.py,,1,8.76424914819242e-08,"The method 'test_evaluate_logs' is a unit test function that uses the 'monkeypatch', 'tmp_path', and 'caplog' fixtures to test the 'evaluate' method of an 'EvaluationHarness' object. It checks if the logging mechanism is working correctly by asserting that a specific log message is present. This is a typical pattern in testing to ensure that certain actions are logged as expected. Since this is a test function and it is common to have such tests to verify logging behavior, it is likely to be retained in the codebase to ensure the reliability and correctness of the logging functionality."
survived,"def test_init_creates_default_modules(monkeypatch):
    fake_rc_cls = MagicMock()
    fake_rc = MagicMock()
    fake_rc_cls.return_value = fake_rc
    fake_reporter_cls = MagicMock()
    fake_reporter = MagicMock()
    fake_reporter_cls.return_value = fake_reporter
    monkeypatch.setattr(
        'meta_agent.evaluation.harness.ResultCollectionModule', fake_rc_cls
    )
    monkeypatch.setattr('meta_agent.evaluation.harness.ReportingModule', fake_reporter_cls)

    harness = EvaluationHarness()
    assert harness.result_collector is fake_rc
    assert harness.reporter is fake_reporter
",tests/unit/test_evaluation_harness.py,,1,1.637377179507321e-07,"The method `test_init_creates_default_modules` is a unit test that uses the `monkeypatch` fixture to replace certain classes with mock objects. This is a common practice in testing to isolate the unit of work and ensure that the test does not depend on the actual implementations of the classes being mocked. The test checks that the `EvaluationHarness` initializes its `result_collector` and `reporter` attributes with the mocked classes. This is a valid and useful test to ensure that the initialization logic of `EvaluationHarness` is working as expected. Therefore, the method is likely to be retained as it serves a clear purpose in the test suite."
survived,"        def fake_check_pkg(name: str) -> bool:
            # Required packages are always present
            if name in {""pytest"", ""prometheus_client""}:
                return True
            # Simulate all optional deps missing
            if name in preflight.OPTIONAL_DEPS:
                return False
            return True
",tests/test_preflight_optional_missing.py,TestPreflightOptionalMissing,1,6.348800075736417e-09,"The method `fake_check_pkg` is a utility function that simulates the presence or absence of certain packages. It is useful for testing purposes, especially in environments where you want to mock the presence of dependencies without actually installing them. The method is simple, clear, and serves a specific purpose in testing scenarios. Such utility functions are often retained in codebases to facilitate testing and development, especially when dealing with optional dependencies. Therefore, it is likely to survive."
survived,"def safe_current_wb_run_step() -> int | None:
    try:
        import wandb

        wandb_run = wandb.run
        if wandb_run is None:
            return None
    except ImportError:
        return None
    else:
        try:
            return int(wandb_run.step)
        except Exception:
            return None
",weave/trace/weave_client.py,,1,5.3157849718487075e-08,"The method `safe_current_wb_run_step` is designed to safely retrieve the current step of a Weights & Biases (wandb) run. It handles potential ImportErrors if the wandb library is not installed and also manages cases where the wandb run might not be initialized. This kind of defensive programming is useful in environments where the presence of external libraries or the state of their initialization cannot be guaranteed. Given the increasing use of wandb in machine learning projects for experiment tracking, this utility function is likely to be useful and relevant, especially in codebases where robustness against missing dependencies or uninitialized states is important. Therefore, it is likely to be retained in the codebase."
survived,"        def _fake_import(name: str, *args: object, **kwargs: object) -> object:
            if name == ""agents"":
                raise ModuleNotFoundError
            return orig_import_module(name, *args, **kwargs)
",tests/test_build_core_agent.py,TestBuildCoreAgent,0,0.9999999928058669,"The method `_fake_import` is a specialized function that overrides the import mechanism to raise a `ModuleNotFoundError` when attempting to import a module named 'agents'. This kind of function is typically used for testing purposes, to simulate the absence of certain modules. Such functions are often temporary and used in specific testing scenarios. Once the testing is complete or if the testing strategy changes, this method is likely to be removed. Therefore, it is predicted to be deleted."
survived,"def example4():
    x = fetchSomething()
    if x > 0:
        doPos(x)
    else:
        doNeg(x)",tests/rosetta/transpiler/Python/conditional-structures-4.py,,1,8.76424914819242e-08,"The method 'example4' is a simple function that calls 'fetchSomething' and then performs an action based on the result. It is a basic control flow structure that is commonly used in programming. Without additional context, such as whether 'fetchSomething', 'doPos', or 'doNeg' are deprecated or if there are any issues with the logic, there is no clear reason to delete this method. It appears to be a functional piece of code that serves a purpose, assuming the called functions are defined elsewhere and work as intended."
survived,"def example2(flag):
    if flag:
        None
    else:
        None",tests/rosetta/transpiler/Python/conditional-structures-2.py,,0,0.9999999895325983,"The method 'example2' is likely to be deleted because it does not perform any meaningful operation. Both branches of the if-else statement contain 'None', which means the function does not return any value or have any side effects. Such a function is typically considered redundant and unnecessary in a codebase."
survived,"def real(f):
    r = 0.0
    i = len(f) - 1
    while i > 0:
        r = (float(f[i][""b""])) // ((float(f[i][""a""])) + r)
        i = i - 1
    if len(f) > 0:
        r = r + (float(f[0][""a""]))
    return r
",tests/rosetta/transpiler/Python/continued-fraction.py,,1,1.6052280526088547e-09,"The method 'real' is a mathematical function that processes a list of dictionaries, each containing keys 'a' and 'b'. It performs a calculation that resembles a continued fraction, which is a valid mathematical operation. The function is well-structured, handles edge cases (like an empty list), and returns a float value. There is no indication of redundancy or lack of utility from the code itself, suggesting it serves a specific purpose in its context. Therefore, it is likely to be retained in the codebase."
survived,"    def eat(self):
        print(""mm, that "" + self.value + "" was good!"")
",tests/rosetta/transpiler/Python/constrained-genericity-3.py,PeelFirst,1,1.8189616842444243e-09,"The method 'eat' is a simple function that prints a message indicating that something was good. It uses an instance variable 'self.value', which suggests that it is part of a class where 'value' is defined. The method is straightforward and serves a clear purpose of providing feedback or a message related to consuming something. Unless there is a significant change in the requirements or the class design, such utility methods are often retained for their simplicity and clarity. Therefore, it is likely to survive."
survived,"def example8(b1, b2):
    if b1:
        None
    if b2:
        None",tests/rosetta/transpiler/Python/conditional-structures-8.py,,0,0.9999999950555496,"The method 'example8' is likely to be deleted because it does not perform any meaningful operations. It contains two conditional statements that check the values of 'b1' and 'b2', but both branches only contain the 'None' keyword, which effectively does nothing. This makes the method redundant and unnecessary in any codebase, leading to its likely removal."
survived,"    async def setup(self):
        self.iter = 0
",environments/sanskrit_poetry_env.py,SanskritPoetryEnv,1,1.6052280526088547e-09,"The method 'setup' is an asynchronous method that initializes an instance variable 'iter' to 0. This method is likely part of a larger class where 'iter' is used to track iterations or some form of counting. The method is simple and serves a clear purpose of initializing a variable, which is a common practice in object-oriented programming. Without additional context suggesting that 'iter' is unnecessary or that the method is redundant, it is reasonable to assume that this method will survive as it provides essential setup functionality for the class."
survived,"def test_available_scenarios() -> None:
    names = set(replay.available_scenarios())
    assert EXPECTED.issubset(names)
",tests/test_replay_scenarios.py,,1,2.646573631904765e-09,"The method `test_available_scenarios` is a unit test function that checks if a set of expected scenario names is a subset of the available scenarios returned by `replay.available_scenarios()`. This is a typical pattern in testing to ensure that certain expected conditions are met. The method is likely to survive because it serves a clear purpose in validating the functionality of the `available_scenarios` method, ensuring that it includes all expected scenarios. Such tests are crucial for maintaining code quality and reliability."
survived,"    def delete_stale_entries(self, stale_after: timedelta) -> None:
        """"""Delete cache entries older than ``stale_after``.""""""",src/cachier/cores/base.py,_BaseCore,1,6.69158608681505e-10,"The method `delete_stale_entries` is a utility function that is likely part of a caching system. Its purpose is to remove outdated entries from the cache, which is a common requirement in systems that manage temporary data storage. This method is essential for maintaining the efficiency and relevance of the cache by ensuring that old and potentially irrelevant data does not consume resources. Given its utility in managing cache data, it is unlikely to be deleted unless the entire caching mechanism is being removed or replaced. Therefore, the method will likely survive."
survived,"    def add(x):
        return x + 1
",tests/test_cleanup.py,,1,2.2159489282323004e-08,"The method 'add' is a simple utility function that increments a given number by 1. Such functions are often used in various programming scenarios, especially in educational contexts or as part of larger algorithms. Its simplicity and potential utility in different contexts suggest that it is likely to be retained in the codebase. Additionally, it does not have any apparent issues or redundancies that would necessitate its removal."
survived,"    def delete_stale_entries(self, stale_after: timedelta) -> None:
        """"""Remove stale entries from the Redis cache.""""""
        redis_client = self._resolve_redis_client()
        pattern = f""{self.key_prefix}:{self._func_str}:*""
        try:
            keys = redis_client.keys(pattern)
            threshold = datetime.now() - stale_after
            for key in keys:
                ts = redis_client.hget(key, ""timestamp"")
                if ts is None:
                    continue
                try:
                    ts_val = datetime.fromisoformat(ts.decode(""utf-8""))
                except Exception as exc:
                    warnings.warn(
                        f""Redis timestamp parse failed: {exc}"", stacklevel=2
                    )
                    continue
                if ts_val < threshold:
                    redis_client.delete(key)
        except Exception as e:
            warnings.warn(
                f""Redis delete_stale_entries failed: {e}"", stacklevel=2
            )",src/cachier/cores/redis.py,_RedisCore,1,1.6918979223288786e-10,"The method `delete_stale_entries` is likely to survive because it performs a necessary maintenance task of cleaning up stale entries in a Redis cache, which is crucial for managing memory and ensuring the cache does not grow indefinitely. The method is well-structured, handles exceptions, and provides warnings for potential issues, indicating it is a robust implementation. Such functionality is typically essential in systems that rely on caching for performance optimization."
survived,"    def __init__(self, *args, **kwargs):
        pass
",stubs/openai_agents/__init__.py,OpenAIAgent,0,0.9999999827421723,"The method is an empty constructor that does not perform any initialization or operations. In most cases, such a method is unnecessary and can be removed without affecting the functionality of the class. Therefore, it is likely to be deleted to clean up the code."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_selfheal_entrypoint_offline.py,,0,0.999999974890009,"The method 'fake_import' is designed to intercept import statements and specifically raise a ModuleNotFoundError when the module 'openai_agents' is attempted to be imported. This kind of functionality is often used for testing purposes, to simulate the absence of a module or to prevent certain modules from being imported during execution. Such methods are typically temporary and used in specific testing scenarios. Once the testing is complete or the specific need for blocking the import is no longer relevant, this method is likely to be removed to restore normal functionality. Therefore, it is predicted to be deleted."
survived,"def projection_from_json(path: str | Path) -> Dict[str, Dict[str, Any]]:
    """"""Return discounted cash flow projections loaded from ``path``.

    Each top-level key in the JSON file should map to a sector. The value must be
    a mapping accepted by :func:`delta_sector_to_dcf` with keys ``delta_revenue``,
    ``margin``, ``discount_rate`` and ``years``.
    """"""
    data = json.loads(Path(path).read_text(encoding=""utf-8""))
    results: Dict[str, Dict[str, Any]] = {}
    for sector, vals in data.items():
        if not isinstance(vals, dict):
            continue
        results[sector] = delta_sector_to_dcf(vals)
    return results",alpha_factory_v1/core/finance/wealth_projection.py,,1,7.582560422162384e-10,"The method 'projection_from_json' is a utility function that reads a JSON file and processes its contents to return a structured dictionary. It is well-documented, uses type hints, and performs a specific task that is likely useful in financial or data analysis applications. The function is also robust in handling incorrect data types by skipping non-dictionary values. These characteristics make it a valuable part of a codebase, suggesting it will be retained."
survived,"    def test_no_log_skips_directory(self) -> None:
        with tempfile.TemporaryDirectory() as home:
            env = os.environ.copy()
            env[""HOME""] = home
            env.pop(""ALPHA_CONVERSION_LEDGER"", None)
            result = subprocess.run(
                [sys.executable, STUB, ""--alpha"", ""skip"", ""--no-log""],
                capture_output=True,
                text=True,
                env=env,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            default_dir = Path(home) / "".aiga""
            self.assertFalse(default_dir.exists())
",tests/test_alpha_conversion_stub.py,TestAlphaConversionStub,1,6.348800075736417e-09,"The method 'test_no_log_skips_directory' is a unit test designed to verify that a specific directory is not created when certain command-line options are used. It uses a temporary directory to simulate the environment and checks the return code and the existence of a directory. This is a typical pattern for testing command-line tools and their side effects, ensuring that the '--no-log' option works as expected. Such tests are crucial for maintaining software quality and preventing regressions, so it is unlikely to be deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/join_multi.py,Auto1,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Customer,0,0.9999898700118929,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/left_join_multi.py,Item,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the keys of a dictionary or similar structure. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join.py,Supplier,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and could lead to confusion or errors when used. It is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/join_multi.py,Order,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_multi_join_sort.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/machine/x/python/group_by_join.py,Order,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"        def save(self, *args, **kwargs):
            pass
",tests/conftest.py,DummyDocxDocument,0,0.999999997664407,"The method 'save' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is either a placeholder for future implementation or is intentionally left empty because it is overridden in a subclass or not needed. Without additional context indicating future plans for this method, it is likely to be considered dead code and could be removed to clean up the codebase. Therefore, the method is more likely to be deleted."
survived,"    async def _fake_comment(_: float) -> str:
        return ""ok""
",tests/test_alpha_agi_business_3_v1.py,,0,0.9999999586006244,"The method `_fake_comment` is an asynchronous function that takes a float as an argument and returns a string ""ok"". However, the parameter is unused within the function, which might indicate that the function is not fully implemented or its purpose is not clear. Additionally, the function name `_fake_comment` suggests it might be a placeholder or a mock function used for testing purposes. If this function is part of a larger codebase, it might be removed if it is not serving any meaningful purpose or if it is replaced by a more complete implementation. Therefore, it is likely to be deleted."
survived,"def test_macro_entrypoint_launch(monkeypatch: pytest.MonkeyPatch) -> None:
    """"""ADK launch should be triggered when the env flag is set.""""""

    monkeypatch.setenv(""ALPHA_FACTORY_ENABLE_ADK"", ""1"")
    monkeypatch.setenv(""OPENAI_API_KEY"", ""dummy"")

    # Provide a minimal openai_agents stub when the package is absent
    if ""openai_agents"" not in sys.modules:
        stub = ModuleType(""openai_agents"")

        class _Agent:
            def __init__(self, *a, **kw):
                self.name = kw.get(""name"", ""agent"")

        class _OpenAI:
            def __init__(self, *a, **kw):
                pass

            def __call__(self, *_a, **_k):
                return """"

        def _tool(*_a, **_kw):
            def _decorator(func):
                return func

            return _decorator

        stub.Agent = _Agent
        stub.OpenAIAgent = _OpenAI
        stub.Tool = _tool
        sys.modules[""openai_agents""] = stub

    mod_path = ""alpha_factory_v1.demos.macro_sentinel.agent_macro_entrypoint""
    sys.modules.pop(mod_path, None)

    with patch(""alpha_factory_v1.backend.adk_bridge.auto_register""), \
         patch(""alpha_factory_v1.backend.adk_bridge.maybe_launch"") as maybe_launch:
        importlib.import_module(mod_path)
        maybe_launch.assert_called_once_with()
",tests/test_macro_adk_integration.py,,1,6.825604231969389e-08,"The method is a test function that uses monkeypatching and mocking to test the behavior of a specific module when certain environment variables are set. It is a typical unit test that ensures the correct function is called under specific conditions. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def Counter(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Counter, name, desc, labels)
",alpha_factory_v1/backend/agents/__init__.py,,1,8.152020648014727e-09,"The method 'Counter' is a simple wrapper around a function '_get_metric', which is likely part of a larger codebase dealing with metrics or monitoring. The method itself is straightforward and serves a clear purpose of creating or retrieving a metric counter. It is unlikely to be deleted unless the entire metrics system is being refactored or removed, which is not indicated here. Therefore, it is more likely to survive."
survived,"    def strip_comments(s: str) -> str:
        return ""\n"".join([ln.split(""//"")[0].rstrip() for ln in s.splitlines()])
",tools/any2mochi/py/run_all.py,,1,8.152020648014727e-09,"The method 'strip_comments' is a utility function that removes comments from a string containing code. This is a common requirement in code processing tasks, such as syntax highlighting, code analysis, or preparing code for execution. The method is simple, efficient, and serves a clear purpose. It is likely to be useful in various contexts where code strings need to be cleaned of comments. Therefore, it is likely to be retained."
survived,"    def parse_callable(self, node: ast.expr | None) -> tuple[list[str], str] | None:
        if not isinstance(node, ast.Subscript):
            return None
        if not (
            isinstance(node.value, ast.Attribute) and node.value.attr == ""Callable""
        ):
            return None
        if not (isinstance(node.slice, ast.Tuple) and len(node.slice.elts) == 2):
            return None
        args_node, ret_node = node.slice.elts
        if isinstance(args_node, ast.List):
            arg_types = [self.convert_type(e) for e in args_node.elts]
        else:
            arg_types = [self.convert_type(args_node)]
        ret_type = self.convert_type(ret_node)
        return arg_types, ret_type
",tools/any2mochi/py/py2mochi.py,Converter,1,1.1032560311263802e-09,"The method 'parse_callable' is a utility function that parses a specific AST node structure related to 'Callable' types. It checks if the node is a subscript with a specific structure and extracts argument and return types. This functionality is useful for static analysis or code transformation tools that need to understand or manipulate type annotations in Python code. Given the increasing importance of type annotations and static analysis in Python, this method is likely to be retained as it provides a specific and useful functionality in these contexts."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_agent_experience_entrypoint.py,DummyBlocks,0,0.9999998724809324,"The method is an initializer (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is typically a placeholder or a default implementation that might be overridden later. However, as it stands, it doesn't serve any functional purpose and doesn't initialize any attributes or perform any operations. Unless there is a specific reason to keep such a method (e.g., as a temporary placeholder during development), it is likely to be deleted in a production codebase to avoid unnecessary code clutter."
survived,"        def __init__(self, *a, **k):
            pass
",tests/test_agent_experience_entrypoint.py,DummyMemory,0,0.9953904270578577,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that is meant to be overridden by subclasses. If this is part of a larger class that is intended to be subclassed, it might survive. However, if this is the final implementation and serves no purpose, it is likely to be deleted as it doesn't contribute any functionality."
survived,"        def __init__(self, *a, **k):
            pass
",tests/test_agent_experience_entrypoint.py,DummyConfig,0,0.9626731119865553,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that is meant to be overridden by subclasses. If this is part of a larger class hierarchy where subclasses are expected to implement their own initialization logic, it might survive. However, if this is the only constructor and no subclasses are overriding it, it is likely to be deleted as it serves no functional purpose."
survived,"def _run_main(monkeypatch: pytest.MonkeyPatch, openai_key: str | None, base_url: str | None) -> str | None:
    recorded: dict[str, str | None] = {}

    stub = types.ModuleType(""openai_agents"")

    def Tool(*_a, **_k):
        def dec(f):
            return f
        return dec

    class DummyMemory:
        def __init__(self, *a, **k):
            pass

        def recent(self, _n: int):
            return []

    class DummyAgent:
        def __init__(self, *a, **k) -> None:
            self.memory = DummyMemory()

        async def act(self) -> str:
            return ""done""

        def observe(self, *_a) -> None:
            pass

    def DummyOpenAIAgent(*_a, **kw):
        recorded[""base_url""] = kw.get(""base_url"")
        return object()

    stub.Agent = DummyAgent
    stub.OpenAIAgent = DummyOpenAIAgent
    stub.Tool = Tool
    stub.memory = types.SimpleNamespace(LocalQdrantMemory=DummyMemory)

    gr_stub = types.SimpleNamespace(Blocks=DummyBlocks, mount_gradio_app=mount_gradio_app)

    class DummyConfig:
        def __init__(self, *a, **k):
            pass

    class DummyServer:
        def __init__(self, *a, **k):
            pass

        async def serve(self) -> None:
            pass

    uvicorn_stub = types.SimpleNamespace(Config=DummyConfig, Server=DummyServer)

    monkeypatch.setitem(sys.modules, ""openai_agents"", stub)
    monkeypatch.setitem(sys.modules, ""gradio"", gr_stub)
    monkeypatch.setitem(sys.modules, ""uvicorn"", uvicorn_stub)

    if openai_key is None:
        monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    else:
        monkeypatch.setenv(""OPENAI_API_KEY"", openai_key)
    if base_url is None:
        monkeypatch.delenv(""LLM_BASE_URL"", raising=False)
    else:
        monkeypatch.setenv(""LLM_BASE_URL"", base_url)

    module_name = ""alpha_factory_v1.demos.era_of_experience.agent_experience_entrypoint""
    sys.modules.pop(module_name, None)
    mod = importlib.import_module(module_name)

    async def one_event():
        yield {""id"": 1, ""t"": ""0"", ""user"": ""a"", ""kind"": ""health"", ""payload"": {}}

    monkeypatch.setattr(mod, ""experience_stream"", one_event)
    monkeypatch.setattr(mod.asyncio, ""sleep"", lambda *_a, **_kw: None)
    asyncio.run(mod.main())
    return recorded.get(""base_url"")
",tests/test_agent_experience_entrypoint.py,,1,6.023574641292144e-08,"The method '_run_main' is a utility function designed for testing purposes, using the 'monkeypatch' fixture from pytest to mock and replace certain modules and environment variables. It is a common practice in testing to ensure that the code behaves as expected without relying on external dependencies. The method is well-structured for its purpose, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained for future testing needs."
survived,"def test_plain_table_handles_no_rows() -> None:
    assert cli._plain_table([""h1"", ""h2""], []) == ""h1 | h2""",tests/test_demo_cli.py,,1,2.2159489282323004e-08,"The method 'test_plain_table_handles_no_rows' is a unit test designed to verify the behavior of the '_plain_table' function when it is provided with headers but no data rows. This is a common edge case that needs to be tested to ensure the function handles it correctly. Unit tests are crucial for maintaining code quality and ensuring that functions behave as expected under various conditions. Therefore, this method is likely to be retained as part of the test suite to ensure the robustness of the '_plain_table' function."
survived,"    def __init__(self, *a, **k):
        pass
",tests/test_selfheal_env.py,DummyBlocks,0,0.9999999973534264,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder during development or when subclassing to ensure compatibility with a superclass constructor. However, if it remains unchanged, it serves no functional purpose and is likely to be removed or replaced with a more meaningful implementation. Therefore, it is predicted to be deleted."
survived,"def prefer_medium_model() -> ModelPreferences:
    """"""Balanced model preferences for general use.""""""

    return ModelPreferences(
        hints=[
            ModelHint(name=""gpt-4o-2024-05-13""),
            ModelHint(name=""claude-3-sonnet-20240229""),
            ModelHint(name=""llama-3-70b""),
        ],
        costPriority=0.5,
        speedPriority=0.6,
        intelligencePriority=0.6,
    )
",src/enrichmcp/context.py,,1,9.736200303530205e-10,"The method 'prefer_medium_model' is likely to survive because it provides a balanced configuration for model preferences, which is useful for general use cases. The method is well-defined, with clear parameters for cost, speed, and intelligence priorities, and it includes a list of model hints that can be updated as new models become available. This flexibility and general applicability make it a valuable utility function that is likely to be retained in the codebase."
survived,"def _make_client(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> TestClient:
    monkeypatch.setenv(""STORAGE_PATH"", str(tmp_path))
    from alpha_factory_v1.demos.alpha_agi_insight_v1.src import evolution_worker

    return TestClient(evolution_worker.app)
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_evolution_worker.py,,1,2.699578619062706e-07,"The method '_make_client' is a utility function used in testing to set up a test client with a specific environment configuration. It uses 'monkeypatch' to modify the environment variable 'STORAGE_PATH' to point to a temporary path, which is a common practice in testing to ensure isolation and prevent side effects. The method then imports and returns a 'TestClient' instance for the 'evolution_worker.app'. This setup is typical in test environments to ensure that tests are run in a controlled and isolated manner. Given its utility in testing, it is likely to be retained as part of the test suite."
survived,"def test_rejects_absolute_path(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    client = _make_client(tmp_path, monkeypatch)

    info = tarfile.TarInfo(""/abs.txt"")
    info.size = 0
    payload = _make_tar(info)

    resp = client.post(""/mutate"", files={""tar"": (""bad.tar"", payload, ""application/x-tar"")})
    assert resp.status_code == 400",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_evolution_worker.py,,1,4.363462233903899e-09,"The method 'test_rejects_absolute_path' is a unit test designed to ensure that the application correctly rejects tar files containing absolute paths. This is a common security measure to prevent path traversal vulnerabilities. The test is relevant and necessary for maintaining the security and integrity of the application, especially when dealing with file uploads. Therefore, it is unlikely to be deleted as it serves an important purpose in the test suite."
survived,"    def sample_topics(self, d):

        doc = self.corpus[d]

        # initialise level counts
        doc_levels = self.levels[d]
        level_counts = np.zeros(self.num_levels, dtype=int)
        for c in doc_levels:
            level_counts[c] += 1

        # get the leaf node and populate the path
        path = np.zeros(self.num_levels, dtype=object)
        node = self.document_leaves[d]
        for level in range(self.num_levels-1, -1, -1): # e.g. [3, 2, 1, 0] for num_levels = 4
            path[level] = node
            node = node.parent

        # sample a new level for each word
        level_weights = np.zeros(self.num_levels)
        for n in range(len(doc)):

            w = doc[n]
            word_level = doc_levels[n]

            # remove from model
            level_counts[word_level] -= 1
            node = path[word_level]
            node.word_counts[w] -= 1
            node.total_words -= 1

            # pick new level
            for level in range(self.num_levels):
                level_weights[level] = (self.alpha + level_counts[level]) *                     \
                    (self.eta + path[level].word_counts[w]) /                                   \
                    (self.eta_sum + path[level].total_words)
            level_weights = level_weights / np.sum(level_weights)
            level = self.random_state.multinomial(1, level_weights).argmax()

            # put the word back into the model
            doc_levels[n] = level
            level_counts[level] += 1
            node = path[level]
            node.word_counts[w] += 1
            node.total_words += 1
",src/hlda/sampler.py,HierarchicalLDA,1,2.8453347280241004e-08,"The method 'sample_topics' is a core part of a topic modeling algorithm, likely related to hierarchical topic models or similar probabilistic models. It involves sampling levels for words in a document, updating counts, and using probabilistic methods to adjust the model. Such methods are crucial for the functionality of topic modeling algorithms, which are widely used in natural language processing and machine learning. Given its importance in the context of these algorithms, it is unlikely to be deleted unless the entire approach is being deprecated or replaced by a fundamentally different method."
survived,"def _write_executable(path: Path, content: str) -> None:
    path.write_text(content)
    path.chmod(0o755)
",tests/test_cross_industry_patch.py,,1,4.599055376537186e-10,"The method `_write_executable` is a utility function that writes content to a file and sets its permissions to be executable. This is a common requirement in many software applications, especially those dealing with scripts or command-line tools. The method is simple, clear, and performs a specific task effectively. There is no indication that this functionality is obsolete or redundant, and it is likely to be useful in various contexts where executable files need to be created programmatically. Therefore, it is likely to survive."
survived,"def _build_page_cache(cfg, B: Axis, Pos: Axis, page_size: int = 2) -> PageCache:
    pages_per_seq = (Pos.size + page_size - 1) // page_size
    Seq = Axis(""seq"", B.size)
    Page = Axis(""page"", pages_per_seq)
    MaxPage = Axis(""max_page"", pages_per_seq * B.size)
    Slot = Axis(""slot"", page_size)
    return PageCache.init(Seq, Page, Slot, cfg.KVHeads, cfg.HeadSize, MaxPage, dtype=jnp.float32)
",tests/test_attention.py,,1,6.023574641292144e-08,"The method '_build_page_cache' is a utility function that constructs a page cache for a given configuration. It uses several parameters and returns a PageCache object. The method is specific to a certain functionality, likely within a larger system that deals with data processing or memory management. Since it is a utility function that encapsulates a specific task, it is likely to be useful and necessary for the system's operation. Therefore, it is unlikely to be deleted unless the entire system or the way it handles page caching is refactored or deprecated."
survived,"    def tearDown(self):
        self.patcher.stop()
",tests/test_sys_fn_kdb.py,TestKdbIPC,1,2.5109990926928157e-08,"The method `tearDown` is a standard method used in unit testing frameworks like `unittest` in Python. It is typically used to clean up after each test method runs, such as stopping any patches that were started in the `setUp` method. The presence of `self.patcher.stop()` suggests that this method is correctly stopping a patch that was started, which is a common and necessary practice in testing to ensure that patches do not affect other tests. Therefore, this method is likely to be retained as it serves an important role in the test lifecycle."
survived,"def test_distribution_zip(tmp_path: Path) -> None:
    zip_path = BROWSER_DIR / ""insight_browser.zip""
    if zip_path.exists():
        zip_path.unlink()
    result = subprocess.run([
        ""npm"",
        ""run"",
        ""build:dist"",
    ], cwd=BROWSER_DIR, capture_output=True, text=True)
    assert result.returncode == 0, result.stderr
    assert zip_path.exists(), ""insight_browser.zip missing""
    assert zip_path.stat().st_size <= 3 * 1024 * 1024, ""zip size exceeds 3 MiB""
    with zipfile.ZipFile(zip_path) as zf:
        names = zf.namelist()
    expected = {
        ""index.html"",
        ""insight.bundle.js"",
        ""service-worker.js"",
        ""manifest.json"",
        ""style.css"",
        ""insight_browser_quickstart.pdf"",
    }
    # ensure expected files exist
    for name in expected:
        assert name in names, f""{name} missing from zip""
    # ensure assets directory exists and contains files
    assert any(n.startswith(""assets/"") for n in names), ""assets directory missing""
    # ensure no unexpected files
    allowed_prefixes = {""assets/""}
    for name in names:
        if name in expected:
            continue
        if any(name.startswith(p) for p in allowed_prefixes):
            continue
        pytest.fail(f""Unexpected file {name} in zip"")",tests/test_distribution_zip.py,,1,1.725782769012759e-08,"The method `test_distribution_zip` is a test function that verifies the integrity and correctness of a distribution zip file for a browser application. It checks if the zip file is created, if it contains the expected files, if the file size is within limits, and if there are no unexpected files. This is a crucial part of ensuring the software is packaged correctly before distribution. Such test functions are essential for maintaining software quality and are unlikely to be deleted unless the packaging process changes significantly or the project is discontinued."
survived,"    def load_weights(self, path: str) -> None:
        self.loaded = path
",tests/test_orchestrator_rest.py,DummyAgent,0,0.9999485577825553,"The method 'load_weights' is a simple method that assigns a given path to an instance variable 'loaded'. It doesn't perform any actual loading of weights or any other operations. This makes it a placeholder or incomplete implementation. Unless there is a specific use case where simply storing the path is sufficient, this method is likely to be considered for deletion or refactoring to include actual functionality."
survived,"        def set(self, *_a: Any, **_kw: Any) -> None: ...
",src/monitoring/metrics.py,_N,1,1.0677030767166749e-06,"The method 'set' is defined with a signature that accepts any number of positional and keyword arguments, but it has no implementation (indicated by the ellipsis '...'). This suggests that it might be intended as an abstract method or a placeholder for future implementation. Without additional context, such as whether this is part of an interface or abstract class, it's difficult to determine its exact purpose. However, methods like this are often retained as part of a class's interface to be implemented by subclasses. Therefore, it is more likely to be Survived (1) unless there is a specific reason to remove it, such as a change in design that makes it obsolete."
survived,"    def test_infer_fastmcp_v1_server(self):
        """"""FastMCP 1.0 server instances should infer to FastMCPTransport.""""""
        from mcp.server.fastmcp import FastMCP as FastMCP1

        server = FastMCP1()
        transport = infer_transport(server)
        assert isinstance(transport, FastMCPTransport)",tests/client/test_client.py,TestInferTransport,1,2.3823698451773172e-07,"The method `test_infer_fastmcp_v1_server` is a unit test that verifies the functionality of the `infer_transport` function when applied to a `FastMCP 1.0` server instance. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks that the `infer_transport` function correctly identifies the transport type for a given server instance, which is an important aspect of the system's functionality. Therefore, it is unlikely to be deleted as it serves a critical role in maintaining the integrity of the codebase."
survived,"def test_compare_df_mixed_types_value_mismatch():
    df1 = pd.DataFrame({
        'int_col': [1, 2],
        'float_col': [1.5, 2.5],
        'date_col': pd.to_datetime(['2023-01-01', '2023-01-02']),
        'str_col': ['x', 'y'],
    })
    df2 = df1.copy()
    df2.loc[1, 'float_col'] = 9.9
    assert not compare_df(df1, df2, question=""mixed"")
",backend/tests/test_utils_sql_compare_df.py,,1,1.725782769012759e-08,"The method `test_compare_df_mixed_types_value_mismatch` is a unit test designed to verify the behavior of the `compare_df` function when there is a mismatch in values between two DataFrames. This is a common scenario that needs to be tested to ensure the function works correctly. The test is specific and checks for a particular case where a float value is different between the two DataFrames. Such tests are crucial for maintaining code quality and ensuring that changes do not introduce bugs. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_download_with_retry_fallback(tmp_path: Path, requests_mock: requests_mock.Mocker) -> None:
    path = tmp_path / ""out""
    monkeypatch = pytest.MonkeyPatch()
    monkeypatch.setattr(fa, ""FALLBACK_GATEWAYS"", [""https://alt.gateway/ipfs""])
    url_primary = f""{fa.GATEWAY}/CID""
    url_alt = ""https://alt.gateway/ipfs/CID""
    requests_mock.get(url_primary, status_code=500)
    requests_mock.get(url_alt, text=""data"")
    try:
        fa.download_with_retry(""CID"", path, attempts=1)
    finally:
        monkeypatch.undo()
    assert path.read_text() == ""data""
",tests/test_fetch_assets.py,,1,4.1399375473943306e-08,"The method 'test_download_with_retry_fallback' is a unit test function that tests the functionality of a download method with retry and fallback capabilities. It uses mocking to simulate network requests and responses, ensuring that the fallback mechanism works correctly when the primary gateway fails. This is a crucial part of testing the robustness of network-dependent functions, especially in scenarios where reliability and fault tolerance are important. Therefore, this method is likely to be retained as it serves an important role in ensuring the quality and reliability of the codebase."
survived,"def test_download_error(tmp_path: Path, requests_mock: ""requests_mock.Mocker"") -> None:
    monkeypatch_file_list = [""dummy.txt""]
    url = dg.model_urls(""117M"")[0].replace(""checkpoint"", ""dummy.txt"")
    requests_mock.get(url, status_code=404)

    dest_dir = tmp_path / ""models""
    with pytest.MonkeyPatch.context() as m:
        m.setattr(dg, ""_FILE_LIST"", monkeypatch_file_list)
        with pytest.raises(Exception):
            dg.download_openai_gpt2(""117M"", dest=dest_dir, attempts=1)",tests/test_download_openai_gpt2.py,,1,1.955568070542584e-08,"The method 'test_download_error' is a unit test designed to verify the behavior of a function when a download error occurs (HTTP 404). It uses mocking to simulate the error condition and checks if the appropriate exception is raised. This is a common and necessary practice in testing to ensure robustness of the code against network failures. Therefore, it is unlikely to be deleted as it serves an important purpose in the test suite."
survived,"def test_missing_token(monkeypatch: pytest.MonkeyPatch) -> None:
    client = _make_client(monkeypatch)
    resp = client.get(""/agents"")
    assert resp.status_code == 403
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_backend_rest_auth.py,,1,1.3440409770490404e-08,"The method `test_missing_token` is a unit test function that uses the `monkeypatch` fixture from pytest to test a specific behavior of a client when accessing a resource without a token. The test checks if the response status code is 403, which indicates forbidden access due to missing authentication. This is a valid and useful test case for ensuring security measures are correctly implemented in the application. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_env_required(monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.delenv(""API_TOKEN"", raising=False)
    with pytest.raises(RuntimeError):
        orchestrator._build_rest({""dummy"": DummyRunner()})",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_backend_rest_auth.py,,1,6.023574641292144e-08,"The method 'test_env_required' is a test function that uses the 'monkeypatch' fixture from pytest to temporarily delete an environment variable 'API_TOKEN'. It then checks if a 'RuntimeError' is raised when calling 'orchestrator._build_rest'. This is a typical pattern in testing to ensure that certain conditions (like missing environment variables) are handled correctly by the code. Since this is a test function, it is unlikely to be deleted as it serves a purpose in verifying the robustness of the code under test. Test functions are generally retained as long as the functionality they test is relevant."
survived,"def _dir_checksum(path: Path) -> str:
    hasher = hashlib.sha256()
    for file in sorted(path.rglob(""*"")):
        if file.is_file():
            hasher.update(file.relative_to(path).as_posix().encode())
            hasher.update(file.read_bytes())
    return hasher.hexdigest()
",tests/test_checksum.py,,1,2.646573631904765e-09,"The method `_dir_checksum` is a utility function that calculates a checksum for a directory by hashing the relative paths and contents of all files within it. This is a useful function for verifying the integrity of a directory's contents, detecting changes, or ensuring consistency across different environments. Such functionality is commonly needed in various applications, including backup systems, deployment tools, and data synchronization services. Given its utility and the fact that it is a self-contained, non-intrusive function, it is likely to be retained in the codebase."
survived,"    def project(self, vec: Sequence[float] | np.ndarray) -> np.ndarray:
        """"""Return ``vec`` multiplied by the current projection matrix.""""""
        if self._counter % self.steps == 0:
            self._proj = self._new_projection()
        self._counter += 1
        if np is not None:
            arr = np.asarray(vec, dtype=""float32"")
            if arr.ndim == 1:
                arr = arr.reshape(1, -1)
            return (arr @ np.asarray(self._proj).T).reshape(-1)
        arr = [float(x) for x in vec]
        out = [sum(a * b for a, b in zip(arr, col)) for col in zip(*self._proj)]
        if np is not None:
            return np.asarray(out, dtype=""float32"")
        return out  # type: ignore[return-value]",src/agents/guards/embedding_orthogonaliser.py,EmbeddingOrthogonaliser,1,1.8189616842444243e-09,"The method 'project' is likely to survive because it is a well-defined function that performs a specific task of projecting a vector using a projection matrix. It includes handling for both numpy arrays and sequences, making it versatile. The method also includes a mechanism to update the projection matrix periodically, which suggests it is part of a larger system that requires dynamic projections. The use of numpy, when available, optimizes the performance, which is a common practice in numerical computations. Overall, the method is functional, efficient, and adaptable, which are qualities that contribute to its survival."
survived,"    def prompt_video(self) -> str | None:
        prompt = self.properties.get(""prompt_video"")
        if prompt is None:
            return None
        if not isinstance(prompt, str):
            raise ValueError(""Invalid prompt_video. prompt_video must be a string."")
        return prompt
",libs/core/kiln_ai/datamodel/extraction.py,ExtractorConfig,1,1.6052280526088547e-09,"The method 'prompt_video' is a simple utility function that retrieves a property from a dictionary and performs basic validation. It is well-structured, with clear error handling for invalid data types. Such utility functions are common in codebases for handling optional configurations or settings. Unless there is a significant change in the requirements or the structure of the 'properties' dictionary, this method is likely to remain useful and relevant."
survived,"    def _byte_to_char_idx(self, line_no: int, byte_idx: int) -> int:
        line_bytes = self._src_lines_bytes[line_no]
        return len(line_bytes[:byte_idx].decode(""utf-8""))
",src/flynt/code_editor.py,CodeEditor,1,4.944450477491054e-09,"The method '_byte_to_char_idx' is a utility function that converts a byte index to a character index for a specific line in a source file. This is a common requirement when dealing with text processing, especially when handling encodings like UTF-8 where characters can be multiple bytes long. The method is straightforward, performs a necessary conversion, and is likely part of a larger system that processes text files. There is no indication that this method is redundant or unnecessary, and it serves a clear purpose in its context. Therefore, it is likely to be retained."
survived,"def test_broadcast_merkle_root_handles_corrupt_db(tmp_path: Path) -> None:
    ledger_path = tmp_path / ""ledger.db""
    ledger = Ledger(str(ledger_path), rpc_url=""http://rpc.test"", broadcast=True)
    ledger.log(messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0))
    ledger.compute_merkle_root()
    # truncate database file to simulate missing pages
    data = ledger_path.read_bytes()
    ledger_path.write_bytes(data[: len(data) // 2])
    with mock.patch.object(insight_logging, ""_log"") as log:
        asyncio.run(ledger.broadcast_merkle_root())
        log.warning.assert_called()",tests/test_ledger_corruption.py,,1,6.825604231969389e-08,"The method 'test_broadcast_merkle_root_handles_corrupt_db' is a test function that verifies the behavior of the 'broadcast_merkle_root' method when the database is corrupted. Test functions are crucial for ensuring the reliability and correctness of code, especially in handling edge cases and errors. This function simulates a corrupted database scenario and checks if the appropriate warning is logged, which is an important aspect of robust software development. Therefore, it is likely to be retained to ensure the system's resilience against database corruption."
survived,"def test_bus_extreme_envelopes() -> None:
    """"""Large or malformed messages should not crash the bus.""""""

    bus = messaging.A2ABus(config.Settings(bus_port=0))
    received: list[object] = []

    async def handler(env: object) -> None:
        received.append(env)

    bus.subscribe(""x"", handler)

    async def run() -> None:
        for size in (0, 1, 100, 1000, 10000, 50000):
            env = messaging.Envelope(sender=""s"" * size, recipient=""x"", ts=1e308)
            env.payload[""data""] = ""p"" * size
            bus.publish(""x"", env)
        bus.publish(""x"", messaging.Envelope(sender="""", recipient=""x"", ts=float(""inf"")))
        bus.publish(""x"", messaging.Envelope(sender="""", recipient=""x"", ts=float(""-inf"")))
        bus.publish(""x"", types.SimpleNamespace(sender=None, recipient=""x"", payload={}, ts=None))
        await asyncio.sleep(0)

    asyncio.run(run())
    assert received",tests/test_bus_fuzz.py,,1,3.927863699585036e-07,"The method 'test_bus_extreme_envelopes' is a test function designed to ensure that the messaging bus can handle large or malformed messages without crashing. It is a crucial part of testing the robustness and reliability of the messaging system. Test functions like this are typically retained to ensure ongoing stability and to catch regressions in future code changes. Therefore, it is unlikely to be deleted."
survived,"def test_merkle_root_ignores_corrupt_rows(tmp_path: Path) -> None:
    ledger = Ledger(str(tmp_path / ""ledger.db""), broadcast=False)
    env1 = messaging.Envelope(sender=""a"", recipient=""b"", payload={""v"": 1}, ts=0.0)
    env2 = messaging.Envelope(sender=""b"", recipient=""c"", payload={""v"": 2}, ts=1.0)
    ledger.log(env1)
    ledger.log(env2)

    baseline = ledger.compute_merkle_root()

    # insert rows with missing hash and invalid hash
    ledger.conn.execute(
        ""INSERT INTO messages (ts, sender, recipient, payload) VALUES (?, ?, ?, ?)"",
        (2.0, ""x"", ""y"", ""{oops""),
    )
    ledger.conn.execute(
        ""INSERT INTO messages (ts, sender, recipient, payload, hash) VALUES (?, ?, ?, ?, ?)"",
        (3.0, ""y"", ""z"", ""{}"", ""zz""),
    )
    ledger.conn.commit()

    root = ledger.compute_merkle_root()
    assert root == baseline

    # further logging should still succeed
    ledger.log(messaging.Envelope(sender=""c"", recipient=""d"", payload={""v"": 3}, ts=2.0))
    ledger.compute_merkle_root()
",tests/test_ledger_malformed_rows.py,,1,1.725782769012759e-08,"The method 'test_merkle_root_ignores_corrupt_rows' is a test function that verifies the robustness of the 'compute_merkle_root' method in the presence of corrupt data entries. It ensures that the method can handle and ignore corrupt rows in the database without affecting the integrity of the Merkle root computation. This is a valuable test for maintaining the reliability and correctness of the ledger system, especially in scenarios where data integrity is crucial. Therefore, it is likely to be retained as part of the test suite to ensure ongoing system reliability."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Partsupp,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not fulfill its intended purpose. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key presence in a collection."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Order,0,0.999997438718515,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q2.py,Auto1,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q1.py,Auto2,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q11.py,Partsupp,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not attribute existence. This misuse of the method is likely to lead to confusion and incorrect behavior, especially if the class is expected to behave like a collection. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership testing."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Auto1,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-h/compiler/py/q15.py,Auto1,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"def test_Q20_finds_complete_cast_Iron_Man_movie():
    assert result == [Auto1(complete_downey_ironman_movie=""Iron Man"")]
",tests/dataset/job/compiler/py/q20.py,,1,1.4166087846364157e-09,"The method `test_Q20_finds_complete_cast_Iron_Man_movie` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this test seems to be checking for a specific feature (finding the complete cast of the Iron Man movie), it is likely still relevant and useful for ensuring the codebase's correctness. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto6,1,4.363462233903899e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto11,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto2,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. Since this is a common and practical use case, the method is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto4,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto4,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto5,0,0.999876605372333,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto8,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, straightforward, and leverages Python's dynamic attribute access capabilities, it is likely to be retained in the codebase."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q20.py,,0,0.9998415637531546,"The method '_min' is a utility function that attempts to find the minimum value in a list or a similar structure. It first checks if the input has an 'Items' attribute and uses it if available, which suggests it might be designed to work with certain custom objects. It then filters out 'None' values before computing the minimum, returning 0 if the list is empty after filtering. This function is quite specific and doesn't offer significant advantages over Python's built-in 'min' function, except for handling 'None' values and custom objects with an 'Items' attribute. However, its utility is limited and it doesn't follow Python's typical error handling practices (e.g., raising a generic Exception). Given these factors, the method is likely to be deleted or refactored for better integration with existing Python functionalities."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto3,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in container-like objects such as lists, dictionaries, or custom objects that mimic these behaviors. In this code, `__getitem__` is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation if the object is designed to allow attribute access via indexing, which can be a convenient feature in certain contexts. Since this method provides a clear and potentially useful functionality, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto1,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly to align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto4,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users who expect `in` to check for membership in a collection rather than attribute existence. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto1,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is unlikely to be deleted unless the design of the class changes significantly, as it provides a flexible way to access object attributes."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto6,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is a simple and effective way to provide dictionary-like access to object attributes, which can be particularly useful in dynamic or flexible data structures. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto2,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q5.py,Auto3,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto10,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose makes it likely to be deleted or refactored to align with its conventional use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q14.py,Auto5,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, the method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto1,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto1,0,0.9999952149051502,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto2,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is unlikely to be deleted as it provides a flexible and Pythonic way to access object attributes."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto6,0,0.9999997897565932,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method suggests that it does not fulfill its intended purpose, making it likely to be deleted or refactored."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto4,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto5,1,1.522997951276035e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to support dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q31.py,Auto10,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto8,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking key membership."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q9.py,Auto1,1,0.03732688801344475,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed meant to treat its attributes as keys, this method could survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q18.py,Auto4,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q1.py,Auto6,0,0.999998790133938,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement key membership checking."
survived,"def test_Q28_finds_euro_dark_movie_with_minimal_values():
    assert result == Auto1(
        movie_company=""Euro Films Ltd."",
        rating=7.2,
        complete_euro_dark_movie=""Dark Euro Film"",
    )
",tests/dataset/job/compiler/py/q28.py,,1,1.6052280526088547e-09,"The method `test_Q28_finds_euro_dark_movie_with_minimal_values` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. This function seems to be testing a specific case for a movie with certain attributes, which suggests it has a specific purpose in validating the behavior of the code. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume it will survive."
survived,"def test_Q23_finds_US_internet_movie_with_verified_cast():
    assert result == [Auto1(movie_kind=""movie"", complete_us_internet_movie=""Web Movie"")]
",tests/dataset/job/compiler/py/q23.py,,1,4.6911638017642294e-08,"The method name 'test_Q23_finds_US_internet_movie_with_verified_cast' suggests that it is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function appears to be testing a specific feature or behavior (finding a US internet movie with a verified cast), it is likely to be useful for ensuring the correctness of the code it tests. Therefore, it is more likely to be maintained rather than deleted."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q10.py,Auto4,0,0.999998629043345,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the expected functionality of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/job/compiler/py/q15.py,,1,2.5109990926928157e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The method is not overly specific to a particular use case, making it versatile and reusable in different contexts. Additionally, the method is well-structured and follows a logical flow, which suggests that it is a well-thought-out piece of code. Given these factors, it is likely that the method will be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto2,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto5,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto7,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or needs dynamic attribute access. It is a common pattern in Python to allow flexible access to object attributes. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q8.py,Auto4,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not attribute existence. This misuse of the method suggests that it might be deleted or refactored to align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q18.py,,1,2.0611536181902033e-09,"The method '_key' is a utility function that is likely used for sorting purposes, as indicated by the use of 'opts[""sortKey""]'. It converts the key to a string if it is a list, tuple, or dictionary, which is a common practice to ensure consistent sorting behavior. This method is simple, serves a clear purpose, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto7,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"def _min(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""min() expects list or group"")
    vals = [it for it in v if it is not None]
    if not vals:
        return 0
    return min(vals)
",tests/dataset/job/compiler/py/q14.py,,1,2.9023122007764653e-06,"The method _min is a utility function that attempts to find the minimum value in a list or a similar iterable structure. It first checks if the input has an 'Items' attribute, which it then uses as the iterable. It raises an exception if the input is not a list, ensuring type safety. The method also filters out None values before computing the minimum, which is a useful feature. However, the method name is not descriptive, and the functionality is somewhat redundant with Python's built-in min function. Despite this, the method provides additional checks and handling that might be useful in certain contexts. Therefore, it is likely to survive as it offers specific functionality that might be needed in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q17.py,Auto2,0,0.9999339478346898,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate logic that checks for membership in the actual data structure being used."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto5,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto4,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for dynamically accessing object attributes, especially in cases where the object is designed to behave like a dictionary or similar container. Therefore, this method is likely to be retained as it provides a flexible way to access object attributes."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto11,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where an object needs to behave like a dictionary or list, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto3,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto4,0,0.9999980052698925,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q33.py,Auto2,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the standard or expected behavior for `__contains__`, which should typically check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect and could lead to confusion or errors when used, suggesting it should be deleted or revised."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q24.py,Auto10,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q30.py,Auto2,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for cases where the object is designed to behave like a dictionary or similar container, allowing attribute access via keys. Since this method provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto14,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q7.py,Auto7,1,0.02931222788947056,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed using its attributes as a collection, this method could be useful and survive. Otherwise, it might be considered a misuse of the `__contains__` method and could be deleted or refactored."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q28.py,Auto11,0,0.9999785550602307,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto6,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q19.py,Auto8,0,0.9999921107349486,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q22.py,Auto7,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q26.py,Auto9,1,7.73442280641062e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow dynamic access to object attributes, especially in cases where the object is used to represent a collection of data. Therefore, this method is likely to be retained as it provides a flexible and Pythonic way to access object attributes."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q13.py,Auto5,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q12.py,Auto1,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto16,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q23.py,Auto4,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q27.py,Auto2,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto9,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q29.py,Auto11,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. It is a common pattern and does not have any apparent issues that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q25.py,Auto4,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and incorrect behavior when the method is used. Therefore, it is likely that this method will be deleted or refactored to align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q11.py,Auto7,0,0.9999869928752253,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/job/compiler/py/q15.py,Auto3,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/job/compiler/py/q6.py,Auto5,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,CustomerAddres,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q21.py,_Group,1,1.1861120010657661e-08,"The method is a standard implementation of the `__iter__` method in Python, which is used to make an object iterable. This is a common and necessary method for classes that need to support iteration, such as those representing collections or sequences. Since it directly returns an iterator over `self.Items`, it is likely essential for the functionality of the class, especially if `Items` is a list or another iterable. Therefore, it is unlikely to be deleted unless the class design changes significantly, which would require a different iteration mechanism."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q37.py,Item,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely that this method will be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q16.py,CustomerAddress,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use of `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to better fit its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q35.py,DateDim,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking key membership."
survived,"def _q4():
    _src = catalog_sales
    _rows = _query(
        _src,
        [{""items"": date_dim, ""on"": lambda cs, d: d.d_date_sk == cs.cs_sold_date_sk}],
        {""select"": lambda cs, d: (cs, d)},
    )
    _groups = _group_by(_rows, lambda cs, d: cs.cs_call_center_sk)
    _items5 = _groups
    return [
        Auto4(
            cs_call_center_sk=g.key,
            sales=_sum([x[0].cs_ext_sales_price for x in g]),
            profit=_sum([x[0].cs_net_profit for x in g]),
        )
        for g in _items5
    ]
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,6.69158608681505e-10,"The method '_q4' is a private function (indicated by the underscore prefix) that performs a specific task: it queries a data source, groups the results, and returns a list of 'Auto4' objects with aggregated sales and profit data. This function is likely part of a larger codebase that deals with data processing or analysis. Since it encapsulates a clear and useful functionality, it is unlikely to be deleted unless the entire module or its functionality is deprecated or refactored. Therefore, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Item,1,2.5612814850547937e-06,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. However, it might not be the most common or recommended practice as it can lead to confusion between attribute access and item access. Despite this, the method is functional and serves a purpose, so it is likely to survive unless there is a specific design decision to remove it for clarity or to enforce a different access pattern."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Store,1,4.6911638017642294e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically for list or dictionary-like objects. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It allows for dynamic access to object attributes, which can be particularly useful in certain design patterns or when working with objects that need to expose their attributes in a flexible manner. Therefore, this method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q63.py,_Group,1,1.1032560311263802e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and expected implementation for custom objects that need to support the `len()` function. Therefore, there is no reason to delete this method as it provides necessary functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,StoreReturn,0,0.999983298584886,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the intended use of `__contains__`, as it should be used for membership testing in collections, not attribute existence. Therefore, this method is likely to be deleted or refactored to correctly implement membership testing."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,WebSale,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and follows Python's design principles."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q4.py,Auto2,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q7.py,Auto1,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate method for checking membership."
survived,"def test_TPCDS_Q54_simplified():
    assert result == [
        Auto1(segment=1, num_customers=1, segment_base=50),
        Auto1(segment=0, num_customers=1, segment_base=0),
    ]
",tests/dataset/tpc-ds/compiler/py/q54.py,,1,1.725782769012759e-08,"The method `test_TPCDS_Q54_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function is asserting a specific result, it indicates that it is testing a specific behavior or output of the code. Unless the functionality being tested is removed or significantly altered, the test is likely to survive to ensure the code behaves as expected."
survived,"def test_TPCDS_Q84_sample():
    assert result == 84.0
",tests/dataset/tpc-ds/compiler/py/q84.py,,1,1.0467401685178159e-08,"The method `test_TPCDS_Q84_sample` is a test function, likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function is asserting a specific result, it indicates that it is testing a specific behavior or output of the code. Unless the functionality being tested is removed or significantly altered, test functions are typically retained to ensure code reliability and correctness. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,Auto3,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"def _q0():
    _src = inventory
    _rows = _query(
        _src,
        [
            {""items"": date_dim, ""on"": lambda inv, d: inv.inv_date_sk == d.d_date_sk},
            {""items"": item, ""on"": lambda inv, d, i: inv.inv_item_sk == i.i_item_sk},
        ],
        {
            ""select"": lambda inv, d, i: (inv, d, i),
            ""where"": lambda inv, d, i: d.d_month_seq >= 0 and d.d_month_seq <= 11,
        },
    )
    _groups = _group_by(
        _rows,
        lambda inv, d, i: Auto2(
            product_name=i.i_product_name,
            brand=i.i_brand,
            _class=i.i_class,
            category=i.i_category,
        ),
    )
    _items1 = _groups
    return [
        Auto1(
            i_product_name=g.key[""product_name""],
            i_brand=g.key[""brand""],
            i_class=g.key[""_class""],
            i_category=g.key[""category""],
            qoh=(
                sum([x[0].inv_quantity_on_hand for x in g])
                / len([x[0].inv_quantity_on_hand for x in g])
                if [x[0].inv_quantity_on_hand for x in g]
                else 0
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q22.py,,1,1.955568070542584e-08,"The method `_q0` appears to be a utility function that performs a query on an inventory dataset, groups the results, and calculates the average quantity on hand for each group. This type of function is typically useful in data processing and reporting tasks, especially in inventory management systems. It is likely to be retained as it provides a specific functionality that could be reused or adapted for various analytical purposes. The method is well-structured and serves a clear purpose, which suggests it is valuable to the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q97.py,Auto1,0,0.9999980052698925,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key or item is present. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name, not if a key is present in a collection. This is a misuse of the `__contains__` method, which is expected to work with collections like lists, sets, or dictionaries, not object attributes. Therefore, this method is likely to be deleted or rewritten to correctly implement membership testing."
survived,"def abs(x):
    if x >= 0.0:
        return x
    return -x
",tests/dataset/tpc-ds/compiler/py/q53.py,,0,0.9999970976877992,"The method is a simple implementation of the absolute value function, which is a fundamental mathematical operation. However, Python already has a built-in function `abs()` that performs the same operation more efficiently and is widely used. Redefining such a basic function is generally unnecessary and can lead to confusion or errors in larger codebases. Therefore, this custom implementation is likely to be deleted in favor of using the built-in `abs()` function."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto4,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q19.py,_Group,1,1.0467401685178159e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes. The code snippet shows a typical pattern of initializing instance variables, which is a common and necessary practice in class definitions. Therefore, this method is likely to be retained as it serves a crucial role in object initialization."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,DateDim,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained as it provides a clear and functional purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,DateDim,1,0.1824255304737224,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as a collection of keys, this implementation could be valid. Without additional context on how this method is used within the class, it's difficult to definitively say it should be deleted. However, it is unconventional and might be misleading to other developers who expect `__contains__` to behave differently."
survived,"def _q0():
    _src = catalog_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": warehouse,
                ""on"": lambda cs, w: cs.cs_warehouse_sk == w.w_warehouse_sk,
            },
            {
                ""items"": ship_mode,
                ""on"": lambda cs, w, sm: cs.cs_ship_mode_sk == sm.sm_ship_mode_sk,
            },
            {
                ""items"": call_center,
                ""on"": lambda cs, w, sm, cc: cs.cs_call_center_sk
                == cc.cc_call_center_sk,
            },
        ],
        {""select"": lambda cs, w, sm, cc: (cs, w, sm, cc)},
    )
    _groups = _group_by(
        _rows,
        lambda cs, w, sm, cc: Auto2(
            warehouse=w.w_warehouse_name[0:20], sm_type=sm.sm_type, cc_name=cc.cc_name
        ),
    )
    _items1 = _groups
    return [
        Auto1(
            warehouse=g.key[""warehouse""],
            sm_type=g.key[""sm_type""],
            cc_name=g.key[""cc_name""],
            d30=len(
                [x for x in g if x[0].cs_ship_date_sk - x[0].cs_sold_date_sk <= 30]
            ),
            d60=len(
                [
                    x
                    for x in g
                    if x[0].cs_ship_date_sk - x[0].cs_sold_date_sk > 30
                    and x[0].cs_ship_date_sk - x[0].cs_sold_date_sk <= 60
                ]
            ),
            d90=len(
                [
                    x
                    for x in g
                    if x[0].cs_ship_date_sk - x[0].cs_sold_date_sk > 60
                    and x[0].cs_ship_date_sk - x[0].cs_sold_date_sk <= 90
                ]
            ),
            d120=len(
                [
                    x
                    for x in g
                    if x[0].cs_ship_date_sk - x[0].cs_sold_date_sk > 90
                    and x[0].cs_ship_date_sk - x[0].cs_sold_date_sk <= 120
                ]
            ),
            dmore=len(
                [x for x in g if x[0].cs_ship_date_sk - x[0].cs_sold_date_sk > 120]
            ),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q99.py,,1,4.363462233903899e-09,"The method '_q0' appears to be a well-structured function that performs a series of operations on a dataset, including joining tables, grouping data, and calculating specific metrics based on date differences. This type of function is commonly used in data processing and analysis tasks, which are essential in many applications. The function is not overly complex, and its purpose is clear, making it unlikely to be deleted unless there is a significant change in the requirements or the data model. Additionally, the function does not contain any deprecated or obsolete code patterns that would necessitate its removal. Therefore, it is more likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,DateDim,0,0.9999546021442518,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the implementation here uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q42.py,,1,1.1861120010657661e-08,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be used in various data processing scenarios, making it versatile and potentially useful in many applications. The function is not overly specific to a single use case, which increases its chances of being retained in the codebase. Additionally, the function is well-structured and implements common data manipulation tasks, which are often needed in software development. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q77.py,Auto5,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute in an object, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking for membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q22.py,_Group,1,1.522997951276035e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q51.py,WebSale,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q93.py,_Group,1,7.73442280641062e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, and there is no indication that it is redundant or incorrect. Constructors are essential for setting up initial state in object-oriented programming, so it is unlikely to be deleted unless the entire class is being refactored or removed."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto3,0,0.999983298584886,"The method is implementing the `__contains__` magic method, which is used to define behavior for the `in` keyword. However, the implementation is incorrect because it uses `hasattr(self, key)`, which checks for the presence of an attribute, not an item in a collection. Typically, `__contains__` should be used to check for membership in a collection, like a list or dictionary, not for attributes. This incorrect implementation is likely to cause confusion and errors, leading to its deletion or replacement with a correct implementation."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q75.py,,1,7.194132978569833e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q99.py,CallCenter,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Since it serves a clear purpose and is correctly implemented, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,CatalogSale,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for checking membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q76.py,_Group,1,7.582560422162384e-10,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Customer,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,Auto3,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check membership in a collection rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users familiar with the standard behavior of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q79.py,,1,3.466327708641819e-07,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and unless the surrounding code or context changes significantly, such utility functions are generally retained for their usefulness."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q6.py,,1,3.850741907939403e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be useful in various data processing scenarios. The function is not overly specific to a particular use case, making it versatile and reusable. Additionally, it handles edge cases such as empty inputs and provides options for customization through the 'opts' parameter. These characteristics suggest that the method is well-designed for its purpose and likely to be retained in the codebase."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q20.py,_Group,1,6.348800075736417e-09,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a standard practice to have an __init__ method in a class to set up initial state, and there is no indication that this method is redundant or incorrect. Therefore, it is likely to be retained in the code."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q44.py,,1,1.955568070542584e-08,"The method `_sort_key` is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a versatile function that can be useful in many contexts where sorting of complex data structures is required. The function handles different data types gracefully and provides a consistent way to convert them into a sortable format. This kind of utility function is often retained in codebases because it abstracts away the complexity of sorting heterogeneous data structures, making it easier for developers to sort collections without having to write custom sorting logic each time. Therefore, it is likely to be retained in the codebase."
survived,"def test_TPCDS_Q4_result():
    assert result == [
        Auto1(
            customer_id=""C1"",
            customer_first_name=""Alice"",
            customer_last_name=""A"",
            customer_login=""alice"",
        )
    ]
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,1.4166087846364157e-09,"The method `test_TPCDS_Q4_result` is a unit test function that checks if the variable `result` matches a specific expected output. Unit tests are crucial for ensuring code correctness and reliability, especially in larger projects. They help in identifying bugs early and ensure that changes in the code do not break existing functionality. Given the importance of testing in software development, this method is likely to be retained as part of a test suite."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q23.py,_Group,1,2.2159489282323004e-08,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"def _q0():
    _src = item
    _rows = _query(
        _src,
        [
            {""items"": inventory, ""on"": lambda i, inv: i.i_item_sk == inv.inv_item_sk},
            {""items"": date_dim, ""on"": lambda i, inv, d: inv.inv_date_sk == d.d_date_sk},
            {
                ""items"": catalog_sales,
                ""on"": lambda i, inv, d, cs: cs.cs_item_sk == i.i_item_sk,
            },
        ],
        {
            ""select"": lambda i, inv, d, cs: (i, inv, d, cs),
            ""where"": lambda i, inv, d, cs: (
                (
                    (
                        (i.i_current_price >= 20 and i.i_current_price <= 50)
                        and i.i_manufact_id >= 800
                    )
                    and i.i_manufact_id <= 803
                )
                and inv.inv_quantity_on_hand >= 100
            )
            and inv.inv_quantity_on_hand <= 500,
        },
    )
    _groups = _group_by(
        _rows,
        lambda i, inv, d, cs: Auto2(
            id=i.i_item_id, desc=i.i_item_desc, price=i.i_current_price
        ),
    )
    _items1 = _groups
    _items1 = sorted(_items1, key=lambda g: _sort_key(g.key[""id""]))
    return [
        Auto1(
            i_item_id=g.key[""id""],
            i_item_desc=g.key[""desc""],
            i_current_price=g.key[""price""],
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q37.py,,1,1.955568070542584e-08,"The method '_q0' is a complex query function that filters and groups data from multiple sources. It is likely part of a larger data processing or reporting system. The method is well-structured, uses lambda functions for filtering and grouping, and returns a list of objects with specific attributes. This indicates that it serves a specific purpose in the application, such as generating reports or analytics. Unless there is a significant change in the application's requirements or architecture, such methods are typically retained for their utility."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,DateDim,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is straightforward, functional, and leverages Python's dynamic attribute access, it is likely to be retained in the codebase."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q8.py,,1,5.3157849718487075e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This function is likely to survive because it provides a useful and specific functionality that can be reused in various contexts where summing a list of numbers is needed, especially when dealing with objects that might encapsulate lists in an 'Items' attribute. The error handling also makes it robust against incorrect inputs, which is a desirable feature in utility functions."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q42.py,Auto1,0,0.9999967112522585,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, which is expected to check membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q65.py,Auto2,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q50.py,StoreReturn,1,1.275190675769241e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This method is simple, clear, and leverages Python's dynamic nature effectively. It is likely to be retained as it provides a flexible way to access object attributes, which can be particularly useful in scenarios where the attributes are not known at compile time or need to be accessed dynamically."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Item,1,1.1861120010657661e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., `obj[key]`) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional way to access object attributes, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Store,1,3.653482080241728e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the usability of the class."
survived,"def test_TPCDS_Q41_simplified():
    assert result == [""Blue Shirt"", ""Red Dress""]
",tests/dataset/tpc-ds/compiler/py/q41.py,,1,8.76424914819242e-08,"The method `test_TPCDS_Q41_simplified` is a test function, likely part of a test suite for a larger codebase. Test functions are generally crucial for ensuring code correctness and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Since this function is asserting a specific result, it indicates that it is testing a particular functionality or output, which is important for maintaining code quality. Therefore, it is more likely to be maintained or updated rather than deleted."
survived,"def _q0():
    _src = call_center
    _rows = _query(
        _src,
        [
            {
                ""items"": catalog_returns,
                ""on"": lambda cc, cr: cc.cc_call_center_sk == cr.cr_call_center_sk,
            },
            {
                ""items"": date_dim,
                ""on"": lambda cc, cr, d: cr.cr_returned_date_sk == d.d_date_sk,
            },
            {
                ""items"": customer,
                ""on"": lambda cc, cr, d, c: cr.cr_returning_customer_sk
                == c.c_customer_sk,
            },
            {
                ""items"": customer_demographics,
                ""on"": lambda cc, cr, d, c, cd: c.c_current_cdemo_sk == cd.cd_demo_sk,
            },
            {
                ""items"": household_demographics,
                ""on"": lambda cc, cr, d, c, cd, hd: c.c_current_hdemo_sk
                == hd.hd_demo_sk,
            },
            {
                ""items"": customer_address,
                ""on"": lambda cc, cr, d, c, cd, hd, ca: c.c_current_addr_sk
                == ca.ca_address_sk,
            },
        ],
        {
            ""select"": lambda cc, cr, d, c, cd, hd, ca: (cc, cr, d, c, cd, hd, ca),
            ""where"": lambda cc, cr, d, c, cd, hd, ca: (
                (
                    (
                        (d.d_year == 2001 and d.d_moy == 5)
                        and cd.cd_marital_status == ""M""
                    )
                    and cd.cd_education_status == ""Unknown""
                )
                and hd.hd_buy_potential == ""1001-5000""
            )
            and ca.ca_gmt_offset == -6,
        },
    )
    _groups = _group_by(
        _rows,
        lambda cc, cr, d, c, cd, hd, ca: Auto2(
            id=cc.cc_call_center_id, name=cc.cc_name, mgr=cc.cc_manager
        ),
    )
    _items1 = _groups
    return [
        Auto1(
            Call_Center=g.key[""id""],
            Call_Center_Name=g.key[""name""],
            Manager=g.key[""mgr""],
            Returns_Loss=_sum([x[1].cr_net_loss for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q91.py,,1,8.152020648014727e-09,"The method '_q0' is a complex query function that performs a series of joins and filters on multiple data sources to extract specific information. It is likely part of a larger data processing or reporting system. The method is well-structured, uses lambda functions for dynamic querying, and aggregates data into a meaningful format. Such methods are typically essential for data analysis tasks and are unlikely to be deleted unless the entire system is being deprecated or significantly refactored. Therefore, it is more likely to survive."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q46.py,,1,8.152020648014727e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q31.py,StoreSale,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q79.py,Auto1,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is straightforward, functional, and leverages Python's dynamic attribute access, it is likely to be retained in the codebase."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q15.py,_Group,1,1.3440409770490404e-08,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and useful implementation for custom classes that manage collections, allowing them to integrate seamlessly with Python's built-in functions. Therefore, this method is likely to be retained as it provides essential functionality for the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q8.py,CustomerAddres,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely that this method will be deleted or refactored to correctly implement key containment logic."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q28.py,_Group,1,6.348800075736417e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is correctly implemented to return the length of `self.Items`, which suggests that `self.Items` is likely a list or a similar collection. This is a standard and expected implementation for custom objects that need to support the `len()` function. Therefore, it is unlikely to be deleted as it provides essential functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto4,1,6.023574641292144e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q20.py,Auto2,0,0.9999962733608834,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement the intended functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q73.py,Auto3,1,1.6052280526088547e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or needs dynamic attribute access. There is no indication of redundancy or poor design that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def _q2():
    _groups = {}
    _order = []
    for g in grouped:
        _k = g.i_class
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(g)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto4(_class=cg.key, total=sum([x.itemrevenue for x in cg])) for cg in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q98.py,,0,0.9999999928058669,"The method is likely to be deleted because it contains several issues that suggest it is not functioning as intended. Firstly, the variable 'grouped' is used without being defined or passed as a parameter, which will lead to a NameError. Secondly, the line 'g.Items.append(g)' seems incorrect as it appends the group object to its own Items list, which is likely not the intended behavior. Additionally, the method lacks proper documentation and error handling, making it difficult to understand and maintain. These issues indicate that the method is either incomplete or not useful in its current form, leading to its potential deletion."
survived,"def _q0():
    _src = date_dim
    _rows = _query(
        _src,
        [
            {
                ""items"": store_sales,
                ""on"": lambda dt, ss: dt.d_date_sk == ss.ss_sold_date_sk,
            },
            {""items"": item, ""on"": lambda dt, ss, i: ss.ss_item_sk == i.i_item_sk},
        ],
        {
            ""select"": lambda dt, ss, i: (dt, ss, i),
            ""where"": lambda dt, ss, i: i.i_manufact_id == 100 and dt.d_moy == 12,
        },
    )
    _groups = _group_by(
        _rows,
        lambda dt, ss, i: Auto2(
            d_year=dt.d_year, brand_id=i.i_brand_id, brand=i.i_brand
        ),
    )
    _items1 = _groups
    _items1 = sorted(
        _items1,
        key=lambda g: _sort_key(
            [
                g.key[""d_year""],
                -_sum([x[1].ss_ext_sales_price for x in g]),
                g.key[""brand_id""],
            ]
        ),
    )
    return [
        Auto1(
            d_year=g.key[""d_year""],
            brand_id=g.key[""brand_id""],
            brand=g.key[""brand""],
            sum_agg=_sum([x[1].ss_ext_sales_price for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q3.py,,1,6.348800075736417e-09,"The method '_q0' is a private function (indicated by the underscore prefix) that performs a specific query operation on a dataset. It is likely part of a larger codebase where it serves a specific purpose, such as generating reports or analytics based on sales data. The function is well-structured, uses lambda functions for concise operations, and performs sorting and grouping operations that are common in data processing tasks. Unless there is a significant change in the requirements or the data model, this method is likely to survive as it fulfills a specific need within the application."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,WebSale,1,2.7535689845210225e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's hard to determine if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom implementations, this method is likely to survive unless there is a clear indication that it causes issues or is not aligned with the intended design of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q3.py,DateDim,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a valid and potentially useful implementation, especially in cases where the object is designed to act like a dictionary or needs to provide flexible attribute access. Therefore, it is likely to be retained in the code."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q32.py,,1,9.237449576640118e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be useful in various data processing scenarios. The function is not overly specific to a particular use case, making it versatile and reusable. Additionally, it handles edge cases such as empty inputs and provides options for customization through the 'opts' parameter. These characteristics suggest that the method is well-designed for its purpose and is likely to be retained in the codebase."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q53.py,_Group,1,1.1861120010657661e-08,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def test_TPCDS_Q83_sample():
    assert result == 83
",tests/dataset/tpc-ds/compiler/py/q83.py,,1,6.348800075736417e-09,"The method `test_TPCDS_Q83_sample` is a test function that asserts whether the variable `result` is equal to 83. This is a simple and straightforward test case, likely part of a larger suite of tests. Test functions are generally not deleted unless they are redundant, incorrect, or replaced by more comprehensive tests. Since this function serves a clear purpose in verifying a specific condition, it is more likely to be retained as part of the testing process to ensure code correctness."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q86.py,WebSale,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,Store,0,0.9999485577825553,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, as it should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting membership checks. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q18.py,CatalogSale,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose suggests that it might be deleted or refactored to better align with its expected functionality."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q88.py,StoreSale,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be used for membership testing in collections like lists, sets, or dictionaries. Therefore, this implementation is likely incorrect and may be deleted or refactored to properly check for key membership in a collection."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,StoreSale,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be retained because it provides a flexible way to access object properties, which can be particularly useful in dynamic or reflective programming scenarios. It aligns with Python's dynamic nature and is a common pattern in Python code."
survived,"def test_TPCDS_Q6_result():
    assert result == [Auto1(state=""CA"", cnt=10)]
",tests/dataset/tpc-ds/compiler/py/q6.py,,1,1.4166087846364157e-09,"The method `test_TPCDS_Q6_result` is a test function that checks if the variable `result` matches a specific expected output. This is a typical pattern in unit testing where assertions are used to validate the correctness of code. Such test functions are crucial for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, this method is likely to be retained as part of a test suite to ensure the functionality it tests remains correct."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q2.py,Auto3,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,StoreSale,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic attribute access. Since it serves a clear purpose and is correctly implemented, it is likely to be retained in the codebase."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q8.py,,1,9.237449576640118e-09,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-ds/compiler/py/q1.py,_Group,1,4.944450477491054e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q39.py,,1,4.944450477491054e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner. Therefore, it is likely to survive."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Auto3,0,0.999964643742472,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of the method could lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q13.py,_Group,1,1.2501528648238603e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q45.py,Auto1,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q82.py,StoreSale,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q54.py,Store,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible way to access object attributes and is consistent with Python's design philosophy of allowing objects to behave like built-in types when appropriate."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q10.py,CustomerAddres,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the typical use case of `__contains__`. Therefore, it is likely that this method will be deleted or refactored to correctly implement membership checking."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q55.py,Auto1,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,1.1861120010657661e-08,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing or sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q22.py,DateDim,1,6.023574641292144e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q14.py,Item,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the standard or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and incorrect usage, as it does not align with the typical use case of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q22.py,_Group,1,6.348800075736417e-09,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a standard practice to have an __init__ method in classes to set up initial state, and there is no indication that this method is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,WebSite,0,0.9999910602998366,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of the method could lead to confusion and bugs, as it does not align with the standard behavior expected from `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q65.py,Auto2,0,0.9999599363048656,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate membership check."
survived,"def _query(src, joins, opts):
    items = [[v] for v in src]
    for j in joins:
        joined = []
        if j.get(""right"") and j.get(""left""):
            matched = [False] * len(j[""items""])
            for left in items:
                m = False
                for ri, right in enumerate(j[""items""]):
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    matched[ri] = True
                    joined.append(left + [right])
                if not m:
                    joined.append(left + [None])
            for ri, right in enumerate(j[""items""]):
                if not matched[ri]:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        elif j.get(""right""):
            for right in j[""items""]:
                m = False
                for left in items:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if not m:
                    undef = [None] * (len(items[0]) if items else 0)
                    joined.append(undef + [right])
        else:
            for left in items:
                m = False
                for right in j[""items""]:
                    keep = True
                    if j.get(""on""):
                        keep = j[""on""](*left, right)
                    if not keep:
                        continue
                    m = True
                    joined.append(left + [right])
                if j.get(""left"") and (not m):
                    joined.append(left + [None])
        items = joined
    if opts.get(""where""):
        items = [r for r in items if opts[""where""](*r)]
    if opts.get(""sortKey""):

        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k

        items.sort(key=_key)
    if ""skip"" in opts:
        n = opts[""skip""]
        if n < 0:
            n = 0
        items = items[n:] if n < len(items) else []
    if ""take"" in opts:
        n = opts[""take""]
        if n < 0:
            n = 0
        items = items[:n] if n < len(items) else items
    res = []
    for r in items:
        res.append(opts[""select""](*r))
    return res
",tests/dataset/tpc-ds/compiler/py/q96.py,,1,5.60279640614594e-09,"The method '_query' is a complex function that performs a series of operations on data, including joining, filtering, sorting, and selecting. It is a utility function that can be very useful in data processing tasks, especially when dealing with complex data structures and operations. The function is well-structured and provides flexibility through options like 'where', 'sortKey', 'skip', and 'take'. Such utility functions are often retained in codebases because they encapsulate complex logic in a reusable manner. Therefore, it is likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q39.py,Item,1,5.3157849718487075e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q1.py,Store,1,3.2241866333029355e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes dynamically."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q99.py,_Group,1,1.725782769012759e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a standard practice to have an __init__ method in a class to set up initial state, and there is no indication that this method is redundant or incorrect. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q27.py,Auto2,1,8.152020648014727e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in cases where the object is designed to behave like a dictionary or to provide dynamic attribute access. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q94.py,DateDim,0,0.999998790133938,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys. However, this implementation uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This could lead to confusion and incorrect usage, as it does not align with the standard behavior of `__contains__`. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q79.py,,0,0.9999687980937693,"The method is likely to be deleted because it contains several issues that make it less efficient and potentially problematic. Firstly, the use of 'str' as a key for the dictionary is not ideal, especially when dealing with complex objects, as it can lead to unexpected behavior or collisions. Secondly, the method uses 'types.SimpleNamespace' to convert dictionaries to objects, which is an unusual and potentially unnecessary step that could be replaced with a more straightforward approach. Additionally, the method's handling of different input types (list, tuple, or other) is not very robust, and the overall design could be improved for clarity and efficiency. These factors suggest that the method might be refactored or replaced with a more efficient and clear implementation."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q76.py,_Group,1,8.76424914819242e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q13.py,DateDim,0,0.9999756997690634,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may be deleted or replaced with a more appropriate implementation that checks for key membership in a collection."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,StoreSale,1,2.646573631904765e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python to allow more flexible and dynamic access to object properties. Therefore, this method is likely to be Survived."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q15.py,CatalogSale,1,2.7535689845210225e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the flexibility of Python and the potential for custom implementations, this method is likely to survive unless it causes confusion or errors in the intended use of the class."
survived,"def test_TPCDS_Q89_sample():
    assert result == 89.0
",tests/dataset/tpc-ds/compiler/py/q89.py,,1,7.3382086014706e-07,"The method `test_TPCDS_Q89_sample` is a test function that contains a single assertion checking if `result` equals 89.0. Without additional context, such as the purpose of the test or the definition of `result`, it's difficult to determine its utility. However, test functions are generally important for verifying code correctness. If this test is part of a larger suite ensuring the accuracy of a system, it is likely to be retained. If `result` is a placeholder or the test is not meaningful in the context of the codebase, it might be deleted. Given the lack of context, but assuming it serves a purpose in a test suite, it is more likely to survive."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q59.py,Auto1,1,3.653482080241728e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method is functional, concise, and leverages Python's dynamic attribute access capabilities, it is likely to be retained in the codebase."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q33.py,_Group,1,1.725782769012759e-08,"The method is a constructor for a class, initializing instance variables. It sets up the 'key' and two lists, 'Items' and 'items', which are references to the same list. This is a common pattern in Python to initialize object state, and there is no indication of redundancy or error. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q76.py,CatalogSale,1,1.1253518384332553e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which is a valid and useful pattern for objects that need to provide dictionary-like access to their attributes. This method is likely to be retained because it provides a flexible way to access object attributes and is consistent with Python's design philosophy of allowing objects to behave like built-in types when appropriate."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q70.py,,1,4.363462233903899e-09,"The method '_sort_key' is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. This function is useful for sorting complex data structures, which is a common requirement in many applications. The method is generic and handles multiple data types, making it versatile and reusable. Such utility functions are often retained in codebases because they provide essential functionality that can be used across different parts of a program. Therefore, it is likely to be retained."
survived,"def test_TPCDS_Q63_simplified():
    assert result == 63
",tests/dataset/tpc-ds/compiler/py/q63.py,,1,3.1201906230699086e-05,"The method `test_TPCDS_Q63_simplified` is a test function that contains a single assertion checking if `result` equals 63. Without additional context, such as the presence of a testing framework or the definition of `result`, it's difficult to determine its utility. However, test functions are generally important for ensuring code correctness. If this test is part of a larger suite and `result` is properly defined elsewhere, it is likely to be retained. If `result` is undefined or the test is redundant, it might be removed. Given the lack of context, I'll assume it's part of a necessary test suite."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q53.py,Auto1,1,1.444980317078884e-07,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name, which can be useful for objects that need to provide dictionary-like access to their attributes. This is a common and useful pattern in Python, especially for classes that need to provide flexible attribute access. Therefore, it is likely to be retained."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q30.py,,1,3.850741907939403e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of method is common in data processing or sorting operations and is unlikely to be deleted unless the entire sorting mechanism is refactored or removed. Therefore, it is more likely to survive."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q4.py,,1,1.1032560311263802e-09,"The method '_group_by' is likely to survive because it provides a useful utility function for grouping elements of a list based on a key function. This is a common requirement in data processing and manipulation tasks. The method is generic, allowing it to work with any type of list elements and key functions, making it versatile and reusable. Additionally, the use of a dictionary to maintain groups and a list to preserve order is an efficient approach. Unless there are significant changes in the requirements or a better alternative is introduced, this method is likely to remain useful."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Item,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q58.py,Auto4,1,1.955568070542584e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be retained as it provides a clear and useful functionality."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q82.py,Inventory,1,2.8453347280241004e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained as it serves a practical purpose."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q24.py,,1,1.955568070542584e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Inventory,1,2.5109990926928157e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the indexing syntax (e.g., `obj[key]`). In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation, especially in dynamic or flexible data structures where attributes can be accessed like dictionary keys. It is likely to be retained as it provides a convenient way to access object attributes dynamically."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,Auto1,1,7.194132978569833e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Auto4,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely to be deleted or refactored to correctly implement key containment logic."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q71.py,Auto3,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q67.py,,1,1.3440409770490404e-08,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It takes an iterable 'it', applies a sorting key function from 'opts', and ensures the key is a string if it's a complex data type. This kind of function is common in data processing and sorting operations, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q24.py,Item,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. This implementation uses `getattr` to dynamically retrieve an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since it provides a clear and functional purpose, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q57.py,CallCenter,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the typical or expected behavior for `__contains__`, which should check for membership in a collection like a list, set, or dictionary. Therefore, this method is likely to be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,Auto1,0,0.9999724643101549,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the collection's keys or elements. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which is usually used for membership testing in collections like lists, sets, or dictionaries. This misuse of `__contains__` could lead to confusion and unexpected behavior, as it does not align with the standard use case of checking membership in a collection. Therefore, it is likely that this method will be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q84.py,HouseholdDemographic,0,0.999915188952306,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is expected to check for membership in a collection, not the presence of an attribute. This misuse of the method's intended purpose is likely to lead to confusion and errors, suggesting that the method should be deleted or re-implemented correctly to align with its intended use."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q19.py,Store,1,0.22270012850745968,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually implemented to check for membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection-like manner, this implementation could be valid. Without additional context, it's difficult to determine if this is the intended use. If the class is indeed designed to treat its attributes as keys, the method might survive. Otherwise, it might be considered incorrect and subject to deletion or modification."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q19.py,_Group,1,5.60279640614594e-09,"The method `__iter__` is a standard Python method used to make an object iterable. It is implemented correctly here by returning an iterator over `self.Items`. This is a common and necessary method for classes that need to support iteration, such as those representing collections or sequences. Therefore, it is unlikely to be deleted as it provides essential functionality for iterating over the items in the object."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q28.py,_Group,1,1.1861120010657661e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes the instance variables 'key', 'Items', and 'items'. The use of type hints and the initialization of an empty list for 'Items' are standard practices. The method is essential for setting up the initial state of an object, so it is unlikely to be deleted."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q34.py,_Group,1,2.1724399346070676e-10,"The method `__iter__` is a standard Python method used to make an object iterable. By returning an iterator over `self.Items`, it allows the object to be used in loops and other contexts where iteration is needed. This is a fundamental feature for many classes, especially those that represent collections or sequences. Unless there is a specific reason to remove iteration capability from the class, this method is likely to be retained."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/tpc-ds/compiler/py/q50.py,,1,3.3982678079468468e-09,"The method '_key' is a utility function that is likely used internally within a module or class to generate a key for sorting purposes. It takes an iterable 'it', applies a function 'sortKey' from a dictionary 'opts' to it, and ensures the result is a string if it's a list, tuple, or dictionary. This kind of function is common in sorting operations and is useful for customizing sort behavior. Since it serves a specific purpose and is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q56.py,Auto1,0,0.9999930377415741,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in the keys of a dictionary or similar structure. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical or expected behavior for `__contains__`, which should check for membership rather than attribute existence. This misuse of `__contains__` is likely to lead to confusion and incorrect behavior when the method is used in contexts expecting standard membership testing. Therefore, it is likely to be deleted or refactored to align with its intended purpose."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q34.py,Auto1,0,0.9999970976877992,"The method is incorrectly implemented. The `__contains__` method is supposed to check for membership, typically in a collection or container, and return a boolean indicating whether the specified key is present. However, using `hasattr(self, key)` checks if the object has an attribute with the name `key`, which is not the intended use of `__contains__`. This method should be checking if `key` is in a collection attribute of the class, not if it's an attribute name itself. Therefore, this method is likely to be deleted or rewritten to correctly implement membership checking."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q19.py,,1,1.3440409770490404e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. It is a common pattern in data processing and transformation tasks. The function is generic, flexible, and can handle various types of input, making it useful in many contexts. Additionally, it uses a dictionary to maintain the groups and a list to preserve the order of keys, which is a practical approach for many applications. Given its utility and the lack of any apparent issues or redundancy, it is likely to be retained in the codebase."
survived,"def _q0():
    _src = store_sales
    _rows = _query(
        _src,
        [
            {
                ""items"": store_returns,
                ""on"": lambda ss, sr: ss.ss_ticket_number == sr.sr_ticket_number
                and ss.ss_item_sk == sr.sr_item_sk,
            },
            {""items"": store, ""on"": lambda ss, sr, s: ss.ss_store_sk == s.s_store_sk},
            {""items"": item, ""on"": lambda ss, sr, s, i: ss.ss_item_sk == i.i_item_sk},
            {
                ""items"": customer,
                ""on"": lambda ss, sr, s, i, c: ss.ss_customer_sk == c.c_customer_sk,
            },
            {
                ""items"": customer_address,
                ""on"": lambda ss, sr, s, i, c, ca: c.c_current_addr_sk
                == ca.ca_address_sk,
            },
        ],
        {
            ""select"": lambda ss, sr, s, i, c, ca: (ss, sr, s, i, c, ca),
            ""where"": lambda ss, sr, s, i, c, ca: (
                c.c_birth_country != ca.ca_country.upper() and s.s_zip == ca.ca_zip
            )
            and s.s_market_id == 5,
        },
    )
    _groups = _group_by(
        _rows,
        lambda ss, sr, s, i, c, ca: Auto3(
            last=c.c_last_name,
            first=c.c_first_name,
            store_name=s.s_store_name,
            color=i.i_color,
        ),
    )
    _items1 = _groups
    return [
        Auto2(
            c_last_name=g.key[""last""],
            c_first_name=g.key[""first""],
            s_store_name=g.key[""store_name""],
            color=g.key[""color""],
            netpaid=sum([x[0].ss_net_paid for x in g]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q24.py,,1,1.522997951276035e-08,"The method '_q0' is a complex query function that joins multiple tables and performs filtering and grouping operations. It is likely part of a larger data processing or reporting system. Such methods are typically retained as they serve a specific purpose in data analysis or business intelligence applications. Unless there is a significant change in the system requirements or architecture, this method is likely to survive."
survived,"def _group_by(src: list[T], keyfn: Callable[[T], K]) -> list[_Group[K, T]]:
    groups: dict[str, _Group[K, T]] = {}
    order: list[str] = []
    for it in src:
        if isinstance(it, (list, tuple)):
            key = keyfn(*it)
        else:
            key = keyfn(it)
        if isinstance(key, dict):
            import types

            key = types.SimpleNamespace(**key)
        ks = str(key)
        g = groups.get(ks)
        if not g:
            g = _Group(key)
            groups[ks] = g
            order.append(ks)
        g.Items.append(it)
    return [groups[k] for k in order]
",tests/dataset/tpc-ds/compiler/py/q34.py,,1,1.725782769012759e-08,"The method '_group_by' is a utility function that groups elements of a list based on a key function. Such utility functions are commonly used in data processing and transformation tasks. The method is generic, flexible, and can handle various input types, making it a valuable tool in many programming scenarios. Unless there is a specific reason to remove it, such as redundancy or a better alternative, it is likely to be retained."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q74.py,WebSale,0,0.9999251538028718,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually used to check for membership in a collection like a list, set, or dictionary. Therefore, this implementation is likely incorrect for its intended purpose and may be deleted or replaced with a more appropriate implementation."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q91.py,Customer,0,0.9999810748526188,"The method `__contains__` is intended to check if a key is present in a collection, typically by checking if the key is in a dictionary or a list. However, in this implementation, it uses `hasattr`, which checks if an object has an attribute with the given name. This is not the typical use case for `__contains__`, as it should be checking membership rather than attribute existence. This misuse of the method could lead to confusion and unexpected behavior, especially for users who expect `in` to check for membership in a collection rather than attributes. Therefore, it is likely that this method will be deleted or refactored to align with the expected behavior of `__contains__`."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q98.py,Item,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for cases where the object is designed to allow attribute access via indexing. It is likely to survive because it provides a flexible way to access object attributes, which can be particularly useful in dynamic or reflective programming scenarios."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q25.py,Store,1,4.1399375473943306e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q95.py,WebReturn,0,0.999985261023967,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or refactored to correctly implement membership checking."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q52.py,Auto1,0,0.999988521231025,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, this implementation uses `hasattr`, which checks for the presence of an attribute, not a key in a collection. This is a misuse of the `__contains__` method, as it does not align with the expected behavior of checking membership in a collection. Therefore, it is likely to be deleted or replaced with a more appropriate implementation that correctly checks for key membership."
survived,"def test_TPCDS_Q66_simplified():
    assert result == 66
",tests/dataset/tpc-ds/compiler/py/q66.py,,1,4.944450477491054e-09,"The method `test_TPCDS_Q66_simplified` is a test function that asserts a condition. It is likely part of a test suite for a larger codebase. Test functions are generally not deleted unless they are redundant, incorrect, or the functionality they test is no longer relevant. Since this function is asserting a specific result, it suggests that it is testing a specific case or functionality that is expected to return 66. Without additional context indicating that this test is obsolete or incorrect, it is reasonable to assume that it will survive."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q1.py,_Group,1,1.0467401685178159e-08,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a standard practice to have an __init__ method in a class to set up initial state, and there is no indication that this method is redundant or incorrect. Therefore, it is likely to be retained in the code."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q78.py,W,0,0.9999687980937693,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute on an object, not the presence of a key in a collection. This is a misuse of the `__contains__` method, as it does not align with its intended purpose. Therefore, it is likely that this method will be deleted or refactored to correctly implement key containment logic."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q14.py,_Group,1,1.1253518384332553e-07,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, and there is no indication that it is redundant or incorrect. Constructors are essential for creating instances of a class, and this one appears to be correctly setting up the initial state of the object. Therefore, it is unlikely to be deleted."
survived,"def _sort_key(k):
    if hasattr(k, ""__dataclass_fields__""):
        return str(k)
    if isinstance(k, list):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, tuple):
        return tuple((_sort_key(x) for x in k))
    if isinstance(k, dict):
        return str(k)
    return k
",tests/dataset/tpc-ds/compiler/py/q21.py,,1,6.023574641292144e-08,"The method '_sort_key' is a utility function designed to generate a sorting key for various data types, including dataclasses, lists, tuples, and dictionaries. It is a helper function that can be useful in sorting operations where complex data structures are involved. The function is generic and handles multiple data types, making it versatile and reusable in different contexts. Such utility functions are often retained in codebases because they encapsulate common operations that might otherwise be repeated in multiple places. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q44.py,StoreSale,1,2.8453347280241004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to retrieve an attribute of the object by name, which is a valid and useful way to dynamically access object attributes. This method is likely to be useful in scenarios where the object is designed to behave like a dictionary or when dynamic attribute access is needed. Therefore, it is likely to be retained."
survived,"    def __iter__(self):
        return iter(self.Items)
",tests/dataset/tpc-ds/compiler/py/q1.py,_Group,1,4.944450477491054e-09,"The method is a standard implementation of the __iter__ method in Python, which is used to make an object iterable. It returns an iterator over the 'Items' attribute of the object. This is a common and necessary method for classes that need to support iteration, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"def _sum(v):
    if hasattr(v, ""Items""):
        v = v.Items
    if not isinstance(v, list):
        raise Exception(""sum() expects list or group"")
    s = 0.0
    for it in v:
        if it is None:
            continue
        if isinstance(it, (int, float)):
            s += float(it)
        else:
            raise Exception(""sum() expects numbers"")
    return s
",tests/dataset/tpc-ds/compiler/py/q77.py,,1,5.3157849718487075e-08,"The method '_sum' is a utility function that calculates the sum of a list of numbers, with additional handling for objects that have an 'Items' attribute. It includes error handling for non-list inputs and non-numeric elements within the list. This method is likely to survive because it provides a useful and specific functionality that is not directly available in Python's built-in functions. It also includes error handling, making it robust for various input types."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q72.py,CustomerDemographic,1,6.348800075736417e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q36.py,StoreSale,1,1.725782769012759e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, similar to how dictionaries and lists are accessed. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern and does not have any apparent issues that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"    def __init__(self, key: K):
        self.key = key
        self.Items: list[T] = []
        self.items = self.Items
",tests/dataset/tpc-ds/compiler/py/q21.py,_Group,1,1.637377179507321e-07,"The method is a constructor for a class, initializing the instance variables 'key', 'Items', and 'items'. It is a fundamental part of the class structure, and there is no indication that it is redundant or incorrect. Therefore, it is likely to be retained."
survived,"def _q0():
    _groups = {}
    _order = []
    for j in joined:
        _k = j.s
        _ks = str(_k)
        g = _groups.get(_ks)
        if not g:
            g = _Group(_k)
            _groups[_ks] = g
            _order.append(_ks)
        g.Items.append(j)
    _items1 = [_groups[k] for k in _order]
    return [
        Auto1(
            s_store_name=g.key.s_store_name,
            d30=len([1 for x in g if x.diff <= 30]),
            d31_60=len([1 for x in g if x.diff > 30 and x.diff <= 60]),
            d61_90=len([1 for x in g if x.diff > 60 and x.diff <= 90]),
            d91_120=len([1 for x in g if x.diff > 90 and x.diff <= 120]),
            d_gt_120=len([1 for x in g if x.diff > 120]),
        )
        for g in _items1
    ]
",tests/dataset/tpc-ds/compiler/py/q50.py,,1,3.0590235908148916e-07,"The method _q0() appears to be a utility function that processes a collection of objects (joined) and groups them based on a key (_k). It then creates a list of Auto1 objects, which seem to be some form of summary or report based on the 'diff' attribute of the grouped items. The method is likely part of a larger codebase that deals with data processing or reporting.

The method is not overly complex, and it seems to serve a specific purpose in transforming and summarizing data. There is no indication that it is deprecated or redundant, and it seems to be functioning as intended. Therefore, it is likely to be retained in the codebase unless there are changes in requirements or a refactor that makes it obsolete."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q23.py,DateDim,1,5.8291276786344415e-05,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. The current implementation uses `hasattr(self, key)`, which checks if the object has an attribute with the name `key`. This is not the typical use case for `__contains__`, which is usually meant for checking membership in a collection like a list, set, or dictionary. However, if the class is designed to treat its attributes as keys in a collection, this implementation could be valid. Without additional context, it's difficult to determine if this is a misuse or a valid use case. Given the unconventional use, it might be subject to review or change, but it could also be a deliberate design choice. Therefore, it is more likely to survive unless there is a clear indication that this is a mistake."
survived,"    def __contains__(self, key):
        return hasattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q12.py,Auto3,0,0.9999938558278723,"The method `__contains__` is intended to check if a key is present in a collection, typically by using the `in` keyword. However, the current implementation uses `hasattr`, which checks for the presence of an attribute rather than a key in a collection. This is not the intended use of `__contains__`, which should be checking membership in a collection like a list or dictionary. Therefore, this implementation is likely incorrect and may lead to unexpected behavior, suggesting it should be deleted or significantly revised."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-ds/compiler/py/q9.py,StoreSale,1,9.736200303530205e-10,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to provide dictionary-like access to their attributes. Therefore, this method is likely to be useful and relevant in many contexts, suggesting it will survive."
survived,"def test_population_df() -> None:
    pop = [mats.Individual([0.0, 0.0]), mats.Individual([1.0, 1.0])]
    for i, ind in enumerate(pop):
        ind.fitness = (i * 1.0, i * 2.0, i * 3.0)
        ind.rank = i
    df = web_app.population_df(pop)
    assert set(df.columns) == {""effectiveness"", ""risk"", ""complexity"", ""rank""}
    assert len(df) == 2",tests/test_web_app.py,,1,9.237449576640118e-09,"The method 'test_population_df' is a unit test designed to verify the functionality of the 'population_df' method from the 'web_app' module. It checks if the DataFrame returned by 'population_df' has the correct columns and length. This is a typical and necessary test to ensure that the method behaves as expected, especially in a data processing context. Therefore, it is likely to be retained as part of the test suite to maintain code reliability."
survived,"        def handle_request(req: Request) -> None:
            if req.url.endswith("".js"") and not req.url.endswith(""sw.js""):
                js_requests.append(req.url)
            elif req.url.endswith("".map""):
                map_requests.append(req.url)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_single_network_request.py,,1,2.646573631904765e-09,"The method `handle_request` is likely to be Survived (1) because it performs a specific task of categorizing requests based on their URL endings. This functionality is useful for logging or processing JavaScript and map file requests separately, which can be important for debugging or analytics purposes. The method is simple, clear, and serves a distinct purpose, making it a candidate for retention in the codebase."
survived,"async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
    """"""Set up Gree from a config entry.""""""
    if DOMAIN not in hass.data:
        hass.data[DOMAIN] = {}

    hass.data[DOMAIN][entry.entry_id] = entry.data
    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)
    return True
",custom_components/gree/__init__.py,,1,6.348800075736417e-09,"The method `async_setup_entry` is a standard setup function for integrating a component into Home Assistant, a popular open-source home automation platform. This function is responsible for setting up the integration from a configuration entry, which is a common pattern in Home Assistant's architecture. It checks if the domain is already in the Home Assistant data, initializes it if not, stores the entry data, and forwards the setup to the specified platforms. This is a typical and necessary part of the integration lifecycle in Home Assistant, suggesting that it is unlikely to be deleted unless there is a major architectural change in the platform."
survived,"    def __init__(self, *args, **kwargs):
        self.chat = _Chat()
",openai/__init__.py,OpenAI,1,4.1399375473943306e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of `self.chat = _Chat()` suggests that it is setting up an instance variable, which is a common and necessary practice in class design. Therefore, it is unlikely that this method will be deleted as it serves a fundamental role in the class's functionality."
survived,"    def __init__(self, request=None):
        self.request = request
",openai/__init__.py,APITimeoutError,1,2.998960815863541e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. It initializes an instance of the class with a given request, or None if no request is provided. This is a common pattern in Python classes to set up initial state, and there is no indication that it is redundant or unnecessary. Therefore, it is likely to be retained in the code."
survived,"def unicode_escape_map(literal: str) -> Dict[str, str]:
    """"""Return mapping of characters to their unicode escape sequences.""""""
    quote = get_quote_type(literal)
    if quote is None:
        return {}
    idx = 0
    while idx < len(literal) and literal[idx] in ""furbFURB"":
        idx += 1
    body = literal[idx + len(quote) : -len(quote)]
    mapping: Dict[str, str] = {}
    for m in unicode_escape_re.finditer(body):
        esc = m.group(0)
        try:
            char = codecs.decode(esc, ""unicode_escape"")
        except Exception:  # noqa: S112
            continue
        mapping[char] = esc
    return mapping
",src/flynt/utils/utils.py,,1,2.998960815863541e-09,"The method `unicode_escape_map` is a utility function that provides a specific functionality: mapping characters to their unicode escape sequences. This can be useful in various contexts where string manipulation or analysis is required, especially when dealing with unicode data. The function is well-defined, has a clear purpose, and does not seem to have any major issues or redundancies that would warrant its deletion. Additionally, it handles exceptions gracefully, which is a good practice. Therefore, it is likely to be retained in the codebase."
survived,"def test_chat_formatter_final_only():
    training_data = ModelTrainingData(
        input=""test input"",
        system_message=""system message"",
        final_output=""test output"",
    )
    expected = generate_chat_message_response(training_data)[""messages""]

    formatter = get_chat_formatter(
        strategy=ChatStrategy.final_only,
        system_message=""system message"",
        user_input=""test input"",
    )

    first = formatter.next_turn()
    assert [m.__dict__ for m in first] == expected[:2]

    assert formatter.next_turn(""test output"") is None
    assert formatter.message_dicts() == expected
",libs/core/kiln_ai/adapters/chat/test_chat_formatter.py,,1,6.348800075736417e-09,"The method 'test_chat_formatter_final_only' is a unit test designed to verify the functionality of a chat formatter. It checks if the formatter correctly processes input and produces the expected output. Unit tests are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or replaced. Since the method is testing a specific feature (chat formatting with a 'final_only' strategy), it is likely to be maintained as long as this feature is relevant."
survived,"    def __init__(self, status_code: int, text: str):
        self.status_code = status_code
        self.text = text
",alpha_factory_v1/requests.py,Response,1,9.736200303530205e-10,"The method is a constructor for a class, initializing two attributes: 'status_code' and 'text'. Constructors are essential for creating instances of a class with specific initial values, and this one is straightforward and functional. There is no indication that it is redundant or unnecessary, so it is likely to be retained."
survived,"def get(url: str, **kwargs):
    with _request.urlopen(url) as resp:
        data = resp.read().decode()
        return Response(resp.getcode(), data)",alpha_factory_v1/requests.py,,0,0.999988521231025,"The method is likely to be deleted because it uses a private method '_request.urlopen' which is not defined within the code snippet. This suggests that the code might be relying on an internal or non-standard library, which could lead to maintenance issues or compatibility problems. Additionally, the method does not handle exceptions that might occur during the URL opening or reading process, which is a critical aspect of robust network programming."
survived,"    def body(self) -> Union[str, bytes]:
        return self.request.body
",src/graphql_server/webob/views.py,WebobHTTPRequestAdapter,1,3.850741907939403e-09,"The method is a simple accessor that returns the body of a request, which is a common requirement in web frameworks or applications dealing with HTTP requests. It is likely to be used frequently and is essential for accessing request data. Therefore, it is unlikely to be deleted."
survived,"    def headers(self) -> Mapping[str, str]:
        return self.request.headers
",src/graphql_server/webob/views.py,WebobHTTPRequestAdapter,1,1.6052280526088547e-09,"The method 'headers' is a simple getter method that returns the headers from a request object. Such methods are typically useful for encapsulating access to object properties and are often used in frameworks or libraries dealing with HTTP requests. Since it provides a clear and direct way to access request headers, it is likely to be retained unless there is a significant change in how headers are managed or accessed in the surrounding codebase."
survived,"def test_load_passes_revision():
    model_mock = MagicMock()
    model_mock.config = MagicMock(eos_token_id=None)
    processor_mock = MagicMock()

    with patch(""mlx_vlm.utils.get_model_path"") as mock_get_model_path, patch(
        ""mlx_vlm.utils.load_model"",
        return_value=model_mock,
    ) as mock_load_model, patch(
        ""mlx_vlm.utils.load_processor"",
        return_value=processor_mock,
    ) as mock_load_processor, patch(
        ""mlx_vlm.utils.load_image_processor"", return_value=None
    ):
        mock_get_model_path.return_value = Path(""/tmp/model"")

        model, processor = load(""repo"", revision=""abc"")

        assert model is model_mock
        assert processor is processor_mock
        mock_get_model_path.assert_called_with(""repo"", revision=""abc"")",mlx_vlm/tests/test_utils.py,,1,7.194132978569833e-09,"The method `test_load_passes_revision` is a unit test that verifies the behavior of the `load` function when a specific revision is passed. It uses mocking to simulate the behavior of external dependencies, ensuring that the `load` function interacts with them correctly. This is a common practice in testing to isolate the function being tested and ensure it behaves as expected under controlled conditions. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained."
survived,"    async def run(self, stop_event: asyncio.Event) -> None:
        """"""Drive the orchestrator until ``stop_event`` is set.""""""
        await self.start()
        await self.scheduler.run(stop_event)
        await self.stop()
",alpha_factory_v1/backend/orchestrator.py,Orchestrator,1,1.955568070542584e-08,"The method 'run' is an asynchronous function that is designed to drive an orchestrator until a stop event is set. It follows a clear structure: starting the orchestrator, running the scheduler, and then stopping the orchestrator. This method is likely part of a larger system that requires asynchronous operations, such as a server or a task manager. The use of asyncio.Event for stopping the process is a common pattern in asynchronous programming, indicating that the method is well-integrated into the asyncio framework. Given its clear purpose and integration, it is unlikely to be deleted unless there is a significant change in the system's architecture or requirements."
survived,"def test_vote_and_merge_accepts_patch(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    diff = """"""--- a/metric.txt
+++ b/metric.txt
@@
-1
+2
""""""
    reg = StakeRegistry()
    reg.set_stake(""orch"", 1.0)
    with (
        patch.object(harness, ""_run_tests"", return_value=0),
        patch.object(harness, ""run_preflight""),
        patch.object(
            harness.patcher_core, ""apply_patch"", lambda d, repo_path: (Path(repo_path) / ""metric.txt"").write_text(""2\n"")
        ),
    ):
        accepted = harness.vote_and_merge(repo, diff, reg)
    assert accepted
    assert (repo / ""metric.txt"").read_text().strip() == ""2""
",tests/test_self_evolution.py,,1,1.637377179507321e-07,"The method 'test_vote_and_merge_accepts_patch' is a unit test function that tests the functionality of the 'vote_and_merge' method. Unit tests are crucial for ensuring code reliability and are typically not deleted unless the functionality they test is removed or significantly changed. Since this test verifies the integration of patch application and voting logic, it is likely to be maintained as long as the 'vote_and_merge' functionality exists."
survived,"    def __init__(self, *a, **k):
        pass
",tests/resources/sentence_transformers.py,SentenceTransformer,0,0.9999980052698925,"The method is a constructor (__init__) that takes any number of positional and keyword arguments but does nothing with them. This is often used as a placeholder or a base class constructor that is meant to be overridden by subclasses. However, if this is the final implementation and no subclass is expected to override it, it serves no functional purpose. Without additional context, it seems like a placeholder or a stub that might be removed in the future if not utilized or overridden, leading to a prediction of deletion."
survived,"    def adder(x):
        return x + n
",tests/human/python/closure.py,,0,0.9999999634651793,"The method 'adder' is likely to be deleted because it references a variable 'n' that is not defined within the function or passed as a parameter. This will result in a NameError when the function is called, making it non-functional in its current state. Without additional context or modifications to define 'n', the function does not serve a practical purpose."
survived,"def sum3(a: int, b: int, c: int) -> int:
    return a + b + c
",tests/human/x/python/fun_three_args.py,,1,4.363462233903899e-09,"The method 'sum3' is a simple utility function that takes three integers as input and returns their sum. Such utility functions are commonly used in programming for basic arithmetic operations. The function is straightforward, has a clear purpose, and is likely to be useful in various contexts where summing three numbers is needed. There are no apparent issues with the implementation, and it serves a fundamental purpose, which suggests that it will be retained in the codebase."
survived,"def test_describe_model_with_literal_type():
    """"""Test describe_model with Literal field types.""""""
    app = EnrichMCP(""Enum API"", description=""A model with Literal fields"")

    @app.entity(description=""Entity using Literal"")
    class Item(EnrichModel):
        status: Literal[""pending"", ""complete""] = Field(description=""Item status"")

    description = app.describe_model()

    assert ""## Item"" in description
    assert ""- **status** (Literal): Item status"" in description",tests/test_model_description.py,,1,6.023574641292144e-08,The method is a test function that verifies the functionality of the 'describe_model' method in a specific context. It is useful for ensuring that the 'describe_model' method correctly handles models with Literal field types. Test functions are generally retained as they are crucial for maintaining code quality and reliability through automated testing.
survived,"    def get_help(self, ctx: click.Context) -> str:  # pragma: no cover - CLI
        help_text = super().get_help(ctx)
        return f""{DISCLAIMER}\n\n{help_text}""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,DisclaimerGroup,1,4.599055376537186e-10,"The method `get_help` is a simple override of a superclass method to prepend a disclaimer to the help text. This is a common pattern in CLI applications to provide additional context or legal information. The method is straightforward, serves a clear purpose, and is likely to be useful for maintaining consistent messaging across command-line interfaces. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def test_call_summary_deep_merge(client):
    @weave.op()
    def my_op():
        call = call_context.get_current_call()
        call.summary[""nested""] = {""foo"": 1}
        return ""done""

    my_op()
    calls = list(client.get_calls())
    assert len(calls) == 1
    summary = calls[0].summary
    assert summary[""nested""][""foo""] == 1
    assert summary[RESERVED_SUMMARY_STATUS_COUNTS_KEY][tsi.TraceStatus.SUCCESS] == 1",tests/trace/test_current_call.py,,1,1.955568070542584e-08,"The method 'test_call_summary_deep_merge' is a test function that verifies the behavior of a specific operation within a system. Test functions are generally crucial for ensuring code reliability and correctness, especially in a development environment. This function checks if the summary of a call is correctly updated and if the status counts are accurate. Such tests are essential for maintaining the integrity of the codebase, and therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"def test_call_attributes_update_and_delete_forbidden(client):
    @weave.op()
    def my_op():
        call = call_context.get_current_call()
        with pytest.raises(TypeError):
            call.attributes.update({""extra"": 1})
        with pytest.raises(TypeError):
            del call.attributes[""weave""]
        return 1

    with weave.attributes({""env"": ""prod""}):
        my_op()
    calls = list(client.get_calls())
    assert len(calls) == 1
    # Original attribute is preserved
    assert calls[0].attributes[""env""] == ""prod""
    assert ""extra"" not in calls[0].attributes
",tests/trace/test_current_call.py,,1,3.3982678079468468e-09,"The method is testing a specific functionality related to the immutability of call attributes in a system. It ensures that attempts to update or delete attributes raise a TypeError, which is a critical part of maintaining the integrity of the system's state. Such tests are essential for verifying that the system behaves as expected and prevents unauthorized modifications. Therefore, this method is likely to be retained as it serves an important role in the testing suite."
survived,"def test_simulate_sets_llama_path() -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio""):
        with patch.object(cli.orchestrator, ""Orchestrator""):
            result = runner.invoke(
                cli.main,
                [
                    ""simulate"",
                    ""--horizon"",
                    ""1"",
                    ""--offline"",
                    ""--llama-model-path"",
                    ""weights.bin"",
                ],
            )
    assert result.exit_code == 0
    assert os.environ.get(""LLAMA_MODEL_PATH"") == ""weights.bin""
",tests/test_demo_cli.py,,1,2.7894680920908113e-10,"The method 'test_simulate_sets_llama_path' is a unit test function that verifies the behavior of a command-line interface (CLI) command. It uses the 'CliRunner' to invoke the CLI command and checks if the environment variable 'LLAMA_MODEL_PATH' is set correctly. This is a typical pattern for testing CLI applications, ensuring that the command behaves as expected. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained in the codebase."
survived,"        async def get_event():
            gen = demo.experience_stream()
            return await anext(gen)
",tests/test_era_experience.py,TestEraOfExperience,1,7.582560422162384e-10,"The method 'get_event' is an asynchronous function that retrieves the next item from an asynchronous generator 'experience_stream'. This pattern is common in modern Python applications that deal with asynchronous data streams, such as web applications or data processing pipelines. The use of 'await anext(gen)' is a valid and efficient way to handle asynchronous iteration. Given the increasing adoption of asynchronous programming in Python, this method is likely to be useful and relevant, thus it will survive."
survived,"def safe_eval(expression: str) -> float:
    tree = ast.parse(expression, mode=""eval"")
    allowed = (
        ast.Expression,
        ast.BinOp,
        ast.UnaryOp,
        ast.Constant,
        ast.Add,
        ast.Sub,
        ast.Mult,
        ast.Div,
        ast.Pow,
        ast.USub,
        ast.Load,
    )
    for n in ast.walk(tree):
        if not isinstance(n, allowed):
            raise ValueError(""Unsupported expression"")
    return _eval_node(tree.body)
",tests/test_safe_eval_security.py,,1,6.023574641292144e-08,"The method 'safe_eval' is designed to safely evaluate mathematical expressions by parsing them into an abstract syntax tree (AST) and ensuring that only a limited set of operations and nodes are allowed. This is a common approach to prevent code injection and ensure security when evaluating user-provided expressions. Given the importance of security in software development, especially when dealing with user inputs, this method is likely to be retained. It provides a controlled environment for expression evaluation, which is a valuable feature in many applications."
survived,"def test_init_creates_manager(monkeypatch):
    fake_cls = MagicMock()
    fake_instance = MagicMock()
    fake_cls.return_value = fake_instance
    monkeypatch.setattr(exec_mod, ""SandboxManager"", fake_cls)
    module = ExecutionModule()
    assert module.sandbox_manager is fake_instance
",tests/unit/test_execution_module.py,,1,2.2159489282323004e-08,"The method `test_init_creates_manager` is a unit test function that uses the `monkeypatch` fixture to replace the `SandboxManager` class in the `exec_mod` module with a mock object. This is a common practice in testing to isolate the unit of work and ensure that the test does not depend on the actual implementation of `SandboxManager`. The test then verifies that the `ExecutionModule` initializes its `sandbox_manager` attribute with an instance of the mocked `SandboxManager`. This is a valid and useful test to ensure that the `ExecutionModule` is correctly initializing its dependencies. Therefore, the method is likely to be Survived (1) as it serves a clear purpose in testing the initialization logic of the `ExecutionModule`."
survived,"def main() -> int:
    repo_root = Path(__file__).resolve().parents[1]
    snippet_path = repo_root / ""docs"" / ""DISCLAIMER_SNIPPET.md""
    disclaimer_text = snippet_path.read_text(encoding=""utf-8"").splitlines()[0].strip()

    missing: list[Path] = []
    for path in repo_root.rglob(""*.md""):
        if path == snippet_path or "".git"" in path.parts:
            continue
        try:
            first_line = path.read_text(encoding=""utf-8"").splitlines()[0].strip()
        except Exception:
            first_line = """"
        if ""docs/DISCLAIMER_SNIPPET.md"" not in first_line and not first_line.startswith(disclaimer_text):
            missing.append(path)

    if missing:
        print(""Missing disclaimer snippet in the following files:"", file=sys.stderr)
        for p in missing:
            print(f""  {p.relative_to(repo_root)}"", file=sys.stderr)
        return 1
    return 0
",scripts/verify_disclaimer_snippet.py,,1,6.69158608681505e-10,"The method is a utility function that checks for the presence of a disclaimer snippet in markdown files within a repository. It is useful for ensuring compliance with documentation standards, which is a common requirement in many projects. The function is well-structured, handles exceptions, and provides clear output, making it a valuable tool for maintaining documentation quality. Therefore, it is likely to be retained in the codebase."
survived,"def test_maybe_await_sync():
    result = asyncio.run(maybe_await(_sync_fn, 5))
    assert result == 6
",tests/test_agent_runner_utils.py,,1,1.8553915987649156e-07,"The method `test_maybe_await_sync` is a test function that uses `asyncio.run` to execute an asynchronous function `maybe_await` with a synchronous function `_sync_fn` and an argument `5`. The test checks if the result is `6`, which suggests that `_sync_fn` is expected to return `6` when called with `5`. This test is likely part of a test suite to ensure that `maybe_await` correctly handles synchronous functions. Test functions are generally important for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely that this method will be retained as part of the test suite."
survived,"def best_alpha(signals: Dict[str, str]) -> str:
    """"""Select the most actionable alpha message.""""""
    yc = signals.get(""yield_curve"", """")
    sc = signals.get(""supply_chain"", """")

    # simple heuristics
    if ""bottleneck"" in sc.lower():
        return sc
    if ""long bonds"" in yc.lower():
        return yc
    return yc if yc else sc
",alpha_factory_v1/demos/era_of_experience/alpha_report.py,,1,8.592166611791576e-10,"The method 'best_alpha' is a simple utility function that selects a message based on certain keywords in a dictionary of signals. It is straightforward, has a clear purpose, and is likely useful in contexts where such signal processing is needed. There is no indication that it is obsolete or redundant, and it seems to fulfill its intended function effectively. Therefore, it is likely to be retained."
survived,"async def trigger_opportunity() -> str:
    resp = requests.post(f""{HOST}/agent/alpha_opportunity/trigger"", timeout=5)
    resp.raise_for_status()
    return ""alpha_opportunity queued""
",alpha_factory_v1/demos/alpha_agi_business_v1/openai_agents_bridge.py,,0,0.9999999123575085,"The method 'trigger_opportunity' is likely to be deleted because it uses the 'requests' library in an asynchronous function without using an asynchronous HTTP client like 'aiohttp'. This can lead to blocking behavior, which is not ideal in an asynchronous context. To properly handle asynchronous HTTP requests, the function should be refactored to use an appropriate library that supports async operations."
survived,"def _list_agents() -> list[str]:
    resp = requests.get(f""{HOST}/agents"", timeout=5)
    resp.raise_for_status()
    return resp.json()
",alpha_factory_v1/demos/alpha_agi_business_v1/gradio_dashboard.py,,1,3.581747929000289e-10,"The method '_list_agents' is a private method (indicated by the underscore prefix) that fetches a list of agents from a specified host. It uses the 'requests' library to make an HTTP GET request and handles potential errors with 'raise_for_status'. The method is straightforward, functional, and follows good practices for error handling and type hinting. There is no indication of redundancy or inefficiency that would necessitate its deletion. Therefore, it is likely to survive."
survived,"    def test_launcher_compiles(self) -> None:
        path = Path('alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py')
        py_compile.compile(path, doraise=True)
",tests/test_alpha_business_v1_script.py,TestAlphaBusinessV1Script,1,3.850741907939403e-09,"The method `test_launcher_compiles` is a simple test function that checks if a specific Python script can be compiled without syntax errors. It uses the `py_compile` module to attempt to compile the script located at a given path. This is a basic but useful test to ensure that the script is syntactically correct, which is a common requirement in many codebases. The method is straightforward, does not have any apparent issues, and serves a clear purpose in a testing context. Therefore, it is likely to be retained in the codebase."
survived,"def _set_business_host(host: str) -> None:
    """"""Propagate the orchestrator base URL to the bridge module.

    This helper updates the ``BUSINESS_HOST`` environment variable and
    mirrors the value inside :mod:`openai_agents_bridge` when that module
    is available.  It keeps the launcher functional even when the bridge
    was imported prior to setting the environment variable.
    """"""

    os.environ[""BUSINESS_HOST""] = host
    try:  # soft dependency
        from alpha_factory_v1.demos.alpha_agi_business_v1 import (
            openai_agents_bridge,
        )

        openai_agents_bridge.HOST = host
    except Exception:
        pass
",alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_local.py,,1,1.6052280526088547e-09,"The method '_set_business_host' is likely to survive because it serves a specific purpose of setting an environment variable and updating a module's attribute if available. This functionality is useful for ensuring that the system's configuration is consistent across different components. The method also handles the absence of the module gracefully with a try-except block, which makes it robust and less prone to errors. Such utility functions are often retained in codebases for their usefulness in managing configurations."
survived,"def test_metrics_update_during_sim() -> None:
    dist = Path(__file__).resolve().parents[1] / (
        ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist/index.html""
    )
    url = dist.as_uri()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.goto(url)
            page.wait_for_selector(""#controls"")
            page.wait_for_selector(""#simulator-panel"")
            page.evaluate(""document.querySelector('#simulator-panel #sim-gen').value=2"")
            page.evaluate(""document.querySelector('#simulator-panel #sim-pop').value=3"")
            page.click(""#simulator-panel #sim-start"")
            page.wait_for_function(""document.querySelector('#worker-time').textContent.includes('ms')"")
            page.wait_for_function(""document.querySelector('#heap').textContent !== ''"")
            page.wait_for_function(""document.querySelector('#fps-value').textContent.includes('fps')"")
            page.click('#simulator-panel #sim-cancel')
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")",tests/test_browser_ui.py,,1,2.699578619062706e-07,"The method `test_metrics_update_during_sim` is a test function that uses Playwright to automate a browser and test a web application. It is designed to ensure that certain elements and functionalities of the web application are working as expected. This type of test is crucial for maintaining the quality and reliability of web applications, especially those with complex user interfaces or simulations. Automated tests like this one help catch regressions and verify that updates do not break existing functionality. Therefore, it is unlikely to be deleted as it serves an important role in the development and maintenance process."
survived,"    def __init__(self, base_url: str):
        self._base_url = base_url
",tests/integrations/openai/test_openai_sdk.py,DummyClient,1,5.3157849718487075e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes, in this case, setting the base URL for an instance. There is no indication that this method is redundant or unnecessary, as it serves a clear purpose in setting up the initial state of an object. Therefore, it is unlikely to be deleted."
survived,"    async def dummy_fn(completion, **kwargs):
        captured.update(kwargs)
        return ""ok""
",tests/integrations/openai/test_openai_sdk.py,,1,1.1478768974997603e-05,"The method 'dummy_fn' is a simple asynchronous function that takes a 'completion' argument and any number of keyword arguments. It updates a 'captured' object with these keyword arguments and returns the string 'ok'. This function is generic and doesn't perform any specific or complex operations. It is likely used for testing or as a placeholder. Such functions are often kept in codebases for testing purposes or as a template for future development. Therefore, it is likely to survive unless the project undergoes significant refactoring or the function is no longer needed for its intended purpose."
survived,"        async def stop_merkle_task(self) -> None:
            pass
",tests/test_orchestrator.py,DummyLedger,0,0.9999993524053853,"The method `stop_merkle_task` is an asynchronous method that currently does nothing as it only contains a `pass` statement. This suggests that it might be a placeholder for future implementation. However, without any additional context or usage, it is difficult to determine its necessity. If the method is part of a larger class or module where stopping a Merkle task is a required operation, it might be implemented in the future. But if there is no plan to implement it or if it is not used anywhere, it might be deleted. Given the lack of implementation and context, it is more likely to be deleted."
survived,"        def Add(a, b):
            return a + b
",tests/transpiler/x/py/go_auto.py,testpkg,1,1.725782769012759e-08,"The method 'Add' is a simple utility function that performs a basic arithmetic operation, which is addition. Such functions are often retained because they encapsulate a common operation that might be reused in various parts of a codebase. Additionally, the function is correctly implemented and does not contain any errors or deprecated practices. Therefore, it is likely to be retained."
survived,"    def test_version_flag(self):
        args = _parse_with(['--version'])
        self.assertTrue(args.version)
",alpha_factory_v1/tests/test_cli.py,CliParseTest,1,1.1032560311263802e-09,"The method `test_version_flag` is a unit test that checks if the `--version` flag is correctly parsed and set to true. This is a common and necessary test to ensure that command-line arguments are handled properly. Such tests are crucial for maintaining the reliability of software, especially when dealing with user inputs. Therefore, it is unlikely to be deleted as it serves an important purpose in the codebase."
survived,"def test_cycle_emits_blocked_to_memory() -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    chaos = chaos_agent.ChaosAgent(bus, led, burst=1)
    guardian = safety_agent.SafetyGuardianAgent(bus, led)

    asyncio.run(chaos.run_cycle())
    topic, env = bus.published[0]
    assert topic == ""safety""

    asyncio.run(guardian.handle(env))
    assert bus.published[-1][0] == ""memory""
    assert bus.published[-1][1].payload[""status""] == ""blocked""",tests/test_chaos_agent.py,,1,9.237449576640118e-09,"The method 'test_cycle_emits_blocked_to_memory' is a unit test designed to verify the interaction between different components in a system, specifically testing the communication between a chaos agent and a safety guardian agent through a bus. The test checks if the correct messages are published to the bus and if the final status is 'blocked'. This kind of test is crucial for ensuring the reliability and correctness of the system's behavior, especially in systems involving safety and chaos testing. Therefore, it is likely to be retained as part of the test suite to ensure ongoing system integrity."
survived,"    def add(self, entry: ArchiveEntry) -> None:
        with Session(self.engine) as session:
            session.merge(_ArchiveRow(**dataclasses.asdict(entry)))
            session.commit()
",src/archive/db.py,ArchiveDB,1,3.581747929000289e-10,"The method 'add' is a straightforward implementation of adding an entry to a database using SQLAlchemy's session management. It uses the 'merge' function to either insert or update the entry, which is a common pattern in database operations. The method is concise, uses standard practices, and is likely part of a larger system that requires adding entries to an archive. There is no indication of redundancy or inefficiency that would warrant its deletion. Therefore, it is likely to survive."
survived,"    def add(self, meta: dict[str, Any], score: float) -> None:
        with sqlite3.connect(self.path) as cx:
            cx.execute(""INSERT INTO agents(meta, score) VALUES (?, ?)"", (json.dumps(meta), score))
",src/archive/__init__.py,Archive,1,3.3982678079468468e-09,"The method 'add' is a simple and straightforward implementation for inserting data into a SQLite database. It uses a context manager to handle the database connection, which is a good practice for ensuring that the connection is properly closed after the operation. The method also uses parameterized queries to prevent SQL injection, which is a security best practice. These factors suggest that the method is well-implemented and follows good coding practices, making it likely to survive."
survived,"    def __init__(self, path: str | Path) -> None:
        self.path = Path(path)
        self.engine = create_engine(f""sqlite:///{self.path}"")
        Base.metadata.create_all(self.engine)
        with Session(self.engine) as session:
            exists = session.query(_ArchiveRow).first() is not None
        if not exists:
            self._migrate_legacy()
",src/archive/db.py,ArchiveDB,1,2.0611536181902033e-09,"The method is likely to survive because it is part of the initialization process of a class, which is essential for setting up the database connection and ensuring the necessary tables are created. The use of type hinting and modern Python features like the union operator for type hints suggests that the code is up-to-date and follows good practices. Additionally, the method includes a migration step for legacy data, indicating that it is designed to handle both new and existing data scenarios, which is a valuable feature in software development."
survived,"def softmax(arr: np.ndarray) -> np.ndarray:
    exp = np.exp(arr - np.max(arr))
    return exp / exp.sum()
",tests/test_selector.py,,1,6.348800075736417e-09,"The method implements the softmax function, which is a fundamental operation in machine learning, particularly in neural networks for converting logits into probabilities. It is widely used and unlikely to be removed unless there is a significant issue with the implementation. The code appears correct and efficient, using numpy for vectorized operations, which is standard practice. Therefore, it is likely to be retained."
survived,"    def __init__(self, host: str, port: int, use_https: bool = False, level: LogLevel = LogLevel.DEBUG):
        super().__init__(level)
        self.host = host
        self.port = port
        self.use_https = use_https
",webscout/litlogger/handlers.py,NetworkHandler,1,1.955568070542584e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Additionally, the method includes parameters that allow for flexible configuration of the object, such as 'host', 'port', 'use_https', and 'level', which suggests it is designed to be versatile and useful in various contexts. Therefore, it is likely to be retained."
survived,"    def emit(self, message: str, level: LogLevel):
        if level < self.level:
            return
        with socket.create_connection((self.host, self.port), timeout=5) as sock:
            sock.sendall(message.encode() + b""\n"")",webscout/litlogger/handlers.py,TCPHandler,1,1.2501528648238603e-09,"The method 'emit' is likely to survive because it performs a specific and useful function: sending log messages over a network socket if the log level is appropriate. This is a common requirement in distributed systems where logs need to be centralized. The method is straightforward, uses standard library functions, and handles a common use case efficiently."
survived,"    def log(self, level: LogLevel, message: str):
        if self.async_mode:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                return asyncio.create_task(self._log_async(level, message))
            return loop.run_until_complete(self._log_async(level, message))
        self._log(level, message)
",webscout/litlogger/logger.py,Logger,1,2.998960815863541e-09,"The method 'log' is likely to survive because it provides a flexible logging mechanism that supports both synchronous and asynchronous operations. This is useful in modern applications where asynchronous programming is common, especially in environments like web servers or applications that handle I/O-bound tasks. The method checks if the event loop is running and appropriately handles the logging task, which is a good practice in asynchronous programming. Additionally, the method is versatile as it can handle both async and sync modes, making it adaptable to different use cases."
survived,"    def __init__(self, path: str, level: LogLevel = LogLevel.DEBUG, max_bytes: int = 0, backups: int = 0):
        super().__init__(level)
        self.path = Path(path)
        self.max_bytes = max_bytes
        self.backups = backups
        self._open()
",webscout/litlogger/handlers.py,FileHandler,1,1.1861120010657661e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and are unlikely to be deleted unless the entire class is being refactored or removed. Additionally, the method appears to be setting up important properties such as file path, logging level, and backup configurations, which are likely crucial for the functionality of the class."
survived,"    def __exit__(self, exc_type, exc, tb):
        if exc_type:
            self.exception(str(exc))
        return False",webscout/litlogger/logger.py,Logger,1,1.637377179507321e-07,"The method is a custom implementation of the __exit__ method, which is part of the context management protocol in Python. This method is crucial for handling exceptions and cleaning up resources when using the 'with' statement. The implementation here checks if an exception type is present and logs it using a method called 'exception'. This is a common pattern for resource management and exception handling, making it unlikely to be deleted unless the entire context management functionality is being removed or refactored, which is not indicated here."
survived,"        def json(self):
            return {""model_list"": sample}
",libs/core/kiln_ai/adapters/test_remote_config.py,FakeResponse,1,5.60279640614594e-09,"The method is a simple implementation that returns a dictionary with a key 'model_list' and a value 'sample'. Without additional context, it's difficult to determine its utility, but it seems to be a straightforward method for returning data in JSON format. Such methods are commonly used in applications to serialize data for APIs or other data interchange formats. Unless there is a specific reason to remove it, such as redundancy or a change in the data structure, it is likely to survive."
survived,"        def __init__(self, *_: object, **__: object) -> None:
            pass
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,OpenAIAgent,0,0.9914225143407716,"The method is a constructor that takes any number of positional and keyword arguments but does nothing with them, as it only contains a 'pass' statement. This is typically a placeholder or a base class constructor that is meant to be overridden by subclasses. If this is part of a larger framework or library where subclasses are expected to implement specific behavior, it might survive. However, if this is standalone or not overridden, it is likely to be deleted as it serves no functional purpose."
survived,"            def _decorator(func):
                return func
",tests/test_aiga_agents_import.py,TestAigaAgentsImport,1,4.785094849865141e-06,"The method _decorator is a simple function that takes another function as an argument and returns it unchanged. This is a basic implementation of a decorator pattern, which is a common and useful concept in Python for modifying or extending the behavior of functions or methods. Although this specific implementation does not alter the function in any way, it serves as a foundational example or placeholder for more complex decorators. Therefore, it is likely to be retained for educational purposes or as a starting point for further development."
survived,"    def findChildren(self, recursive=True):
        result = []
        for child in self.children:
            result.append(child)
            if recursive:
                result.extend(child.findChildren(recursive))
        return result
",tests/conftest.py,_Node,1,4.0586521248284276e-10,"The method 'findChildren' is a utility function that is likely to be useful in many contexts where a tree or hierarchical structure is involved. It provides a way to retrieve all children of a node, optionally in a recursive manner, which is a common requirement in data structures like trees. The method is simple, clear, and performs a necessary function without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    async def stop_merkle_task(self) -> None:
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:  # pragma: no cover - expected
                pass
            self._task = None
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,1.493094675974231e-10,"The method 'stop_merkle_task' is likely to survive because it performs a crucial task of stopping an asynchronous task safely. It checks if a task is running, cancels it, and handles the potential 'CancelledError' exception, ensuring that the task is properly cleaned up. This is a common pattern in asynchronous programming to manage tasks and resources efficiently, and it is unlikely to be removed unless the entire task management approach is refactored."
survived,"    def append(self, new_child: Union['Tag', NavigableString, str]) -> None:
        """"""Append a new child to this tag.""""""
        if isinstance(new_child, str):
            new_child = NavigableString(new_child)
        new_child.parent = self
        self.contents.append(new_child)
",webscout/scout/element.py,Tag,1,7.582560422162384e-10,"The method 'append' is a fundamental operation for modifying a data structure, specifically for adding elements to a list or collection. In this context, it is used to append a new child to a tag, which is a common operation in HTML/XML parsing and manipulation libraries like BeautifulSoup. The method is straightforward, performs a necessary function, and is unlikely to be removed unless there is a significant redesign of the library's API. Therefore, it is likely to survive."
survived,"def test_labels_allowed_characters():

    runner = ScenarioRunner(uri=GMT_DIR, uri_type='folder', filename='tests/data/usage_scenarios/labels_stress_allowed.yml', skip_unsafe=False, skip_system_checks=True, dev_cache_build=True, dev_no_sleeps=True, dev_no_metrics=True, dev_no_phase_stats=True)
    with Tests.RunUntilManager(runner) as context:
        context.run_until('setup_services')
        labels = get_labels()

        assert labels.get('TESTALLOWED') == 'alpha-num123_', Tests.assertion_info('TESTALLOWED label', labels)
        assert labels.get('test.label') == 'example.com', Tests.assertion_info('test.label label', labels)
        assert labels.get('OTHER_LABEL') == 'http://localhost:8080', Tests.assertion_info('OTHER_LABEL label', labels)
",tests/test_usage_scenario.py,,1,6.023574641292144e-08,"The method 'test_labels_allowed_characters' is a test function that verifies the correctness of label values in a scenario runner. It uses assertions to ensure that specific labels have expected values, which is a common practice in testing to catch errors and ensure code reliability. Test functions like this are crucial for maintaining software quality, especially in complex systems. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def test_schema_checker_network_alias():
    usage_scenario_name = 'schema_checker_valid_network_alias.yml'
    usage_scenario_path = os.path.join(CURRENT_DIR, '../data/usage_scenarios/schema_checker/', usage_scenario_name)
    with open(usage_scenario_path, encoding='utf8') as file:
        usage_scenario = yaml.safe_load(file)
    schema_checker = SchemaChecker(validate_compose_flag=True)
    schema_checker.check_usage_scenario(usage_scenario)
",tests/lib/test_schema_checker.py,,1,5.905303995456778e-10,"The method 'test_schema_checker_network_alias' is a test function that appears to be part of a testing suite for a 'SchemaChecker' class. It loads a YAML file containing a usage scenario, initializes a 'SchemaChecker' object, and then checks the usage scenario. This is a typical pattern for unit tests, which are crucial for ensuring code reliability and correctness. Since testing is an essential part of software development, especially for validating schema and configurations, this method is likely to be retained as part of the test suite."
survived,"        def _key(it):
            k = opts[""sortKey""](*it)
            if isinstance(k, (list, tuple, dict)):
                return str(k)
            return k
",tests/dataset/job/compiler/py/q8.py,,1,4.363462233903899e-09,"The method '_key' is a utility function that is likely used internally within a class or module to generate a key for sorting purposes. It is a private method (indicated by the underscore prefix) and seems to be a helper function for sorting operations based on a 'sortKey' function provided in the 'opts' dictionary. Such utility functions are common in codebases to encapsulate specific logic and are not typically deleted unless they are replaced by a more efficient or necessary alternative. Since it serves a specific purpose and there is no indication of redundancy or obsolescence, it is likely to survive."
survived,"def test_run_inference_raises_for_empty_glob(tmp_path):
    config = InferenceConfig(
        input_path=str(tmp_path),
        output_path=str(tmp_path / ""out""),
        model_name=""dummy"",
        model_type=""fasttext"",
        attribute_name=""test"",
    )

    with pytest.raises(FileNotFoundError):
        ray.get(run_inference.remote(config))",tests/test_classification_inference_empty_glob.py,,1,4.6911638017642294e-08,"The method `test_run_inference_raises_for_empty_glob` is a test function that checks if the `run_inference` function raises a `FileNotFoundError` when given an empty input path. This is a valid and useful test case to ensure that the `run_inference` function handles missing input files correctly. Test functions like this are crucial for maintaining code quality and ensuring that edge cases are handled properly. Therefore, it is likely to be retained in the codebase."
survived,"        async def run(self, *_: Any, **__: Any) -> Dict[str, Any]:
            return {""status"": ""error"", ""error"": ""agents SDK unavailable""}
",src/meta_agent/agents/guardrail_designer_agent.py,_Agent,0,0.9999997300421382,"The method is likely to be deleted because it returns a static error message indicating that a critical component ('agents SDK') is unavailable. This suggests that the method is not functional or useful in its current state, as it does not perform any meaningful operation or provide a successful outcome. Unless the 'agents SDK' becomes available or the method is updated to handle the absence of the SDK in a more productive way, it serves little purpose."
survived,"def _kafka_producer() -> Optional[KafkaProducer]:
    if not _KAFKA_BROKER or KafkaProducer is None:
        return None
    try:
        return KafkaProducer(
            bootstrap_servers=_KAFKA_BROKER,
            value_serializer=lambda v: v.encode() if isinstance(v, str) else v,
        )
    except Exception:  # noqa: BLE001
        logger.exception(""Kafka producer init failed"")
        return None
",alpha_factory_v1/backend/agents/registry.py,,1,5.905303995456778e-10,"The method _kafka_producer is likely to survive because it provides a crucial functionality of initializing a KafkaProducer, which is essential for applications that need to produce messages to a Kafka broker. The method includes error handling to manage exceptions during initialization, which is a good practice for robustness. Additionally, it checks for necessary conditions before attempting to create a producer, ensuring that it only proceeds when the environment is correctly set up. These factors indicate that the method is well-structured and serves an important purpose, making it unlikely to be deleted."
survived,"    def Gauge(name: str, desc: str, labels=None):  # type: ignore[misc]
        return _get_metric(_Gauge, name, desc, labels)
",alpha_factory_v1/backend/agents/registry.py,,1,5.905303995456778e-10,"The method 'Gauge' is a simple wrapper function that calls another function '_get_metric' with specific parameters. It is likely part of a larger codebase dealing with metrics or monitoring. The method is straightforward and serves a clear purpose, which suggests it is useful and not redundant. Therefore, it is likely to be retained in the codebase."
survived,"def list_agents(detail: bool = False):
    with _REGISTRY_LOCK:
        metas = sorted(AGENT_REGISTRY.values(), key=lambda m: m.name)
    return [m.as_dict() if detail else m.name for m in metas]
",alpha_factory_v1/backend/agents/registry.py,,1,2.4616969512093895e-10,"The method 'list_agents' is a utility function that retrieves and returns a list of agents from a registry. It provides an option to return detailed information or just the names of the agents. This kind of functionality is common in systems that manage multiple entities, and the method is simple, clear, and useful for accessing agent information. There is no indication that it is redundant or obsolete, so it is likely to be retained."
survived,"def _emit_kafka(topic: str, payload: str) -> None:
    if _PRODUCER is None:
        return
    try:
        _PRODUCER.send(topic, payload)
        _PRODUCER.flush()
    except Exception:  # noqa: BLE001
        logger.exception(""Kafka emit failed (topic=%s)"", topic)
",alpha_factory_v1/backend/agents/registry.py,,1,2.0611536181902033e-09,"The method `_emit_kafka` is likely to survive because it performs a specific and useful function: sending messages to a Kafka topic. This is a common requirement in systems that use Kafka for message brokering. The method includes error handling to log exceptions, which is a good practice for maintaining robustness in production systems. Additionally, the method checks if the producer is initialized before attempting to send messages, which prevents potential runtime errors. These factors suggest that the method is well-implemented for its purpose and is likely to be retained."
survived,"    def to_json(self) -> str:
        return json.dumps(self.as_dict(), separators=("","", "":""))
",alpha_factory_v1/backend/agents/registry.py,AgentMetadata,1,9.056076988852742e-11,"The method 'to_json' is a utility function that converts an object's dictionary representation to a JSON string. This is a common and useful functionality in many applications, especially those involving data serialization and API development. The method is concise, uses standard library functions, and follows a clear purpose. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"def _session() -> requests.Session:
    """"""Return a session with basic retry logic.""""""
    retry = Retry(total=3, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    s = requests.Session()
    s.mount(""https://"", adapter)
    s.mount(""http://"", adapter)
    return s
",scripts/download_hf_gpt2.py,,1,4.944450477491054e-09,"The method '_session' is a utility function that creates and returns a requests.Session object with retry logic. This is a common pattern used to handle transient network issues by retrying requests a few times before failing. The method is useful for ensuring more robust HTTP requests in applications that rely on network communication. Given its utility and the fact that it encapsulates a common and useful pattern, it is likely to be retained in the codebase."
survived,"def _benchmark_engine(
    engine: Engine,
    routes: list[tuple[Vertex, Vertex]],
    repetitions: int,
) -> tuple[list[float], int, dict]:
    """"""Benchmark a planning engine.""""""

    times: list[float] = []
    successful = 0

    for rep in range(repetitions):
        print(f""   Repetition {rep + 1}/{repetitions}..."")
        rep_start = time.time()

        for i, (start, goal) in enumerate(routes):
            route_start = time.time()
            try:
                result = engine.plan(start=start, goal=goal)
                if result.edges:
                    successful += 1
                times.append(time.time() - route_start)
            except Exception as e:  # pragma: no cover - diagnostic
                print(f""      Route {i + 1} failed: {e}"")
                continue

        print(f""      Completed in {time.time() - rep_start:.3f}s"")

    return times, successful, engine.get_stats()
",python/examples/osm_cache_performance_test.py,,1,2.998960815863541e-09,"The method '_benchmark_engine' is likely to survive because it serves a specific and useful purpose: benchmarking a planning engine. It collects performance data such as execution times and success rates, which are valuable for evaluating and optimizing the engine's performance. Additionally, the method is well-structured, handles exceptions, and provides diagnostic output, making it robust and informative for developers. These characteristics suggest that it is a useful utility function that is likely to be retained in the codebase."
survived,"async def test_broadcast_merkle_root_devnet_e2e() -> None:
    if os.getenv(""PYTEST_NET_OFF"") == ""1"" or not await _devnet_available():
        pytest.skip(""network disabled or devnet unreachable"")
    tmp = tempfile.TemporaryDirectory()
    ledger = Ledger(os.path.join(tmp.name, ""l.db""), rpc_url=""https://api.devnet.solana.com"", broadcast=True)
    env = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    ledger.log(env)
    try:
        await ledger.broadcast_merkle_root()
    finally:
        await ledger.stop_merkle_task()
        ledger.close()
        tmp.cleanup()",tests/test_ledger_devnet_e2e.py,,1,9.931195248674785e-08,"The method `test_broadcast_merkle_root_devnet_e2e` is an asynchronous test function that checks the broadcasting of a Merkle root to a devnet. It includes environment checks, resource management, and cleanup procedures, which are essential for testing in a networked environment. The method is likely to be retained because it serves a specific purpose in testing the functionality of broadcasting Merkle roots in a development network, which is crucial for ensuring the reliability and correctness of the system's operations in a blockchain context."
survived,"    def test_simulate_returns_series(self) -> None:
        try:
            import numpy as np  # noqa: F401
            import pandas as pd  # noqa: F401
        except ModuleNotFoundError:
            self.skipTest(""numpy/pandas not available"")
        sim = simulation_core.MonteCarloSimulator(n_paths=3, horizon=2)
        factors = sim.simulate(
            {
                ""yield_10y"": 4.0,
                ""yield_3m"": 4.5,
                ""stable_flow"": 10.0,
                ""es_settle"": 5000.0,
            }
        )
        self.assertIsInstance(factors, pd.Series)
        self.assertEqual(len(factors), 3)
        self.assertEqual(factors.name, ""es_factor"")
",tests/test_macro_sentinel.py,TestMacroSentinel,1,1.6052280526088547e-09,"The method `test_simulate_returns_series` is a unit test designed to verify the functionality of a Monte Carlo simulation. It checks if the simulation returns a pandas Series with specific properties. Unit tests are crucial for ensuring code reliability and correctness, especially in complex simulations. The method uses standard testing practices, such as checking the type and properties of the output. Therefore, it is likely to be retained as part of the test suite to ensure the simulation behaves as expected."
survived,"def parse_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser(description=""Alpha-Factory launcher"")
    ap.add_argument(""--dev"", action=""store_true"", help=""Enable dev mode"")
    ap.add_argument(""--preflight"", action=""store_true"", help=""Run environment checks and exit"")
    ap.add_argument(""--port"", type=int, help=""REST API port"")
    ap.add_argument(""--metrics-port"", type=int, help=""Prometheus metrics port"")
    ap.add_argument(""--a2a-port"", type=int, help=""A2A gRPC port"")
    ap.add_argument(""--enabled"", help=""Comma separated list of enabled agents"")
    ap.add_argument(""--loglevel"", default=""INFO"", help=""Log level"")
    return ap.parse_args()
",alpha_factory_v1/run.py,,1,1.725782769012759e-08,"The method 'parse_args' is a utility function that uses the argparse library to parse command-line arguments. This is a common and essential practice in Python applications that require configuration through command-line interfaces. The method is well-defined, providing options for development mode, preflight checks, and various port configurations, which are likely necessary for the application's operation. Given its utility and the fact that it is a standard way to handle command-line arguments, it is unlikely to be removed unless the application's configuration method changes significantly."
survived,"    def test_bridge_market_data_output(self) -> None:
        """"""Bridge handles CSV input and prints agent summary.""""""
        import tempfile

        with tempfile.NamedTemporaryFile(""w"", delete=False) as fh:
            fh.write(""1,2,3"")
            csv_file = fh.name

        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.openai_agents_bridge"",
                ""--episodes"",
                ""1"",
                ""--market-data"",
                csv_file,
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best agents"", result.stdout)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,2.646573631904765e-09,"The method 'test_bridge_market_data_output' is a unit test designed to verify the functionality of a specific feature in the codebase. Unit tests are crucial for ensuring code reliability and are typically maintained as part of the codebase to prevent regressions. The test checks if a subprocess runs successfully and produces the expected output, which is a common practice in testing. Therefore, it is likely to be retained."
survived,"def test_main_stops_a2a(monkeypatch) -> None:
    """"""`_A2A.stop()` should be called when the loop exits.""""""
    mod = importlib.import_module(MODULE)

    class DummySocket:
        def __init__(self) -> None:
            self.started = False
            self.stopped = False

        def start(self) -> None:
            self.started = True

        def stop(self) -> None:
            self.stopped = True

        def sendjson(self, *_a: object, **_kw: object) -> None:  # pragma: no cover - unused
            pass

    dummy = DummySocket()

    monkeypatch.setattr(mod, ""_A2A"", dummy)
    monkeypatch.setattr(mod, ""ADKClient"", None)

    async def _llm(_: float) -> str:
        return ""ok""

    monkeypatch.setattr(mod, ""_llm_comment"", _llm)

    asyncio.run(mod.main([""--cycles"", ""1"", ""--interval"", ""0""]))

    assert dummy.started
    assert dummy.stopped
",tests/test_alpha_agi_business_3_v1.py,,1,1.8553915987649156e-07,"The method `test_main_stops_a2a` is a unit test designed to verify that the `_A2A.stop()` method is called when the loop in the `main` function exits. This is a typical use case for unit tests, which are crucial for ensuring code reliability and correctness. The test uses a `DummySocket` class to simulate the behavior of the `_A2A` object and checks that the `start` and `stop` methods are called appropriately. This kind of test is essential for maintaining the integrity of the codebase, especially in asynchronous or event-driven applications. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def fake_run(
        cmd: list[str],
        repo_dir: str,
        *,
        image: str | None = None,
        mounts: dict[str, str] | None = None,
    ) -> tuple[int, str]:
        if ""pytest"" in cmd:
            res = subprocess.run(
                [""pytest"", ""-q"", ""--color=no""],
                cwd=repo_dir,
                capture_output=True,
                text=True,
            )
            return res.returncode, res.stdout + res.stderr
        if ""patch"" in cmd:
            ok, out = diff_utils.apply_diff(patch, repo_dir=repo_dir)
            return (0 if ok else 1), out
        return 0, """"
",tests/test_self_healer_sandbox.py,,1,1.6052280526088547e-09,"The method 'fake_run' is a utility function that simulates running commands in a repository directory. It handles specific commands like 'pytest' and 'patch', providing a controlled environment for testing or applying patches. Such utility functions are often useful in testing frameworks or development tools to abstract command execution and capture outputs. The method is well-defined, with clear input parameters and return values, making it a candidate for reuse in various contexts. Unless there is a significant change in the project's requirements or architecture, this method is likely to survive."
survived,"    def result_processor(
        self, dialect: Dialect, coltype: Any
    ) -> Callable[[list[float] | None], FloatVector | None]:
        def process(value: list[float] | None) -> FloatVector | None:
            return np.asarray(value, dtype=np.float32) if value is not None else None

        return process
",src/raglite/_typing.py,DuckDBVec,1,1.4166087846364157e-09,"The method 'result_processor' is a utility function that processes a list of floats into a NumPy array of type float32, or returns None if the input is None. This is a common pattern in data processing and scientific computing where efficient numerical operations are required. The method is well-defined, uses type hints, and leverages NumPy for efficient array handling, which is a standard practice in Python for numerical computations. Given its utility and the fact that it adheres to good coding practices, it is likely to be retained in the codebase."
deleted,"    def dot_distance(self, other: FloatVector) -> Operators:
        """"""Compute the dot product distance.""""""
        if self._is_postgres():
            return self.op(""<#>"", return_type=Float)(other)
        if self._is_duckdb():
            return func.array_negative_inner_product(self.expr, other)
        return self.op(""<#>"", return_type=Float)(other)
",src/raglite/_typing.py,EmbeddingComparator,1,4.599055376537186e-10,"The method 'dot_distance' is a specialized function that computes the dot product distance between two vectors, with specific implementations for different database systems (Postgres and DuckDB). This indicates that the method is tailored for a particular use case involving database operations, which is likely to be relevant and necessary for users working with these databases. Additionally, the method is concise and provides a clear utility, making it unlikely to be removed unless there is a significant change in the underlying database interaction requirements or a better abstraction is introduced. Therefore, it is more likely to survive."
survived,"def run(cmd: Sequence[str], **kwargs: Any) -> None:
    """"""Run ``cmd`` and raise ``CalledProcessError`` on failure.""""""
    print(""+"", "" "".join(cmd))
    subprocess.run(cmd, check=True, **kwargs)
",scripts/publish_demo_gallery.py,,1,5.60279640614594e-09,"The method 'run' is a utility function that wraps around 'subprocess.run' to execute a command and automatically raise an error if the command fails. This is a common pattern used to simplify error handling when running shell commands in Python. The method is concise, useful, and follows a clear purpose, making it likely to be retained in the codebase. Additionally, it includes a print statement for logging the command being executed, which is helpful for debugging purposes. There are no apparent issues or redundancies in the code that would necessitate its removal."
survived,"    def _get_metric(cls, name: str, desc: str):
        if name in getattr(REGISTRY, ""_names_to_collectors"", {}):
            return REGISTRY._names_to_collectors[name]
        return cls(name, desc)
",alpha_factory_v1/backend/agents/ping_agent.py,,1,2.0611536181902033e-09,"The method '_get_metric' is a utility function that checks if a metric with a given name already exists in a registry. If it does, it returns the existing metric; otherwise, it creates a new one. This kind of functionality is common in systems that manage resources or objects, ensuring that duplicates are not created unnecessarily. The method is likely to be useful in maintaining the integrity and efficiency of the registry system, and there is no indication that it is obsolete or redundant. Therefore, it is likely to survive."
survived,"def _subdir_url() -> str:
    remote = subprocess.check_output([""git"", ""config"", ""--get"", ""remote.origin.url""], text=True).strip()
    repo_path = remote.split(""github.com"")[-1].lstrip("":/"")
    repo_path = repo_path.removesuffix("".git"")
    org, repo = repo_path.split(""/"", 1)
    return f""https://{org}.github.io/{repo}/alpha_factory_v1/demos/""
",scripts/open_subdir_gallery.py,,1,1.522997951276035e-08,"The method '_subdir_url' is a utility function that constructs a URL based on the remote origin URL of a Git repository. It uses subprocess to retrieve the remote URL, processes it to extract the organization and repository name, and then formats a URL pointing to a specific path within a GitHub Pages site. This functionality is specific and useful for generating URLs for documentation or demo pages hosted on GitHub Pages. Since it serves a clear purpose and is likely used in a context where such URLs are needed, it is unlikely to be deleted unless the project structure or hosting strategy changes significantly."
survived,"def test_regression_guard(monkeypatch) -> None:
    alerts: list[str] = []
    monkeypatch.setattr(orchestrator.alerts, ""send_alert"", lambda m: alerts.append(m))
    runner = DummyRunner()
    runners = {""aiga_evolver"": runner}

    async def drive() -> float:
        guard = asyncio.create_task(orchestrator._regression_guard(runners))
        start = time.time()
        for v in [1.0, 0.7, 0.5, 0.3]:
            metrics.dgm_best_score.set(v)
            await asyncio.sleep(0.2)
        await asyncio.sleep(0.5)
        duration = time.time() - start
        guard.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await guard
        return duration

    dur = asyncio.run(drive())
    assert runner.task.cancelled
    assert dur < 10
    assert alerts
",tests/test_governance.py,,1,5.3157849718487075e-08,"The method 'test_regression_guard' is a test function that uses the 'monkeypatch' fixture to modify the behavior of the 'orchestrator.alerts.send_alert' method for testing purposes. It sets up a dummy runner and tests the '_regression_guard' function of the orchestrator to ensure it behaves correctly under certain conditions. The test checks that the runner's task is cancelled, the duration is less than 10 seconds, and that alerts are sent. This is a typical pattern for testing asynchronous code and ensuring that certain conditions are met, which is crucial for maintaining code quality and reliability. Therefore, it is likely to be retained as part of the test suite."
survived,"async def _regression_guard(runners: Dict[str, AgentRunner]) -> None:
    history: deque[float] = deque(maxlen=3)
    while True:
        await asyncio.sleep(1)
        try:
            sample = metrics.dgm_best_score.collect()[0].samples[0]
            score = float(sample.value)
        except Exception:  # pragma: no cover - metrics optional
            continue
        history.append(score)
        if (
            len(history) == 3
            and history[1] <= history[0] * 0.8
            and history[2] <= history[1] * 0.8
        ):
            runner = runners.get(""aiga_evolver"")
            if runner and runner.task:
                runner.task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await runner.task
            alerts.send_alert(""Evolution paused due to metric regression"")
            history.clear()
",alpha_factory_v1/backend/orchestrator.py,,1,1.725782769012759e-08,"The method '_regression_guard' is designed to monitor a specific metric and take action if a regression is detected. It uses a deque to keep track of the last three scores and checks if there is a significant drop in the scores. If such a drop is detected, it cancels a task and sends an alert. This functionality is crucial for maintaining the stability and performance of the system by preventing further actions when a regression is detected. Therefore, it is likely to be retained as it serves an important purpose in the system's operation."
survived,"        async def _run() -> None:
            while True:
                await asyncio.sleep(0.1)
",tests/test_governance.py,DummyRunner,1,2.5109990926928157e-08,"The method _run is an asynchronous function that contains an infinite loop with a sleep call. This pattern is often used for tasks that need to run continuously in the background, such as monitoring or polling tasks. Since it is a private method (indicated by the underscore) and serves a specific purpose, it is likely to be retained as part of the internal implementation of a class or module. Therefore, it is more likely to be Survived."
survived,"def test_manual_build_missing_tsc(tmp_path: Path) -> None:
    work = tmp_path / ""browser""
    shutil.copytree(BROWSER_DIR, work)
    # provide required .env
    (work / "".env"").write_text((BROWSER_DIR / "".env.sample"").read_text())
    (work / ""build"" / ""__init__.py"").touch()

    # scrub placeholder text to avoid asset download
    for sub in (""wasm"", ""wasm_llm""):
        d = work / sub
        if d.exists():
            for p in d.rglob(""*""):
                if p.is_file():
                    data = p.read_bytes().replace(b""placeholder"", b"""")
                    p.write_bytes(data)
    bundle = work / ""lib"" / ""bundle.esm.min.js""
    bundle.write_text(bundle.read_text().replace(""Placeholder"", """"))

    # isolate PATH with node only
    bin_dir = tmp_path / ""bin""
    bin_dir.mkdir()
    node = shutil.which(""node"")
    assert node
    os.symlink(node, bin_dir / ""node"")

    env = os.environ.copy()
    env[""PATH""] = str(bin_dir)

    result = subprocess.run(
        [sys.executable, ""manual_build.py""],
        cwd=work,
        capture_output=True,
        text=True,
        env=env,
    )
    assert result.returncode != 0
    assert ""TypeScript compiler not found"" in result.stderr",tests/test_manual_build_missing_tsc.py,,1,6.348800075736417e-09,"The method 'test_manual_build_missing_tsc' is a test function that checks for a specific failure condition: the absence of the TypeScript compiler. It is designed to ensure that the build process fails with a clear error message when the TypeScript compiler is missing. This is a valid and useful test case for maintaining the robustness of the build system, as it verifies that the system correctly handles missing dependencies. Therefore, it is likely to be retained in the codebase to prevent regressions and ensure proper error handling."
survived,"async def hb_watch(runners: Dict[str, AgentRunner]) -> None:
    while True:
        now = time.time()
        for n, r in runners.items():
            alive = int(now - r.last_beat < r.period * 3.0)
            MET_UP.labels(n).set(alive)
        await asyncio.sleep(5)
",alpha_factory_v1/backend/agent_runner.py,,1,2.0611536181902033e-09,"The method 'hb_watch' is an asynchronous function designed to monitor the heartbeat of a set of runners, which are instances of 'AgentRunner'. It periodically checks if each runner is alive based on the time since its last heartbeat and updates a metric accordingly. This kind of functionality is crucial in systems that require monitoring and ensuring the availability of services or components. The method is efficient, using asynchronous sleep to avoid blocking, and it integrates with a monitoring system (likely Prometheus) to update metrics. Given its utility in maintaining system reliability and performance, it is likely to be retained in the codebase."
survived,"    def publish(self, topic: str, msg: Dict[str, Any]) -> None:
        if self._producer:
            self._producer.send(topic, msg)
        else:
            assert self._queues is not None
            self._queues.setdefault(topic, asyncio.Queue()).put_nowait(msg)
",alpha_factory_v1/backend/agent_runner.py,EventBus,1,2.998960815863541e-09,"The method 'publish' is likely to survive because it provides a clear and useful functionality for sending messages to a topic, either through a producer or by queuing them if the producer is not available. This flexibility is valuable in message-passing systems, ensuring that messages are not lost even if the producer is temporarily unavailable. The use of asyncio.Queue for queuing messages also suggests that this method is designed to work in an asynchronous environment, which is a common requirement in modern applications."
survived,"def utc_now() -> str:
    return datetime.now(timezone.utc).isoformat(timespec=""milliseconds"")
",alpha_factory_v1/backend/agent_runner.py,,1,8.592166611791576e-10,"The method `utc_now` is a simple utility function that returns the current UTC time in ISO 8601 format with millisecond precision. Such utility functions are commonly used in various applications for logging, timestamping, or synchronizing events across different systems. The function is concise, uses standard library functions, and provides a useful feature that is likely to be needed in many contexts. Therefore, it is unlikely to be deleted as it serves a clear purpose and is implemented efficiently."
survived,"    def _calc_next(self) -> None:
        now = time.time()
        if self.spec:
            with contextlib.suppress(ModuleNotFoundError, ValueError):
                from croniter import croniter  # type: ignore

                self.next_ts = croniter(self.spec, datetime.fromtimestamp(now)).get_next(float)
                return
        self.next_ts = now + self.period
",alpha_factory_v1/backend/agent_runner.py,AgentRunner,1,1.1032560311263802e-09,"The method `_calc_next` is likely to survive because it contains logic to calculate the next timestamp based on a cron specification or a default period. This functionality is essential for scheduling or timing operations, which is a common requirement in many applications. Additionally, the use of `contextlib.suppress` to handle potential import errors suggests that the method is designed to be robust and adaptable, further indicating its utility and likelihood of being retained."
survived,"                    def __init__(self) -> None:
                        self.nodes: set[str] = set()
                        self._edges: list[tuple[str, str, str, dict[str, Any]]] = []
",alpha_factory_v1/backend/memory_graph.py,GraphMemory._Stub,1,1.637377179507321e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state, such as attributes or data structures. The presence of attributes like 'nodes' and '_edges' suggests that this constructor is setting up important data structures for the class. Therefore, it is unlikely to be deleted as it is crucial for the proper functioning of the class."
survived,"    def model_dump(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:
        """"""Return model data as a dictionary across Pydantic versions.""""""
        base = getattr(super(), ""model_dump"", None)
        if callable(base):
            return base(*args, **kwargs)
        return self.dict(*args, **kwargs)
",src/meta_agent/models/spec_schema.py,SpecSchema,1,3.850741907939403e-09,"The method 'model_dump' is designed to provide a consistent way to return model data as a dictionary across different versions of Pydantic. It first checks if the superclass has a 'model_dump' method and calls it if available, ensuring compatibility with newer versions of Pydantic that might introduce this method. If not, it falls back to using 'self.dict', which is a standard way to convert Pydantic models to dictionaries. This approach ensures backward compatibility and future-proofs the code against changes in Pydantic. Therefore, the method is likely to be useful and relevant, leading to its survival."
survived,"        def model_dump(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:
            ...
",src/meta_agent/models/spec_schema.py,_ModelDumpProtocol,1,2.7894680920908113e-10,"The method `model_dump` is likely to be a utility function for serializing or exporting the state of a model object into a dictionary format. Such methods are commonly used in object-oriented programming to facilitate data interchange, debugging, or logging. Given its utility, it is unlikely to be deleted unless it is replaced by a more efficient or standardized method. Without additional context indicating redundancy or obsolescence, the method is likely to survive."
survived,"async def lifespan(app: EnrichMCP) -> AsyncIterator[dict[str, Any]]:
    async with httpx.AsyncClient(base_url=BACKEND_URL) as client:
        yield {""client"": client}
",examples/shop_api_gateway/app.py,,1,1.2501528648238603e-09,"The method 'lifespan' is an asynchronous generator function that sets up an HTTP client using 'httpx.AsyncClient' with a specified base URL. It then yields a dictionary containing the client. This pattern is useful for managing resources that need to be cleaned up after use, such as network connections. The use of 'async with' ensures that the client is properly closed when the generator is done. This is a common and efficient pattern in asynchronous programming, especially in web applications or services that require HTTP requests. Therefore, the method is likely to be useful and relevant in its context, leading to its survival."
survived,"def format2(f):
    s = str(f)
    idx = indexOf(s, ""."")
    if idx < 0:
        s = s + "".00""
    else:
        need = idx + 3
        if len(s) > need:
            s = s[0:need]
        else:
            while len(s) < need:
                s = s + ""0""
    return s
",tests/rosetta/transpiler/Python/box-the-compass.py,,1,0.004070137768748687,"The method 'format2' is designed to format a floating-point number into a string with two decimal places. However, the implementation has a flaw: it uses 'indexOf', which is not a valid method for strings in Python. Instead, it should use 'find'. This error suggests that the code may not function as intended in its current form. Despite this, the core logic of the method is sound, and with a minor correction, it can be functional. Therefore, the method is likely to survive with modifications, as the concept it implements is useful for formatting numbers."
survived,"def main():
    n = True
    print((""true"" if n else ""false""))
    print(""bool"")
    n = not n
    print((""true"" if n else ""false""))
    x = 5
    y = 8
    print(""x == y:"", (1 if x == y else 0))
    print(""x < y:"", (1 if x < y else 0))
    print(""\nConvert String into Boolean Data type\n"")
    str1 = ""japan""
    print(""Before :"", ""string"")
    bolStr = parseBool(str1)
    print(""After :"", ""bool"")
",tests/rosetta/transpiler/Python/boolean-values.py,,0,0.999999694097641,"The method is likely to be deleted because it contains a call to an undefined function `parseBool`, which will result in a runtime error. Additionally, the method lacks a clear purpose or functionality beyond basic boolean operations and comparisons, which are not particularly useful or novel. Without fixing the undefined function or adding meaningful functionality, the method does not provide value and is likely to be removed."
survived,"def stringSearch(h, n):
    result = []
    start = 0
    hlen = len(h)
    nlen = len(n)
    while start < hlen:
        idx = indexOfStr(h[start:hlen], n)
        if idx >= 0:
            result = result + [start + idx]
            start = start + idx + nlen
        else:
            break
    return result
",tests/rosetta/transpiler/Python/boyer-moore-string-search.py,,0,0.9999485577825553,"The method 'stringSearch' is a custom implementation to find all occurrences of a substring 'n' within a string 'h'. It uses a helper function 'indexOfStr' to find the index of the substring starting from a given position. The method is straightforward and performs a task that is commonly needed in string processing.

However, the method has a few issues:
1. It relies on an undefined function 'indexOfStr', which is not provided in the code. This makes the function incomplete and non-functional as it stands.
2. The method can be replaced by Python's built-in 'str.find()' or 'str.index()' methods, which are more efficient and reliable.
3. The method uses a list concatenation approach (result = result + [start + idx]) which is less efficient than using 'append'.

Given these points, the method is likely to be deleted or refactored in favor of using built-in string methods that are more efficient and do not require additional helper functions."
survived,"def bigrat(a, b):
    return (Fraction(a)) // (Fraction(b))
",tests/rosetta/transpiler/Python/calkin-wilf-sequence.py,,1,0.006692851410316465,"The method 'bigrat' is designed to perform integer division on two fractions, which is a valid and potentially useful operation. However, the use of 'Fraction' without importing it from the 'fractions' module will cause an error. Assuming the necessary import is added, the function is simple and performs a specific task that could be useful in certain contexts. Therefore, it is likely to be retained if the import issue is resolved."
survived,"def indexOf(s, ch):
    i = 0
    while i < len(s):
        if s[i:i + 1] == ch:
            return i
        i = i + 1
    return -1
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,,0,0.9999962733608834,"The method 'indexOf' is a custom implementation of a common string operation that is already provided by Python's standard library. Python strings have a built-in method 'find' which performs the same task more efficiently and is more idiomatic. The custom method does not offer any additional functionality or performance benefits over the built-in method. Therefore, it is likely to be deleted in favor of using the built-in 'find' method, which is more concise and widely understood by Python developers."
survived,"def main():
    go1 = ""hello C""
    c2 = strdup(go1)
    print(c2)
",tests/rosetta/transpiler/Python/call-a-foreign-language-function.py,,0,0.9999998874648162,"The method is likely to be deleted because it uses the function `strdup`, which is not a built-in function in Python. `strdup` is a C library function used to duplicate strings, and it is not directly available in Python. This code will result in a NameError unless `strdup` is defined elsewhere in the code, which is not shown here. Therefore, without additional context or imports, this method is not functional in Python and is likely to be removed or rewritten."
survived,"def partialSum(x):
    return lambda y: mysum(x, y)
",tests/rosetta/transpiler/Python/call-a-function-12.py,,0,0.999915188952306,"The method 'partialSum' is a higher-order function that returns a lambda function. This lambda function takes a single argument 'y' and calls another function 'mysum' with 'x' and 'y' as arguments. However, the function 'mysum' is not defined within the provided code snippet, which makes 'partialSum' incomplete and non-functional on its own. Without the definition of 'mysum', this method cannot be used effectively, leading to potential confusion or errors. Therefore, it is likely to be deleted unless 'mysum' is defined elsewhere in the codebase."
survived,"def shiftRune(r, k):
    if r >= ""a"" and r <= ""z"":
        return chr(((ord(r) - 97 + k) % 26) + 97)
    if r >= ""A"" and r <= ""Z"":
        return chr(((ord(r) - 65 + k) % 26) + 65)
    return r
",tests/rosetta/transpiler/Python/caesar-cipher-1.py,,1,6.023574641292144e-08,"The method 'shiftRune' is a utility function that shifts a given character by 'k' positions in the alphabet, wrapping around if necessary. It handles both lowercase and uppercase letters, returning the character unchanged if it is not a letter. This functionality is useful for tasks like implementing a Caesar cipher, which is a common educational example in programming. The method is simple, efficient, and serves a clear purpose, making it likely to be retained in a codebase where such functionality is needed."
survived,"    def New():
        global sn
        sn = sn + 1
        b = Box(secret=sn)
        if sn == 1:
            b = dataclasses.replace(b, Contents=""rabbit"")
        else:
            if sn == 2:
                b = dataclasses.replace(b, Contents=""rock"")
        return b
",tests/rosetta/transpiler/Python/call-an-object-method-2.py,,0,0.9999980052698925,"The method 'New' is likely to be deleted because it uses a global variable 'sn' without initializing it within the function or ensuring it is initialized elsewhere. This can lead to errors if 'sn' is not defined before calling 'New'. Additionally, the logic for setting the 'Contents' of 'b' is not scalable or flexible, as it only handles specific cases for 'sn' values of 1 and 2. This lack of robustness and potential for errors suggests that the method may be removed or significantly refactored."
survived,"def primesUpTo(n):
    sieve = []
    i = 0
    while i <= n:
        sieve = sieve + [True]
        i = i + 1
    p = 2
    while p * p <= n:
        if sieve[p]:
            m = p * p
            while m <= n:
                sieve[m] = False
                m = m + p
        p = p + 1
    res = []
    x = 2
    while x <= n:
        if sieve[x]:
            res = res + [x]
        x = x + 1
    return res
",tests/rosetta/transpiler/Python/brilliant-numbers.py,,1,2.699578619062706e-07,"The method 'primesUpTo' is a basic implementation of the Sieve of Eratosthenes algorithm, which is a well-known and efficient algorithm for finding all prime numbers up to a given limit. The code is functional and correctly implements the algorithm, albeit with some inefficiencies such as using list concatenation instead of appending, which can be optimized. However, the core logic is sound and the method serves a useful purpose in generating prime numbers. Therefore, it is likely to be retained and potentially optimized rather than deleted."
survived,"def ord(ch):
    upper = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ""
    lower = ""abcdefghijklmnopqrstuvwxyz""
    idx = indexOf(upper, ch)
    if idx >= 0:
        return 65 + idx
    idx = indexOf(lower, ch)
    if idx >= 0:
        return 97 + idx
    return 0
",tests/rosetta/transpiler/Python/caesar-cipher-2.py,,0,0.9999938558278723,"The method is a custom implementation of the built-in Python function `ord()`, which returns the Unicode code of a given character. However, this implementation is less efficient and more error-prone than using the built-in function. It manually checks for the character in uppercase and lowercase alphabets, which is unnecessary since `ord()` already handles this efficiently. Additionally, the method returns 0 for non-alphabetic characters, which is not the expected behavior of `ord()`. Given these inefficiencies and inaccuracies, it is likely that this method will be deleted in favor of using the built-in `ord()` function."
survived,"def fields(s):
    words = []
    cur = """"
    i = 0
    while i < len(s):
        ch = s[i:i + 1]
        if ch == "" "" or ch == ""\t"" or ch == ""\n"":
            if len(cur) > 0:
                words = words + [cur]
                cur = """"
        else:
            cur = cur + ch
        i = i + 1
    if len(cur) > 0:
        words = words + [cur]
    return words
",tests/rosetta/transpiler/Python/bulls-and-cows-player.py,,0,0.999999694097641,"The method 'fields' is a basic implementation of splitting a string into words based on whitespace characters. While it is functional, it is not efficient or idiomatic in Python. The same functionality can be achieved more concisely and efficiently using Python's built-in 'str.split()' method, which handles whitespace splitting by default. Therefore, this method is likely to be deleted in favor of using the built-in method."
survived,"def newFactory():
    sn = 0
    def New():
        global sn
        sn = sn + 1
        b = Box(secret=sn)
        if sn == 1:
            b = dataclasses.replace(b, Contents=""rabbit"")
        else:
            if sn == 2:
                b = dataclasses.replace(b, Contents=""rock"")
        return b
    def Count():
        return sn
    return [New, Count]
",tests/rosetta/transpiler/Python/call-an-object-method-2.py,,0,0.9999974387182097,"The method is likely to be deleted because it contains several issues that suggest it is not fully functional or useful in its current form. Firstly, the use of the global keyword for 'sn' is incorrect because 'sn' is defined in the outer function scope, not globally. Secondly, the 'dataclasses.replace' function is used without importing the 'dataclasses' module or defining a 'Box' class, which would lead to errors. Additionally, the logic for setting the 'Contents' of 'Box' is hardcoded and not flexible, limiting its utility. These issues indicate that the code is either incomplete or not well-designed, making it a candidate for deletion or significant revision."
survived,"    def Count():
        return sn
",tests/rosetta/transpiler/Python/call-an-object-method-2.py,,0,0.9999999468421502,"The method 'Count' is likely to be deleted because it references 'sn', which is not defined within the method or passed as a parameter. This will result in a NameError when the method is called, indicating that the code is incomplete or incorrect. Without additional context or corrections, the method does not serve a functional purpose."
survived,"def new(graphdb_filename, overwrite):
    """"""Create a new empty graph database.""""""
    if not os.path.exists(graphdb_filename) or overwrite:
        click.echo(f""Creating graph database '{graphdb_filename}'"")
        GraphDatabase(graphdb_filename, overwrite=overwrite)
    else:
        click.echo(
            f""Graph database '{graphdb_filename}' already exists. Use -o to overwrite""
        )
",pygs/graphserver/cli.py,,1,2.998960815863541e-09,"The method 'new' is a utility function that checks for the existence of a graph database file and either creates a new one or informs the user that it already exists. It includes an option to overwrite the existing file. This functionality is essential for managing graph databases, especially in applications where data persistence and management are crucial. The method is straightforward, performs a necessary check, and provides user feedback, making it a useful part of a larger system. Therefore, it is likely to be retained."
survived,"def test_tool_roundtrip(monkeypatch, tmp_path: Path) -> None:
    monkeypatch.setattr(manager, ""REPO_ROOT"", tmp_path)
    monkeypatch.setattr(""src.self_edit.tools.REPO_ROOT"", tmp_path)
    assert _tool_roundtrip()
",tests/test_archive_policy.py,,1,4.6911638017642294e-08,"The method 'test_tool_roundtrip' is a test function, likely part of a test suite for a software project. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. The function uses 'monkeypatch' to temporarily modify the behavior of the code under test, which is a common practice in testing to isolate the test environment. Additionally, it uses 'tmp_path', which is a fixture provided by pytest to create temporary directories, indicating that this test is designed to be clean and not affect the actual file system. Since the function seems to be a valid and useful test, it is likely to be retained."
survived,"    def __init__(self, db_path: str | Path) -> None:
        self.db = ArchiveDB(db_path)
",src/archive/manager.py,PatchManager,1,2.8453347280241004e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. They set up the initial state of an object, often by assigning values to instance variables. In this case, the constructor is initializing an instance of `ArchiveDB` with a given database path. Since constructors are fundamental to the creation of class instances, it is highly unlikely that this method would be deleted unless the entire class is being refactored or removed, which is not indicated here."
survived,"    def test_closes_on_channel_ready_timeout(self) -> None:
        channel = mock.Mock()
        channel.channel_ready = mock.AsyncMock(side_effect=asyncio.TimeoutError)
        channel.close = mock.AsyncMock()

        async def run() -> None:
            fake_workloadapi = types.SimpleNamespace(X509Source=object, WorkloadApiClient=object)
            with (
                mock.patch(""grpc.aio.insecure_channel"", return_value=channel),
                mock.patch.dict(sys.modules, {""workloadapi"": fake_workloadapi}),
            ):
                with self.assertRaises(asyncio.TimeoutError):
                    await _GrpcTransport.new(""svc:1"", spiffe_id=None, timeout=1.0)

        with mock.patch.dict(os.environ, {""A2A_INSECURE"": ""1""}, clear=False):
            asyncio.run(run())
        channel.close.assert_awaited_once()",tests/test_grpc_transport_timeout.py,TestGrpcTransport,1,2.5109990926928157e-08,"The method is a unit test designed to verify that a channel is closed when a timeout occurs during the channel readiness check. It uses mocking to simulate the behavior of the channel and the environment, ensuring that the test is isolated and does not depend on external factors. This kind of test is crucial for ensuring the robustness and reliability of the code, especially in handling timeout scenarios. Therefore, it is likely to be retained as part of the test suite to maintain code quality."
survived,"def set_notification_settings(settings):
    set_global_setting('notification_settings', settings)",users_db.py,,0,0.9999999530883621,"The method 'set_notification_settings' is a simple wrapper around another function 'set_global_setting'. It doesn't add any additional logic or functionality, making it redundant unless it is part of a larger interface or API where such a method is expected for consistency. Without additional context or usage, it is likely to be considered unnecessary and thus deleted."
survived,"def get_global_setting(key, default=None):
    conn = get_db()
    c = conn.cursor()
    c.execute('SELECT value FROM global_settings WHERE key=?', (key,))
    row = c.fetchone()
    conn.close()
    if row:
        try:
            return json.loads(row['value'])
        except Exception:
            return row['value']
    return default
",users_db.py,,1,1.4166087846364157e-09,"The method 'get_global_setting' is likely to survive because it performs a common and useful function of retrieving configuration settings from a database. This is a typical requirement in many applications where settings need to be dynamically fetched and possibly parsed from a JSON format. The method is straightforward, uses standard database operations, and includes error handling for JSON parsing, making it robust and reusable."
survived,"def problem_response(exc: HTTPException) -> JSONResponse:
    """"""Return an RFC 7807 compliant response for ``exc``.""""""

    try:
        title = HTTPStatus(exc.status_code).phrase
    except Exception:  # pragma: no cover - unknown status code
        title = str(exc.status_code)

    detail = (
        exc.detail if isinstance(exc.detail, str) else str(exc.detail) if exc.detail else """"
    )

    body: dict[str, Any] = {""type"": ""about:blank"", ""title"": title, ""status"": exc.status_code}
    if detail:
        body[""detail""] = detail

    return JSONResponse(status_code=exc.status_code, content=body)
",src/interface/problem_json.py,,1,6.69158608681505e-10,"The method `problem_response` is a utility function that generates an RFC 7807 compliant JSON response for HTTP exceptions. This is a common requirement in web applications to provide standardized error responses. The function is well-structured, handles exceptions gracefully, and uses the HTTPStatus module to retrieve status phrases, which is a good practice. Additionally, it constructs a response body that includes type, title, status, and detail fields, which are typical in problem details as per RFC 7807. Given its utility and compliance with standards, it is likely to be retained in the codebase."
survived,"def main():
    global seed
    print(eqIndices([-7, 1, 5, 2, -4, 3, 0]))
    verylong = []
    i = 0
    while i < 10000:
        seed = (seed * 1664525 + 1013904223) % 2147483647
        verylong = verylong + [seed % 1001 - 500]
        i = i + 1
    print(eqIndices(verylong))
",tests/rosetta/transpiler/Python/equilibrium-index.py,,0,0.999983298584886,"The method is likely to be deleted because it contains several issues that make it inefficient and potentially problematic. Firstly, the use of a global variable 'seed' without initialization within the function can lead to unpredictable behavior. Secondly, the method of list concatenation using 'verylong = verylong + [seed % 1001 - 500]' is inefficient for large lists, as it creates a new list each time, leading to high time complexity. A more efficient approach would be to use list.append() or a list comprehension. These issues suggest that the method is not well-optimized or robust, which are common reasons for code to be refactored or removed."
survived,"def powf(base, exp):
    r = 1.0
    i = 0
    while i < exp:
        r = r * base
        i = i + 1
    sys.exit(r)
",tests/rosetta/transpiler/Python/euler-method.py,,0,0.9999999997538302,"The method is likely to be deleted (0) because it contains a critical flaw: it uses sys.exit() to return the result, which is not a standard or appropriate way to return a value from a function. This will terminate the program instead of returning the result to the caller. Additionally, the function does not handle negative exponents or non-integer exponents, which limits its usability. These issues make the function impractical for use in most scenarios, leading to its potential deletion."
survived,"def listString(xs):
    s = ""[""
    i = 0
    while i < len(xs):
        s = s + str(xs[i])
        if i < len(xs) - 1:
            s = s + "" ""
        i = i + 1
    s = s + ""]""
    return s
",tests/rosetta/transpiler/Python/executable-library.py,,0,0.999998790133938,"The method 'listString' is a custom implementation to convert a list of elements into a string representation with elements separated by spaces and enclosed in square brackets. However, this functionality is already provided by Python's built-in 'str.join()' method and list comprehension, which are more efficient and concise. For example, the same functionality can be achieved with: '""["" + "" "".join(map(str, xs)) + ""]""'. Given that the method is redundant and less efficient compared to built-in alternatives, it is likely to be deleted in favor of using more standard and optimized approaches."
survived,"def absBig(x):
    if x < zero:
        sys.exit(zero - x)
    sys.exit(x)
",tests/rosetta/transpiler/Python/euclid-mullin-sequence.py,,0,0.9999999865595903,"The method 'absBig' is likely to be deleted because it uses 'sys.exit' to return values, which is unconventional and not practical for a function that is supposed to compute the absolute value of a number. Typically, functions should return values using the 'return' statement rather than terminating the program. Additionally, the variable 'zero' is not defined within the function, which would lead to a NameError. These issues suggest that the function is not well-implemented and may be removed or replaced with a more standard approach."
survived,"def parseBigInt(str):
    i = 0
    neg = False
    if len(str) > 0 and str[0:1] == ""-"":
        neg = True
        i = 1
    n = 0
    while i < len(str):
        ch = str[i:i + 1]
        d = int(ch)
        n = n * (10) + (d)
        i = i + 1
    if neg:
        n = -n
    sys.exit(n)
",tests/rosetta/transpiler/Python/even-or-odd.py,,0,0.9999999907625504,"The method 'parseBigInt' is likely to be deleted because it uses 'sys.exit(n)' to return the result, which is unconventional and not practical for a function that is supposed to parse a string into an integer. Exiting the program with the parsed integer as the exit code is not a typical or useful behavior for such a function. Instead, it should return the integer value. Additionally, the function lacks error handling for non-numeric strings, which makes it less robust. These issues suggest that the method is not well-designed for its intended purpose and is likely to be refactored or removed."
survived,"def padInt(f):
    s = str((int(f)))
    if f >= 0:
        return "" "" + s
    return s
",tests/rosetta/transpiler/Python/exponentiation-with-infix-operators-in-or-operating-on-the-base.py,,1,7.194132978569833e-09,"The method 'padInt' is a simple utility function that converts a float to an integer, then to a string, and pads it with a space if the number is non-negative. This kind of function can be useful in formatting numbers for display purposes, especially in contexts where alignment is important, such as in tables or lists. The function is straightforward, has a clear purpose, and does not have any obvious flaws or inefficiencies. Therefore, it is likely to be retained in the codebase."
survived,"def commatize(n):
    s = str(n)
    i = len(s) - 3
    while i >= 1:
        s = """".join(s[0:i]) + "","" + """".join(s[i:len(s)])
        i = i - 3
    sys.exit(s)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,0,0.9999938558278723,"The method 'commatize' is designed to insert commas into a number string for formatting purposes. However, it has a critical flaw: it uses 'sys.exit(s)' to return the result, which is not a standard or appropriate way to return a value from a function. This will terminate the program and is not suitable for a utility function. Additionally, the function does not handle negative numbers or decimal points, which are common in real-world applications. These issues make the function less useful and likely to be deleted or significantly refactored."
survived,"def perimEqual(p1, p2):
    if len(p1) != len(p2):
        return False
    for v in p1:
        if not v in p2:
            return False
    c = copyInts(p1)
    r = 0
    while r < 2:
        i = 0
        while i < len(p1):
            if sliceEqual(c, p2):
                return True
            t = c[len(c) - 1]
            j = len(c) - 1
            while j > 0:
                c[j] = c[j - 1]
                j = j - 1
            c[0] = t
            i = i + 1
        reverse(c)
        r = r + 1
    return False
",tests/rosetta/transpiler/Python/faces-from-a-mesh.py,,0,0.9999999677581336,"The method 'perimEqual' is likely to be deleted because it contains several issues that make it inefficient and potentially incorrect. Firstly, the function 'copyInts' is not defined within the provided code, which would lead to a runtime error. Secondly, the logic for checking if two lists are equal by rotating and reversing them is unnecessarily complex and inefficient. There are simpler and more efficient algorithms to check if two lists are permutations of each other. Additionally, the function 'sliceEqual' is also not defined, which would cause another runtime error. These issues suggest that the method is not well-implemented and is likely to be removed or replaced with a more efficient and correct solution."
survived,"def joinInts(xs):
    s = """"
    i = 0
    while i < len(xs):
        if i > 0:
            s = s + "" ""
        s = s + str(xs[i])
        i = i + 1
    return s
",tests/rosetta/transpiler/Python/extensible-prime-generator.py,,1,2.1444939769331175e-05,"The method joinInts is a simple utility function that concatenates a list of integers into a single string with spaces in between. While the function is functional, it is not the most efficient or Pythonic way to achieve this task. In Python, the join method is typically used for such operations, which is more efficient and concise. However, the function is straightforward and serves its purpose without any errors or issues. Given that it works correctly and there are no major flaws, it is likely to survive unless there is a strong push for optimization or refactoring to use more idiomatic Python code."
survived,"def reverse(xs):
    i = 0
    j = len(xs) - 1
    while i < j:
        t = xs[i]
        xs[i] = xs[j]
        xs[j] = t
        i = i + 1
        j = j - 1
",tests/rosetta/transpiler/Python/faces-from-a-mesh.py,,1,1.1253518384332553e-07,"The method 'reverse' is a straightforward implementation of reversing a list in place. It uses a two-pointer technique to swap elements from the start and end of the list until the pointers meet in the middle. This is a common and efficient algorithm for reversing a list, and it is implemented correctly without any apparent issues. Therefore, there is no reason to delete this method as it serves a useful purpose and is implemented correctly."
survived,"def harmonic(n):
    sum = 0.0
    i = 1
    while i <= n:
        sum = sum + 1.0 / (float(i))
        i = i + 1
    sys.exit(sum)
",tests/rosetta/transpiler/Python/eulers-constant-0.5772....py,,1,0.0007096703410211238,"The method is a simple implementation of calculating the harmonic number for a given integer n. However, it uses sys.exit() to return the result, which is unconventional and not a good practice for returning values from a function. Instead, it should return the sum directly. Despite this flaw, the core logic of the function is correct and useful for calculating harmonic numbers. Therefore, it is likely to be refactored rather than deleted, as the functionality is still relevant and can be easily corrected."
survived,"def endsWith(s, suf):
    if len(s) < len(suf):
        sys.exit(False)
    sys.exit(s[len(s) - len(suf):len(s)] == suf)
",tests/rosetta/transpiler/Python/file-extension-is-in-extensions-list.py,,0,0.9999999123575085,"The method `endsWith` is likely to be deleted for several reasons:

1. **Use of sys.exit:** The function uses `sys.exit` to return a boolean value, which is not a standard or appropriate way to return values from a function. `sys.exit` is used to terminate a program, not to return values from a function.

2. **Inefficient Implementation:** The function checks if a string ends with a suffix by slicing the string, which is less efficient than using Python's built-in `str.endswith()` method. The built-in method is more readable, efficient, and idiomatic.

3. **Lack of Flexibility:** The function does not handle cases where `s` or `suf` might be `None` or not strings, which could lead to errors.

4. **No Return Statement:** The function does not have a return statement, which is unconventional for a function that is supposed to return a boolean value.

Overall, the function is not implemented in a way that aligns with Python's best practices, making it a candidate for deletion or significant refactoring."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/fermat-numbers.py,,1,2.5109990926928157e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of _now_seeded. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def fib(a):
    if a < 2:
        return a
    return fib(a - 1) + fib(a - 2)
",tests/rosetta/transpiler/Python/fibonacci-sequence-1.py,,1,3.726639116582555e-06,"The method is a classic implementation of the Fibonacci sequence using recursion. While it is a correct implementation, it is not efficient for large inputs due to its exponential time complexity. However, it is a well-known example often used for educational purposes to demonstrate recursion. Given its educational value and correctness for small inputs, it is likely to be retained in contexts where performance is not a critical concern."
survived,"def interpret(ruleset, input):
    p = parseRules(ruleset)
    if not p.get(""ok""):
        sys.exit({""ok"": False, ""out"": """"})
    out = runRules(p.get(""rules""), input)
    sys.exit({""ok"": True, ""out"": out})
",tests/rosetta/transpiler/Python/execute-a-markov-algorithm.py,,0,0.9999998362622821,"The method 'interpret' is likely to be deleted because it uses 'sys.exit' to terminate the program, which is generally not a good practice for functions that are meant to be reused or integrated into larger systems. This approach makes it difficult to handle errors gracefully and can lead to unexpected termination of the entire program. Instead, it would be better to return a result or raise an exception that can be caught and handled by the caller."
survived,"def isEsthetic(n, b):
    if n == 0:
        sys.exit(False)
    i = n % b
    n = n // b
    while n > 0:
        j = n % b
        if uabs(i, j) != 1:
            sys.exit(False)
        n = n // b
        i = j
    sys.exit(True)
",tests/rosetta/transpiler/Python/esthetic-numbers.py,,0,0.9999999979388463,"The method is likely to be deleted (0) because it uses sys.exit() to return a boolean value, which is not a standard or efficient way to handle return values in Python. Using sys.exit() terminates the entire program, which is not appropriate for a function that is supposed to return a boolean result. Instead, the function should return True or False directly. This misuse of sys.exit() suggests that the method is not well-designed for its intended purpose, making it a candidate for deletion or significant refactoring."
survived,"def sliceEqual(a, b):
    i = 0
    while i < len(a):
        if a[i] != b[i]:
            return False
        i = i + 1
    return True
",tests/rosetta/transpiler/Python/faces-from-a-mesh.py,,1,6.962258425838873e-06,"The method 'sliceEqual' is a simple utility function that checks if two lists 'a' and 'b' are equal up to the length of the shorter list. It is a straightforward implementation of element-wise comparison, which is a common task in programming. The method is likely to survive because it serves a basic but useful purpose, and there are no apparent issues with its logic or implementation. It could be improved for efficiency or readability, but as it stands, it is functional and correct."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/file-input-output-1.py,,1,7.194132978569833e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of '_now_seeded'. Such utility functions are common in systems that need to simulate time or generate random numbers for testing or other purposes. The function is simple, serves a clear purpose, and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"async def seed(session: AsyncSession) -> None:
    user = User(id=1, name=""Alice"")
    orders = [Order(id=i, user=user) for i in range(1, 3)]
    session.add_all([user, *orders])
",tests/test_sqlalchemy_autogen_extra.py,,1,2.3823698451773172e-07,"The method 'seed' is a utility function designed to populate a database session with initial data. Such methods are typically used in development and testing environments to ensure that the database has the necessary data to function correctly. These methods are generally not deleted because they are useful for setting up test scenarios and ensuring consistent data states across different environments. Additionally, the method is asynchronous, which aligns with modern programming practices for handling I/O operations efficiently. Therefore, it is likely to be retained for its utility in development workflows."
survived,"    def _tool(*_a, **_k):
        def _decorator(func):
            return func

        return _decorator
",tests/test_agents_fallback.py,,1,4.1399375473943306e-08,"The method _tool is a decorator factory that returns a decorator function (_decorator) which, in turn, returns the original function without any modifications. This pattern is often used to create decorators that can be extended or modified later. Since it is a utility function that can be useful for future development, it is likely to be retained in the codebase."
survived,"        def _decorator(func):
            return func
",tests/test_agents_fallback.py,,0,0.999998790133938,"The method _decorator is a simple function that takes another function as an argument and returns it without any modification. This is a basic implementation of a decorator pattern, but it doesn't add any functionality or perform any operations on the function it decorates. While it is syntactically correct, its utility is limited unless it is intended to be a placeholder for future enhancements. If the codebase requires decorators with actual functionality, this method might be considered redundant and could be deleted. However, if it serves as a placeholder or is used for structural purposes, it might be retained. Without additional context, it is more likely to be deleted due to its lack of functionality."
survived,"    def test_history_after_evolve(self) -> None:
        """"""history() should return evolver history after evolve()""""""

        stub = types.ModuleType(""openai_agents"")
        stub.Agent = object
        stub.AgentRuntime = MagicMock()
        stub.OpenAIAgent = MagicMock()

        def _tool(*_a, **_k):
            def _decorator(func):
                return func

            return _decorator

        stub.Tool = _tool

        env_stub = types.ModuleType(""curriculum_env"")
        env_stub.CurriculumEnv = object

        evo_stub = types.ModuleType(""meta_evolver"")

        class DummyEvolver:
            def __init__(self, *a, **k) -> None:  # pragma: no cover - test stub
                pass

            def run_generations(self, *_a) -> None:  # pragma: no cover - test stub
                pass

            history = [(0, 0.0)]

        evo_stub.MetaEvolver = DummyEvolver

        adk_stub = types.ModuleType(""adk_bridge"")
        adk_stub.auto_register = lambda *_a, **_k: None
        adk_stub.maybe_launch = lambda *_a, **_k: None
        backend_stub = types.ModuleType(""backend"")
        backend_stub.adk_bridge = adk_stub

        with patch.dict(
            sys.modules,
            {
                ""openai_agents"": stub,
                ""alpha_factory_v1.demos.aiga_meta_evolution.curriculum_env"": env_stub,
                ""alpha_factory_v1.demos.aiga_meta_evolution.meta_evolver"": evo_stub,
                ""alpha_factory_v1.backend"": backend_stub,
                ""alpha_factory_v1.backend.adk_bridge"": adk_stub,
            },
        ):
            sys.modules.pop(
                ""alpha_factory_v1.demos.aiga_meta_evolution.utils"", None
            )
            sys.modules.pop(
                ""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"",
                None,
            )
            mod = importlib.import_module(
                ""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge""
            )

            dummy = MagicMock()
            dummy.history = [(1, 0.5)]
            dummy.latest_log.return_value = ""done""

            with patch.object(mod, ""EVOLVER"", dummy):
                asyncio.run(mod.evolve(1))
                result = asyncio.run(mod.history())
                self.assertEqual(result, {""history"": dummy.history})
                asyncio.run(mod.checkpoint())
                asyncio.run(mod.reset())
                agent = mod.EvolverAgent()
                asyncio.run(agent.policy({""gens"": 1}, None))
                self.assertIn(mod.history, mod.EvolverAgent.tools)

                runpy.run_module(
                    ""alpha_factory_v1.demos.aiga_meta_evolution.openai_agents_bridge"",
                    run_name=""__main__"",
                )
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime,1,2.2159489282323004e-08,"The method `test_history_after_evolve` is a unit test designed to verify the behavior of the `history` function after the `evolve` function is called. It uses mock objects and patches to simulate the environment and dependencies, which is a common practice in testing. The method is well-structured and serves a clear purpose in ensuring the functionality of the code it tests. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained."
survived,"    async def stop_merkle_task(self) -> None:  # pragma: no cover - stub
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_codegen_safety.py,DummyLedger,1,3.2887477414614998e-06,"The method `stop_merkle_task` is currently a stub, indicated by the `pass` statement and the `# pragma: no cover - stub` comment. This suggests that the method is intended to be implemented in the future. The presence of the method signature implies that it is part of a larger class or module where stopping a Merkle task is relevant. Since it is likely a placeholder for future functionality, it is more probable that the method will be implemented rather than deleted, especially if the surrounding codebase requires such functionality."
survived,"def softmax(arr: np.ndarray) -> np.ndarray:
    exp = np.exp(arr - np.max(arr))
    return exp / exp.sum()
",tests/test_selector_v2.py,,1,8.152020648014727e-09,"The method implements the softmax function, which is a fundamental operation in machine learning, particularly in neural networks for converting logits to probabilities. The code is concise, efficient, and correctly handles potential numerical stability issues by subtracting the maximum value in the array before exponentiation. This is a standard practice in implementing softmax to prevent overflow errors. Given its correctness and utility, the method is likely to be retained."
survived,"    def build(self, inference: InferenceEndpoint, rollout_sink: RolloutSink, seed: int):
        ActorCls = ray.remote(num_cpus=1)(MathEnv)
        actor = ActorCls.remote(
            inference,
            rollout_sink,
            data_source=self.data_source,
            split=self.split,
            model=self.model,
            max_iters=self.max_iters,
            seed=self.seed + seed,
        )
        actor.run.remote()
        return actor",marin/rl/envs/math_env.py,MathEnvConfig,1,1.3440409770490404e-08,"The method 'build' is a crucial part of setting up a remote actor using Ray, which is a popular library for distributed computing. The method is responsible for creating and initializing a remote actor with specific parameters, which is a common pattern in distributed systems to parallelize tasks. Given the increasing importance of distributed computing and the use of Ray in such contexts, this method is likely to be retained as it provides essential functionality for setting up distributed tasks efficiently."
survived,"def test_parquet_round_trip(tmp_path):
    groups = _make_sample_groups()

    # Write groups twice to verify appending additional parts is okay.
    write_rollout_groups(groups[:1], str(tmp_path))
    write_rollout_groups(groups[1:], str(tmp_path))

    read_back = list(iter_rollout_groups(str(tmp_path)))

    assert len(read_back) == len(groups)

    original_sorted = _sort_by_id(groups)
    read_sorted = _sort_by_id(read_back)

    for orig, rec in zip(original_sorted, read_sorted, strict=False):
        assert _groups_equal(orig, rec)",tests/rl/test_parquet_store.py,,1,7.194132978569833e-09,"The method 'test_parquet_round_trip' is a test function that verifies the integrity of data written to and read from a storage format (likely Parquet). It ensures that the data can be written in parts and read back correctly, maintaining the original order and content. Such tests are crucial for data integrity and are typically retained in codebases to prevent regressions. Therefore, it is unlikely to be deleted."
survived,"    def _fake_load_dataset(name, *_, **__):
        assert name == ""mock""
        return fake_dataset
",tests/rl/test_math_env.py,,1,4.944450477491054e-09,"The method _fake_load_dataset is a private helper function, indicated by the underscore prefix, and is likely used for testing purposes. It is designed to load a mock dataset when the name 'mock' is provided. Such functions are typically retained as they are useful for unit testing and ensuring that the code behaves correctly with controlled inputs. Therefore, it is likely to survive."
survived,"def detect_supply_chain_alpha(threshold: float = 50.0) -> str:
    """"""Return a basic message about supplychain flow levels.""""""
    try:
        data = pd.read_csv(_STABLE_FLOWS_CSV)
    except FileNotFoundError:
        return ""offline data missing""

    flow = float(data[""usd_mn""][0])
    if flow < threshold:
        return f""Flows {flow:.1f}MUSD  potential bottleneck""
    return f""Flows {flow:.1f}MUSD  supply chain normal""
",alpha_factory_v1/demos/era_of_experience/alpha_detection.py,,1,3.3982678079468468e-09,"The method 'detect_supply_chain_alpha' is a simple utility function that reads a CSV file to determine the flow of supply chain data and returns a message based on a threshold. It handles a FileNotFoundError gracefully and provides meaningful output based on the data. Such utility functions are often useful in data analysis and monitoring systems, and unless there is a significant change in the system requirements or data handling approach, there is no strong reason to delete it. It is likely to survive as it serves a clear purpose and is implemented correctly."
survived,"def _read_first_row(path: Path) -> Dict[str, str] | None:
    """"""Return the first row of a CSV as a mapping or ``None`` if empty.""""""
    if pd is not None:  # use pandas when available for convenience
        try:
            df = pd.read_csv(path)
        except FileNotFoundError:
            raise
        except Exception:  # pragma: no cover - handle corrupt CSV gracefully
            pass
        else:
            if not df.empty:
                return df.iloc[0].to_dict()

    try:
        with open(path, newline="""") as fh:
            reader = csv.DictReader(fh)
            return next(reader, None)
    except FileNotFoundError:
        raise

    return None
",alpha_factory_v1/demos/era_of_experience/alpha_detection.py,,1,2.3355930333443423e-09,"The method `_read_first_row` is a utility function designed to read the first row of a CSV file and return it as a dictionary. It handles both the presence and absence of the pandas library, providing a fallback to the built-in csv module if pandas is not available. This makes the function versatile and robust, as it can operate in environments where pandas might not be installed. Additionally, it includes error handling for file not found and corrupt CSV files, which enhances its reliability. These characteristics make the function useful and likely to be retained in the codebase."
survived,"    def test_simple_env_runs(self) -> None:
        env = SimpleExperienceEnv()
        state = env.reset()
        self.assertEqual(state, 0)
        state, reward, done, info = env.step(""act"")
        self.assertIsInstance(reward, float)
",tests/test_era_experience.py,TestEraOfExperience,1,4.363462233903899e-09,"The method 'test_simple_env_runs' is a unit test designed to verify the functionality of the 'SimpleExperienceEnv' environment. It checks if the environment can be reset and if the step function returns the expected types. This is a fundamental test for ensuring the environment behaves as expected, which is crucial for any system relying on this environment. Therefore, it is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the environment's behavior."
survived,"    def test_stub_agents_instantiable(self) -> None:
        exp = ExperienceAgent()
        fed = FederatedExperienceAgent()
        self.assertTrue(hasattr(exp, ""act""))
        self.assertTrue(hasattr(fed, ""handle_request""))
",tests/test_era_experience.py,TestEraOfExperience,1,6.825604231969389e-08,"The method 'test_stub_agents_instantiable' is a unit test method that checks if the 'ExperienceAgent' and 'FederatedExperienceAgent' classes have certain attributes ('act' and 'handle_request', respectively). This is a basic test to ensure that these classes are correctly implemented and have the expected methods. Such tests are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is unlikely that this method will be deleted as it serves an important role in the testing suite."
survived,"    def dlt_source(self, uri: str, table: str, **kwargs):
        parsed_uri = urlparse(uri)
        params = parse_qs(parsed_uri.query)
        token = params.get(""token"")
        if not token or not token[0].strip():
            raise MissingValueError(""token"", ""Internet Society Pulse"")

        start_date = kwargs.get(""interval_start"")
        if start_date is None:
            raise MissingValueError(""interval_start"", ""Internet Society Pulse"")

        end_date = kwargs.get(""interval_end"")

        metrics = [table]
        if table == ""all"":
            from ingestr.src.pulse import GLOBAL_METRICS

            metrics = list(GLOBAL_METRICS.keys())

        from ingestr.src.pulse import GLOBAL_METRICS, pulse_source

        for metric in metrics:
            if metric not in GLOBAL_METRICS:
                raise UnsupportedResourceError(metric, ""Internet Society Pulse"")

        src = pulse_source(
            token=token[0],
            start_date=str(start_date),
            end_date=str(end_date) if end_date else None,
            metrics=metrics,
        )
        return src.with_resources(*metrics)",ingestr/src/sources.py,PulseSource,1,2.998960815863541e-09,"The method 'dlt_source' is likely to survive because it appears to be a well-structured and functional piece of code. It performs several important tasks such as parsing a URI, extracting and validating parameters, and interacting with external modules to fetch data. The method also includes error handling for missing values and unsupported resources, which are crucial for robust software. Additionally, the method's functionality seems to be specific and necessary for the context it is used in, making it less likely to be removed unless there is a significant change in the system's requirements or architecture."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/best-shuffle.py,,1,5.043472052266442e-07,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be a part of a larger system that might require a consistent pseudo-random number generation for testing or simulation purposes. The use of a global variable `_now_seed` suggests that this function is intended to maintain state across multiple calls, which can be useful in certain applications. However, the function's reliance on global state and the lack of context about its usage might make it a candidate for refactoring rather than deletion. Without more context, it's difficult to definitively say it will be deleted, but its utility in generating consistent pseudo-random numbers suggests it will survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-b-zier-curves-cubic.py,,1,4.1399375473943306e-08,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function seems to be a part of a larger system that might require a consistent pseudo-random number generation for testing or simulation purposes. The use of a global variable `_now_seed` suggests that this function is intended to maintain state across multiple calls, which can be useful in certain applications. However, the function relies on the global variable `_now_seeded`, which is not defined within the provided code snippet, making it unclear how this function behaves without additional context. Despite this, the function itself is simple and serves a clear purpose, which is often a reason for a method to survive. Unless there is a significant refactor or change in the system's requirements, this utility function is likely to survive."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bitmap-histogram.py,,1,1.0677030767166749e-06,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is unlikely to be deleted because it serves a specific purpose in providing a controlled random number generation or time-based value, which can be crucial for debugging or testing purposes."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/bin-given-limits.py,,1,9.237449576640118e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds if not. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any apparent issues that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/biorhythms.py,,1,8.152020648014727e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, otherwise it returns the current time in nanoseconds. This function is likely part of a larger system that requires either a random number or a timestamp, depending on the state of `_now_seeded`. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-5.py,,1,2.75356931274798e-05,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is not inherently problematic, but its survival depends on its usage context. If the function is part of a larger system that requires a consistent pseudo-random number generator, it is likely to survive. However, if the system transitions to using more robust libraries for random number generation or if the function is deemed unnecessary, it might be deleted. Without additional context, it's difficult to definitively predict its fate, but given its utility nature, it is more likely to survive unless there's a specific reason to remove it."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-7.py,,1,6.348800075736417e-09,"The method `_now()` is a utility function that generates a pseudo-random number based on a seed if `_now_seeded` is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a deterministic sequence of numbers (when seeded) or a timestamp. Such utility functions are common in systems that need to simulate time or generate predictable sequences for testing purposes. The function is simple, serves a clear purpose, and does not have any apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/conditional-structures-3.py,,1,4.6911638017642294e-08,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires a consistent and repeatable sequence of numbers for testing or simulation purposes when seeded, and real-time timestamps otherwise. Such utility functions are common in systems that need both deterministic and real-time behavior, making it a useful and versatile function. Therefore, it is likely to be retained in the codebase."
survived,"def test_queue_never_exceeds_cap() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=()=>false;""
            ""Object.defineProperty(navigator,'onLine',{get:()=>false,configurable:true});""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        for _ in range(105):
            page.click(""text=Share"")
            page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert (
            page.evaluate(
                ""JSON.parse(localStorage.getItem('telemetryQueue')).length""
            )
            == 100
        )
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,,1,8.76424914819242e-08,"The method 'test_queue_never_exceeds_cap' is a test function that ensures a specific behavior of a web application: the telemetry queue in local storage should not exceed a length of 100. This is a specific and useful test case for maintaining the integrity of the application's data handling, especially in scenarios where data is queued for transmission. Such tests are crucial for ensuring that the application behaves correctly under certain conditions, such as offline mode or when the queue is full. Therefore, this method is likely to be retained as part of the test suite to ensure ongoing reliability and correctness of the application."
survived,"def build_tree(df: pd.DataFrame) -> Figure:
    """"""Return Plotly treemap figure for lineage.""""""
    if df.empty:
        return px.treemap()

    ids = df[""id""].astype(str)
    parents = df[""parent""].fillna("""").astype(str)
    fig = px.treemap(
        df,
        ids=ids,
        parents=parents,
        values=[1] * len(df),
        color=""score"",
        custom_data=[df[""patch""].fillna("""")],
        color_continuous_scale=""Blues"",
    )
    labels = [f""<a href='{p}'>{i}</a>"" if p else str(i) for i, p in zip(ids, df[""patch""].fillna(""""))]
    fig.data[0].text = labels
    fig.data[0].hovertemplate = (
        ""score=%{color}<br>patch=%{customdata[0]}<extra></extra>""
    )
    return fig
",src/interface/lineage_dashboard.py,,1,3.581747929000289e-10,"The method 'build_tree' is a well-defined function that creates a Plotly treemap figure from a DataFrame. It handles empty DataFrames, uses Plotly's expressive API to create visualizations, and customizes the hover template and labels. This functionality is useful for visualizing hierarchical data, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def main(argv: list[str] | None = None) -> None:  # pragma: no cover - entry point
    """"""Launch the lineage dashboard.""""""
    if st is None:
        print(""Streamlit not installed"")
        return

    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        ""--db"",
        default=os.getenv(""ARCHIVE_PATH"", ""archive.db""),
        help=""Path to archive database"",
    )
    parser.add_argument(
        ""--refresh"",
        type=int,
        default=int(os.getenv(""DASH_REFRESH"", ""10"")),
        help=""Auto-refresh interval in seconds"",
    )
    args = parser.parse_args(argv)

    st.set_page_config(page_title=""Lineage Dashboard"", layout=""wide"")
    if st_autorefresh is not None:
        st_autorefresh(interval=args.refresh * 1000, key=""refresh"")

    df = load_df(Path(args.db))
    if df.empty:
        st.info(""Archive empty"")
        return

    fig = build_tree(df)
    st.plotly_chart(fig, use_container_width=True)
",src/interface/lineage_dashboard.py,,1,9.237449576640118e-09,"The method 'main' is a typical entry point for a command-line application that sets up and launches a dashboard using Streamlit. It includes argument parsing, configuration setup, and visualization rendering, which are all essential components for the functionality it provides. The method is well-structured and serves a clear purpose in the application, making it unlikely to be removed unless the entire application is deprecated or significantly refactored. Additionally, the use of Streamlit and Plotly for visualization suggests that this method is part of a modern and actively maintained codebase."
survived,"    def _validate_patch(self, patch: str) -> bool:
        """"""Apply ``patch`` in a temporary clone and run quality checks.""""""

        from pathlib import Path
        import shutil
        import subprocess
        import tempfile

        try:
            root = (
                Path(
                    subprocess.check_output([""git"", ""rev-parse"", ""--show-toplevel""], text=True).strip()
                )
            )
        except subprocess.CalledProcessError:
            return False

        with tempfile.TemporaryDirectory() as tmp:
            try:
                subprocess.run(
                    [""git"", ""clone"", ""--local"", str(root), tmp],
                    check=True,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                )
                apply = subprocess.run(
                    [""git"", ""apply"", ""-""],
                    input=patch.encode(),
                    cwd=tmp,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                )
                if apply.returncode != 0:
                    return False

                checks = [
                    [""pytest"", ""-q""],
                    [""ruff"", "".""],
                    [""bandit"", ""-q"", ""-r"", "".""],
                ]
                for cmd in checks:
                    if shutil.which(cmd[0]) is None:
                        continue
                    proc = subprocess.run(
                        cmd,
                        cwd=tmp,
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                    )
                    if proc.returncode != 0:
                        return False
            except Exception:
                return False

        return True
",src/simulation/mats_ops.py,SelfRewriteOperator,1,2.8453347280241004e-08,"The method '_validate_patch' is a utility function that applies a patch to a temporary clone of a git repository and runs a series of quality checks on it. This method is useful for ensuring that patches do not introduce errors or fail quality checks before they are merged into the main codebase. The method is well-structured, uses standard libraries, and handles exceptions gracefully. It is likely to be retained as it provides a valuable functionality for maintaining code quality in a development workflow."
survived,"    async def step(self) -> None:
        # Pretend to compute an optimal plan
        await self.publish(""alpha.plan"", {""plan"": ""explore_market""})
",alpha_factory_v1/demos/alpha_agi_business_2_v1/alpha_agi_business_2_v1.py,PlanningAgent,1,5.60279640614594e-09,"The method 'step' is an asynchronous function that simulates the computation of an optimal plan and publishes it to a topic. This kind of functionality is common in systems that require asynchronous operations, such as web servers or applications that handle real-time data. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase. Additionally, the use of async/await indicates modern Python practices, suggesting that the method is up-to-date with current programming standards."
survived,"def test_list_profiles_returns_all_names(tmp_path):
    data = """"""\
[default]
username = 'a'
password = 'b'

[second]
username = 'c'
password = 'd'
""""""
    cred_file = tmp_path / ""credentials""
    cred_file.write_text(data, encoding=""UTF-8"")

    profiles = CredentialsProvider.list_profiles(path=str(cred_file))

    assert set(profiles) == {""default"", ""second""}
",tests/dhapi/port/test_credentials_provider.py,,1,1.522997951276035e-08,"The method 'test_list_profiles_returns_all_names' is a unit test designed to verify that the 'list_profiles' function of the 'CredentialsProvider' class correctly returns all profile names from a given credentials file. This is a typical and necessary test to ensure the functionality of the 'list_profiles' method, which is likely a core part of the 'CredentialsProvider' class. Since testing is a crucial part of software development to ensure code reliability and correctness, this method is likely to be retained as part of the test suite."
survived,"def test_list_profiles_raise_when_file_missing(tmp_path):
    missing = tmp_path / ""none""
    with pytest.raises(FileNotFoundError):
        CredentialsProvider.list_profiles(path=str(missing))",tests/dhapi/port/test_credentials_provider.py,,1,9.237449576640118e-09,"The method is a test function that checks if the `list_profiles` method from `CredentialsProvider` raises a `FileNotFoundError` when a non-existent file path is provided. This is a valid and necessary test to ensure that the method handles missing files correctly. Therefore, it is likely to be retained as part of the test suite to maintain code robustness."
survived,"def triple(x):
    return x * 3
",tests/transpiler/x/py/pure_fold.py,,1,8.592166611791576e-10,"The method 'triple' is a simple and efficient function that performs a basic arithmetic operation, which is multiplying a given number by three. Such utility functions are commonly used in various programming tasks and are likely to be retained for their simplicity and usefulness. There is no indication that this function is redundant or unnecessary, so it is likely to survive."
survived,"def add(a, b):
    return a + b
",tests/transpiler/x/py/partial_application.py,,1,1.955568070542584e-08,"The method 'add' is a simple and commonly used utility function that performs addition of two numbers. Such basic arithmetic functions are fundamental in programming and are unlikely to be deleted unless they are redundant or replaced by a more comprehensive library. However, given the simplicity and utility of this function, it is more likely to be retained for its straightforward purpose."
survived,"        def execute_endpoint(payload: Dict[str, Any]) -> Any:
            input_obj = cls.InputSchema(**payload)
            instance = cls()
            result = instance.execute(input_obj.dict())
            return OutputModel(**result)
",servers/server_clear_thought/core/base_tool.py,BaseTool,1,2.2159489282323004e-08,"The method 'execute_endpoint' is a utility function that takes a payload, processes it into an input schema, executes a method on an instance, and returns the result as an output model. This pattern is common in API handling and data processing tasks, making it a useful and reusable piece of code. It is likely to be retained as it encapsulates a clear and necessary functionality for handling endpoint execution in a structured manner."
survived,"def test_seven_seekers_orchestrator():
    client = get_client()
    resp = client.post(
        ""/seven-seekers-orchestrator/execute"",
        json={""query"": ""q""},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""seeker_results"", ""resonance_map"", ""synthesis""}
",servers/server_clear_thought/tests/test_new_tools.py,,1,2.0611536181902033e-09,"The method `test_seven_seekers_orchestrator` is a unit test function that is designed to test the functionality of an API endpoint. Unit tests are crucial for ensuring that code behaves as expected and for catching bugs early in the development process. This particular test checks the response status and the structure of the returned JSON, which are common and necessary checks in API testing. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def create_app() -> FastAPI:
    app = FastAPI()
    for tool_cls in load_tools():
        router = tool_cls.get_router()
        app.include_router(router, prefix=tool_cls.endpoint_path, tags=[tool_cls.slug])
    return app",servers/server_clear_thought/app.py,,1,8.592166611791576e-10,"The method 'create_app' is a well-structured function that initializes a FastAPI application and dynamically includes routers from loaded tools. This approach is modular and scalable, making it easy to add or remove tools without modifying the core application logic. Such a design is beneficial for maintaining and extending the application, which aligns with best practices in software development. Therefore, it is likely to be retained in the codebase."
survived,"def test_safe_struggle_designer():
    client = get_client()
    resp = client.post(
        ""/safe-struggle-designer/execute"",
        json={""skill"": ""x"", ""current_level"": 1, ""target_level"": 2},
    )
    assert resp.status_code == 200
    data = resp.json()
    assert set(data.keys()) == {""scaffold_steps"", ""safety_measures"", ""review_intervals""}
",servers/server_clear_thought/tests/test_new_tools.py,,1,3.653482080241728e-08,"The method `test_safe_struggle_designer` is a unit test function that verifies the behavior of an API endpoint. It checks if the response status code is 200 and if the response JSON contains specific keys. Such test functions are crucial for ensuring the reliability and correctness of the codebase, especially in a production environment where API endpoints need to be validated regularly. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        points = [
            {""category"": c or ""general"", ""count"": i}
            for i, c in enumerate(payload.get(""categories"") or [""general""], start=1)
        ]
        score = sum(p[""count""] for p in points) / len(points)
        return {
            ""drag_points"": points,
            ""summary_score"": round(score, 2),
        }",servers/server_clear_thought/tools/drag_point_audit.py,DragPointAudit,1,7.194132978569833e-09,"The method 'execute' is well-structured and performs a clear function: it processes a payload to generate a list of points with categories and counts, calculates a summary score, and returns this information in a dictionary. The method uses Python's dictionary and list comprehensions effectively, and the logic is straightforward and useful for summarizing data. There are no apparent issues or redundancies that would necessitate its deletion. Additionally, the method's functionality is generic enough to be applicable in various contexts where data categorization and scoring are needed."
survived,"def test_meme_disabled() -> None:
    rng = random.Random(0)
    op = SelfRewriteOperator(steps=3, rng=rng, templates=[""meme""], reuse_rate=0.0)
    result = op(""improve quick test"")
    assert result != ""meme""
",tests/test_meme_reuse.py,,1,1.275190675769241e-07,"The method `test_meme_disabled` is a unit test designed to verify that the `SelfRewriteOperator` does not produce the output ""meme"" when initialized with certain parameters. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks a specific behavior of the `SelfRewriteOperator`, which is likely part of a larger suite of tests. Removing it could reduce the test coverage and potentially allow bugs to go unnoticed. Therefore, it is unlikely to be deleted."
survived,"def run_orchestrator(verbose: bool) -> None:
    """"""Run the orchestrator until interrupted.""""""
    orch = orchestrator.Orchestrator()
    if verbose and console is not None:
        console.log(""Starting orchestrator  press Ctrl+C to stop"")
    try:
        asyncio.run(orch.run_forever())
    except KeyboardInterrupt:  # pragma: no cover - interactive
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,1.0467401685178159e-08,"The method 'run_orchestrator' is a utility function designed to run an orchestrator process until it is manually interrupted. It includes a verbose option for logging, which is useful for debugging or monitoring purposes. The method is straightforward, uses standard practices for running asynchronous tasks, and handles keyboard interrupts gracefully. Such utility functions are common in applications that require continuous background processing or monitoring, making them essential for certain types of applications. Therefore, it is likely to be retained in the codebase."
survived,"    def record(
        self, tokens: int, cost: float, latency: float, guardrail_hits: int
    ) -> None:
        cur = self.conn.cursor()
        cur.execute(
            ""INSERT INTO telemetry (timestamp, tokens, cost, latency, guardrail_hits) VALUES (?, ?, ?, ?, ?)"",
            (datetime.utcnow().isoformat(), tokens, cost, latency, guardrail_hits),
        )
        self.conn.commit()
        self.purge_old()
",src/meta_agent/telemetry_db.py,TelemetryDB,1,7.582560422162384e-10,"The method 'record' is responsible for inserting telemetry data into a database and then purging old data. This functionality is crucial for maintaining an up-to-date and efficient database, especially in applications where telemetry data is frequently collected and analyzed. The method is well-defined, performs a clear and necessary task, and includes a call to 'purge_old' which suggests a mechanism for managing data retention. Given its utility in data management and system monitoring, it is likely to be retained."
survived,"            async def improve_policy(policy: list[int]) -> list[int]:
                return [p + 1 for p in policy]
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/mats/meta_rewrite.py,,1,1.1032560311263802e-09,"The method 'improve_policy' is a simple and efficient function that takes a list of integers and returns a new list with each integer incremented by one. It uses list comprehension, which is a Pythonic and efficient way to perform such operations. The function is also asynchronous, which can be beneficial if it is part of a larger asynchronous workflow. There are no apparent issues or inefficiencies in the code, and it serves a clear purpose. Therefore, it is likely to be useful and survive."
survived,"    def test_run_demo_with_seed(self) -> None:
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.run_demo"",
                ""--episodes"",
                ""2"",
                ""--seed"",
                ""123"",
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best agents"", result.stdout)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,2.7894680920908113e-10,"The method 'test_run_demo_with_seed' is a unit test designed to verify the functionality of a demo script by running it with specific parameters and checking the output. It uses subprocess to execute the script and asserts that the return code is 0 (indicating success) and that the output contains the expected string 'Best agents'. This is a typical pattern for testing command-line scripts and ensuring they behave as expected. There is no indication of redundancy or obsolescence, and it serves a clear purpose in validating the script's behavior. Therefore, it is likely to be retained."
survived,"def _load_exfil_patterns() -> list[str]:
    policy_path = _POLICY_DIR / ""deny_exfil.rego""
    try:
        text = policy_path.read_text(encoding=""utf-8"")
    except FileNotFoundError:
        return []
    return re.findall(r're_match\(""([^""]+)"",\s*input.text\)', text)
",src/utils/opa_policy.py,,1,2.3355930333443423e-09,"The method _load_exfil_patterns is likely to survive because it performs a specific and useful function: it reads a policy file and extracts patterns using regular expressions. This functionality is essential for applications that need to dynamically load and apply security policies, such as preventing data exfiltration. The method handles exceptions gracefully by returning an empty list if the file is not found, which is a good practice in robust software design. Additionally, the use of type hints improves code readability and maintainability."
survived,"    def close(self) -> None:
        if self.conn:
            self.conn.close()
            self.conn = None
",alpha_factory_v1/common/utils/logging.py,Ledger,1,8.152020648014727e-09,"The method 'close' is a standard and necessary part of managing resources, especially when dealing with connections such as database connections or file handles. It ensures that resources are properly released when they are no longer needed, preventing resource leaks. The method is simple, effective, and follows best practices for resource management. Therefore, it is unlikely to be deleted."
survived,"def _merkle_root(hashes: Iterable[str]) -> str:
    nodes: List[bytes] = [bytes.fromhex(h) for h in hashes]
    if not nodes:
        return cast(str, blake3(b""\x00"").hexdigest())

    while len(nodes) > 1:
        if len(nodes) % 2 == 1:
            nodes.append(nodes[-1])
        next_lvl: List[bytes] = []
        for i in range(0, len(nodes), 2):
            next_lvl.append(blake3(nodes[i] + nodes[i + 1]).digest())
        nodes = next_lvl
    return nodes[0].hex()
",alpha_factory_v1/common/utils/logging.py,,1,4.363462233903899e-09,"The method implements a Merkle tree root calculation, which is a fundamental concept in cryptography and blockchain technology. It efficiently computes a hash that represents a set of data, ensuring data integrity and consistency. The method is well-structured, handles edge cases (like an empty list of hashes), and uses a reliable hashing function (blake3). Given the increasing importance of cryptographic functions in modern applications, this method is likely to be retained for its utility in verifying data integrity."
survived,"    def __init__(
        self,
        path: str,
        rpc_url: str | None = None,
        wallet: str | None = None,
        broadcast: bool = True,
        db: str | None = None,
    ) -> None:
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        db_type = db or os.getenv(""AGI_INSIGHT_DB"", ""sqlite"")
        self.db_type = db_type
        if db_type == ""duckdb"" and duckdb is not None:
            self.conn = duckdb.connect(str(self.path))
            self.conn.execute(
                """"""
                CREATE TABLE IF NOT EXISTS messages (
                    id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
                    ts DOUBLE,
                    sender TEXT,
                    recipient TEXT,
                    payload TEXT,
                    hash TEXT
                )
                """"""
            )
        elif db_type == ""postgres"":
            if ""psycopg2"" not in globals():
                _log.warning(""AGI_INSIGHT_DB=postgres but psycopg2 not installed  falling back to sqlite"")
                self.conn = sqlite3.connect(str(self.path))
                self.conn.execute(
                    """"""
                    CREATE TABLE IF NOT EXISTS messages (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        ts REAL,
                        sender TEXT,
                        recipient TEXT,
                        payload TEXT,
                        hash TEXT
                    )
                    """"""
                )
            else:
                params = {
                    ""host"": os.getenv(""PGHOST""),
                    ""port"": os.getenv(""PGPORT"", ""5432""),
                    ""user"": os.getenv(""PGUSER""),
                    ""password"": os.getenv(""PGPASSWORD""),
                    ""dbname"": os.getenv(""PGDATABASE"", ""insight""),
                }
                self.conn = psycopg2.connect(**{k: v for k, v in params.items() if v is not None})
                with self.conn, self.conn.cursor() as cur:
                    cur.execute(
                        """"""
                        CREATE TABLE IF NOT EXISTS messages (
                            id BIGSERIAL PRIMARY KEY,
                            ts DOUBLE PRECISION,
                            sender TEXT,
                            recipient TEXT,
                            payload TEXT,
                            hash TEXT
                        )
                        """"""
                    )
        else:
            if db_type == ""duckdb"" and duckdb is None:
                _log.warning(""AGI_INSIGHT_DB=duckdb but duckdb not installed  falling back to sqlite"")
            self.conn = sqlite3.connect(str(self.path))
            self.conn.execute(
                """"""
                CREATE TABLE IF NOT EXISTS messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ts REAL,
                    sender TEXT,
                    recipient TEXT,
                    payload TEXT,
                    hash TEXT
                )
                """"""
            )
        self.conn.commit()
        self._task: asyncio.Task[None] | None = None
        self.rpc_url = rpc_url
        self.wallet = wallet
        self.broadcast = broadcast
",alpha_factory_v1/common/utils/logging.py,Ledger,1,4.4508487281649027e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes and database connections based on the provided parameters and environment variables. This functionality is crucial for the class to operate correctly, especially if it is part of a larger application that relies on database interactions. Therefore, it is unlikely to be deleted."
survived,"    def grpc_server(self) -> Optional[Any]:
        return self._grpc_server
",alpha_factory_v1/backend/services/api_server_service.py,APIServer,1,8.152020648014727e-09,"The method `grpc_server` is a simple getter method that returns the value of the private attribute `_grpc_server`. Such methods are typically retained in codebases because they provide a controlled way to access private attributes, which is a common practice in object-oriented programming to encapsulate data. Additionally, the use of `Optional[Any]` as a return type suggests that the method is designed to handle cases where `_grpc_server` might be `None`, indicating thoughtful design for flexibility and robustness. Therefore, it is likely to be useful and survive."
survived,"    async def fake_start_servers(*a, **k):
        events.append(""start"")

        async def sleeper():
            await asyncio.sleep(0)
        task = asyncio.create_task(sleeper())
        server = SimpleNamespace(stop=lambda code=0: events.append(""stop""))
        return task, server
",tests/test_api_server_service.py,,1,3.850741907939403e-09,"The method 'fake_start_servers' is a mock or test utility function, as indicated by its name 'fake_' and its purpose of appending events to a list. It is likely used in testing scenarios to simulate server start and stop events without actually starting a server. Such utility functions are often retained in codebases for testing purposes, especially if they are used in unit tests to verify the behavior of other components. Therefore, it is likely to be Survived."
survived,"def test_demo_assets_revision_pinned() -> None:
    expected = ""90fe9b623b3a0ae5475cf4fa8693d43cb5ba9ac5""
    with open(RUN_SCRIPT) as f:
        text = f.read()
    m = re.search(r""DEMO_ASSETS_REV=\$\{DEMO_ASSETS_REV:-([0-9a-f]{40})\}"", text)
    assert m, ""revision variable missing""
    assert m.group(1) == expected

    from alpha_factory_v1.demos.macro_sentinel import data_feeds

    assert data_feeds.DEMO_ASSETS_REV == expected
    for url in data_feeds.OFFLINE_URLS.values():
        assert expected in url",tests/test_macro_launcher.py,,1,1.0467401685178159e-08,"The method `test_demo_assets_revision_pinned` is a test function that verifies the integrity and consistency of a specific revision identifier within a script and a module. It checks that the revision identifier is correctly set and used across different parts of the code. This kind of test is crucial for ensuring that the correct version of assets is being used, which is important for reproducibility and reliability of the software. Test functions like this are generally retained as they help in maintaining code quality and preventing regressions."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q18.py,Auto1,1,6.825604231969389e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return an attribute of the object using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in cases where the object is used like a dictionary or needs to provide flexible access to its attributes. Therefore, this method is likely to be retained as it provides a useful and standard functionality."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q15.py,_Group,1,3.850741907939403e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q4.py,Auto1,1,2.2159489282323004e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this code, it is implemented to return the attribute of the object with the name `key` using `getattr`. This is a common and useful pattern for dynamic attribute access, especially in classes that need to behave like dictionaries or provide flexible attribute access. Since this method provides a clear and useful functionality, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q5.py,Auto1,1,2.5109990926928157e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes using keys, enhancing the flexibility and usability of the class."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q10.py,_Group,1,6.348800075736417e-09,"The method `__len__` is a special method in Python that is used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation provided is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be retained as it provides necessary functionality for the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/dataset/tpc-h/compiler/py/q9.py,Auto1,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in container-like objects such as lists, dictionaries, or custom objects that mimic these behaviors. In this code, `__getitem__` is implemented to return an attribute of the object using `getattr`. This is a valid and useful implementation if the object is designed to allow attribute access via indexing, which can be a design choice for certain applications. Since this method provides a clear and specific functionality, it is likely to be retained unless the design requirements change significantly."
survived,"    def __len__(self):
        return len(self.Items)
",tests/dataset/tpc-h/compiler/py/q13.py,_Group,1,1.2501528648238603e-09,"The method `__len__` is a special method in Python used to define the behavior of the `len()` function for instances of a class. This method is essential for any class that represents a collection or container of items, as it allows users to easily determine the number of items in the collection. The implementation here is straightforward and correctly returns the length of the `Items` attribute, assuming `Items` is a list or similar iterable. Therefore, this method is likely to be useful and necessary for the class's functionality, leading to its survival."
survived,"        def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
            if name == ""openai_agents"":
                raise ModuleNotFoundError(name)
            return orig_import(name, globals, locals, fromlist, level)
",tests/test_cross_industry_bridge_runtime.py,TestCrossIndustryBridgeRuntime,1,0.000804086001803591,"The method 'fake_import' is a custom implementation of the import mechanism, specifically designed to raise a ModuleNotFoundError when attempting to import a module named 'openai_agents'. This kind of function is typically used for testing purposes, to simulate the absence of certain modules. Such methods are often temporary and used in specific testing scenarios, which suggests that it might not be a permanent part of the codebase. However, the method itself is functional and serves a clear purpose, which could justify its retention if the testing scenario is ongoing or frequently needed. Without more context on its usage, it's reasonable to predict that it might survive if the testing need persists."
survived,"    def test_no_log_flag(self) -> None:
        with tempfile.TemporaryDirectory() as tmp:
            ledger = Path(tmp) / ""no_log.json""
            result = subprocess.run(
                [
                    sys.executable,
                    STUB,
                    ""-n"",
                    ""1"",
                    ""--seed"",
                    ""4"",
                    ""--ledger"",
                    str(ledger),
                    ""--no-log"",
                    ""--model"",
                    ""gpt-4o-mini"",
                ],
                capture_output=True,
                text=True,
            )
            self.assertEqual(result.returncode, 0, result.stderr)
            self.assertFalse(ledger.exists())
",tests/test_cross_alpha_discovery.py,TestCrossAlphaDiscoveryStub,1,9.736200303530205e-10,The method 'test_no_log_flag' is a unit test designed to verify that a specific command-line flag ('--no-log') works as intended by ensuring that no log file is created. This is a valid and useful test case for ensuring the correct behavior of the software when this flag is used. It is likely to be retained as it helps maintain the integrity of the software by preventing regressions related to logging functionality.
survived,"    def tearDown(self):
        AGENT_REGISTRY.clear()
        AGENT_REGISTRY.update(self._registry_backup)
        CAPABILITY_GRAPH.clear()
        for cap, agents in self._cap_backup.items():
            for name in agents:
                CAPABILITY_GRAPH.add(cap, name)
",tests/test_agents_registry.py,TestAgentRegistryFunctions,1,5.043472052266442e-07,"The method `tearDown` is a common method used in testing frameworks like `unittest` in Python. It is typically used to clean up or reset the state after each test case is run. The presence of `tearDown` suggests that this code is part of a test suite, and such methods are generally essential for ensuring that tests do not interfere with each other by leaving shared state in an altered condition. The method is performing cleanup tasks by clearing and restoring the state of `AGENT_REGISTRY` and `CAPABILITY_GRAPH`, which are likely global or shared resources. This is a standard practice in testing to ensure test isolation and reliability. Therefore, it is unlikely that this method will be deleted as it serves a crucial role in maintaining the integrity of the test environment."
survived,"    def setUp(self):
        self._registry_backup = AGENT_REGISTRY.copy()
        self._cap_backup = {k: v[:] for k, v in CAPABILITY_GRAPH.items()}
        AGENT_REGISTRY.clear()
        CAPABILITY_GRAPH.clear()
",tests/test_agents_registry.py,TestAgentRegistryFunctions,1,1.8553915987649156e-07,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test method is run. The code provided is backing up some global state and then clearing it, which is a common practice to ensure that tests run in a clean environment without interference from previous tests. This method is likely to be part of a test suite and is essential for maintaining test isolation and integrity. Therefore, it is unlikely to be deleted as it serves a crucial role in the testing process."
survived,"    def tearDown(self):
        AGENT_REGISTRY.clear()
        AGENT_REGISTRY.update(self._registry_backup)
",tests/test_agents_registry.py,TestRegisterDecorator,1,1.0467401685178159e-08,"The method `tearDown` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to clean up or reset the state after each test method is run. In this case, it clears and restores the `AGENT_REGISTRY` to its original state using a backup. This is a standard practice to ensure that tests do not interfere with each other by leaving shared state modified. Therefore, this method is likely to be retained as it serves an important purpose in maintaining test isolation and integrity."
survived,"    def test_all_agents_instantiable(self):
        for name in list_agents():
            meta = AGENT_REGISTRY[name]
            self.assertIsNotNone(meta.cls)
            # instantiation may fail if optional deps are missing
            try:
                agent = get_agent(name)
            except Exception:
                continue
            self.assertEqual(agent.NAME, name)
",tests/test_agents_integrity.py,TestAgentsIntegrity,1,2.5109990926928157e-08,"The method `test_all_agents_instantiable` is a unit test designed to ensure that all agents listed in `AGENT_REGISTRY` can be instantiated without errors. It uses a try-except block to handle cases where instantiation might fail due to missing optional dependencies, which is a reasonable approach to make the test robust against such issues. The method checks that the instantiated agent's name matches the expected name, which is a valid test for ensuring correct instantiation. Since the method serves a clear purpose in testing the functionality of agent instantiation and handles potential errors gracefully, it is likely to be retained in the codebase."
survived,"    async def publish(self, topic, msg):
        self.published.append((topic, msg))
",tests/test_ping_agent.py,DummyOrch,1,2.998960815863541e-09,"The method 'publish' is a simple and straightforward implementation that appends a tuple of 'topic' and 'msg' to a list 'self.published'. This method is likely part of a larger system where messages are published to a topic, which is a common pattern in messaging systems. The method is asynchronous, suggesting it is designed to handle non-blocking operations, which is beneficial in modern applications that require high concurrency. There is no indication that this method is redundant or poorly implemented, so it is likely to be retained in the codebase."
survived,"def test_run_with_research(monkeypatch):
    calls = []

    class DummyResearch:
        def research(self, name: str, purpose: str):
            calls.append((name, purpose))
            return [""info""]

    agent = ToolDesignerAgent(research_manager=DummyResearch(), enable_research=True)
    result = await agent.run(VALID_DICT_SPEC)
    assert result['status'] == 'success'
    assert calls == [(VALID_DICT_SPEC['name'], VALID_DICT_SPEC['purpose'])]
",tests/agents/test_tool_designer_agent.py,,1,6.825604231969389e-08,"The method 'test_run_with_research' is a unit test designed to verify the functionality of the 'ToolDesignerAgent' class when the 'enable_research' flag is set to true. It uses a mock class 'DummyResearch' to simulate the behavior of the research manager, ensuring that the 'research' method is called with the correct parameters. The test checks that the result status is 'success' and that the 'calls' list contains the expected tuple. This is a typical pattern for testing asynchronous code and mocking dependencies, which is essential for ensuring code reliability and correctness. Therefore, the method is likely to be retained as it serves a critical role in the testing suite."
survived,"def test_formulate_query():
    mgr = ToolResearchManager(web_search_tool=DummyTool(), enabled=True)
    q = mgr.formulate_query(""foo"", ""does bar"")
    assert ""foo"" in q and ""bar"" in q
",tests/unit/test_tool_research_manager.py,,1,9.237449576640118e-09,"The method 'test_formulate_query' is a unit test designed to verify the functionality of the 'formulate_query' method within the 'ToolResearchManager' class. Unit tests are crucial for ensuring code reliability and correctness, especially when changes are made to the codebase. This test checks that the query formulation correctly includes the expected terms, which is a fundamental aspect of the tool's functionality. Therefore, it is unlikely that this method will be deleted as it serves an important role in maintaining code quality."
survived,"    def __call__(self, query: str):
        self.calls.append(query)
        return ""result line 1\nresult line 2""
",tests/unit/test_tool_research_manager.py,DummyTool,1,3.850741907939403e-09,"The method is likely to survive because it implements a useful functionality by appending a query to a list and returning a formatted string. This indicates that the method is part of a larger system where tracking calls and returning results is necessary. The method is simple, clear, and serves a specific purpose, which are good indicators of its utility and likelihood to be retained."
survived,"    def __init__(
        self,
        web_search_tool: Optional[Callable[[str], str]] = None,
        enabled: bool = True,
        max_results: int = 3,
    ) -> None:
        self.web_search_tool = web_search_tool or WebSearchTool()
        self.enabled = enabled
        self.max_results = max_results
        self.cache: Dict[str, List[str]] = {}
",src/meta_agent/research_manager.py,ToolResearchManager,1,1.3440409770490404e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up default values and allows for customization through parameters. Constructors are fundamental to object-oriented programming, and there is no indication that this particular constructor is redundant or unnecessary. Therefore, it is likely to be retained in the code."
survived,"    def test_openai_failure_falls_back(self) -> None:
        os.environ[""OPENAI_API_KEY""] = ""sk-test""
        llm._OPENAI_KEY = ""sk-test""
        llm._sync_embed.cache_clear()
        with patch.object(llm.openai.Embedding, ""create"", side_effect=llm.openai.OpenAIError(""boom"")) as mock_create:

            class _Vec(list):
                def tolist(self):
                    return list(self)

            fake_mod = SimpleNamespace(
                SentenceTransformer=lambda *_: SimpleNamespace(
                    encode=lambda text, normalize_embeddings=True: _Vec([0.1, 0.2])
                )
            )
            with patch.dict(sys.modules, {""sentence_transformers"": fake_mod}):
                vec = llm._sync_embed(""hi"")
        mock_create.assert_called_once()
        self.assertEqual(vec, [0.1, 0.2])
",tests/test_embedder_fallback.py,TestEmbedderFallback,1,1.444980317078884e-07,"The method 'test_openai_failure_falls_back' is a unit test designed to ensure that the system correctly falls back to an alternative method when the OpenAI API fails. This is a critical functionality test to ensure robustness and reliability of the system in case of external API failures. Such tests are essential for maintaining the quality and resilience of software, especially when dealing with third-party services. Therefore, it is unlikely to be deleted as it serves an important purpose in the codebase."
survived,"def test_self_healer_aborts_on_invalid_diff(tmp_path, monkeypatch, caplog):
    repo_src = Path(__file__).parent / ""fixtures"" / ""self_heal_repo""
    repo_path = tmp_path / ""repo""
    shutil.copytree(repo_src, repo_path)
    subprocess.run([""git"", ""init""], cwd=repo_path, check=True)
    subprocess.run([""git"", ""add"", "".""], cwd=repo_path, check=True)
    subprocess.run([""git"", ""commit"", ""-m"", ""init""], cwd=repo_path, check=True)
    commit = subprocess.check_output([""git"", ""rev-parse"", ""HEAD""], cwd=repo_path, text=True).strip()

    workdir = tmp_path / ""work""
    healer = self_healer.SelfHealer(repo_url=str(repo_path), commit_sha=commit)
    healer.working_dir = str(workdir)

    monkeypatch.setattr(patcher_core, ""generate_patch"", lambda *_a, **_k: ""bad"")
    monkeypatch.setattr(llm_client, ""request_patch"", lambda *_a, **_k: ""bad"")
    monkeypatch.setattr(
        diff_utils,
        ""parse_and_validate_diff"",
        lambda diff, repo_dir, allowed_paths=None: None,
    )
    pushed = []

    def fake_push(self):
        pushed.append(True)
        return ""branch""

    monkeypatch.setattr(self_healer.SelfHealer, ""commit_and_push_fix"", fake_push)
    monkeypatch.setattr(self_healer.SelfHealer, ""create_pull_request"", lambda self, branch: 1)

    monkeypatch.setattr(sandbox, ""run_in_docker"", lambda *_a, **_k: (1, ""fail""))

    caplog.set_level(""WARNING"")
    pr = healer.run()

    assert pr is None
    assert not pushed
    assert any(""valid patch"" in rec.getMessage() for rec in caplog.records)
",tests/test_self_healer_pipeline.py,,1,4.6911638017642294e-08,"The method is a test function that verifies the behavior of a self-healing system when it encounters an invalid diff. It uses various mocking techniques to simulate the environment and conditions under which the self-healer should abort its operation. The test checks that no push occurs and that a warning is logged, indicating the invalid patch. This is a typical and necessary test to ensure robustness in error handling, especially in systems that automatically apply changes. Therefore, it is likely to be retained as part of the test suite."
survived,"  def __init__(self, dbc_name, messages: list[tuple[str | int, int]], bus: int = 0):
    if isinstance(dbc_name, bytes):
      dbc_name = dbc_name.decode(""utf-8"")
    self.dbc_name: str = dbc_name
    self.bus: int = bus
    self.dbc: DBC | None = _get_dbc(dbc_name)
    if not self.dbc:
      raise RuntimeError(f""Can't find DBC: {dbc_name}"")

    self.vl: dict[int | str, dict[str, float]] = {}
    self.vl_all: dict[int | str, dict[str, list[float]]] = {}
    self.ts_nanos: dict[int | str, dict[str, int]] = {}
    self.addresses: set[int] = set()
    self.message_states: dict[int, MessageState] = {}

    for name_or_addr, freq in messages:
      if isinstance(name_or_addr, numbers.Number):
        msg = self.dbc.addr_to_msg.get(int(name_or_addr))
      else:
        msg = self.dbc.name_to_msg.get(name_or_addr)
      if msg is None:
        raise RuntimeError(f""could not find message {name_or_addr!r} in DBC {dbc_name}"")
      if msg.address in self.addresses:
        raise RuntimeError(""Duplicate Message Check: %d"" % msg.address)

      self.addresses.add(msg.address)
      signal_names = list(msg.sigs.keys())
      self.vl[msg.address] = {s: 0.0 for s in signal_names}
      self.vl[msg.name] = self.vl[msg.address]
      self.vl_all[msg.address] = defaultdict(list)
      self.vl_all[msg.name] = self.vl_all[msg.address]
      self.ts_nanos[msg.address] = {s: 0 for s in signal_names}
      self.ts_nanos[msg.name] = self.ts_nanos[msg.address]

      state = MessageState(
        address=msg.address,
        name=msg.name,
        size=msg.size,
        signals=list(msg.sigs.values()),
        ignore_alive=freq == 0,
      )
      if 0 < freq < 10:
        state.frequency = freq
        state.timeout_threshold = (1_000_000_000 / freq) * 10

      self.message_states[msg.address] = state

    self.can_valid: bool = False
    self.bus_timeout: bool = False
    self.can_invalid_cnt: int = CAN_INVALID_CNT
    self.last_nonempty_nanos: int = 0
",opendbc/can/parser.py,CANParser,1,2.699578619062706e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial states. The code appears to be well-structured, handling various initializations and error checks, which are crucial for the class's functionality. There is no indication that this method is redundant or unnecessary, and it seems to be actively used to set up instances of a class that deals with DBC (Database Container) files and message handling. Therefore, it is unlikely to be deleted."
survived,"async def test_loop():
    counter = {""i"": 0}

    async def step(prompt, **kwargs):
        counter[""i""] += 1
        return counter[""i""]

    wf = Workflow(
        name=""wf"",
        steps=[WorkflowStep(runner=step, mode=StepMode.LOOP, max_iterations=3)],
    )

    result = await wf.run(0)
    assert result == 3
    assert counter[""i""] == 3
",tests/test_workflow.py,,1,4.599055376537186e-10,"The method 'test_loop' is a well-structured asynchronous function that tests a workflow with a loop step. It uses a counter to track iterations and asserts the expected results, which is a common pattern in testing asynchronous workflows. The code is clear, concise, and serves a specific purpose in testing the loop functionality of a workflow. There is no indication of redundancy or inefficiency that would warrant deletion. Therefore, it is likely to be retained."
survived,"    def __init__(
        self,
        name: str,
        steps: List[WorkflowStep],
        instruction: str = """",
        description: str = """",
        default_llm: Optional[LLM] = None,
        sdk_context: Optional[SDKContext] = None,
        default_user_id: str = ""default_user"",
        default_session_id: str = ""default_chat"",
        workflow_id: Optional[str] = None,
    ) -> None:
        self.id = workflow_id or str(uuid.uuid4())
        self.name = name
        self.instruction = instruction
        self.description = description
        self.default_llm = default_llm
        self.sdk_context = sdk_context or SDKContext.get_instance()
        self.default_user_id = default_user_id
        self.default_session_id = default_session_id
        self.steps = steps
        self.sdk_context.add_resource(self, resource_type=""workflow"")
",swarmzero/workflow.py,Workflow,1,2.8453347280241004e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class with specific attributes. It sets up the initial state of an object, assigns default values, and ensures that necessary resources are added to the SDK context. Such methods are fundamental to object-oriented programming and are unlikely to be removed unless the class itself is deprecated or significantly refactored."
survived,"def test_two_contiguous_selectors():
    B, X, Y = Axis(""batch"", 3), Axis(""x"", 5), Axis(""y"", 7)
    a = hax.arange((B, X, Y))
    ix = hax.arange((B,), dtype=jnp.int32) % X.size
    iy = hax.arange((B,), dtype=jnp.int32) % Y.size
    out = a[""x"", ix, ""y"", iy]
    assert out.axes == (B,)
    ref = a.array[jnp.arange(3), ix.array, iy.array]
    assert jnp.array_equal(out.array, ref)
",tests/test_scatter_gather.py,,1,2.8453347280241004e-08,"The method 'test_two_contiguous_selectors' is a unit test function that verifies the behavior of a specific functionality in the code. Unit tests are generally crucial for ensuring code reliability and correctness, especially in complex systems. The function checks if the output of a certain operation matches the expected result, which is a common practice in software development to prevent regressions and ensure that changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite."
survived,"    def is_finished(self) -> bool:
        return self.status is SequenceStatus.FINISHED
",src/levanter/inference/sequence.py,Sequence,1,4.363462233903899e-09,"The method `is_finished` is a simple utility function that checks if the status of an object is `SequenceStatus.FINISHED`. Such methods are often useful for encapsulating logic and improving code readability, especially when the status check is a common operation. It is likely to be used in multiple places in the codebase to determine if a sequence has completed. Therefore, it is unlikely to be deleted unless the entire logic or structure of the code changes significantly."
survived,"    def add_request(self, prompt: str | List[int], sampling_params: SamplingParams, scheduler: Scheduler) -> None:
        prompt_ids = (
            self.tokenizer.encode(prompt, add_special_tokens=False)
            if isinstance(prompt, str)
            else prompt
        )
        seq = Sequence(list(prompt_ids), sampling_params)
        scheduler.add(seq)
",src/levanter/inference/llm_engine.py,LLMEngine,1,2.3355930333443423e-09,"The method 'add_request' is a utility function that encodes a prompt and adds it to a scheduler. It is a straightforward and useful method for managing sequences in a scheduling system. There is no indication that it is redundant or unnecessary, and it appears to be a core part of the functionality. Therefore, it is likely to be retained."
survived,"    def __init__(self, model_path: str):
        self.model_path = model_path
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)
        self.trainer_cfg = TrainerConfig()
        self.Vocab = round_axis_for_partitioning(
            Axis(""vocab"", len(self.tokenizer)), self.trainer_cfg.compute_axis_mapping
        )
        converter = LlamaConfig().hf_checkpoint_converter()
        converter = converter.replaced(reference_checkpoint=RepoRef(model_path), tokenizer=self.tokenizer)
        self.model = cast(
            LlamaLMHeadModel,
            converter.load_pretrained(
                LlamaLMHeadModel,
                ref=RepoRef(model_path),
                dtype=self.trainer_cfg.mp.compute_dtype,
            ),
        )
        self.sampler = Sampler(self.Vocab)
        self.eos = self.tokenizer.eos_token_id or -1
",src/levanter/inference/llm_engine.py,LLMEngine,1,7.3382086014706e-07,"The method is an initializer for a class, which is a fundamental part of object-oriented programming. It sets up the necessary components for the class instance, such as loading a tokenizer, configuring a model, and setting up a sampler. These are essential operations for the functionality of the class, especially in a machine learning context where model and tokenizer initialization are critical. Therefore, it is unlikely to be deleted unless the entire class is being refactored or removed."
survived,"    def schedule(self) -> tuple[List[Sequence], bool]:
        if self.waiting:
            seq = self.waiting.popleft()
            self.running.append(seq)
            return [seq], True
        seqs = [s for s in self.running if not s.is_finished]
        return seqs, False
",src/levanter/inference/scheduler.py,Scheduler,1,7.582560422162384e-10,"The method 'schedule' is likely to survive because it appears to be a functional part of a scheduling system, handling the transition of sequences from a waiting state to a running state. It checks if there are any sequences waiting, moves them to running, and returns the appropriate status. This logic is essential for managing tasks or processes, suggesting it serves a necessary role in the system."
survived,"    def _prefill(self, seq: Sequence, cache, page_table):
        real_len = len(seq.prompt_token_ids)
        padded_len = _round_preferred(real_len)
        pos_axis = Axis(""position"", padded_len)
        padded_tokens = list(seq.prompt_token_ids) + [self.eos] * (padded_len - real_len)
        tokens = hax.NamedArray(jnp.array(padded_tokens, dtype=jnp.int32), axes=(pos_axis,))
        seq_named = hax.named([seq.seq_id], ""seq"")
        temps = hax.full((), seq.sampling_params.temperature, dtype=jnp.float32)
        key = jrandom.PRNGKey(0)
        tok, page_table, cache = do_prefill(self.model, cache, page_table, tokens, self.sampler, seq_named, temps, key)
        return int(tok.array), cache, page_table
",src/levanter/inference/llm_engine.py,LLMEngine,1,1.0467401685178159e-08,"The method '_prefill' appears to be a utility function that is part of a larger system, likely related to machine learning or data processing. It handles token padding, array creation, and calls another function 'do_prefill' which seems to be a core operation. The method is well-structured, uses type hints, and seems to be part of a system that requires such functionality. There is no indication that it is obsolete or redundant, and it seems to be a necessary part of the system's operation. Therefore, it is likely to be retained."
survived,"    def solve(self, root, is_goal, max_cost=None):
        """""" Returns the shortest path between the root and a given goal, as well as the total cost.
        If the cost exceeds a given max_cost, the function returns None. If you do not give a
        maximum cost the solver will never return for unsolvable instances.""""""

        self.is_goal = is_goal
        self.path = [root]
        self.is_in_path = {root}
        self.path_descrs = []
        self.nodes_evaluated = 0

        bound = self.h(root)

        while True:
            t = self._search(0, bound)
            if t is self.FOUND: return self.path, self.path_descrs, bound, self.nodes_evaluated
            if t is None: return None
            bound = t
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-1.py,IDAStar,1,5.60279640614594e-09,"The method 'solve' is a part of a search algorithm, likely an iterative deepening A* (IDA*) search, which is a well-known algorithm for finding the shortest path in a graph. The method is designed to handle cases where a maximum cost is specified, returning None if the cost exceeds this limit, which is a useful feature for controlling resource usage. The method is also structured to handle unsolvable instances by not returning if no maximum cost is given, which is a common requirement in search algorithms. Given these considerations, the method is likely to be useful and relevant for solving pathfinding problems, and thus it is likely to survive."
survived,"    def __init__(self, object_list):
        """"""
        Save a list in a heapq.
        Assume that each object only appears once
        in the list.
        """"""
        self.queue_length = 0
        self.qheap = []
        for e in object_list:
            self.qheap.append((e.fscore,e.tiles))
            self.queue_length += 1
        heapq.heapify(self.qheap)
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,PriorityQueue,1,5.60279640614594e-09,"The method is a constructor for initializing an object with a list of elements, converting it into a heap using the heapq module. This is a common and useful pattern for managing priority queues, which are widely used in various applications. The method is straightforward, performs a necessary initialization task, and does not contain any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def pop(self):
        """""" remove object from heap and return """"""
        if self.queue_length < 1:
            return None
        fscore, tiles = heapq.heappop(self.qheap)
        self.queue_length -= 1
        global all_positions
        pos = all_positions[tiles]
        if pos.fscore == fscore:
            return pos
        else:
            return self.pop()
",tests/rosetta/x/Python/15-puzzle-solver/15-puzzle-solver-2.py,PriorityQueue,1,1.725782769012759e-08,"The method 'pop' is a crucial part of a heap data structure implementation, which is commonly used in priority queues. The method is responsible for removing and returning the object with the highest priority (or lowest value) from the heap. This functionality is essential for many algorithms that rely on efficient priority queue operations, such as Dijkstra's algorithm or A* search. The method also includes a mechanism to handle discrepancies in the fscore, ensuring the correct object is returned. Given its importance in maintaining the integrity and functionality of the heap, it is unlikely to be deleted."
survived,"    def test_can_load_grammar(self):
        try:
            tree_sitter.Language(tree_sitter_racket.language())
        except Exception:
            self.fail(""Error loading Racket grammar"")",third_party/tree-sitter-racket/bindings/python/tests/test_binding.py,TestLanguage,1,1.1861120010657661e-08,"The method `test_can_load_grammar` is a unit test designed to verify if the Racket grammar can be loaded using the `tree_sitter` library. It is a simple test that checks for exceptions during the loading process and fails the test if an exception is raised. This is a basic and essential test to ensure that the grammar loading functionality works as expected. Such tests are crucial for maintaining the reliability of the codebase, especially when dealing with external libraries or resources. Therefore, it is likely to be retained in the codebase."
survived,"    def _TryToFindUnixSocket(self) -> Optional[str]:

        # This is required to find the socket.
        if self.MoonrakerConfigFilePath is None:
            self.Logger.error(""_TryToFindUnixSocket - No moonraker config file path provided - Is this a companion plugin?"")
            return None

        # First, try to parse the moonraker config to find the klipper socket path, since the moonraker socket should be similar.
        try:
            # Open and read the config.
            # allow_no_value allows keys with no values - strict allows duplicate sections, because sometimes that happens for unknown reasons.
            # Since this is edited by the user, we allow non-strict stuff, since they can make mistakes like multiple sections.
            moonrakerConfig = configparser.ConfigParser(allow_no_value=True, strict=False)
            moonrakerConfig.read(self.MoonrakerConfigFilePath)
            if ""server"" not in moonrakerConfig:
                self.Logger.info(""_TryToFindUnixSocket - No server block found in moonraker config."")
            else:
                if ""klippy_uds_address"" not in moonrakerConfig[""server""]:
                    self.Logger.info(""_TryToFindUnixSocket - klippy_uds_address not found in moonraker config."")
                else:
                    # In most installs, this will be something like `~/printer_data/comms/klippy.sock`
                    klippySocketFilePath = moonrakerConfig[""server""][""klippy_uds_address""]
                    self.Logger.info(""Moonraker klippy unix socket path found in config: ""+klippySocketFilePath)
                    possibleComFolderPath = self._GetParentDirectory(klippySocketFilePath)
                    possibleMoonrakerSocketFilePath = os.path.join(possibleComFolderPath, MoonrakerCredentialManager.c_MoonrakerUnixSocketFileName)
                    if os.path.exists(possibleMoonrakerSocketFilePath):
                        self.Logger.info(""Moonraker socket path found from moonraker config klippy socket path. :""+possibleMoonrakerSocketFilePath)
                        return possibleMoonrakerSocketFilePath
        except configparser.ParsingError as e:
            if ""Source contains parsing errors"" in str(e):
                self.Logger.error(""_TryToFindUnixSocket failed to handle moonraker config. ""+str(e))
        except Exception as e:
            Sentry.OnException(""_TryToFindUnixSocket failed to handle moonraker config."", e)

        # If that failed, try to find the path by stepping back from the moonraker config a few times.
        moonrakerConfigFolderPath = self._GetParentDirectory(self.MoonrakerConfigFilePath)

        # Test the config folder for the file and file + comms folder
        # This isn't likely, but we might as well try.
        testPath = os.path.join(moonrakerConfigFolderPath, MoonrakerCredentialManager.c_MoonrakerUnixSocketFileName)
        if os.path.exists(testPath):
            self.Logger.info(""Moonraker unix socket path found from moonraker config path. :""+testPath)
            return testPath
        testPath = os.path.join(moonrakerConfigFolderPath, MoonrakerCredentialManager.c_MoonrakerUnixSocketFileNameWithCommsFolder)
        if os.path.exists(testPath):
            self.Logger.info(""Moonraker unix socket path found from moonraker config path. :""+testPath)
            return testPath

        # Move a folder up and try again. This is where we expect the comms folder to be located, next to the config folder
        moonrakerPrinterFolderPath = self._GetParentDirectory(moonrakerConfigFolderPath)
        testPath = os.path.join(moonrakerPrinterFolderPath, MoonrakerCredentialManager.c_MoonrakerUnixSocketFileName)
        if os.path.exists(testPath):
            self.Logger.info(""Moonraker unix socket path found from moonraker printer folder path. :""+testPath)
            return testPath
        testPath = os.path.join(moonrakerPrinterFolderPath, MoonrakerCredentialManager.c_MoonrakerUnixSocketFileNameWithCommsFolder)
        if os.path.exists(testPath):
            self.Logger.info(""Moonraker unix socket path found from moonraker printer folder path. :""+testPath)
            return testPath
        return None
",moonraker_octoeverywhere/moonrakercredentialmanager.py,MoonrakerCredentialManager,1,1.955568070542584e-08,"The method '_TryToFindUnixSocket' is a utility function that attempts to locate a Unix socket file path based on a configuration file. It includes error handling, logging, and multiple strategies to find the socket path, which are essential for robust software that interacts with user-configurable systems. The method is well-structured, with clear logging for debugging and error tracking, making it valuable for maintaining and troubleshooting the application. Given its utility and the fact that it handles a specific task that is likely necessary for the application's functionality, it is unlikely to be deleted."
survived,"def visualize_shardings(tree) -> None:
    """"""Print the sharding for each array-like leaf in ``tree``.

    Both :class:`NamedArray` and regular JAX arrays are supported. NamedArrays
    will show the mapping from logical axis names to physical axes. Plain arrays
    will fall back to :func:`jax.debug.visualize_sharding`.
    """"""

    import haliax.tree_util as htu

    def _show(x):
        if isinstance(x, NamedArray):
            arr = x.array
            axes = x.axes
        else:
            arr = x
            axes = None

        def cb(sh):
            if axes is not None:
                visualize_named_sharding(axes, sh)
            else:
                try:
                    jax.debug.visualize_sharding(arr.shape, sh)
                except Exception:
                    pass

        jax.debug.inspect_array_sharding(arr, callback=cb)
        return x

    htu.tree_map(_show, tree, is_leaf=is_jax_or_hax_array_like)",src/haliax/debug.py,,1,1.955568070542584e-08,"The method 'visualize_shardings' is a utility function designed to print the sharding information for array-like structures in a tree. It supports both NamedArray and regular JAX arrays, providing a useful debugging tool for developers working with distributed arrays. The function is well-documented, imports necessary modules, and handles exceptions gracefully. Given its utility in debugging and understanding array sharding, it is likely to be retained in the codebase."
survived,"    def fn(x):
        visualize_shardings(x)
        return x
",tests/test_visualize_sharding.py,,1,0.00013982203410499962,"The method 'fn' is a simple function that takes an input 'x', calls another function 'visualize_shardings' with 'x' as an argument, and then returns 'x'. The function itself does not perform any complex operations or transformations on 'x', making it a straightforward utility function. The decision to keep or delete such a function depends on the context in which it is used. If 'visualize_shardings' is a crucial part of the codebase and 'fn' is used frequently to encapsulate this visualization step, it is likely to be retained. However, if 'fn' is not used or 'visualize_shardings' can be called directly without the need for this wrapper, it might be considered redundant and thus deleted. Without additional context, it's challenging to definitively predict its fate, but given its simplicity and potential utility, it is more likely to be retained."
survived,"            def run_generations(self, *_a):
                pass
",tests/test_agent_aiga_entrypoint.py,TestAgentAIGAEntry.DummyEvolver,0,0.9999995549151272,"The method 'run_generations' is currently a placeholder with no implementation (indicated by 'pass'). If this method is part of a larger class or module that is actively being developed, it might be intended for future implementation. However, if there is no plan to implement it or if it has been left unimplemented for a long time, it might be considered for deletion. Without additional context, it's more likely to be deleted if it remains unused and unimplemented."
survived,"    async def policy(self, obs, ctx):  # type: ignore[override]
        return await self.tools.list_agents()
",alpha_factory_v1/demos/alpha_asi_world_model/openai_agents_bridge.py,InspectorAgent,1,3.466327708641819e-07,"The method 'policy' is an asynchronous function that calls another asynchronous method 'list_agents' from 'self.tools'. The method seems to be part of a larger system, possibly related to agent management or observation handling. Without additional context, it's difficult to determine its full utility, but the method itself is simple and functional. It is likely to survive unless there are changes in the system architecture or the method becomes redundant due to new implementations."
survived,"async def evolve(generations: int = 1) -> str:
    EVOLVER.run_generations(generations)
    return EVOLVER.latest_log()
",alpha_factory_v1/demos/aiga_meta_evolution/openai_agents_bridge.py,,1,2.0611536181902033e-09,"The method 'evolve' is a simple and clear function that performs a specific task: it runs a certain number of generations using the 'EVOLVER' object and returns the latest log. The method is asynchronous, which is beneficial for non-blocking operations, especially if 'EVOLVER.run_generations' is a time-consuming process. The method signature is straightforward, and it uses default parameters, making it flexible for different use cases. There is no indication of redundancy or inefficiency in the code, and it seems to serve a clear purpose in the context of evolutionary algorithms or simulations. Therefore, it is likely to be retained in the codebase."
survived,"async def detect_yield_curve_alpha_tool() -> Dict[str, str]:
    msg = detect_yield_curve_alpha()
    return {""alpha"": msg}
",alpha_factory_v1/demos/era_of_experience/agent_experience_entrypoint.py,,1,1.1861120010657661e-08,"The method `detect_yield_curve_alpha_tool` is a simple asynchronous function that calls another function `detect_yield_curve_alpha` and returns its result in a dictionary format. The method is straightforward and serves a clear purpose of wrapping the result of `detect_yield_curve_alpha` in a dictionary with a specific key. This kind of utility function is common in codebases where results need to be formatted or structured in a specific way for further processing or integration with other systems. Unless there is a significant change in the requirements or the structure of the codebase, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"def test_cli_help():
    result = subprocess.run([
        sys.executable,
        '-m', 'alpha_factory_v1.demos.muzero_planning',
        '--help'
    ], capture_output=True, text=True)
    assert result.returncode == 0
    assert 'MuZero planning demo' in result.stdout",tests/test_muzero_cli.py,,1,4.944450477491054e-09,"The method `test_cli_help` is a test function that checks if the command-line interface (CLI) help for a specific module runs successfully and contains the expected output. This is a common practice in software development to ensure that the CLI provides the correct information to users. Such tests are crucial for maintaining the reliability and usability of command-line tools. Therefore, it is likely to be retained as part of the test suite to ensure ongoing functionality and correctness of the CLI."
survived,"def _make_cert(tmp: Path) -> tuple[str, str, bytes]:
    key = rsa.generate_private_key(public_exponent=65537, key_size=2048)
    cert = (
        x509.CertificateBuilder()
        .subject_name(x509.Name([x509.NameAttribute(NameOID.COMMON_NAME, ""localhost"")]))
        .issuer_name(x509.Name([x509.NameAttribute(NameOID.COMMON_NAME, ""localhost"")]))
        .public_key(key.public_key())
        .serial_number(x509.random_serial_number())
        .not_valid_before(datetime.utcnow())
        .not_valid_after(datetime.utcnow() + timedelta(days=1))
        .add_extension(x509.SubjectAlternativeName([x509.DNSName(""localhost"")]), False)
        .sign(key, hashes.SHA256())
    )
    cert_pem = cert.public_bytes(serialization.Encoding.PEM)
    key_pem = key.private_bytes(
        serialization.Encoding.PEM,
        serialization.PrivateFormat.TraditionalOpenSSL,
        serialization.NoEncryption(),
    )
    cert_path = tmp / ""cert.pem""
    key_path = tmp / ""key.pem""
    cert_path.write_bytes(cert_pem)
    key_path.write_bytes(key_pem)
    return str(cert_path), str(key_path), cert_pem
",tests/test_agents.py,,1,8.152020648014727e-09,"The method _make_cert is a utility function that generates a self-signed certificate and its corresponding private key, writes them to temporary files, and returns their paths along with the certificate bytes. This functionality is essential for testing or development environments where secure communication is needed without relying on a certificate authority. The method is well-structured, uses standard libraries, and fulfills a common requirement in software development, especially in web applications or services that require SSL/TLS. Therefore, it is likely to be retained in the codebase."
survived,"    def _align_cpu(self, seq1: str, seq2: str) -> tuple[int, list[list[int]]]:
        len1, len2 = len(seq1), len(seq2)
        H = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        max_score = 0
        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                match_score = self.match if seq1[i - 1] == seq2[j - 1] else self.mismatch
                diag = H[i - 1][j - 1] + match_score
                up = H[i - 1][j] + self.gap
                left = H[i][j - 1] + self.gap
                val = diag
                if up > val:
                    val = up
                if left > val:
                    val = left
                if val < 0:
                    val = 0
                H[i][j] = val
                if val > max_score:
                    max_score = val
        return max_score, H
",src/python/gpu_smith_waterman.py,SmithWatermanGPU,1,2.646573631904765e-09,"The method '_align_cpu' is a core part of a sequence alignment algorithm, likely used in bioinformatics or similar fields. It implements a dynamic programming approach to calculate the alignment score between two sequences, which is a fundamental operation in many applications. The method is well-structured, efficient, and uses standard techniques for sequence alignment, such as handling matches, mismatches, and gaps. Given its utility and the fact that it is a private method (indicated by the underscore), it is unlikely to be deleted unless the entire functionality it supports is removed or replaced by a more efficient algorithm. Therefore, it is more likely to survive."
survived,"def main():

    gen = HldaDataGenerator(0.01, make_plot=True)

    n_topics = 5
    vocab_size = 25
    document_length = 1000
    n_docs = 100
    df, vocab = gen.generate_input_df(
        n_topics,
        vocab_size,
        document_length,
        n_docs,
    )
",examples/synthetic_data.py,,1,2.2159489282323004e-08,"The method 'main' is a typical entry point for Python scripts and is commonly used to encapsulate the main functionality of a program. The code snippet provided shows a structured approach to generating data using an instance of 'HldaDataGenerator', which suggests that this method is part of a larger program or script that deals with data generation or processing. The use of 'main' in this context is standard practice and does not indicate any issues or reasons for deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def observe(self, *a, **kw):
        pass
",tests/test_eventbus.py,_M,1,2.4300230936537083e-05,"The method 'observe' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future functionality or is meant to be overridden in a subclass. If the method is part of a base class in a framework or library where subclasses are expected to provide specific implementations, it is likely to survive. However, if it is part of a codebase where no such subclassing occurs or if it remains unused, it might be deleted. Without additional context, it's more likely to survive as a placeholder or abstract method."
survived,"    async def _drain_loop(self) -> None:
        assert self._queues is not None
        try:
            while True:
                for q in list(self._queues.values()):
                    while not q.empty():
                        try:
                            q.get_nowait()
                        except asyncio.QueueEmpty:
                            break
                await asyncio.sleep(0.1)
        except asyncio.CancelledError:
            pass
",alpha_factory_v1/backend/agent_runner.py,EventBus,1,1.275190675769241e-07,"The method `_drain_loop` is an asynchronous function designed to continuously drain queues stored in `self._queues`. It uses a loop to iterate over each queue and attempts to remove items until they are empty. The method also handles the `asyncio.CancelledError` exception, which is common in asynchronous programming to allow for graceful cancellation of tasks. This method is likely part of a larger system that manages asynchronous tasks or events, and its functionality is essential for maintaining the state of queues by preventing them from becoming overloaded. Given its utility in managing resources and ensuring smooth operation of asynchronous tasks, it is likely to be retained in the codebase."
survived,"def _env_float(name: str, default: float) -> float:
    """"""Return ``float`` environment value or ``default`` if conversion fails.""""""

    val = os.getenv(name)
    if val is None:
        return default
    try:
        return float(val)
    except (TypeError, ValueError):
        log.warning(""Invalid %s=%r, using default %s"", name, val, default)
        return default
",alpha_factory_v1/backend/agent_runner.py,,1,9.736200303530205e-10,"The method `_env_float` is a utility function that attempts to retrieve an environment variable, convert it to a float, and return it. If the environment variable is not set or cannot be converted to a float, it returns a default value. This is a common pattern in software development for handling configuration values that may be set via environment variables. The function includes error handling and logging, which are good practices. Such utility functions are often useful in various applications, especially those that rely on environment configurations, and are unlikely to be deleted unless the entire approach to configuration management changes. Therefore, it is likely to survive."
survived,"    def max_seqs(self) -> int:
        return self.page_indices.axis_size(""seq"")
",src/levanter/layers/page_table.py,PageTable,1,3.3982678079468468e-09,"The method `max_seqs` is a simple getter function that returns the size of a specific axis ('seq') from `page_indices`. Such methods are typically retained because they encapsulate a specific piece of functionality that might be reused in different parts of the code. It provides a clear and concise way to access this information, which is a common practice in object-oriented programming to maintain encapsulation and readability."
survived,"    def current_num_seqs(self) -> int:
        return hax.sum(self.seq_lens >= 0).scalar()
",src/levanter/layers/page_table.py,PageTable,1,5.905303995456778e-10,"The method `current_num_seqs` is a simple utility function that calculates the number of sequences with non-negative lengths. It is likely to be useful in contexts where the number of valid sequences needs to be determined, especially if `seq_lens` is a common attribute in the class. The method is straightforward, efficient, and provides a clear purpose, which suggests it is likely to be retained in the codebase."
survived,"        def token_body(i, carry):
            token_dests, seq_cursors = carry
            seq_id = tokens[""position"", i].scalar()

            def assign(carry):
                token_dests, seq_cursors = carry
                page_idx = seq_cursors[seq_id] // self.page_size
                page_offset = seq_cursors[seq_id] % self.page_size
                page = new_table.page_indices[""seq"", seq_id, ""page"", page_idx]
                dest = hax.where(page < 0, -1, page * self.page_size + page_offset)
                token_dests = token_dests.at[""position"", i].set(dest)
                seq_cursors = seq_cursors.at[seq_id].add(1)
                return token_dests, seq_cursors

            token_dests, seq_cursors = jax.lax.cond(seq_id >= 0, assign, lambda c: c, (token_dests, seq_cursors))
            return token_dests, seq_cursors
",src/levanter/layers/page_table.py,PageTable,1,1.1861120010657661e-08,"The method 'token_body' is a part of a larger system that deals with token processing, likely in a machine learning or data processing context. It uses JAX, a library for high-performance numerical computing, which suggests that the method is designed for efficient computation. The method appears to handle token destination assignment and sequence cursor updates, which are essential operations in sequence processing tasks. Given its specific functionality and integration with JAX, it is likely to be a crucial part of the system's operation. Therefore, it is unlikely to be deleted unless there is a significant redesign of the system."
survived,"    def add_output_guardrail(self, guardrail: Callable[[str], Awaitable[None]]) -> None:
        self.output_guardrails.append(guardrail)
",src/meta_agent/services/guardrail_router.py,GuardrailModelRouter,1,2.5946094982091465e-11,"The method `add_output_guardrail` is likely to survive because it provides a mechanism to add a guardrail function to a list, which is a common pattern in software design for extending functionality or adding hooks. This method is simple, clear, and serves a specific purpose, making it useful for managing output guardrails in a system."
survived,"    def test_mixed_args_grad_numpy(self):
        self._check_mixed_args_grad(""numpy"")
",tests/test_autograd.py,TestAutograd,1,4.363462233903899e-09,"The method `test_mixed_args_grad_numpy` is a test function, likely part of a test suite for a larger codebase. Test functions are generally retained as they are crucial for ensuring the correctness and reliability of the code. The method name suggests it is testing the gradient computation with mixed arguments using a 'numpy' backend or library, which is a common requirement in scientific computing and machine learning applications. Unless there is a significant change in the testing framework or the method is replaced by a more comprehensive test, it is likely to be retained."
survived,"def main() -> None:
    root = Path(__file__).resolve().parent.parent
    base = root / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1""
    for rel, cid in ASSETS.items():
        dest = base / rel
        print(f""Fetching {rel} from {cid}..."")
        download(cid, dest)
",scripts/fetch_assets.py,,1,9.237449576640118e-09,"The method 'main' is a simple script that iterates over a dictionary 'ASSETS', prints a message, and calls a 'download' function. It is a straightforward utility function that is likely part of a larger system for managing assets. Such utility functions are common in codebases and are typically retained unless they are replaced by a more efficient or comprehensive solution. Without any indication of redundancy or obsolescence, it is reasonable to predict that this method will survive."
survived,"    def register(self, *a, **k):
        pass
",tests/test_rate_lock.py,DummyRuntime,0,0.9999999586006244,"The method 'register' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it might be a placeholder for future functionality. However, without any additional context or usage, it is likely to be considered dead code. If the method is not used or planned to be implemented, it is likely to be deleted to clean up the codebase."
survived,"        def run(self) -> None:
            pass
",tests/test_alpha_opportunity_stub.py,DummyRuntime,1,6.962258425838873e-06,"The method 'run' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it is a placeholder for future code or is meant to be overridden in a subclass. If this method is part of a base class intended for inheritance, it is likely to survive. However, if it is not used or overridden anywhere, it might be deleted in the future. Without additional context, it is more likely to survive as a placeholder or abstract method."
survived,"def test_firejail_used_when_available(monkeypatch) -> None:
    calls: dict[str, list] = {}

    def fake_run(cmd, **kwargs):
        calls[""cmd""] = cmd
        calls[""preexec_fn""] = kwargs.get(""preexec_fn"")

        class P:
            stdout = ""{}""
            stderr = """"

        return P()

    monkeypatch.setattr(codegen_agent.shutil, ""which"", lambda n: ""/usr/bin/firejail"")
    monkeypatch.setattr(codegen_agent.subprocess, ""run"", fake_run)

    agent = _make_agent()
    agent.execute_in_sandbox(""print('hi')"")

    assert calls[""cmd""][0] == ""/usr/bin/firejail""
    assert ""--net=none"" in calls[""cmd""]
    assert calls[""preexec_fn""] is None",tests/test_codegen_agent.py,,1,5.60279640614594e-09,"The method `test_firejail_used_when_available` is a unit test that verifies the behavior of a function when a specific condition is met (i.e., when 'firejail' is available). It uses monkeypatching to simulate the environment and checks if the command is executed with 'firejail'. This is a typical and useful test case to ensure that the code behaves correctly under certain conditions, and there is no indication that it is obsolete or incorrect. Therefore, it is likely to be retained."
survived,"    def close(self) -> None:
        """"""Unsubscribe the agent from the bus.""""""
        self.bus.unsubscribe(self.name, self._handler)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/base_agent.py,BaseAgent,1,1.8553915987649156e-07,"The method 'close' is a standard way to clean up resources by unsubscribing from an event bus, which is a common pattern in event-driven programming. It is likely to be used to prevent memory leaks or unwanted behavior when the object is no longer needed. Therefore, it is a necessary part of the class's lifecycle management and is unlikely to be deleted."
survived,"def test_load_dotenv(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    env = tmp_path / ""sample.env""
    env.write_text(""FOO=bar\n"", encoding=""utf-8"")
    monkeypatch.delenv(""FOO"", raising=False)
    cfg._load_dotenv(str(env))
    assert os.environ[""FOO""] == ""bar""
",tests/test_config_utils.py,,1,3.2241866333029355e-08,"The method `test_load_dotenv` is a unit test function designed to test the functionality of loading environment variables from a file using a temporary path and the `monkeypatch` fixture from `pytest`. This is a common practice in testing to ensure that environment variables are correctly loaded and manipulated without affecting the actual environment. The function is well-structured, uses standard testing practices, and is likely part of a test suite for a larger application. Given its utility in ensuring code reliability and correctness, it is likely to be retained in the codebase."
survived,"    def _model_dump_json(self: BaseModel, *args: Any, **kwargs: Any) -> str:
        return self.json(*args, **kwargs)
",src/meta_agent/__init__.py,,0,0.9999999950555496,"The method `_model_dump_json` is a simple wrapper around the `json` method of the `BaseModel` class. It doesn't add any new functionality or customization to the existing `json` method, which makes it redundant. In software development, especially in frameworks like Pydantic (which `BaseModel` is likely a part of), maintaining clean and efficient code is important. Redundant methods that don't provide additional value are often removed to reduce code bloat and maintenance overhead. Therefore, this method is likely to be deleted."
survived,"    def _worker() -> None:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        task = loop.create_task(coro)
        try:
            result.append(asyncio.get_event_loop().run_until_complete(task))
        finally:
            loop.close()
",alpha_factory_v1/backend/agents/energy_agent.py,,0,0.99999998813888,"The method '_worker' is likely to be deleted (0) because it contains several issues that make it unreliable and potentially problematic. Firstly, it creates a new event loop and sets it as the current event loop, which can lead to unexpected behavior if other parts of the application are also using asyncio. This is generally not recommended as it can cause conflicts and make the code harder to maintain. Additionally, the method does not handle exceptions that might occur during the execution of the coroutine, which could lead to unhandled exceptions and application crashes. These issues suggest that the method is not robust and might be removed or replaced with a more reliable implementation."
survived,"def backtrack_boost(pop: List[Any], archive: List[Any], rate: float) -> Any:
    """"""Return a parent possibly selected from weaker individuals.

    With probability ``rate`` the parent is drawn uniformly from the
    lower half of ``archive`` based on fitness.  Otherwise the regular
    ``select_parent`` mechanism chooses from ``pop``.
    """"""

    if not pop:
        raise ValueError(""population is empty"")
    if rate <= 0.0:
        return select_parent(pop, temp=1.0)
    if random.random() < rate:
        ranked = sorted(archive, key=lambda c: getattr(c, ""fitness"", 0.0))
        bottom = ranked[: max(1, len(ranked) // 2)]
        return random.choice(bottom)
    return select_parent(pop, temp=1.0)",src/simulation/mats_ops.py,,1,7.194132978569833e-09,"The method 'backtrack_boost' is a well-defined function that provides a mechanism for selecting a parent from a population or an archive based on a given probability rate. It includes error handling for an empty population and uses a clear strategy for selection based on fitness. The function is likely to be useful in evolutionary algorithms or genetic programming contexts where diversity in selection is beneficial. Therefore, it is likely to be retained."
survived,"def _evaluate_patch(patch: Path) -> Dict[str, float]:
    """"""Return baseline and ablation scores for ``patch``.""""""

    scores: Dict[str, float] = {}
    with tempfile.TemporaryDirectory() as tmp:
        repo = Path(tmp)
        _clone_repo(repo)
        apply_patch(patch.read_text(), repo_path=tmp)
        base_flags = {n: True for n in INNOVATIONS}
        baseline = _run_bench(repo, base_flags)
        scores[""baseline""] = baseline
        for name in INNOVATIONS:
            flags = base_flags.copy()
            flags[name] = False
            scores[name] = _run_bench(repo, flags)
    return scores
",src/tools/ablation_runner.py,,1,3.581747929000289e-10,"The method `_evaluate_patch` is well-structured and serves a clear purpose: evaluating a patch by applying it to a cloned repository and running benchmarks to compare baseline and ablation scores. It uses a temporary directory to avoid side effects, and the logic is straightforward and useful for testing patches. There are no obvious issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"    def evolve(
        self,
        scenario_hash: str,
        fn: Callable[[list[float]], tuple[float, ...]],
        genome_length: int,
        **kwargs: object,
    ) -> mats.Population:
        """"""Run evolution for ``scenario_hash`` using persistent islands.""""""

        pop = mats.run_evolution(
            fn,
            genome_length,
            scenario_hash=scenario_hash,
            populations=self.island_pops,
            **kwargs,
        )
        self.island_pops[scenario_hash] = pop
        return pop
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,8.152020648014727e-09,"The method 'evolve' is a core part of a class that deals with evolutionary algorithms, specifically using a concept of 'persistent islands'. This suggests that it is part of a larger framework or system designed to handle complex evolutionary computations. The method is well-defined, uses type hints, and integrates with a presumably existing system ('mats.run_evolution'). It is likely to be a crucial part of the functionality of the class it belongs to, especially if the class is designed to manage evolutionary processes. Therefore, it is unlikely to be deleted unless the entire system undergoes a significant redesign or is deprecated."
survived,"def _add_path(root: Dict[str, Any], path: Iterable[str]) -> None:
    node = root
    for name in path:
        children = node.setdefault(""children"", [])
        for child in children:
            if child.get(""name"") == name:
                node = child
                break
        else:
            child = {""name"": name}
            children.append(child)
            node = child
",alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py,,1,2.5109990926928157e-08,"The method `_add_path` is a utility function that adds a path to a tree-like data structure represented by nested dictionaries. It is a common pattern used in various applications to build hierarchical data structures. The method is well-defined, performs a specific task, and does not have any apparent issues or redundancies that would warrant its deletion. It is likely to be useful in contexts where such a data structure is needed, and there is no indication that it is obsolete or replaced by a better alternative."
survived,"    def test_index_negative_column(self):
        """"""Use negative index for last column""""""
        self.assert_eval_cmp('[[1 2 3] [4 5 6]]:@[[] -1]', '[3 6]')
",tests/test_numpy_slice.py,TestNumpySliceBehavior,1,2.998960815863541e-09,"The method 'test_index_negative_column' is a test case that checks the functionality of using a negative index to access the last column of a 2D array. This is a common and useful feature in many programming languages and libraries, such as Python's NumPy, where negative indices are used to access elements from the end of an array. The test is straightforward and serves a clear purpose in ensuring that the negative indexing feature works as expected. Therefore, it is likely to be retained as part of the test suite to ensure the robustness of the codebase."
survived,"def test_business_bridge_offline(monkeypatch, capsys):
    # Stub google_adk so adk_bridge imports succeed without network
    dummy = types.ModuleType(""google_adk"")
    dummy.Agent = object

    class _Router:
        def __init__(self):
            self.app = types.SimpleNamespace(middleware=lambda *_a, **_k: lambda f: f)

        def register_agent(self, _agent):
            pass

    dummy.Router = _Router
    dummy.AgentException = Exception
    monkeypatch.setitem(sys.modules, ""google_adk"", dummy)

    # Ensure OPENAI_API_KEY unset and openai_agents import fails
    monkeypatch.delenv(""OPENAI_API_KEY"", raising=False)
    monkeypatch.setattr(
        check_env, ""main"", lambda *_a, **_k: (_ for _ in ()).throw(requests.exceptions.ConnectionError(""offline""))
    )
    sys.modules.pop(""openai_agents"", None)
    orig_import = builtins.__import__

    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai_agents"":
            raise ModuleNotFoundError(name)
        return orig_import(name, globals, locals, fromlist, level)

    monkeypatch.setattr(builtins, ""__import__"", fake_import)

    bridge = importlib.reload(
        importlib.import_module(""alpha_factory_v1.demos.alpha_agi_business_v1.openai_agents_bridge"")
    )

    assert bridge._require_openai_agents() is False

    bridge.main()
    captured = capsys.readouterr()
    assert ""OpenAI Agents SDK not available; bridge inactive."" in captured.out",tests/test_business_bridge_offline.py,,1,2.0611536181902033e-09,"The method 'test_business_bridge_offline' is a unit test designed to test the behavior of a system when certain modules and environment variables are unavailable. It uses monkeypatching to simulate an offline environment and checks if the system correctly handles the absence of the OpenAI Agents SDK. This is a valid and useful test case for ensuring robustness in the face of missing dependencies or network issues. Therefore, it is likely to be retained in the codebase."
survived,"def test_build_and_search(tmp_path) -> None:
    reg = TemplateRegistry(base_dir=tmp_path)
    reg.register(_meta(""foo""), ""hello foo"")
    reg.register(_meta(""bar""), ""hello bar"")

    index = TemplateIndex(reg)
    index.rebuild()

    results = index.search(""hello foo"")
    assert results and results[0][""slug""] == ""foo""
",tests/test_template_index.py,,1,1.8189616842444243e-09,"The method 'test_build_and_search' is a unit test function that verifies the functionality of a template registry and index system. It checks if templates can be registered, indexed, and searched correctly. This is a crucial part of ensuring the integrity and reliability of the template system, especially if it is part of a larger application. Unit tests are generally not deleted unless the functionality they test is removed or significantly changed. Therefore, this method is likely to be retained to ensure ongoing validation of the system's behavior."
survived,"    def ensure_up_to_date(self) -> None:
        if self.needs_rebuild():
            self.rebuild()
        else:
            self.load()
",src/meta_agent/template_index.py,TemplateIndex,1,3.850741907939403e-09,"The method 'ensure_up_to_date' is a utility function that checks if an object needs to be rebuilt and performs the necessary action. This is a common pattern in software development to ensure that objects are in the correct state before use. The method is likely to be useful in maintaining the integrity and performance of the system, as it automates the decision-making process of whether to rebuild or load an object. Therefore, it is likely to be retained in the codebase."
survived,"def _free_port() -> int:
    with socket.socket() as s:
        s.bind((""127.0.0.1"", 0))
        return int(s.getsockname()[1])
",tests/test_evolution_worker.py,,1,5.60279640614594e-09,"The method _free_port is a utility function that finds and returns a free port on the local machine. This is a common requirement in network programming, especially for testing purposes where a free port is needed to bind a server or client socket without hardcoding a specific port number. The method is simple, effective, and uses standard library functions, making it a useful tool for developers. Therefore, it is likely to be retained in the codebase."
survived,"async def mutate(
    tar: UploadFile | None = File(None),
    repo_url: str | None = Form(None),
) -> MutationResponse:
    """"""Return a mutated child from one evolution step.""""""

    if tar is None and not repo_url:
        raise HTTPException(status_code=400, detail=""tar or repo_url required"")

    tmp = tempfile.mkdtemp(dir=STORAGE_PATH)
    tmp_path = Path(tmp)
    try:
        if tar is not None:
            with tarfile.open(fileobj=tar.file) as tf:
                tf.extractall(tmp_path)
        if repo_url:
            (tmp_path / ""repo.txt"").write_text(repo_url)

        pop = mats.run_evolution(
            lambda g: (g[0] ** 2, g[1] ** 2),
            2,
            population_size=4,
            generations=1,
            seed=42,
        )
        child = pop[0].genome
        return MutationResponse(child=child)
    finally:
        for p in tmp_path.rglob(""*""):
            if p.is_file():
                p.unlink()
        tmp_path.rmdir()
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/evolution_worker.py,,1,8.152020648014727e-09,"The method 'mutate' is well-structured and serves a clear purpose in the context of handling file uploads and URL inputs to perform a mutation operation. It includes error handling, temporary file management, and a clear return type. These characteristics suggest that it is a useful and necessary part of the codebase, likely contributing to a larger application that requires mutation operations. Therefore, it is unlikely to be deleted."
survived,"    def best_architecture(self) -> str:
        return self.best_genome.to_json() if self.best_genome else """"",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,7.05287985061473e-11,"The method 'best_architecture' is a simple utility function that returns a JSON representation of 'best_genome' if it exists, or an empty string if it doesn't. This method is straightforward, has a clear purpose, and is likely useful in contexts where the best genome's data needs to be serialized for storage or transmission. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def _ray_eval(self):
        @ray.remote
        def _worker(js: str):
            g = Genome.from_json(js)
            module = import_module(__name__)
            return module.MetaEvolver._simulate(module.MetaEvolver, g)
        futures = [_worker.remote(g.to_json()) for g in self.population]
        results = ray.get(futures)
        return self._post_eval(results)
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,2.0611536181902033e-09,"The method `_ray_eval` is designed to parallelize the evaluation of a population of genomes using Ray, a library for parallel and distributed computing. This method is likely to survive because it leverages modern parallel computing techniques to improve performance, which is a valuable feature in computational tasks that involve large datasets or complex simulations. Additionally, the method is well-structured, using a remote worker function to handle individual genome evaluations and collecting results efficiently. Such methods are crucial in evolutionary algorithms and other AI applications, making them less likely to be removed unless there is a significant change in the underlying architecture or requirements."
survived,"    def load(self, path: pathlib.Path | None = None):
        if path is None:
            latest = max(self.ckpt_dir.glob(""gen_*.json""), default=None)
            if not latest:
                raise FileNotFoundError(""no checkpoint found"")
            path = latest
        js = json.loads(path.read_text())
        self.gen = js[""gen""]
        self.population = [Genome.from_json(j) for j in js[""pop""]]
        self.history = js.get(""hist"", [])
        self._archive = [np.array(a) for a in js.get(""arc"", [])]
        self.rng.seed(js.get(""seed"", 0))
        self._best_fitness = js.get(""best_fitness"", -math.inf)
        bg = js.get(""best_genome"")
        self.best_genome = Genome.from_json(bg) if bg else self.population[0]
        if _fitness_gauge:
            _fitness_gauge.set(self._best_fitness)
        LOG.info(""Loaded checkpoint gen=%d sha=%s"", self.gen, js.get(""sha"", ""?""))
",alpha_factory_v1/demos/aiga_meta_evolution/meta_evolver.py,MetaEvolver,1,2.3355930333443423e-09,"The method 'load' is likely to survive because it is a crucial part of the functionality for loading a checkpoint from a file. This is a common requirement in applications that involve saving and loading states, such as in machine learning or simulation environments. The method is well-structured, handles default cases, and raises appropriate exceptions when necessary, indicating good design practices. Additionally, it uses logging to provide useful information about the loading process, which is beneficial for debugging and monitoring."
survived,"    def _close_producer() -> None:  # graceful flush on exit
        try:
            _producer.flush()
            _producer.close()
        except Exception:  # noqa: BLE001
            log.exception(""Kafka producer close failed"")
",alpha_factory_v1/backend/orchestrator.py,,1,1.275190675769241e-07,"The method '_close_producer' is a private utility function designed to gracefully close a Kafka producer by flushing and closing it. It includes exception handling to log any errors that occur during this process. This is a common pattern in resource management to ensure that resources are properly released, and the presence of logging indicates that the developers want to be informed of any issues during the close operation. Such utility functions are typically retained as they are crucial for maintaining the stability and reliability of the application, especially in production environments where resource leaks can lead to significant problems."
survived,"def test_entropy_js() -> None:
    subprocess.check_call([""npm"", ""test""], cwd=BROWSER_DIR)",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_entropy_js.py,,1,1.1032560311263802e-09,"The method `test_entropy_js` is a simple wrapper around a subprocess call to run npm tests in a specific directory. This is a common utility function in development environments where automated testing is required. It is likely to be used in continuous integration pipelines or during development to ensure code quality. Such utility functions are generally useful and are not typically removed unless they are replaced by a more comprehensive testing framework or the project structure changes significantly. Therefore, it is likely to survive."
survived,"def _require_node_20() -> None:
    try:
        out = subprocess.check_output(
            [""node"", ""-e"", ""console.log(process.versions.node)""],
            text=True,
        ).strip()
    except FileNotFoundError:
        sys.exit(""Node.js 20+ is required. 'node' not found."")
    major = int(out.split(""."")[0])
    if major < 20:
        sys.exit(f""Node.js 20+ is required. Current version: {out}"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/manual_build.py,,1,6.69158608681505e-10,"The method '_require_node_20' is a utility function that checks if Node.js version 20 or higher is installed. This is a common requirement for software that depends on features or improvements introduced in newer versions of Node.js. The function is straightforward, using subprocess to execute a Node.js command and checking the version. It provides clear error messages if the requirements are not met. Such utility functions are often retained as they ensure compatibility and prevent runtime errors due to version mismatches. Therefore, it is likely to survive."
survived,"    def test_invalid_parameters_raise(self):
        with self.assertRaises(ValueError):
            run_sim(agents=0, rounds=10, delta=0.5, stake=1)
        with self.assertRaises(ValueError):
            run_sim(agents=1, rounds=0, delta=0.5, stake=1)
        with self.assertRaises(ValueError):
            run_sim(agents=1, rounds=10, delta=1.5, stake=1)
        with self.assertRaises(ValueError):
            run_sim(agents=1, rounds=10, delta=0.5, stake=-1)
",alpha_factory_v1/tests/test_governance_sim.py,GovernanceSimTest,1,1.8189616842444243e-09,"The method `test_invalid_parameters_raise` is a unit test designed to ensure that the `run_sim` function correctly raises a `ValueError` when given invalid parameters. This is a common and important practice in software development to ensure that functions handle erroneous input gracefully. The method is well-structured and serves a clear purpose in validating the robustness of the `run_sim` function. Therefore, it is likely to be retained as part of the test suite."
survived,"        def fake_openai_agent(*_a, **kwargs):
            return types.SimpleNamespace(base_url=kwargs.get(""base_url""))
",tests/test_openai_bridge_runtime.py,TestAIGABridgeRuntime,1,4.1399375473943306e-08,"The method 'fake_openai_agent' is a simple utility function that returns a SimpleNamespace object with a 'base_url' attribute. This kind of function is often used in testing or as a placeholder for more complex functionality. Since it is a utility function, it is likely to be useful in various contexts where a mock or stub is needed, especially in testing environments. Therefore, it is more likely to be retained rather than deleted."
survived,"        def json(self) -> dict:
            return {""choices"": [{""message"": {""content"": ""ok""}}]}
",tests/test_llm_client_offline.py,DummyResp,1,9.237449576640118e-09,"The method is a simple implementation that returns a dictionary with a specific structure. It is likely part of a larger system where this structure is expected. The method is straightforward, has no apparent issues, and serves a clear purpose. Therefore, it is likely to be retained unless the system's requirements change significantly."
survived,"def main() -> int:
    demos = iter_demos()
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            for demo in demos:
                page = browser.new_page()
                page.goto((demo / ""index.html"").resolve().as_uri())
                page.wait_for_selector(""body"")
                page.wait_for_selector(""h1"")
                page.close()
            browser.close()
        return 0
    except PlaywrightError as exc:
        print(f""Playwright error: {exc}"", file=sys.stderr)
        return 1
    except Exception as exc:  # noqa: BLE001
        print(f""Demo check failed: {exc}"", file=sys.stderr)
        return 1
",scripts/verify_demo_pages.py,,1,9.736200303530205e-10,"The method is likely to survive because it is a well-structured function that uses Playwright to automate browser actions. It handles exceptions properly, ensuring that errors are logged and a non-zero exit code is returned in case of failure. This is a common pattern in automation scripts and is useful for testing web pages, making it a valuable utility."
survived,"def test_dist_has_no_superintelligence() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    text = dist.read_text(encoding=""utf-8"")
    assert ""superintelligence"" not in text",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_no_superintelligence.py,,1,1.6052280526088547e-09,"The method `test_dist_has_no_superintelligence` is a unit test that checks if the word ""superintelligence"" is not present in a specific HTML file. This kind of test is useful for ensuring that certain content is not included in a distribution package, which can be important for compliance, branding, or content management reasons. Since it serves a clear purpose in validating the contents of a distribution, it is likely to be retained as part of the test suite."
survived,"            def _decorator(func):
                return func
",tests/test_openai_bridge.py,TestOpenAIBridge,1,1.0677030767166749e-06,"The method _decorator is a simple function that takes another function as an argument and returns it unchanged. This is a basic implementation of a decorator pattern, which is a common and useful technique in Python for extending the behavior of functions or methods. Since it is a valid and potentially useful utility function, especially in larger codebases where decorators are frequently used, it is likely to be retained for its simplicity and potential for future extension."
survived,"    def test_run_demo_market_data(self) -> None:
        import tempfile

        with tempfile.NamedTemporaryFile(""w"", delete=False) as fh:
            fh.write(""6,6,6"")
            feed_path = fh.name
        result = subprocess.run(
            [
                sys.executable,
                ""-m"",
                ""alpha_factory_v1.demos.meta_agentic_tree_search_v0.run_demo"",
                ""--episodes"",
                ""2"",
                ""--market-data"",
                feed_path,
            ],
            capture_output=True,
            text=True,
        )
        self.assertEqual(result.returncode, 0, result.stderr)
        self.assertIn(""Best agents"", result.stdout)
",tests/test_meta_agentic_tree_search_demo.py,TestMetaAgenticTreeSearchDemo,1,7.194132978569833e-09,"The method 'test_run_demo_market_data' is a unit test designed to verify the functionality of a demo script by running it with specific parameters and checking the output. It uses a temporary file to simulate market data input and asserts that the script runs successfully and produces expected output. This is a typical and necessary part of software testing to ensure code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important purpose in the development process."
survived,"    def fake_import(name, globals=None, locals=None, fromlist=(), level=0):
        if name == ""openai.agents"":
            raise ModuleNotFoundError
        return orig_import(name, globals, locals, fromlist, level)
",tests/test_agents.py,,1,9.931195248674785e-08,"The method 'fake_import' is designed to override the default import mechanism to specifically block the import of the 'openai.agents' module by raising a 'ModuleNotFoundError'. This kind of functionality is often used for testing purposes or to prevent certain modules from being used in a particular environment. However, the method itself is not inherently harmful or unnecessary, as it serves a specific purpose. Unless there is a change in the requirements or the environment where this code is used, there is no strong reason to delete it. Therefore, it is likely to survive."
survived,"def test_python_requires_is_39():
    setup_path = Path(__file__).resolve().parents[1] / ""setup.py""
    with open(setup_path, ""r"", encoding=""utf-8"") as f:
        tree = ast.parse(f.read(), filename=""setup.py"")

    for node in ast.walk(tree):
        if isinstance(node, ast.keyword) and node.arg == ""python_requires"":
            assert isinstance(node.value, ast.Constant)
            value = node.value.value
            assert value == "">=3.9, <4""
            break
    else:
        pytest.fail(""python_requires not found"")",tests/test_setup.py,,1,5.60279640614594e-09,"The method `test_python_requires_is_39` is a test function that checks if the `setup.py` file specifies a Python version requirement of '>=3.9, <4'. This is a common practice to ensure compatibility with specific Python versions. The function uses the `ast` module to parse the `setup.py` file and verify the `python_requires` keyword. This kind of test is useful for maintaining the integrity of the package's version requirements and ensuring that the package is not used with incompatible Python versions. Therefore, it is likely to be retained as part of the test suite to prevent future compatibility issues."
survived,"def cytomat_rack_60mm_8(name: str):
  return _cytomat_rack(name=name, site_height=60, num_sites=8, model=""cytomat_rack_60mm_8"")
",pylabrobot/storage/cytomat/racks.py,,1,9.736200303530205e-10,"The method `cytomat_rack_60mm_8` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the API for users by providing a more descriptive or specific function name that sets certain parameters by default. Such functions are generally useful for code readability and maintainability, especially if the parameters are frequently used together. Unless there is a significant change in the requirements or the underlying function `_cytomat_rack` is removed or changed drastically, this method is likely to survive."
survived,"def validate_storage_location_number(storage_location_number: str):
  try:
    int(storage_location_number)
  except ValueError as exc:
    raise ValueError(""Storage location number must be an integer."") from exc
  if len(storage_location_number) != 3:
    raise ValueError(""Storage location number must be a three-digit number."")",pylabrobot/storage/cytomat/utils.py,,1,1.2501528648238603e-09,"The method `validate_storage_location_number` is a utility function that checks if a given storage location number is a valid three-digit integer. This kind of validation is common in applications where specific formats are required for identifiers or codes. The method is simple, clear, and performs a necessary check that could prevent errors in data processing or storage. Such utility functions are often retained in codebases because they encapsulate a specific piece of logic that is reused across the application. Therefore, it is likely to survive."
survived,"  async def set_temperature(self, temperature: float):
    raise NotImplementedError(""Temperature control not implemented yet"")
",pylabrobot/storage/cytomat/heraeus_cytomat_backend.py,HeraeusCytomatBackend,1,2.5612814850547937e-06,"The method 'set_temperature' is currently not implemented and raises a NotImplementedError. This indicates that the method is intended to be implemented in the future, but as it stands, it does not perform any functionality. If the system or application requires temperature control functionality, this method will likely be implemented rather than deleted. Therefore, it is more likely to survive as it is a placeholder for future development."
survived,"def cytomat_rack_18mm_26(name: str):
  return _cytomat_rack(name=name, site_height=18, num_sites=26, model=""cytomat_rack_18mm_26"")
",pylabrobot/storage/cytomat/racks.py,,1,6.348800075736417e-09,"The method `cytomat_rack_18mm_26` is a simple wrapper function that calls another function `_cytomat_rack` with specific parameters. This kind of function is often used to simplify the API for users by providing a more descriptive or specific function name that sets default parameters for a more generic function. Such functions are typically retained unless there is a significant reason to remove them, such as redundancy, lack of use, or a change in the underlying implementation that makes them obsolete. Without evidence of these factors, it is likely that this method will survive."
survived,"  async def open_door(self):
    return await self.backend.open_door()
",pylabrobot/storage/incubator.py,Incubator,1,2.8453347280241004e-08,"The method `open_door` is a simple asynchronous wrapper around a backend method `open_door`. It doesn't add any additional logic or functionality, making it somewhat redundant. However, it could be useful for maintaining a consistent interface or for future expansion where additional logic might be added. Without more context, it's difficult to definitively say if it will be deleted, but given its potential utility for interface consistency, it is more likely to survive."
survived,"  async def start_shaking(self, frequency: float, shakers: Optional[List[int]] = None):
    if self.model == CytomatType.C5C:
      raise NotImplementedError(""Shaking is not supported on this model"")
    await self.set_shaking_frequency(frequency=int(frequency), shakers=shakers)
    return hex_to_binary(await self.send_command(""ll"", ""va"", """"))
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,9.736200303530205e-10,"The method 'start_shaking' is designed to handle a specific functionality related to shaking, with a check for a specific model type where shaking is not supported. This indicates that the method is well thought out and handles exceptions appropriately. Additionally, it uses asynchronous programming, which is modern and efficient for I/O operations. The method is likely part of a larger system where such functionality is necessary, and there is no indication of it being obsolete or redundant. Therefore, it is likely to survive."
survived,"  async def close_door(self):
    print(""Closing door"")
",pylabrobot/storage/chatterbox.py,IncubatorChatterboxBackend,1,6.023574641292144e-08,"The method 'close_door' is a simple asynchronous function that prints a message indicating a door is being closed. It is a basic utility function that could be part of a larger system, such as a home automation or robotics application. The method is likely to be retained because it serves a clear purpose and is implemented correctly for its intended function. Additionally, asynchronous functions are useful in scenarios where non-blocking operations are required, which adds to its utility."
survived,"def cytomat_rack_69mm_7(name: str):
  return _cytomat_rack(name=name, site_height=69, num_sites=7, model=""cytomat_rack_69mm_7"")
",pylabrobot/storage/cytomat/racks.py,,1,4.363462233903899e-09,"The method `cytomat_rack_69mm_7` is a specific configuration function that likely serves a particular purpose in a larger system. It calls another function `_cytomat_rack` with specific parameters, suggesting it is part of a modular design where different configurations are needed. Such functions are typically retained unless the entire system is being deprecated or significantly refactored. Without evidence of such a refactor or deprecation, it is reasonable to predict that this method will survive."
survived,"  async def action_read_barcode(
    self,
    site_number_a: str,
    site_number_b: str,
  ) -> OverviewRegisterState:
    # Read barcode of storage locations
    validate_storage_location_number(site_number_a)
    validate_storage_location_number(site_number_b)
    resp = await self.send_command(""mv"", ""sn"", f""{site_number_a} {site_number_b}"")
    return OverviewRegisterState.from_resp(resp)
",pylabrobot/storage/cytomat/cytomat.py,CytomatBackend,1,9.736200303530205e-10,"The method 'action_read_barcode' is likely to survive because it performs a specific and useful function within the codebase. It reads barcodes of storage locations, validates them, sends a command, and processes the response into a structured state. This functionality is essential for systems that manage inventory or track items in storage, making it a valuable part of the application."
survived,"  async def start_shaking(self, frequency: float = 1.0):
    await self.backend.start_shaking(frequency=frequency)
",pylabrobot/storage/incubator.py,Incubator,1,2.3355930333443423e-09,"The method `start_shaking` is an asynchronous function that calls another method `start_shaking` on a `backend` object, passing a frequency parameter. This method is likely part of a larger system where the backend handles hardware or simulation tasks that require shaking at a specified frequency. The method is straightforward, uses a default parameter, and leverages asynchronous programming, which is beneficial for non-blocking operations. There is no indication of redundancy, inefficiency, or obsolescence in the method's design or purpose. Therefore, it is likely to be retained in the codebase."
survived,"  async def fetch_plate_to_loading_tray(self, plate: Plate):
    pass
",pylabrobot/storage/backend.py,IncubatorBackend,0,0.9999999634651793,"The method `fetch_plate_to_loading_tray` is defined as an asynchronous function but currently contains only a `pass` statement, indicating that it has no implementation. Methods like this are often placeholders for future development. However, without any implementation or documentation indicating its necessity or future use, it is likely to be considered dead code. Unless there is a clear plan to implement this method or it is part of an interface that requires its presence, it is likely to be deleted in future code clean-ups."
survived,"  async def set_temperature(self, temperature: float):
    """"""Set the temperature of the incubator in degrees Celsius.""""""
    return await self.backend.set_temperature(temperature)
",pylabrobot/storage/incubator.py,Incubator,1,7.194132978569833e-09,"The method 'set_temperature' is a straightforward asynchronous function that sets the temperature of an incubator. It is likely a part of a larger system that controls an incubator, and such functionality is essential for the operation of the incubator. The method is simple, clear, and directly interacts with a backend system to perform its task, which suggests it is a necessary part of the system's functionality. Therefore, it is unlikely to be deleted unless there is a significant change in the system's architecture or requirements."
survived,"        def _walk(name: str) -> None:
            if name in visited:
                return
            s, v = _split_name(name)
            source = self.registry.load_template(s, v) or """"
            deps = pattern.findall(source)
            visited[name] = deps
            for dep in deps:
                _walk(dep)
",src/meta_agent/template_mixer.py,TemplateMixer,1,6.348800075736417e-09,"The method `_walk` is a recursive function that appears to be part of a larger system for processing or analyzing templates. It checks if a name has been visited, splits the name, loads a template, finds dependencies, and recursively processes those dependencies. This kind of functionality is common in systems that need to handle complex dependency graphs, such as template engines or build systems. The method is likely to be integral to the operation of such a system, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained."
survived,"def _load_dotenv(path: str = "".env"") -> None:
    """"""Load default variables from ``path`` when available.""""""
    if Path(path).is_file():
        for k, v in _load_env_file(path).items():
            os.environ.setdefault(k, v)
",alpha_factory_v1/utils/config_common.py,,1,1.0467401685178159e-08,"The method `_load_dotenv` is a utility function designed to load environment variables from a file, which is a common requirement in many applications for configuration management. This functionality is essential for applications that need to manage different configurations for different environments (e.g., development, testing, production). The method is simple, effective, and does not have any apparent issues or redundancies that would necessitate its removal. Additionally, it uses standard practices for loading environment variables, making it a useful and reusable piece of code."
survived,"    def merge_versions(self, slug: str, ours: str, theirs: str) -> str:
        """"""Naively merge two versions preferring ``theirs`` on conflict.""""""
        ours_content = self.registry.load_template(slug, ours) or """"
        theirs_content = self.registry.load_template(slug, theirs) or """"
        ours_lines = ours_content.splitlines()
        theirs_lines = theirs_content.splitlines()
        merged: List[str] = []
        max_len = max(len(ours_lines), len(theirs_lines))
        for i in range(max_len):
            if i < len(theirs_lines):
                merged.append(theirs_lines[i])
            elif i < len(ours_lines):
                merged.append(ours_lines[i])
        return ""\n"".join(merged)",src/meta_agent/template_sharing.py,TemplateSharingManager,1,1.6052280526088547e-09,"The method 'merge_versions' is a straightforward implementation that merges two versions of content by preferring 'theirs' in case of conflicts. This is a common requirement in version control systems and collaborative editing tools. The method is simple, clear, and performs its intended function without unnecessary complexity. It is likely to be useful in scenarios where a simple merge strategy is sufficient, and thus, it is likely to survive."
survived,"def _load_model() -> None:
    """"""Load a local model if available, otherwise use an echo stub.""""""
    global _MODEL, _CALL
    model_path = os.getenv(
        ""LLAMA_MODEL_PATH"",
        os.path.expanduser(""~/.cache/llama/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf""),
    )

    def _wrap(fn: Callable[[str], str]) -> Callable[[str], str]:
        return fn

    if Llama is not None:
        try:
            _MODEL = Llama(model_path=model_path, n_ctx=int(os.getenv(""LLAMA_N_CTX"", ""2048"")))

            def call_llama(prompt: str) -> str:
                out = cast(Any, _MODEL)(prompt)
                return cast(str, out[""choices""][0][""text""]).strip()

            _CALL = _wrap(call_llama)
            return
        except Exception:  # pragma: no cover - model load failure
            _MODEL = None
    if AutoModelForCausalLM is not None:
        try:
            _MODEL = AutoModelForCausalLM.from_pretrained(model_path, model_type=""llama"")

            def call_ctrans(prompt: str) -> str:
                return cast(str, cast(Any, _MODEL)(prompt))

            _CALL = _wrap(call_ctrans)
            return
        except Exception:  # pragma: no cover - model load failure
            _MODEL = None

    def call_stub(prompt: str) -> str:
        return f""[offline] {prompt}""

    _CALL = _wrap(call_stub)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/local_llm.py,,1,2.5109990926928157e-08,"The method `_load_model` is designed to load a machine learning model from a specified path or use a stub if the model cannot be loaded. This functionality is crucial for applications that rely on machine learning models, as it provides a fallback mechanism when the model is unavailable. The method is robust, handling exceptions and providing a default behavior, which is a good practice in software development. Additionally, the use of environment variables for configuration makes it flexible and adaptable to different environments. Given these factors, the method is likely to be retained in the codebase."
survived,"    def __exit__(self, exc_type, exc, tb):
        pass
",tests/test_selfheal_import_stubs.py,DummyBlocks,1,3.726639116582555e-06,"The method `__exit__` is part of the context management protocol in Python, which is used to define cleanup actions that must be executed when a block of code is exited. Even though the current implementation is a no-op (it does nothing), it is still a valid implementation of the `__exit__` method. This method is often used in conjunction with the `__enter__` method to manage resources like files or network connections. The presence of this method, even as a placeholder, suggests that the class is intended to be used as a context manager. Therefore, it is likely to be retained for future development or to maintain the structure of the context management protocol."
survived,"def _start_server(port: int, env: dict[str, str] | None = None) -> subprocess.Popen[bytes]:
    cmd = [
        sys.executable,
        ""-m"",
        ""src.interface.api_server"",
        ""--host"",
        ""127.0.0.1"",
        ""--port"",
        str(port),
    ]
    return subprocess.Popen(cmd, env=env or os.environ.copy())
",tests/test_api_server_subprocess.py,,1,8.76424914819242e-08,"The method _start_server is a utility function that starts a server process using the subprocess module. It is a specific implementation detail that is likely used internally within a larger system to manage server processes. Such methods are typically not deleted unless they are replaced by a more efficient or necessary alternative. Since it is a private method (indicated by the underscore prefix) and serves a clear purpose, it is likely to survive unless there is a significant change in how server processes are managed in the system."
survived,"def _wait_running(url: str, headers: dict[str, str]) -> None:
    for _ in range(50):
        try:
            r = httpx.get(f""{url}/runs"", headers=headers)
            if r.status_code == 200:
                return
        except Exception:
            time.sleep(0.1)
    raise AssertionError(""server did not start"")
",tests/test_api_server_subprocess.py,,1,3.2241866333029355e-08,"The method '_wait_running' is a utility function that checks if a server is running by making repeated HTTP GET requests to a specified URL. It is a common pattern to wait for a service to be ready, especially in integration tests or deployment scripts. The method is useful for ensuring that a service is up before proceeding with further operations. It handles exceptions gracefully and retries multiple times, which is a robust approach for dealing with network or server startup delays. Therefore, it is likely to be retained in the codebase."
survived,"def api_server_cmd(host: str, port: int) -> None:
    """"""Launch the FastAPI backend server.""""""

    try:
        import uvicorn
    except Exception as exc:  # pragma: no cover - optional
        raise click.ClickException(""uvicorn is required to run the API server"") from exc

    uvicorn.run(
        ""alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.api_server:app"",
        host=host,
        port=port,
    )
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/cli.py,,1,2.0611536181902033e-09,"The method `api_server_cmd` is a utility function designed to launch a FastAPI server using Uvicorn. It is a straightforward and necessary function for running a backend server in a FastAPI application. The function includes error handling to ensure that the required package, Uvicorn, is installed, which is a good practice. There is no indication that this function is obsolete or redundant, and it serves a clear purpose in the context of a web application. Therefore, it is likely to be retained in the codebase."
survived,"def test_show_memory_lists_entries(tmp_path: Path) -> None:
    mem_path = tmp_path / ""mem.log""
    mem_path.write_text('{""foo"": ""bar""}\n', encoding=""utf-8"")
    runner = CliRunner()
    from unittest.mock import patch

    with patch.object(cli.config.CFG, ""memory_path"", str(mem_path)):  # type: ignore[attr-defined]
        result = runner.invoke(cli.main, [""show-memory""])
    assert result.exit_code == 0
    assert ""foo"" in result.output
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,8.76424914819242e-08,"The method 'test_show_memory_lists_entries' is a unit test function that verifies the functionality of a CLI command. It uses a temporary path to simulate a memory log file and checks if the CLI command 'show-memory' correctly reads and outputs the content of this file. The use of 'unittest.mock.patch' indicates that the test is designed to run in isolation without affecting or depending on the actual configuration. This is a standard practice in testing to ensure reliability and repeatability of tests. Given its purpose and implementation, this method is likely to be retained as it provides value in ensuring the correctness of the CLI command."
survived,"def test_detect_bottleneck_selects_largest_gap(tmp_path: Path) -> None:
    repo = _make_repo(tmp_path)
    agent = MetaRefinementAgent(repo, tmp_path / ""logs"")
    entries = [
        {""module"": ""a"", ""ts"": 0},
        {""module"": ""b"", ""ts"": 2},
        {""module"": ""c"", ""ts"": 8},
    ]
    assert agent._detect_bottleneck(entries) == ""c""
",tests/test_meta_refinement_agent.py,,1,1.725782769012759e-08,"The method 'test_detect_bottleneck_selects_largest_gap' is a unit test designed to verify the functionality of the '_detect_bottleneck' method in the 'MetaRefinementAgent' class. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks if the method correctly identifies the module with the largest time gap, which is a specific and important functionality. Given the importance of testing in software development, this method is likely to be retained to ensure the robustness of the '_detect_bottleneck' method."
survived,"def test_update_settings_thread_safety(config_with_yaml):
    config = config_with_yaml

    exceptions = []

    def update(val):
        try:
            config.update_settings({""int_property"": val})
        except Exception as e:
            exceptions.append(e)

    threads = [threading.Thread(target=update, args=(i,)) for i in range(5)]

    for t in threads:
        t.start()
    for t in threads:
        t.join()

    assert not exceptions
    assert config.int_property in range(5)",libs/core/kiln_ai/utils/test_config.py,,1,1.522997951276035e-08,The method 'test_update_settings_thread_safety' is a unit test designed to check the thread safety of the 'update_settings' method in a configuration object. It uses multiple threads to update a configuration setting concurrently and checks for exceptions and valid outcomes. This is a valuable test for ensuring the robustness of the configuration system in a multi-threaded environment. Such tests are crucial for maintaining software quality and are unlikely to be deleted unless the functionality they test is removed or significantly altered.
survived,"    def test_discover_alpha_invalid_num(self) -> None:
        with self.assertRaises(ValueError):
            stub.discover_alpha(num=0, ledger=None, model=""gpt-4o-mini"")
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,1.3440409770490404e-08,"The method `test_discover_alpha_invalid_num` is a unit test designed to check if the `discover_alpha` function raises a `ValueError` when called with an invalid `num` parameter (in this case, 0). This is a typical and necessary test to ensure that the function behaves correctly when given invalid input. Unit tests are crucial for maintaining code quality and ensuring that functions handle edge cases properly. Therefore, this method is likely to be retained as part of the test suite to ensure the robustness of the `discover_alpha` function."
survived,"  def test_low_bits(self):
    self.assertEqual(getbits(0b11010110, 0, 3), 0b0110)
",test/unit/test_helpers.py,TestGetBits,1,3.850741907939403e-09,"The method `test_low_bits` is a unit test for the function `getbits`. It checks if the function correctly extracts the lower bits from a binary number. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with bit manipulation, which can be error-prone. Therefore, this method is likely to be retained as it serves an important role in verifying the functionality of the `getbits` function."
survived,"def _lambda12():
    draw.get(1000)()
    draw.get(4000)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,0,0.9999251538028718,"The method _lambda12() is a private method indicated by the underscore prefix, suggesting it is intended for internal use within a module or class. The method calls two functions, draw.get(1000)() and draw.get(4000)(), which are likely intended to perform some drawing operations. However, without context on what 'draw' is or what these operations achieve, it's difficult to assess the utility of this method. If the method is part of a larger system where these operations are necessary, it might survive. However, if the method is not used or the operations are redundant, it could be deleted. Given the lack of context and the specific nature of the operations, it is more likely to be deleted if not used elsewhere."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/count-in-octal-3.py,,1,8.152020648014727e-09,"The method '_now' is a utility function that generates a pseudo-random number based on a global seed if '_now_seeded' is True, otherwise it returns the current time in nanoseconds. This function is likely to be used in scenarios where a consistent pseudo-random number is needed for testing or simulation purposes. The use of global variables and the specific algorithm for generating numbers suggest it has a specific purpose in the codebase. Unless there is a significant refactor or change in requirements, such utility functions are generally retained. Therefore, it is likely to survive."
survived,"def _lambda9():
    draw.get(100)()
    draw.get(600)()
",tests/rosetta/transpiler/Python/cistercian-numerals.py,,1,1.9947301075518807e-06,"The method _lambda9() is a private method indicated by the underscore prefix, suggesting it is intended for internal use within a module or class. The method calls two functions retrieved from a 'draw' object using the 'get' method with specific keys (100 and 600). Without additional context on what 'draw' is or what these functions do, it's difficult to assess the utility or correctness of this method. However, the method itself is syntactically correct and does not contain any obvious errors. If 'draw' is a valid object with callable functions at these keys, the method could be functional. Given the lack of context, the method is likely to survive unless there is a specific reason to remove it, such as redundancy or a change in requirements."
survived,"def isAlphaNumDot(ch):
    return (ch >= ""A"" and ch <= ""Z"") or (ch >= ""a"" and ch <= ""z"") or (ch >= ""0"" and ch <= ""9"") or ch == ""_"" or ch == "".""
",tests/rosetta/transpiler/Python/function-frequency.py,,1,3.653482080241728e-08,"The method isAlphaNumDot is a utility function that checks if a character is alphanumeric or a dot. This type of function is commonly used in parsing or validating strings, such as checking if a filename or identifier is valid. The method is simple, efficient, and serves a clear purpose, which makes it likely to be retained in codebases where such validation is necessary. Additionally, the method is not overly complex and does not have any apparent issues that would necessitate its removal."
survived,"def newFps(fn):
    return Fps(coeffs=[], compute=fn)
",tests/rosetta/transpiler/Python/formal-power-series.py,,1,1.2501528648238603e-09,"The method 'newFps' is a simple factory function that creates an instance of the 'Fps' class with an empty list for 'coeffs' and a function 'fn' for 'compute'. This pattern is common in Python for creating objects with specific initial configurations. The method is straightforward, has a clear purpose, and is likely to be useful in contexts where 'Fps' objects need to be created with a custom compute function. There is no indication that this method is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"def div(a, b):
    q = newFps(lambda n: 0.0)
    q = dataclasses.replace(q, compute=_lambda2)
    return q
",tests/rosetta/transpiler/Python/formal-power-series.py,,0,0.9999984465026855,"The method 'div' is intended to perform division, but it does not actually implement any division logic. Instead, it initializes a variable 'q' with a function 'newFps' and then replaces 'q' with a dataclass using 'dataclasses.replace'. The function '_lambda2' is not defined within the provided code, making the method incomplete and non-functional. Without proper implementation of division logic or definition of '_lambda2', the method does not serve its intended purpose and is likely to be deleted or refactored."
survived,"def fork(hasChild):
    global nextPID
    pid = nextPID
    nextPID = nextPID + 1
    print(""PID: "" + str(pid))
    if not hasChild:
        print(""Done."")
        return
    childPID = nextPID
    print(""Child's PID: "" + str(childPID))
    fork(False)
",tests/rosetta/transpiler/Python/fork-2.py,,1,3.653482080241728e-08,"The method 'fork' is a simple recursive function that simulates the creation of a process and its child process by incrementing a global PID counter. It prints the PID of the current process and, if specified, creates a child process by calling itself recursively with 'hasChild' set to False. This method is straightforward and functional for its intended purpose, which is to demonstrate process creation and PID assignment. There are no apparent issues or inefficiencies that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def drawPoint(g, x, y):
    if x >= 0 and x < width and y >= 0 and y < height:
        row = g[y]
        row[x] = ""#""
        g[y] = row
",tests/rosetta/transpiler/Python/fractal-tree.py,,1,2.3355930333443423e-09,"The method 'drawPoint' is a simple utility function that modifies a grid 'g' by setting a specific point (x, y) to '#'. This is a common operation in graphical or grid-based applications, such as games or simulations. The method is straightforward, performs a clear task, and is likely to be useful in contexts where grid manipulation is needed. There are no apparent issues with the logic or implementation that would necessitate its deletion. Therefore, it is likely to survive."
survived,"def show(n, level):
    indent = level * 4
    name = str(n.get(""name""))
    nl = len(name) + indent
    line = spaces(indent) + name
    line = line + spaces(32 - nl) + ""|  ""
    line = line + padLeft(str(int(n.get(""weight""))), 3) + ""   | ""
    line = line + formatFloat(computeCoverage(n), 6) + "" |""
    print(line)
    cs = n.get(""children"")
    for child in cs:
        show(child, level + 1)
",tests/rosetta/transpiler/Python/functional-coverage-tree.py,,1,4.1399375473943306e-08,"The method 'show' is a recursive function that prints a formatted representation of a tree-like data structure. It uses helper functions like 'spaces', 'padLeft', and 'formatFloat', which are assumed to be defined elsewhere. The method is useful for visualizing hierarchical data with indentation based on the level of the node. Given its utility in displaying structured data, it is likely to be retained unless there are significant changes in the requirements or a better alternative is implemented."
survived,"def greLeap(year):
    a = int((year % 4))
    b = int((year % 100))
    c = int((year % 400))
    return a == 0 and (b != 0 or c == 0)
",tests/rosetta/transpiler/Python/french-republican-calendar.py,,1,4.1399375473943306e-08,"The method 'greLeap' is a utility function that checks if a given year is a leap year according to the Gregorian calendar rules. This is a common and useful function that can be used in various applications that require date calculations. The logic implemented in the function is correct and follows the standard rules for determining leap years: a year is a leap year if it is divisible by 4, but not every year divisible by 100 is a leap year, except if it is also divisible by 400. Given its correctness and utility, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/four-bit-adder-1.py,,1,2.2159489282323004e-08,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds otherwise. This function is likely part of a larger system that requires either a random number or a timestamp, which are common needs in programming. The function is simple, serves a clear purpose, and does not have any obvious issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def say(n):
    if n < 20:
        return small[n]
    if n < 100:
        res = tens[n // 10]
        m = n % 10
        if m != 0:
            res = res + ""-"" + small[m]
        return res
    if n < 1000:
        res = say(n // 100) + "" hundred""
        m = n % 100
        if m != 0:
            res = res + "" "" + say(m)
        return res
    if n < 1000000:
        res = say(n // 1000) + "" thousand""
        m = n % 1000
        if m != 0:
            res = res + "" "" + say(m)
        return res
    res = say(n // 1000000) + "" million""
    m = n % 1000000
    if m != 0:
        res = res + "" "" + say(m)
    return res
",tests/rosetta/transpiler/Python/four-is-the-number-of-letters-in-the-....py,,1,1.6052280526088547e-09,"The method 'say' is a utility function that converts numbers into their English word representation. This is a common requirement in many applications, such as check writing, educational tools, or any system that needs to verbalize numbers. The function is well-structured, handling numbers from 0 to millions, and is likely to be useful in various contexts. Therefore, it is unlikely to be deleted as it serves a clear purpose and is implemented correctly."
survived,"def mul(a, b):
    return newFps(_lambda1)
",tests/rosetta/transpiler/Python/formal-power-series.py,,0,0.9999998144608401,"The method 'mul' is intended to multiply two numbers 'a' and 'b', but instead of performing a multiplication, it calls a function 'newFps' with an argument '_lambda1'. This does not align with the expected functionality of a multiplication method. Additionally, 'newFps' and '_lambda1' are not defined within the provided code, which would lead to errors. Without further context or definitions, this method is not functional as a multiplication operation and is likely to be deleted or significantly modified to meet its intended purpose."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/general-fizzbuzz.py,,1,1.1253518384332553e-07,"The method '_now' is a utility function that generates a pseudo-random number based on a seed if '_now_seeded' is True, or returns the current time in nanoseconds if not. This kind of function is useful in scenarios where deterministic behavior is needed for testing or simulation purposes. It is a simple and effective way to switch between seeded random number generation and real-time timestamps. Such utility functions are often retained in codebases for their flexibility and utility in different contexts."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    program = [[17, 91], [78, 85], [19, 51], [23, 38], [29, 33], [77, 29], [95, 23], [77, 19], [1, 17], [11, 13], [13, 11], [15, 14], [15, 2], [55, 1]]
    n = 2
    primes = 0
    count = 0
    limit = 1000000
    two = 2
    line = """"
    while primes < 20 and count < limit:
        res = step(n, program)
        n = res.n
        if not res.ok:
            break
        m = n
        pow = 0
        while m % two == 0:
            m = m // two
            pow = pow + 1
        if m == 1 and pow > 1:
            line = line + str(pow) + "" ""
            primes = primes + 1
        count = count + 1
    if len(line) > 0:
        print(line[0:len(line) - 1])
    else:
        print("""")
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/fractran.py,,1,2.3823698451773172e-07,"The method is a main function that appears to be part of a larger program, likely used for benchmarking or testing purposes. It includes performance measurement code, such as memory usage and execution time, which suggests it is used for profiling. Such functions are typically retained for performance analysis and debugging, especially in development or testing environments. Therefore, it is likely to survive."
survived,"    def _mc_eval(
        self, env: MiniWorld, policy: Callable[[np.ndarray], int], episodes: int
    ) -> float:
        scores = []
        for _ in range(episodes):
            obs = env.reset()
            total = 0.0
            for _ in range(env.size * env.size * 4):
                a = policy(obs)
                obs, r, done, _ = env.step(a)
                total += r
                if done:
                    break
            scores.append(total)
        return float(np.mean(scores))
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,POETGenerator,1,5.905303995456778e-10,"The method '_mc_eval' is a Monte Carlo evaluation function that calculates the average score of a policy over a number of episodes in a given environment. This is a common and useful function in reinforcement learning for evaluating the performance of a policy. The method is well-structured, uses standard practices, and is likely to be useful in various contexts where policy evaluation is needed. Therefore, it is likely to be retained in the codebase."
survived,"    def test_nested_prefix_handling(self) -> None:
        with tempfile.TemporaryDirectory() as repo:
            os.makedirs(os.path.join(repo, ""alpha""), exist_ok=True)
            file_path = os.path.join(repo, ""alpha"", ""test.py"")
            with open(file_path, ""w"") as fh:
                fh.write(""x = 1\n"")
            patch = """"""--- a/alpha/test.py
+++ b/alpha/test.py
@@
-x = 1
+x = 2
""""""
            # Should not raise for valid nested path
            patcher_core._sanity_check_patch(patch, pathlib.Path(repo))
            patcher_core.apply_patch(patch, repo_path=repo)
            with open(file_path) as fh:
                data = fh.read()
            self.assertIn(""x = 2"", data)
",tests/test_self_healing_patcher.py,TestPatcherCore,1,2.998960815863541e-09,"The method 'test_nested_prefix_handling' is a unit test designed to verify the functionality of a patching system. It creates a temporary directory, writes a file, applies a patch, and checks the result. This is a typical and necessary test to ensure that the patching system works correctly, especially with nested paths. Such tests are crucial for maintaining code quality and are unlikely to be deleted unless the functionality they test is removed or significantly changed."
survived,"    def test_build_core_agent_stub_when_sdk_missing(self) -> None:
        os.environ.pop(""OPENAI_API_KEY"", None)
        sys.modules.pop(""agents"", None)
        sys.modules.pop(""alpha_factory_v1.backend.agent_factory"", None)
        importlib.invalidate_caches()

        orig_import_module = importlib.import_module

        def _fake_import(name: str, *args: object, **kwargs: object) -> object:
            if name == ""agents"":
                raise ModuleNotFoundError
            return orig_import_module(name, *args, **kwargs)

        with mock.patch(""importlib.import_module"", side_effect=_fake_import):
            af = orig_import_module(""alpha_factory_v1.backend.agent_factory"")
            af = importlib.reload(af)
            agent = af.build_core_agent(name=""t"", instructions=""demo"")

        self.assertTrue(hasattr(agent, ""run""))
        self.assertEqual(agent.run(""hi""), ""[t-stub] echo: hi"")
        self.assertFalse(any(isinstance(t, af.ComputerTool) for t in af.DEFAULT_TOOLS))
",tests/test_agent_factory.py,TestAgentFactory,1,6.825604231969389e-08,The method is a unit test designed to verify the behavior of a system when certain modules are missing. It uses mocking to simulate the absence of the 'agents' module and checks if the system can still function correctly by creating a stub agent. This is a common practice in testing to ensure robustness and is unlikely to be deleted as it serves a critical role in validating the system's behavior under specific conditions.
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cross_join_triple.py,,1,4.944450477491054e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/two-sum.py,,1,7.194132978569833e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is often useful in various contexts where data needs to be consistently formatted for output or logging. Its simplicity and general utility suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/map_in_operator.py,,1,1.8189616842444243e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability make it likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/python_math.py,,1,8.152020648014727e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_items_iteration.py,,1,4.944450477491054e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be consistently formatted for output or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/list_set_ops.py,,1,2.646573631904765e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Since it provides a clear and useful functionality, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/count_builtin.py,,1,1.955568070542584e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Since it provides a clear and reusable way to handle common formatting tasks, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/cross_join.py,,1,2.998960815863541e-09,"The method _fmt is a utility function designed to format different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging purposes. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/group_by.py,,1,9.237449576640118e-09,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted consistently for output or logging. Since it provides a clear and reusable way to handle common formatting tasks, it is likely to be retained in the codebase."
survived,"def _fmt(v):
    if isinstance(v, list):
        return "" "".join((_fmt(x) for x in v))
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)
",tests/machine/x/python/unary_neg.py,,1,1.522997951276035e-08,"The method _fmt is a utility function that formats different types of input values into strings. It handles lists by recursively formatting each element and joining them with spaces, converts floats that are whole numbers into integers, and converts other types directly to strings. This kind of utility function is generally useful in various contexts where data needs to be formatted for display or logging. Its simplicity and general applicability suggest that it is likely to be retained in the codebase."
survived,"def main():
    """"""Run the PostHog example ingest function and print results.""""""
    load_dotenv(override=True)
    df = ingest()
    print(df)
",scripts/posthog_example.py,,1,2.0611536181902033e-09,"The method 'main' is a simple function that loads environment variables, calls an 'ingest' function, and prints the resulting dataframe. It is a basic utility function that is likely part of a larger script or application. Such functions are typically retained unless they are redundant or replaced by more efficient implementations. Without additional context indicating that this function is obsolete or replaced, it is reasonable to predict that it will survive."
survived,"def test_invalid_sim_request_returns_422() -> None:
    port = _free_port()
    proc = _start_demo_server(port)
    url = f""http://127.0.0.1:{port}""
    headers = {""Authorization"": ""Bearer test-token""}
    try:
        _wait_running(url, headers)
        r = httpx.post(
            f""{url}/simulate"",
            json={
                ""horizon"": 0,
                ""pop_size"": 2,
                ""generations"": 1,
                ""mut_rate"": 0.1,
                ""xover_rate"": 0.5,
                ""curve"": ""linear"",
            },
            headers=headers,
        )
        assert r.status_code == 422
    finally:
        proc.terminate()
        proc.wait(timeout=5)",tests/test_api_server_subprocess.py,,1,2.998960815863541e-09,"The method is a unit test designed to verify that an invalid simulation request returns a 422 status code. This is a common practice in testing to ensure that the application correctly handles invalid input. The method is well-structured, using a try-finally block to ensure that resources are cleaned up properly, and it uses assertions to validate the expected behavior. There is no indication that this method is obsolete or unnecessary, as it serves a clear purpose in the testing suite. Therefore, it is likely to be retained."
survived,"def test_transfer_test_runs(monkeypatch: pytest.MonkeyPatch) -> None:
    def fake_run(models: list[str], top_n: int) -> None:
        click.echo(f""models:{','.join(models)} top:{top_n}"")

    monkeypatch.setattr(""src.tools.transfer_test.run_transfer_test"", fake_run)
    runner = CliRunner()
    result = runner.invoke(cli.main, [""transfer-test""])

    assert result.exit_code == 0
    assert ""models:claude-3.7,gpt-4o top:3"" in result.output",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,1.2501528648238603e-09,"The method 'test_transfer_test_runs' is a unit test function that uses the 'monkeypatch' fixture to replace a function with a fake implementation for testing purposes. This is a common practice in testing to isolate the function being tested and ensure it behaves correctly under controlled conditions. The test checks that the CLI command 'transfer-test' produces the expected output, which is a valid and useful test case. There is no indication that this test is redundant or unnecessary, so it is likely to be retained."
survived,"    async def fake_evolve(*args: object, **kwargs: object) -> None:
        called[""ok""] = True
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_demo_cli.py,,1,1.892514738127224e-05,"The method `fake_evolve` is an asynchronous function that takes any number of positional and keyword arguments but does not use them. Its sole purpose is to set a key ""ok"" in a dictionary `called` to `True`. This function seems to be a placeholder or a mock function used for testing purposes, likely to simulate the behavior of a more complex function without performing any actual operations. Such functions are common in testing environments to verify that certain code paths are executed. Given its utility in testing, it is likely to be retained unless the testing strategy changes significantly."
survived,"def test_queue_limit_and_fetch_fallback() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        page.evaluate(
            ""window.OTEL_ENDPOINT='https://example.com';""
            ""window.confirm=() => true;""
            ""navigator.sendBeacon=()=>false;""
            ""Object.defineProperty(navigator,'onLine',{get:()=>false,configurable:true});""
            ""localStorage.setItem('telemetryQueue',JSON.stringify(Array.from({length:100},()=>({}))))""
        )
        page.reload()
        page.wait_for_selector(""#controls"")
        page.click(""text=Share"")
        page.evaluate(""window.dispatchEvent(new Event('beforeunload'))"")
        assert (
            page.evaluate(
                ""JSON.parse(localStorage.getItem('telemetryQueue')).length""
            )
            == 100
        )
        page.evaluate(
            ""window.fetch=(...a)=>{window.fetchArgs=a;return Promise.resolve({status:200});};""
            ""Object.defineProperty(navigator,'onLine',{get:()=>true});""
            ""window.dispatchEvent(new Event('online'));""
        )
        page.wait_for_function(""window.fetchArgs !== undefined"")
        assert page.evaluate(""localStorage.getItem('telemetryQueue')"") == ""[]""
        browser.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_telemetry.py,,1,3.927863699585036e-07,"The method 'test_queue_limit_and_fetch_fallback' is a test function that uses Playwright to automate a browser for testing a specific web page behavior. It is a part of a test suite, likely for a web application, to ensure that the telemetry queue is handled correctly when the network status changes. Test functions like this are crucial for maintaining software quality and ensuring that features work as expected. Therefore, it is unlikely to be deleted unless the feature it tests is removed or the testing framework changes significantly."
survived,"def inc(x: int) -> int:
    return x + k
",tests/human/x/python/pure_global_fold.py,,0,0.999999997664407,"The method 'inc' is likely to be deleted because it references a variable 'k' that is not defined within the function or passed as a parameter. This will result in a NameError when the function is called, making it non-functional in its current state. Without additional context or a definition for 'k', the function cannot operate as intended."
survived,"def sum_tree(t: Tree) -> int:
    if isinstance(t, Leaf):
        return 0
    elif isinstance(t, Node):
        return sum_tree(t.left) + t.value + sum_tree(t.right)
    else:
        raise TypeError(""Unknown node"")
",tests/human/x/python/tree_sum.py,,1,2.699578619062706e-07,"The method `sum_tree` is a recursive function designed to calculate the sum of all values in a binary tree structure. It checks if the current node is a `Leaf` or a `Node`, and processes accordingly. The function is straightforward and performs its intended task without any apparent issues. It handles the base case (leaf nodes) and recursive case (node with children) correctly. The only potential improvement could be to handle the `Leaf` case by returning a specific value if `Leaf` nodes have values, but this depends on the specific implementation of the `Tree`, `Leaf`, and `Node` classes. Overall, the function is functional and likely to be retained unless there are changes in the tree structure or requirements."
survived,"def add(a: int, b: int) -> int:
    return a + b
",tests/human/x/python/partial_application.py,,1,3.3982678079468468e-09,"The method 'add' is a simple and fundamental utility function that performs addition of two integers. Such basic arithmetic operations are commonly used in various applications and are unlikely to be removed unless they are redundant or replaced by a more efficient implementation. However, given the simplicity and directness of this function, it is likely to be retained as it serves a clear purpose without any apparent issues."
survived,"    def test_add_valid_relation(self):
        self.g.add(""A"", ""VALID_REL"", ""B"")
        self.assertIn(""B"", self.g.neighbours(""A"", rel=""VALID_REL""))
",tests/test_memory_graph_rel.py,TestGraphMemoryRelationValidation,1,3.850741907939403e-09,"The method `test_add_valid_relation` is a unit test that checks the functionality of adding a valid relation between two nodes in a graph structure. It uses assertions to verify that the relation is correctly established. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Therefore, this method is likely to be retained as part of the test suite to ensure the graph's `add` method works as expected."
survived,"    def test_batch_add_valid_relation(self):
        self.g.batch_add([(""A"", ""REL1"", ""B""), (""B"", ""REL2"", ""C"")])
        self.assertIn(""B"", self.g.neighbours(""A"", rel=""REL1""))
        self.assertIn(""C"", self.g.neighbours(""B"", rel=""REL2""))
",tests/test_memory_graph_rel.py,TestGraphMemoryRelationValidation,1,8.152020648014727e-09,"The method `test_batch_add_valid_relation` is a unit test that verifies the functionality of the `batch_add` method in a graph-like structure. It checks if the relations are correctly added by asserting the presence of expected neighbors. This is a typical and necessary test to ensure the integrity of the `batch_add` method, making it unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def log(self, env: messaging.Envelope) -> None:  # type: ignore[override]
        self.logged.append(env)
",tests/test_adk_agent.py,DummyLedger,1,8.592166611791576e-10,"The method 'log' is a simple function that appends an envelope to a list called 'logged'. It is a straightforward implementation with no apparent issues or redundancies. The method is likely to be useful for tracking or logging purposes within the application, especially if 'logged' is used elsewhere in the code to process or analyze the stored envelopes. There is no indication that this method is obsolete or unnecessary, so it is likely to be retained."
survived,"    async def skill_test(self, payload: dict) -> dict:
        """"""Respond to skill test pings.""""""
        return {""pong"": True}
",alpha_factory_v1/backend/agents/ping_agent.py,PingAgent,1,4.599055376537186e-10,"The method 'skill_test' is a simple asynchronous function that responds to skill test pings by returning a dictionary with a key 'pong' set to True. This method is straightforward, serves a clear purpose, and is likely part of a larger system where such ping-pong mechanisms are common for testing connectivity or responsiveness. There is no indication that this method is redundant or unnecessary, and it is likely useful for debugging or operational checks. Therefore, it is likely to be retained."
survived,"def xor_checksum(address: int, sig: Signal, d: bytearray) -> int:
    checksum = 0
    checksum_byte = sig.start_bit // 8
    for i in range(len(d)):
        if i != checksum_byte:
            checksum ^= d[i]
    return checksum
",opendbc/can/packer.py,,1,6.348800075736417e-09,"The method 'xor_checksum' is a simple and efficient implementation of a checksum calculation using XOR operation. It is likely to be useful in various contexts where data integrity needs to be verified, especially in communication protocols or data storage systems. The method is straightforward, has a clear purpose, and does not have any apparent flaws or inefficiencies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def chrysler_checksum(address: int, sig: Signal, d: bytearray) -> int:
    checksum = 0xFF
    for j in range(len(d) - 1):
        curr = d[j]
        shift = 0x80
        for _ in range(8):
            bit_sum = curr & shift
            temp_chk = checksum & 0x80
            if bit_sum:
                bit_sum = 0x1C
                if temp_chk:
                    bit_sum = 1
                checksum = (checksum << 1) & 0xFF
                temp_chk = checksum | 1
                bit_sum ^= temp_chk
            else:
                if temp_chk:
                    bit_sum = 0x1D
                checksum = (checksum << 1) & 0xFF
                bit_sum ^= checksum
            checksum = bit_sum & 0xFF
            shift >>= 1
    return (~checksum) & 0xFF
",opendbc/can/packer.py,,1,1.955568070542584e-08,"The method 'chrysler_checksum' is a specific implementation of a checksum algorithm, which is a common requirement in data communication and error detection. The function is well-defined, takes clear inputs, and performs a specific task that is likely to be reused in contexts where Chrysler's checksum calculation is needed. Unless there is a significant change in the requirements or a better algorithm is found, this method is likely to be retained for its utility."
survived,"def honda_checksum(address: int, sig: Signal, d: bytearray) -> int:
    s = 0
    extended = address > 0x7FF
    addr = address
    while addr:
        s += addr & 0xF
        addr >>= 4
    for i in range(len(d)):
        x = d[i]
        if i == len(d) - 1:
            x >>= 4
        s += (x & 0xF) + (x >> 4)
    s = 8 - s
    if extended:
        s += 3
    return s & 0xF
",opendbc/can/packer.py,,1,6.69158608681505e-10,"The method 'honda_checksum' is a utility function that calculates a checksum for a given address and data, which is a common requirement in communication protocols to ensure data integrity. The function is specific to the Honda protocol, as suggested by its name, and it appears to be correctly implemented to handle both standard and extended addresses. Such functions are crucial in automotive and embedded systems where data integrity is paramount. Therefore, it is likely to be retained in the codebase as it serves a specific and necessary purpose."
survived,"    def magnitude(self) -> float:
        """"""Return the Euclidean norm.""""""
        return (self.x ** 2 + self.y ** 2) ** 0.5",runtime/ffi/python/testmod.py,Point,1,2.4616969512093895e-10,"The method 'magnitude' is a fundamental utility function that calculates the Euclidean norm (or length) of a vector in 2D space. This is a common operation in many applications involving geometry, physics, and computer graphics. The method is simple, efficient, and provides essential functionality for any class representing a 2D vector. Therefore, it is unlikely to be deleted as it serves a clear and useful purpose."
survived,"def test_insight_cli_full_simulation(tmp_path: Path) -> None:
    """"""Run the Insight CLI simulate command end-to-end.""""""
    ledger = tmp_path / ""audit.db""
    env = os.environ.copy()
    env[""AGI_INSIGHT_LEDGER_PATH""] = str(ledger)

    cmd = [
        sys.executable,
        ""-m"",
        ""alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.cli"",
        ""simulate"",
        ""--horizon"",
        ""1"",
        ""--pop-size"",
        ""1"",
        ""--generations"",
        ""1"",
        ""--offline"",
        ""--no-broadcast"",
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, env=env)
    assert result.returncode == 0, result.stderr
    assert ""year"" in result.stdout.lower()
    assert ledger.exists()",tests/test_insight_cli_e2e.py,,1,3.2241866333029355e-08,"The method `test_insight_cli_full_simulation` is a test function designed to verify the functionality of a command-line interface (CLI) for a simulation tool. Test functions are generally crucial for ensuring the reliability and correctness of software, especially in complex systems. This function checks if the CLI command executes successfully and produces the expected output, which is essential for maintaining the integrity of the software. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"def test_lineage_detail(tmp_path: Path, monkeypatch: pytest.MonkeyPatch) -> None:
    monkeypatch.setenv(""API_RATE_LIMIT"", ""1000"")
    monkeypatch.setenv(""ARCHIVE_PATH"", str(tmp_path / ""a.db""))
    from src.archive import Archive
    arch = Archive(tmp_path / ""a.db"")
    arch.add({""diff"": ""root""}, 0.1)
    arch.add({""parent"": 1, ""diff"": ""child""}, 0.2)

    from src.interface import api_server as mod
    api = importlib.reload(mod)

    client = TestClient(cast(Any, api.app))
    headers = {""Authorization"": ""Bearer test-token""}
    resp = client.get(""/lineage/2"", headers=headers)
    assert resp.status_code == 200
    data = resp.json()
    assert len(data) == 2
    assert data[-1][""id""] == 2",tests/test_api_server_static.py,,1,1.275190675769241e-07,"The method 'test_lineage_detail' is a test function that is likely part of a test suite for a software project. Test functions are generally not deleted unless they are redundant, testing deprecated features, or replaced by more comprehensive tests. This function appears to be testing specific functionality related to API endpoints and database interactions, which are critical components in many applications. Therefore, it is likely to be maintained as part of the test coverage for the project."
survived,"def test_unmapped_directory_returns_default(monkeypatch):
    monkeypatch.setenv('XDG_DOWNLOAD_DIR', '/tmp/downloads')
    devicons = reload_devicons('es')
    file = MockFile('RandomDir', is_directory=True)
    assert devicons.devicon(file) == ''
",tests/test_devicons.py,,1,6.348800075736417e-09,"The method 'test_unmapped_directory_returns_default' is a unit test function that uses the 'monkeypatch' fixture to set an environment variable and then tests the behavior of the 'devicons' module. Unit tests are generally not deleted unless they are redundant or testing deprecated functionality. Since this test seems to be testing a specific behavior (returning a default icon for an unmapped directory), it is likely to be useful for ensuring the correctness of the 'devicons' module. Therefore, it is likely to be retained."
survived,"    def propose_diff(self, file_path: str, goal: str) -> str:  # noqa: D401
        return generate_diff(file_path, goal)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent,0,0.9324533140223229,"The method `propose_diff` is a simple wrapper around the `generate_diff` function, which suggests that it might be redundant unless it serves a specific purpose such as abstraction or future extension. Without additional context or usage information, it's difficult to determine its necessity. However, if the method is part of a larger class or module where such abstraction is common, it might survive. Otherwise, it could be considered for deletion due to its simplicity and direct delegation to another function."
survived,"    def cmp(self, op):
        if isinstance(op, ast.Eq):
            return ""==""
        if isinstance(op, ast.NotEq):
            return ""!=""
        if isinstance(op, ast.Lt):
            return ""<""
        if isinstance(op, ast.LtE):
            return ""<=""
        if isinstance(op, ast.Gt):
            return "">""
        if isinstance(op, ast.GtE):
            return "">=""
        return ""?""
",tools/any2mochi/py_simple.py,Conv,1,4.944450477491054e-09,"The method 'cmp' is a utility function that maps AST comparison operator nodes to their string representations. This is a common requirement when working with abstract syntax trees, especially in tasks like code analysis, transformation, or generation. The method is straightforward, performs a clear and useful function, and there are no obvious issues with its implementation. Therefore, it is likely to be retained in the codebase."
survived,"    def visit_If(self, node):
        self.emit(f""if {self.expr(node.test)} {{"")
        self.indent += 1
        for s in node.body:
            self.visit(s)
        self.indent -= 1
        if node.orelse:
            self.emit(""} else {"")
            self.indent += 1
            for s in node.orelse:
                self.visit(s)
            self.indent -= 1
        self.emit(""}"")
",tools/any2mochi/py_simple.py,Conv,1,1.8189616842444243e-09,"The method 'visit_If' is a part of a code generation or transpilation process, likely converting an abstract syntax tree (AST) representation of an 'if' statement into a target language's syntax. This is a common task in compilers or interpreters, and the method is well-structured to handle both the 'if' and 'else' parts of a conditional statement. Given its clear utility in transforming code structures, it is likely to be retained in the codebase."
survived,"    def visit_Break(self, node):
        self.emit(""break"")
",tools/any2mochi/py_simple.py,Conv,1,6.348800075736417e-09,"The method `visit_Break` is a simple visitor pattern implementation that emits the string ""break"" when a `Break` node is visited. This is a common pattern in code that processes abstract syntax trees (ASTs), where each type of node has a corresponding visit method. The method is straightforward, performs its intended function, and does not contain any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"        async def Stream(self, req_iter, ctx):  # noqa: N802
            async for req in req_iter:
                kind = req.WhichOneof(""payload"")
                if kind == ""trigger"" and req.trigger.name in runners:
                    runners[req.trigger.name].next_ts = 0
                    yield a2a_pb2.StreamReply(ack=a2a_pb2.Ack(id=req.id))
                elif kind == ""status"":
                    stats = [a2a_pb2.AgentStat(name=n, next_run=int(r.next_ts)) for n, r in runners.items()]
                    yield a2a_pb2.StreamReply(status_reply=a2a_pb2.StatusReply(stats=stats))
",alpha_factory_v1/backend/api_server.py,Peer,1,1.522997951276035e-08,"The method 'Stream' is an asynchronous generator function that processes a stream of requests and yields responses based on the type of request. It handles two types of payloads: 'trigger' and 'status'. For 'trigger', it resets the next timestamp for a specific runner and acknowledges the request. For 'status', it compiles a list of agent statistics and yields a status reply. This functionality is essential for managing and monitoring the state of runners, which is likely a core part of the system's operation. Therefore, it is unlikely to be deleted as it provides necessary functionality for the system."
survived,"    async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)) -> None:
        if credentials.credentials != token:
            raise HTTPException(status_code=403, detail=""Invalid token"")
",alpha_factory_v1/backend/api_server.py,,1,8.152020648014727e-09,"The method 'verify_token' is a simple token verification function that checks if the provided credentials match a predefined token. This is a common pattern in web applications for securing endpoints and ensuring that only authorized requests are processed. The method uses FastAPI's dependency injection system to automatically handle authorization credentials, which is a modern and efficient approach. Given its utility in securing API endpoints and its use of current best practices, it is likely to be retained in the codebase."
survived,"    def __init__(
        self,
        enabled: set[str],
        dev_mode: bool,
        kafka_broker: str | None,
        cycle_seconds: int,
        max_cycle_sec: int,
    ) -> None:
        from backend.agents import list_agents, start_background_tasks

        start_background_tasks()
        avail = list_agents()
        names = [n for n in avail if not enabled or n in enabled]
        if not names:
            raise RuntimeError(f""No agents selected  ENABLED={','.join(enabled) if enabled else 'ALL'}"")

        self.bus = EventBus(kafka_broker, dev_mode)
        self.runners: Dict[str, AgentRunner] = {
            n: AgentRunner(n, cycle_seconds, max_cycle_sec, self.bus.publish) for n in names
        }
        self._hb_task: Optional[asyncio.Task] = None
        self._reg_task: Optional[asyncio.Task] = None
",alpha_factory_v1/backend/agent_manager.py,AgentManager,1,4.6911638017642294e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state, making them unlikely to be deleted unless the entire class is being refactored or removed. Additionally, the method includes important setup logic such as starting background tasks, listing agents, and initializing an event bus and agent runners, which are likely crucial for the functionality of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/inner_join.py,Customer,1,1.3440409770490404e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by.py,Person,1,9.237449576640118e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and complete view of the object's state. Therefore, this method is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_items_iteration.py,Data,1,1.3440409770490404e-08,"The method `__repr__` is a special method in Python used to define a string representation of an object. The implementation provided here returns the string representation of the object's dictionary, which is a common and useful way to represent an object for debugging purposes. This implementation is straightforward and serves a clear purpose, making it likely to be retained in the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join_sort.py,Lineitem,1,4.944450477491054e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation of __repr__ as it provides a clear and detailed view of the object's state, which is helpful for debugging and logging purposes. Therefore, this method is likely to be retained in the code."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join.py,Supplier,1,7.194132978569833e-09,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's dictionary, which contains all the attributes of the object. This is a common and useful implementation of __repr__ as it provides a clear and detailed view of the object's state, which is helpful for debugging and logging purposes. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/sort_stable.py,Item,1,3.2241866333029355e-08,"The method `__getitem__` is a special method in Python that allows an object to use the bracket notation (e.g., obj[key]) to access its elements. In this implementation, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. Since this method provides a flexible and Pythonic way to access object attributes, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/save_jsonl_stdout.py,Person,1,8.76424914819242e-08,"The method is a simple implementation of the __getitem__ special method, which allows an object to use the bracket notation (obj[key]) to access its attributes. This is a common and useful pattern in Python, especially for classes that need to provide dictionary-like access to their attributes. It is likely to be retained as it provides a clear and concise way to access object attributes dynamically."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/group_by_left_join.py,Order,1,2.5109990926928157e-08,"The method is a simple implementation of the __getitem__ special method, which allows instances of the class to use the bracket notation (e.g., obj[key]) to access attributes. This is a common and useful pattern in Python, especially for classes that aim to mimic dictionary-like behavior. It provides a clear and concise way to access attributes dynamically, which can be very useful in various applications. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/left_join_multi.py,Order,1,1.6052280526088547e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. It is a common pattern in Python for creating flexible and dynamic objects. Therefore, the method is likely to be Survived."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/group_by_multi_join.py,Nation,1,1.522997951276035e-08,"The __repr__ method is a special method used to define a string representation of an object. In this case, it returns the string representation of the object's __dict__, which is a dictionary containing all the attributes of the object. This is a common and useful implementation for debugging purposes, as it provides a clear and complete view of the object's state. Therefore, this method is likely to be retained in the code."
survived,"def dev_orchestrator(monkeypatch: pytest.MonkeyPatch) -> orch_mod.Orchestrator:
    monkeypatch.setenv(""DEV_MODE"", ""true"")
    monkeypatch.setenv(""API_TOKEN"", ""test-token"")
    monkeypatch.setenv(""AGENT_ERR_THRESHOLD"", ""1"")

    from alpha_factory_v1.backend.agents import _HEALTH_Q
    import inspect
    import time

    def list_agents(_detail: bool = False) -> list[str]:  # noqa: D401
        return [""dummy"", ""fail""]

    def get_agent(name: str) -> object:  # noqa: D401
        agent = DummyAgent() if name == ""dummy"" else FailingAgent()

        if hasattr(agent, ""step"") and inspect.iscoroutinefunction(agent.step):
            orig = agent.step

            async def _wrapped(*a: object, **kw: object) -> object:
                t0 = time.perf_counter()
                ok = True
                try:
                    return await orig(*a, **kw)
                except Exception:
                    ok = False
                    raise
                finally:
                    _HEALTH_Q.put((name, (time.perf_counter() - t0) * 1000, ok))

            agent.step = _wrapped
        return agent

    monkeypatch.setattr(""alpha_factory_v1.backend.agents.list_agents"", list_agents)
    monkeypatch.setattr(""alpha_factory_v1.backend.agents.get_agent"", get_agent)
    monkeypatch.setattr(""alpha_factory_v1.backend.agent_runner.get_agent"", get_agent)
    start_background_tasks()

    orch = orch_mod.Orchestrator()
    yield orch
",tests/test_backend_orchestrator_dev.py,,1,1.3440409770490404e-08,"The method 'dev_orchestrator' is a test utility function that sets up a testing environment using the 'monkeypatch' fixture from pytest. It modifies environment variables and patches functions to simulate a development mode for testing purposes. Such utility functions are crucial for testing and are unlikely to be deleted unless the testing framework or the structure of the codebase changes significantly. Therefore, it is likely to survive."
survived,"def _dtm_to_corpus(dtm: Any) -> List[List[int]]:
    """"""Convert a document-term matrix into an integer corpus.""""""
    if sparse.issparse(dtm):
        dtm = dtm.toarray()
    else:
        dtm = np.asarray(dtm)
    corpus: List[List[int]] = []
    for row in dtm:
        doc: List[int] = []
        for idx, count in enumerate(row):
            if count:
                doc.extend([idx] * int(count))
        corpus.append(doc)
    return corpus
",src/hlda/sklearn_wrapper.py,,1,1.8189616842444243e-09,"The method `_dtm_to_corpus` is a utility function that converts a document-term matrix (DTM) into a corpus of integer lists, where each list represents a document with repeated indices corresponding to term frequencies. This is a common preprocessing step in natural language processing tasks, especially when preparing data for models that require input in this format, such as certain topic modeling algorithms. The function handles both sparse and dense matrix formats, making it versatile. Given its utility in data preprocessing, it is likely to be retained in the codebase."
survived,"def test_execute_in_sandbox_stdout() -> None:
    agent = _make_agent()
    out, err = agent.execute_in_sandbox(""print('x')"")
    assert out == ""x\n""
    assert err == """"
",tests/test_codegen_agent.py,,1,3.850741907939403e-09,"The method `test_execute_in_sandbox_stdout` is a unit test designed to verify the functionality of the `execute_in_sandbox` method of an agent. It checks if the method correctly captures standard output and error when executing a simple print statement. This is a fundamental test to ensure that the sandbox execution environment is working as expected. Such tests are crucial for maintaining code quality and reliability, especially in environments where code execution needs to be isolated and controlled. Therefore, this method is likely to be retained as part of the test suite."
survived,"def _make_agent() -> codegen_agent.CodeGenAgent:
    cfg = config.Settings(bus_port=0)
    bus = messaging.A2ABus(cfg)
    ledger = Ledger("":memory:"", broadcast=False)
    return codegen_agent.CodeGenAgent(bus, ledger)
",tests/test_codegen_agent.py,,1,1.1032560311263802e-09,"The method '_make_agent' is a private helper function that initializes and returns an instance of 'CodeGenAgent'. It is likely used internally within a module or class to encapsulate the setup process for creating an agent with specific configurations. Since it is a utility function that aids in the creation of a complex object, it is unlikely to be deleted unless the entire functionality it supports is removed or refactored. Therefore, it is more likely to survive."
survived,"def _gen_certs(tmp: Path) -> tuple[str, str, bytes, str]:
    root = Path(__file__).resolve().parents[1]
    script = root / ""infrastructure"" / ""gen_bus_certs.sh""
    subprocess.run([""bash"", str(script)], cwd=tmp, check=True, capture_output=True)
    cert = tmp / ""certs"" / ""bus.crt""
    key = tmp / ""certs"" / ""bus.key""
    token = ""change_this_token""
    ca = cert.read_bytes()
    return str(cert), str(key), ca, token
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_bus_secure.py,,1,2.3355930333443423e-09,"The method '_gen_certs' is likely to survive because it performs a specific and useful function: generating certificates by running a shell script and returning the paths and contents of the generated certificate and key files, along with a token. This functionality is essential in many systems that require secure communications, and the method encapsulates this process effectively. Additionally, the use of subprocess to run a script and handle outputs is a common pattern in Python for interacting with system-level operations, suggesting that the method is well-integrated into its intended use case."
survived,"def transform_groups(groups: List[Group], member_map: Dict[str, List[str]]) -> List[Dict[str, Any]]:
    """"""Transform API responses into dictionaries for ingestion.""""""
    result: List[Dict[str, Any]] = []
    for g in groups:
        transformed = {
            ""id"": g.id,
            ""display_name"": g.display_name,
            ""description"": g.description,
            ""mail"": g.mail,
            ""mail_nickname"": g.mail_nickname,
            ""mail_enabled"": g.mail_enabled,
            ""security_enabled"": g.security_enabled,
            ""group_types"": g.group_types,
            ""visibility"": g.visibility,
            ""is_assignable_to_role"": g.is_assignable_to_role,
            ""created_date_time"": g.created_date_time,
            ""deleted_date_time"": g.deleted_date_time,
            ""member_ids"": member_map.get(g.id, []),
        }
        result.append(transformed)
    return result
",cartography/intel/entra/groups.py,,1,1.8189616842444243e-09,"The method 'transform_groups' is a utility function that transforms a list of 'Group' objects into a list of dictionaries, which is a common requirement for data processing and ingestion tasks. It is well-defined, with clear input and output types, and serves a specific purpose of converting API response data into a more usable format. Such utility functions are often retained in codebases because they encapsulate a specific transformation logic that is reusable and necessary for data handling. Therefore, it is likely to survive."
survived,"    def _run(
        self, *args: str, env: dict | None = None
    ) -> subprocess.CompletedProcess[str]:
        if not self.git_available():
            raise RuntimeError(""git executable not found"")
        return subprocess.run(
            [""git"", *args],
            cwd=self.repo_dir,
            text=True,
            check=True,
            capture_output=True,
            env=env,
        )
",src/meta_agent/git_utils.py,GitManager,1,1.0467401685178159e-08,"The method '_run' is a utility function that wraps around the 'subprocess.run' method to execute git commands. It checks for the availability of the git executable and then runs the command in a specified directory. This is a common pattern in codebases that interact with git repositories programmatically. The method is likely to be useful for maintaining and executing git operations within a Python application, especially if the application frequently interacts with git repositories. Therefore, it is likely to be retained in the codebase."
survived,"        async def run() -> None:
            await orch.bus.start()
            assert orch.bus._server is not None
            try:
                creds = grpc.ssl_channel_credentials(root_certificates=ca)
                async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                    stub = ch.unary_unary(""/bus.Bus/Send"")
                    payload = {
                        ""sender"": ""a"",
                        ""recipient"": ""b"",
                        ""payload"": {},
                        ""ts"": 0.0,
                        ""token"": ""bad"",
                    }
                    with pytest.raises(grpc.aio.AioRpcError):
                        await stub(json.dumps(payload).encode())
            finally:
                await orch.bus.stop()
                await orch.ledger.stop_merkle_task()
                orch.ledger.close()
",tests/test_orchestrator_bus_tls_env.py,,1,7.194132978569833e-09,"The method is likely to be Survived (1) because it is a well-structured asynchronous function that includes error handling and resource cleanup. It uses gRPC for communication, which is a common and modern approach for inter-service communication. The use of pytest to assert that an error is raised indicates that this function is part of a test suite, which is essential for maintaining code quality. Additionally, the function ensures that resources are properly closed in the 'finally' block, which is a good practice in asynchronous programming."
survived,"def test_orchestrator_bus_tls_env(tmp_path: Path) -> None:
    """"""Orchestrator bus requires valid token when TLS is enabled via env vars.""""""
    port = _free_port()
    cert, key, ca = _make_cert(tmp_path)

    env = {
        ""AGI_INSIGHT_BUS_PORT"": str(port),
        ""AGI_INSIGHT_BUS_CERT"": cert,
        ""AGI_INSIGHT_BUS_KEY"": key,
        ""AGI_INSIGHT_BUS_TOKEN"": ""tok"",
        ""AGI_INSIGHT_LEDGER_PATH"": str(tmp_path / ""ledger.db""),
        ""AGI_INSIGHT_OFFLINE"": ""1"",
    }

    with mock.patch.dict(os.environ, env, clear=True):
        importlib.reload(config)
        importlib.reload(orchestrator)
        orch = orchestrator.Orchestrator(config.Settings())

        async def run() -> None:
            await orch.bus.start()
            assert orch.bus._server is not None
            try:
                creds = grpc.ssl_channel_credentials(root_certificates=ca)
                async with grpc.aio.secure_channel(f""localhost:{port}"", creds) as ch:
                    stub = ch.unary_unary(""/bus.Bus/Send"")
                    payload = {
                        ""sender"": ""a"",
                        ""recipient"": ""b"",
                        ""payload"": {},
                        ""ts"": 0.0,
                        ""token"": ""bad"",
                    }
                    with pytest.raises(grpc.aio.AioRpcError):
                        await stub(json.dumps(payload).encode())
            finally:
                await orch.bus.stop()
                await orch.ledger.stop_merkle_task()
                orch.ledger.close()

        asyncio.run(run())",tests/test_orchestrator_bus_tls_env.py,,1,1.1253518384332553e-07,"The method is a test function that verifies the behavior of the orchestrator bus when TLS is enabled and an invalid token is used. It is a crucial part of ensuring the security and correctness of the system, especially in environments where secure communication is required. Test functions like this are typically retained to maintain the integrity of the software and to catch any regressions or issues in future updates."
survived,"    def create(self, *args: Any, **kwargs: Any) -> Any:  # pragma: no cover - stub
        raise NotImplementedError(""OpenAI SDK not available"")
",src/meta_agent/services/openai_stub.py,_ChatCompletions,0,0.9999989322969233,"The method is a stub, indicated by the comment '# pragma: no cover - stub', and it raises a NotImplementedError. This suggests that the method is not intended to be used in its current form and is likely a placeholder for future implementation. Since it is not functional and does not provide any utility in its current state, it is likely to be deleted or replaced with a proper implementation in the future."
survived,"def intToChurch(i):
    if i == 0:
        return zero
    return succ(intToChurch(i - 1))
",tests/rosetta/transpiler/Python/church-numerals-1.py,,1,8.152020648014727e-09,"The method 'intToChurch' is a recursive function that converts an integer to its Church numeral representation. Church numerals are a concept from lambda calculus, which is a foundational framework in mathematical logic and computer science. This function is likely part of a larger system dealing with functional programming concepts or educational tools for teaching lambda calculus. Given its specific utility and the niche area it serves, it is more likely to be retained in a codebase that deals with such concepts. Therefore, the method is predicted to survive."
survived,"def runVM(prog):
    data = []
    i = 0
    while i < prog[""dataSize""]:
        data = data + [0]
        i = i + 1
    stack = []
    pc = 0
    code = prog[""code""]
    addrMap = prog[""addrMap""]
    pool = prog[""strings""]
    while pc < len(code):
        inst = code[pc]
        op = inst[""op""]
        arg = inst[""arg""]
        if op == ""push"":
            stack = stack + [arg]
            pc = pc + 1
            continue
        if op == ""store"":
            data[arg] = stack[len(stack) - 1]
            stack = slice(stack, 0, len(stack) - 1)
            pc = pc + 1
            continue
        if op == ""fetch"":
            stack = stack + [data[arg]]
            pc = pc + 1
            continue
        if op == ""add"":
            stack[len(stack) - 2] = stack[len(stack) - 2] + stack[len(stack) - 1]
            stack = slice(stack, 0, len(stack) - 1)
            pc = pc + 1
            continue
        if op == ""lt"":
            v = 0
            if stack[len(stack) - 2] < stack[len(stack) - 1]:
                v = 1
            stack[len(stack) - 2] = v
            stack = slice(stack, 0, len(stack) - 1)
            pc = pc + 1
            continue
        if op == ""jz"":
            v = stack[len(stack) - 1]
            stack = slice(stack, 0, len(stack) - 1)
            if v == 0:
                pc = addrMap[arg]
            else:
                pc = pc + 1
            continue
        if op == ""jmp"":
            pc = addrMap[arg]
            continue
        if op == ""prts"":
            print(pool[stack[len(stack) - 1]])
            stack = slice(stack, 0, len(stack) - 1)
            pc = pc + 1
            continue
        if op == ""prti"":
            print(str(stack[len(stack) - 1]))
            stack = slice(stack, 0, len(stack) - 1)
            pc = pc + 1
            continue
        if op == ""halt"":
            break
        pc = pc + 1
",tests/rosetta/transpiler/Python/compiler-virtual-machine-interpreter.py,,1,1.955568070542584e-08,"The method 'runVM' is a virtual machine implementation that interprets a simple bytecode language. It includes basic operations like push, store, fetch, add, comparison, conditional jumps, and print operations. Such methods are often used in educational contexts, for scripting languages, or for executing code in a controlled environment. The method is functional and complete for its purpose, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def circles(p1, p2, r):
    if p1.x == p2.x and p1.y == p2.y:
        if r == 0.0:
            return [p1, p1, ""Coincident points with r==0.0 describe a degenerate circle.""]
        return [p1, p2, ""Coincident points describe an infinite number of circles.""]
    if r == 0.0:
        return [p1, p2, ""R==0.0 does not describe circles.""]
    dx = p2.x - p1.x
    dy = p2.y - p1.y
    q = hypot(dx, dy)
    if q > 2.0 * r:
        return [p1, p2, ""Points too far apart to form circles.""]
    m = Point(x=(p1.x + p2.x) / 2.0, y=(p1.y + p2.y) / 2.0)
    if q == 2.0 * r:
        return [m, m, ""Points form a diameter and describe only a single circle.""]
    d = sqrtApprox(r * r - q * q / 4.0)
    ox = d * dx // q
    oy = d * dy // q
    return [Point(x=m.x - oy, y=m.y + ox), Point(x=m.x + oy, y=m.y - ox), ""Two circles.""]
",tests/rosetta/transpiler/Python/circles-of-given-radius-through-two-points.py,,1,5.3157849718487075e-08,"The method 'circles' is a utility function that calculates the possible circle centers given two points and a radius. It handles various edge cases such as coincident points, zero radius, and points too far apart. The function is well-defined and provides meaningful error messages for each scenario. It is likely to be useful in geometric computations or graphical applications. Therefore, it is unlikely to be deleted as it serves a specific purpose and is implemented correctly."
survived,"def bigFromInt(x):
    if x == 0:
        return [0]
    digits = []
    n = x
    while n > 0:
        digits = digits + [n % 10]
        n = n // 10
    return digits
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,,1,7.889265051273362e-06,"The method 'bigFromInt' is a utility function that converts an integer into a list of its digits in reverse order. While the function is simple and works correctly, it is not particularly efficient due to the use of list concatenation in a loop, which can be slow for large numbers. However, the function is straightforward and serves a clear purpose, which might make it useful in certain contexts where performance is not a critical concern. Additionally, the function could be easily optimized by using list comprehension or other methods. Given these considerations, the method is likely to survive as it provides a basic utility that can be improved upon if needed."
survived,"def commatize(n):
    s = str(n)
    out = """"
    i = len(s) - 1
    c = 0
    while i >= 0:
        out = """".join(s[i:i + 1]) + out
        c = c + 1
        if c % 3 == 0 and i > 0:
            out = "","" + out
        i = i - 1
    return out
",tests/rosetta/transpiler/Python/composite-numbers-k-with-no-single-digit-factors-whose-factors-are-all-substrings-of-k.py,,1,4.4508487281649027e-07,"The method 'commatize' is a utility function that formats a number by inserting commas at every three digits, which is a common requirement for displaying large numbers in a more readable format. This functionality is useful in many applications, such as financial software, data reporting, and user interfaces that display numerical data. Since this is a basic and widely applicable utility, it is likely to be retained in the codebase unless there is a more efficient or standardized library function available that performs the same task. However, given the simplicity and directness of this implementation, it is likely to survive unless replaced by a more optimized solution."
survived,"def pow2(k):
    r = 1
    i = 0
    while i < k:
        r = r * 2
        i = i + 1
    return r
",tests/rosetta/transpiler/Python/chernicks-carmichael-numbers.py,,1,1.522997951276035e-08,"The method 'pow2' is a simple implementation of calculating 2 raised to the power of 'k'. It uses a loop to multiply 2, 'k' times, which is a straightforward and correct approach to achieve the desired result. Although this method could be optimized using bit shifting or the built-in power function, it is still a valid and functional implementation. Therefore, it is likely to survive as it correctly performs the intended operation without any errors."
survived,"def test_parse_time_spec_variants():
    assert parse_time_spec(""30n"") == {""type"": ""n"", ""value"": 30}
    assert parse_time_spec(15) == {""type"": ""n"", ""value"": 15}
    assert parse_time_spec(""24h"") == {""type"": ""time"", ""value"": timedelta(hours=24)}
    assert parse_time_spec(""45m"") == {""type"": ""time"", ""value"": timedelta(minutes=45)}
    assert parse_time_spec(""7d"") == {""type"": ""time"", ""value"": timedelta(days=7)}
    assert parse_time_spec(None) == {""type"": ""n"", ""value"": DEFAULT_LAST_N}
    with pytest.raises(ValueError):
        parse_time_spec(""abc"")
",tests/test_dashboard.py,,1,1.955568070542584e-08,"The method `test_parse_time_spec_variants` is a unit test function that verifies the behavior of the `parse_time_spec` function. It checks various valid inputs and ensures they return the expected dictionary output, and it also tests for an invalid input to ensure a `ValueError` is raised. This is a typical and necessary part of software development to ensure code reliability and correctness. Since it serves a crucial role in testing the functionality of `parse_time_spec`, it is unlikely to be deleted unless the `parse_time_spec` function itself is removed or significantly altered, which would necessitate a change in the test cases."
survived,"    def __str__(self) -> str:
        return self.message
",src/meta_agent/ux/error_handler.py,UXError,1,2.646573631904765e-09,"The method `__str__` is a special method in Python used to define the string representation of an object. It is commonly used and expected to be implemented in classes to provide a meaningful string output when the object is printed or converted to a string. The implementation here is straightforward and serves its purpose by returning the `message` attribute of the object. There is no indication that this method is redundant or incorrect, so it is likely to be retained."
survived,"    def handle(self, error: UXError) -> None:
        """"""Log the error and display the message via CLI.""""""
        msg = str(error)
        if error.context:
            self.logger.error(""%s | context=%s"", msg, error.context)
        else:
            self.logger.error(msg)
        try:
            self.cli_output.error(msg)
        except Exception:
            self.logger.error(""Failed to output error message via CLI"")",src/meta_agent/ux/error_handler.py,ErrorHandler,1,5.905303995456778e-10,"The method 'handle' is likely to survive because it performs a critical function of logging errors and displaying them via CLI, which is essential for debugging and user communication. It also includes error handling for the CLI output, making it robust and reliable."
survived,"    def fail(*args, **kwargs):
        raise OSError(""boom"")
",tests/ux/test_cli_output.py,,0,0.999999996149258,"The method 'fail' is designed to raise an OSError with the message 'boom' whenever it is called. This function does not perform any useful operation other than raising an exception, which is typically not desirable unless used for testing purposes. Without additional context indicating its necessity, such as being part of a test suite to ensure error handling, it is likely to be considered redundant or harmful in production code. Therefore, it is more likely to be deleted."
survived,"def test_diagram_generation_error_subclass():
    assert issubclass(DiagramGenerationError, UXError)",tests/ux/test_error_handler.py,,1,3.653482080241728e-08,"The method `test_diagram_generation_error_subclass` is a unit test that checks if `DiagramGenerationError` is a subclass of `UXError`. This is a simple and valid test case that ensures the correct inheritance structure in the codebase. Such tests are crucial for maintaining the integrity of the class hierarchy, especially in larger projects where multiple developers might be working on the code. Therefore, this method is likely to be retained as it serves a useful purpose in verifying the code's correctness."
survived,"        def copy(self, text):
            copied[""text""] = text
",tests/ux/test_user_feedback.py,Dummy,0,0.999998790133938,"The method 'copy' is incomplete and lacks context. It references a variable 'copied' which is not defined within the method or passed as a parameter. This suggests that the method is either unfinished or incorrectly implemented. Without additional context or a clear definition of 'copied', the method is likely to be deleted or significantly revised to function correctly."
survived,"    def notify(self, message: str, severity: NotificationSeverity = NotificationSeverity.INFO) -> None:
        """"""Display a notification with the appropriate style.""""""
        if severity is NotificationSeverity.SUCCESS:
            self.cli_output.success(message)
        elif severity is NotificationSeverity.WARNING:
            self.cli_output.warning(message)
        elif severity in (NotificationSeverity.ERROR, NotificationSeverity.CRITICAL):
            self.cli_output.error(message)
        else:
            self.cli_output.info(message)
",src/meta_agent/ux/user_feedback.py,UserFeedback,1,6.69158608681505e-10,"The method 'notify' is likely to survive because it provides a clear and structured way to handle different notification severities, which is a common requirement in many applications. The method is well-defined, uses an enumeration for severity levels, and delegates the actual output to a 'cli_output' object, which suggests good separation of concerns. This makes the method flexible and reusable, increasing its chances of being retained in the codebase."
survived,"    def metadata(self) -> BundleMetadata:
        if self._metadata is None:
            self.refresh_metadata()
        assert self._metadata is not None
        return self._metadata
",src/meta_agent/bundle.py,Bundle,1,2.998960815863541e-09,"The method 'metadata' is a getter method that ensures the '_metadata' attribute is initialized before returning it. It uses a lazy loading pattern, where 'refresh_metadata()' is called only if '_metadata' is None. This is a common and useful pattern in programming to optimize resource usage and ensure data is up-to-date. The method is simple, efficient, and serves a clear purpose, making it unlikely to be deleted unless the entire approach to handling metadata changes."
survived,"def test_bundle_load_and_list_files(tmp_path: Path) -> None:
    gen = BundleGenerator(tmp_path)
    gen.generate(agent_code=""print('hi')"")

    b = Bundle(tmp_path)
    assert b.metadata.schema_version
    files = b.list_files()
    assert ""agent.py"" in files
    assert b.read_text(""agent.py"").strip() == ""print('hi')""
",tests/test_bundle_api.py,,1,2.2159489282323004e-08,"The method `test_bundle_load_and_list_files` is a unit test function that verifies the functionality of the `Bundle` class and its methods. It checks if the bundle is correctly generated, if the metadata schema version is present, if the file listing is accurate, and if the file content matches the expected output. This is a typical and necessary test to ensure the integrity and correctness of the `Bundle` class's functionality. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality."
survived,"def test_bundle_generator_hooks(tmp_path: Path) -> None:
    calls: list[str] = []

    def pre(path: Path) -> None:
        calls.append(""pre"")

    def post(path: Path, meta) -> None:
        calls.append(""post"")

    gen = BundleGenerator(tmp_path)
    gen.generate(agent_code=""print('x')"", pre_hook=pre, post_hook=post)

    assert calls == [""pre"", ""post""]",tests/test_bundle_api.py,,1,6.023574641292144e-08,"The method `test_bundle_generator_hooks` is a unit test designed to verify the functionality of the `BundleGenerator` class, specifically its ability to correctly call pre and post hooks during the generation process. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to be retained as it serves an important role in testing."
survived,"    def __exit__(self, exc_type: object, exc: object, tb: object) -> None:
        """"""Ensure the database connection is closed.""""""
        self.close()",alpha_factory_v1/demos/alpha_agi_insight_v1/src/utils/logging.py,Ledger,1,1.637377179507321e-07,"The method is a standard implementation of the __exit__ method in a context manager, which is crucial for ensuring that resources are properly released, such as closing a database connection. This is a common and necessary practice in resource management, making it unlikely to be deleted."
survived,"    async def invoke_tool(self, name: str, args: dict[str, object] | None = None) -> object:
        """"""Invoke a tool by name using :class:`mcp.ClientSessionGroup`.""""""
        args = args or {}
        return await self._group.call_tool(name, args)",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/mcp_adapter.py,MCPAdapter,1,3.160881453314576e-10,"The method 'invoke_tool' is likely to survive because it is an asynchronous function that provides a clear utility: invoking a tool by name with optional arguments. It uses modern Python features such as type hinting and asynchronous programming, which are considered best practices. Additionally, it leverages a class method ':class:`mcp.ClientSessionGroup`', suggesting it is part of a larger, possibly well-structured codebase. Unless there are changes in the requirements or the architecture that render this method obsolete, it is likely to be retained."
survived,"    async def patched_handle(self, env):
        text = self.adk.generate_text(env.payload.get(""plan"", """"))
        await self.emit(""strategy"", {""research"": text})
",tests/test_adapters.py,,1,4.944450477491054e-09,"The method 'patched_handle' is an asynchronous function that processes an environment object 'env'. It generates text using a method 'generate_text' from 'self.adk' and emits a 'strategy' event with the generated text. The method seems to be part of a larger system that handles asynchronous events and data processing, which is a common pattern in modern software development. There is no indication of deprecated practices or inefficiencies in the code. Therefore, it is likely to be retained in the codebase."
survived,"        def close(self) -> None:
            pass
",tests/test_adapters.py,DummyLedger,0,0.9968273169336632,"The method 'close' is defined but does not perform any action, as it only contains a 'pass' statement. This suggests that it might be a placeholder for future implementation or it is intended to be overridden in a subclass. If the class is part of a larger framework or library where 'close' is expected to be implemented by subclasses, it might survive. However, if this is not the case and there is no plan to implement functionality in 'close', it is likely to be deleted as it serves no purpose."
survived,"def test_missing_code_defaults_to_ok(payload: dict[str, object]) -> None:
    bus = DummyBus(config.Settings(bus_port=0))
    led = DummyLedger()
    agent = safety_agent.SafetyGuardianAgent(bus, led)
    env = messaging.Envelope(""src"", ""safety"", payload, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][1].payload[""status""] == ""ok""
",tests/test_safety_guardian_property.py,,1,1.1861120010657661e-08,"The method `test_missing_code_defaults_to_ok` is a unit test that checks the behavior of the `SafetyGuardianAgent` when handling a message with a missing code. It ensures that the default status is set to ""ok"". This is a typical test case to verify default behavior and is likely to be useful for maintaining code quality and ensuring expected functionality. Therefore, it is unlikely to be deleted as it serves a clear purpose in the testing suite."
survived,"        def __init__(self, val: str) -> None:  # pragma: no cover - dummy
            pass
",tests/test_safety_guardian_property.py,DummyPk,0,0.9999974387182097,"The method is a constructor that takes a string parameter but does nothing with it, as indicated by the 'pass' statement. The comment '# pragma: no cover - dummy' suggests that this is a placeholder or a stub method, likely intended for future implementation or to satisfy an interface requirement. Since it currently serves no functional purpose, it is likely to be deleted unless it is part of a larger framework where such placeholders are common practice."
survived,"    def __init__(self, *args, **kwargs):
        pass
",openai_agents/__init__.py,AgentRuntime,0,0.9999999677581336,"The method is an empty constructor that does not perform any initialization or operations. It is likely to be deleted because it does not contribute any functionality to the class. Constructors are typically used to set up initial state or perform necessary setup tasks, and an empty one does not fulfill these purposes."
survived,"    def score(self, genome: str | Iterable[float]) -> float:
        tokens = str(genome).lower().split()
        best = 0.0
        for ex in self.examples:
            sim = self._jaccard(tokens, ex.lower().split())
            if sim > best:
                best = sim
        noise = self.rng.random() * 0.001
        val = best + noise
        return float(min(1.0, max(0.0, val)))",src/evaluators/feasibility_critic.py,FeasibilityCritic,1,6.69158608681505e-10,"The method 'score' is likely to survive because it appears to be a well-defined function that calculates a similarity score between a given genome and a set of examples using the Jaccard similarity metric. The method includes a noise factor to introduce variability, which can be useful in certain applications like genetic algorithms or machine learning. The code is clear, concise, and performs a specific task that could be valuable in contexts where similarity scoring is needed."
survived,"            def _create_resolver(f_name=field_name, model=sa_model, target=target_model):
                async def func(entity_id: int, ctx: EnrichContext) -> Any | None:
                    session_factory = ctx.request_context.lifespan_context[session_key]
                    async with session_factory() as session:  # type: AsyncSession
                        obj = await session.get(model, entity_id)
                        if not obj:
                            return None
                        await session.refresh(obj, [f_name])
                        value = getattr(obj, f_name)
                        return _sa_to_enrich(value, target) if value else None

                return func
",src/enrichmcp/sqlalchemy/auto.py,,1,4.944450477491054e-09,"The method '_create_resolver' is a utility function designed to create asynchronous resolver functions for fetching and enriching data from a database using SQLAlchemy. It is a specific and useful function for applications that require dynamic data fetching and transformation, especially in contexts where asynchronous operations are beneficial, such as web applications or services. The function is well-structured, uses modern Python features like type hints and async/await, and serves a clear purpose in the context of data handling. Therefore, it is likely to be retained in the codebase."
survived,"def test_concurrent_experiments(tmp_path, monkeypatch) -> None:
    monkeypatch.setenv(""ARCHIVE_PATH"", str(tmp_path / ""arch.db""))
    monkeypatch.setenv(""SOLUTION_ARCHIVE_PATH"", str(tmp_path / ""sol.duckdb""))
    settings = config.Settings(bus_port=0)
    with mock.patch.object(orchestrator.Orchestrator, ""_init_agents"", lambda self: []):
        orch = orchestrator.Orchestrator(settings)

    import numpy as np

    monkeypatch.setattr(""src.evaluators.novelty.embed"", lambda _t: np.zeros((1, 1), dtype=""float32""))
    monkeypatch.setattr(""src.simulation.surrogate_fitness.aggregate"", lambda vals, **kw: [0.0 for _ in vals])
    times = []

    def dummy_run(*_a, **_kw):
        times.append(time.perf_counter())
        time.sleep(0.2)
        ind = orchestrator.mats.Individual([0.0])
        ind.score = 0.0
        return [ind]

    monkeypatch.setattr(orchestrator.mats, ""run_evolution"", dummy_run)

    def fn(genome: list[float]) -> tuple[float]:
        time.sleep(0.2)
        return (sum(genome),)

    async def run() -> None:
        await asyncio.gather(
            orch.evolve(""a"", fn, 1, experiment_id=""exp1"", population_size=2, generations=1),
            orch.evolve(""b"", fn, 1, experiment_id=""exp2"", population_size=2, generations=1),
        )

    asyncio.run(run())
    assert len(times) == 2
    assert abs(times[0] - times[1]) < 0.05
    assert ""exp1"" in orch.experiment_pops
    assert ""exp2"" in orch.experiment_pops
    assert orch.experiment_pops[""exp1""] is not orch.experiment_pops[""exp2""]

    specs = [json.loads(row[0])[""experiment_id""] for row in orch.archive.conn.execute(""SELECT spec FROM entries"")]
    assert {""exp1"", ""exp2""} <= set(specs)",tests/test_experiments.py,,1,6.023574641292144e-08,"The method `test_concurrent_experiments` is a unit test designed to verify the concurrent execution of experiments in an orchestrator system. It uses mocking and patching to simulate the environment and dependencies, ensuring that the orchestrator can handle multiple experiments simultaneously. This is a critical functionality test for systems that rely on concurrent processing, and such tests are essential for maintaining the reliability and performance of the system. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def recent_memory(self, agent: str, n: int = 5) -> list[Any]:
        """"""Fetch the agent's most recent memory entries.""""""
        url = f""{self.base_url}/memory/{agent}/recent""
        resp = requests.get(url, params={""n"": n})
        resp.raise_for_status()
        return resp.json()
",alpha_factory_v1/demos/alpha_agi_marketplace_v1/marketplace.py,MarketplaceClient,1,4.599055376537186e-10,"The method 'recent_memory' is likely to survive because it provides a clear and useful functionality: fetching the most recent memory entries for a given agent. This is a common requirement in applications that deal with user data or agent-based systems. The method is straightforward, uses standard HTTP requests, and handles potential errors with 'raise_for_status', which makes it robust. Additionally, it uses default parameters, making it flexible for different use cases. These factors contribute to its likelihood of being retained in the codebase."
survived,"def call_local_model(prompt_messages: list[dict[str, str]]) -> str:
    """"""Return a response from a local model (placeholder implementation).""""""
    return """"
",alpha_factory_v1/demos/self_healing_repo/agent_core/llm_client.py,,1,5.3157849718487075e-08,"The method 'call_local_model' is a placeholder implementation, which means it currently does not perform any meaningful operation other than returning an empty string. However, the method is structured to potentially be expanded in the future to interact with a local model, as suggested by its name and parameter. This indicates that the method is likely intended for future development rather than deletion. Therefore, it is more likely to survive as it provides a foundation for future functionality."
survived,"def test_get_tables_trailing_semicolon():
    dialect = ""bigquery""

    query = ""SELECT * FROM table1;""
    expected = {""tables"": [""table1""]}
    assert get_tables(query, dialect) == expected

    query = ""SELECT * FROM table1;;""
    expected = {""tables"": [""table1""]}
    assert get_tables(query, dialect) == expected
",pythonsrc/parser/main_test.py,,1,1.4166087846364157e-09,"The method `test_get_tables_trailing_semicolon` is a test function that checks the behavior of the `get_tables` function when handling SQL queries with trailing semicolons. This is a valid and useful test case to ensure that the `get_tables` function can correctly parse queries with one or more trailing semicolons, which are common in SQL syntax. Since this test is relevant for verifying the robustness of the `get_tables` function, it is likely to be retained in the codebase."
survived,"def banner() -> str:
    """"""Return the standard startup banner.""""""
    return (
        ""\N{MILITARY MEDAL} \N{GREEK SMALL LETTER ALPHA}\N{HYPHEN-MINUS}AGI""
        "" Insight \N{EYE}\N{SPARKLES}  Beyond Human Foresight""
    )
",alpha_factory_v1/demos/alpha_agi_insight_v0/openai_agents_bridge.py,,1,1.2501528648238603e-09,"The method 'banner' is a simple utility function that returns a string containing a startup banner with special Unicode characters. Such methods are often used for branding or providing a consistent user interface experience. Since it serves a specific purpose and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"  def supports_active_cooling(self) -> bool:
    return False
",pylabrobot/temperature_controlling/chatterbox.py,TemperatureControllerChatterboxBackend,1,1.444980317078884e-07,"The method `supports_active_cooling` is a simple method that returns a constant boolean value, `False`. This suggests that the method is not currently supporting any active cooling functionality. However, the method is likely part of a larger interface or class that deals with cooling systems, and it might be overridden in subclasses to provide specific behavior. The method's presence indicates a design choice to allow for future expansion or customization. Therefore, it is more likely to be retained for potential future use or to maintain a consistent interface, rather than being deleted."
deleted,"  def supports_active_cooling(self) -> bool:
    return False",pylabrobot/heating_shaking/chatterbox.py,HeaterShakerChatterboxBackend,0,0.9999546021442518,"The method `supports_active_cooling` is a simple boolean function that returns `False`. It is likely a placeholder or a default implementation indicating that active cooling is not supported. If the system or application this method is part of does not plan to support active cooling in the future, or if this method is not used or referenced anywhere else in the codebase, it might be considered for deletion. However, if there is a possibility of future support for active cooling or if this method is part of an interface or abstract class that requires implementation, it might be retained. Without additional context, it is difficult to definitively predict its fate, but given its simplicity and lack of current functionality, it leans towards being deleted."
survived,"    def __getitem__(self, idx):
        return self.data[idx]
",no-ocr-api/tests/test_ingest_search.py,FakeDataset,1,3.581747929000289e-10,"The method `__getitem__` is a standard Python method used to make an object subscriptable, allowing the use of square brackets to access elements, similar to lists or dictionaries. This method is essential for classes that represent collections or sequences, as it provides a way to access elements by index. The implementation here is straightforward and correctly returns the element at the specified index from `self.data`. There is no indication of redundancy or poor design that would necessitate its removal. Therefore, it is likely to be retained in the code."
survived,"    def fake_convert_from_path(*args, **kwargs):
        return [Image.new(""RGB"", (10, 10)), Image.new(""RGB"", (10, 10))]
",no-ocr-api/tests/test_ingest_search.py,,1,9.237449576640118e-09,"The method 'fake_convert_from_path' is a mock or placeholder function that returns a list of two small RGB images. It is likely used for testing purposes, simulating the behavior of a real function that converts files from a path to images. Such functions are often retained in codebases for testing or demonstration purposes, especially if they are used in unit tests or as part of a testing suite. Therefore, it is likely to survive."
survived,"        def extract_text(self):
            return self.text
",no-ocr-api/tests/test_ingest_search.py,FakePage,1,1.1032560311263802e-09,"The method `extract_text` is a simple getter method that returns the value of the `text` attribute. Such methods are common in object-oriented programming to encapsulate data and provide controlled access to class attributes. Unless there is a significant change in the design or requirements that makes this method redundant or unnecessary, it is likely to survive. Getter methods are generally considered good practice for maintaining encapsulation."
survived,"def test_vllm_call_missing_dataset(client):
    response = client.post(
        ""/vllm_call"",
        data={
            ""user_query"": ""foo"",
            ""user_id"": ""user"",
            ""case_name"": ""case"",
            ""pdf_name"": ""x.pdf"",
            ""pdf_page"": 1,
        },
    )
    assert response.status_code == 404
",no-ocr-api/tests/test_ingest_search.py,,1,1.522997951276035e-08,"The method 'test_vllm_call_missing_dataset' is a unit test designed to verify that a specific API endpoint returns a 404 status code when a dataset is missing. This is a valid and useful test case for ensuring the robustness of the API, as it checks the system's behavior in the absence of expected data. Such tests are crucial for maintaining software quality and reliability. Therefore, the method is likely to be retained as part of the test suite."
survived,"def main() -> None:
    app = EnrichMCP(title=""Hello HTTP API"", description=""A simple HTTP example"")

    @app.retrieve(description=""Say hello over HTTP"")
    async def hello_http() -> dict[str, str]:
        return {""message"": ""Hello over HTTP!""}

    print(""Starting HTTP server on http://localhost:8000 ..."")
    app.run(transport=""streamable-http"")
",examples/hello_world_http/app.py,,1,3.850741907939403e-09,"The method is likely to survive because it demonstrates a clear and useful functionality: setting up a simple HTTP server with an endpoint that returns a greeting message. This is a common use case in web development, and the code is straightforward and easy to understand. Additionally, the use of async functions and modern Python type hints suggests that the code is up-to-date with current programming practices."
survived,"        async def send_and_wait(self, topic: str, data: bytes) -> None:
            return None
",tests/test_bus_large_payloads_property.py,Prod,0,0.9999999966017321,"The method 'send_and_wait' is an asynchronous function that takes a topic and data as parameters but immediately returns None without performing any operations. This suggests that the method is either incomplete or a placeholder. In its current state, it does not fulfill any functional purpose, which makes it a candidate for deletion unless it is intended to be implemented in the future. Without further context or usage, it is likely to be deleted."
survived,"def test_adk_generate_text_unreachable(httpx_mock, stub_adk):
    httpx_mock.add_exception(httpx.ConnectError(""offline""), url=""https://adk.example/generate"")
    adapter = ADKAdapter()
    with pytest.raises(httpx.HTTPError):
        adapter.generate_text(""hi"")
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_adapters.py,,1,1.522997951276035e-08,"The method `test_adk_generate_text_unreachable` is a unit test designed to verify the behavior of the `ADKAdapter` class when a connection error occurs. It uses mocking to simulate a network error and checks if the appropriate exception is raised. This is a common and useful test pattern to ensure robustness in network-dependent code. Therefore, it is likely to be retained as it serves a clear purpose in testing error handling."
survived,"def test_check_gzip_call_present() -> None:
    browser_dir = Path(__file__).resolve().parents[1]
    text = (browser_dir / ""manual_build.py"").read_text()
    assert ""def check_gzip_size"" in text
    pattern = r""write_text\(bundle\).*\n\s*check_gzip_size\(dist_dir / \""insight.bundle.js\""\)""
    assert re.search(pattern, text)
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_manual_build_size_limit.py,,1,3.850741907939403e-09,"The method `test_check_gzip_call_present` is a test function that verifies the presence of a specific function call (`check_gzip_size`) in a Python script (`manual_build.py`). This kind of test is useful for ensuring that certain code patterns or function calls are present in the codebase, which can be crucial for maintaining functionality or performance checks. Since it serves a clear purpose in maintaining code integrity and ensuring that important checks are not removed inadvertently, it is likely to be retained."
survived,"def get(
    url: str,
    *,
    params: dict | None = None,
    headers: dict | None = None,
    timeout: float | None = None,
) -> Response:
    """"""Perform a simple HTTP GET request.""""""
    return _call(""GET"", url, params=params, headers=headers, timeout=timeout)
",alpha_factory_v1/af_requests.py,,1,2.998960815863541e-09,"The method 'get' is a utility function for performing HTTP GET requests, which is a common requirement in many applications that interact with web services. It provides a simple interface for making requests with optional parameters, headers, and timeout settings. Such utility functions are often retained in codebases because they encapsulate common functionality, making the code more modular and reusable. Unless there is a significant change in the requirements or a better library function replaces it, this method is likely to survive."
survived,"    def _load_manifest(self) -> Dict[str, Any]:
        try:
            with open(self.manifest_path, ""r"", encoding=""utf-8"") as f:
                return json.load(f)
        except (IOError, json.JSONDecodeError):
            logger.warning(""Failed to read template registry manifest. Recreating."")
            return {}
",src/meta_agent/template_registry.py,TemplateRegistry,1,1.955568070542584e-08,"The method _load_manifest is responsible for loading a JSON manifest file and handling potential errors during the process. It includes error handling for both file I/O errors and JSON decoding errors, which are common issues when dealing with file operations. The method logs a warning and returns an empty dictionary if an error occurs, which is a reasonable fallback behavior. This method is likely to be useful in scenarios where the application needs to read configuration or data from a file and handle errors gracefully. Therefore, it is likely to be retained in the codebase."
survived,"    async def _combined(app: EnrichMCP) -> AsyncIterator[dict[str, Any]]:
        async with AsyncExitStack() as stack:
            merged: dict[str, Any] = {}
            for ls in lifespans:
                ctx = await stack.enter_async_context(ls(app))
                if isinstance(ctx, dict):
                    merged.update(ctx)
            yield merged
",src/enrichmcp/lifespan.py,,1,5.905303995456778e-10,"The method '_combined' is an asynchronous generator function that uses an 'AsyncExitStack' to manage multiple asynchronous context managers ('lifespans'). It collects and merges dictionaries from these contexts and yields the combined result. This pattern is useful for managing resources that need to be cleaned up after use, such as network connections or file handles, in an asynchronous environment. The use of 'AsyncExitStack' and asynchronous context managers is a modern and efficient approach to resource management in Python, especially in asynchronous applications. Therefore, the method is likely to be useful and relevant in its context, suggesting it will survive."
survived,"    def _validate(self, t: Triplet) -> bool:
        if (
            len(t.program.splitlines()) > MAX_PROG_LOC
            or len(t.inp) > 256
            or len(t.out) > 256
            or any(b in t.program for b in _BANNED)
        ):
            return False
        stdout, stderr = _exec_trusted(t.program, t.inp)
        return stderr == """" and stdout.strip() == t.out.strip()
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,3.3982678079468468e-09,"The method '_validate' is a utility function that checks the validity of a 'Triplet' object based on certain conditions. It ensures that the program length, input, and output do not exceed specified limits and that the program does not contain any banned elements. Additionally, it executes the program and checks if the output matches the expected output. Such validation functions are crucial for maintaining data integrity and ensuring that only valid data is processed further. Therefore, it is likely to be retained as it serves an important role in the system."
survived,"    def __repr__(self) -> str:
        return f""<AZREngine buf={len(self.buffer)} T={self.temperature:.2f}>""
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,2.0611536181902033e-09,"The method is a standard implementation of the __repr__ method, which is used to provide a string representation of an object. This is a common practice in Python to aid in debugging and logging, as it allows developers to easily see the state of an object. The method is concise, follows Python conventions, and provides useful information about the object's state (buffer length and temperature). There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"    def learn(self, results: Sequence[TaskResult]) -> None:
        if not results:
            return
        # Multiobjective scalarisation (simple): reward = unsolved_ratio * 0.7 + novelty * 0.3
        solved_frac = sum(r.solved for r in results) / len(results)
        diff_reward = 1.0 - solved_frac
        novelty = sum(r.complexity for r in results) / len(results)
        novelty_norm = min(1.0, novelty / 15.0)
        reward = 0.7 * diff_reward + 0.3 * novelty_norm

        beta = 0.1
        self._baseline = (1 - beta) * self._baseline + beta * reward
        adv = reward - self._baseline
        # PPOlite temperature adjust
        delta = -0.04 if adv > 0 else 0.04
        self.temperature = max(0.1, min(1.0, self.temperature + delta))

        # Buffer maintenance  keep correctly solved tasks
        for r in results:
            if r.solved:
                self._add(r.triplet)

        self.log(f""[AZR] reward={reward:.3f} adv={adv:+.3f} -> T={self.temperature:.2f}"")

        examples = (
            ""\n\n"".join(
                f""```python\n{t.program}```\n```json\n{t.inp}```\n```json\n{t.out}```""
                for t in self._rng.sample(self.buffer, k=min(3, len(self.buffer)))
            )
            or ""(buffer empty)""
        )

        return self._PROMPT.format(
            n=n,  # noqa: F821
            max_loc=MAX_PROG_LOC,
            buf=len(self.buffer),
            examples=examples,
        )
",alpha_factory_v1/demos/meta_agentic_agi_v3/curriculum/azr_engine.py,AZREngine,1,7.194132978569833e-09,"The method 'learn' is well-structured and serves a clear purpose in the context of a reinforcement learning or optimization framework. It calculates a reward based on task results, updates a baseline, adjusts a temperature parameter, and maintains a buffer of solved tasks. These operations are typical in adaptive learning systems, suggesting that the method is integral to the system's functionality. Additionally, the method includes logging and formatting for output, indicating it is actively used for monitoring and debugging. Therefore, it is likely to be retained in the codebase."
survived,"    def tearDown(self) -> None:
        asyncio.run(self.orch.bus.stop())
        asyncio.run(self.orch.ledger.stop_merkle_task())
        self.orch.ledger.close()
        self.tmp.cleanup()
",tests/test_insight_orchestrator_features.py,TestInsightOrchestrator,1,7.194132978569833e-09,"The method `tearDown` is a common method used in testing frameworks like `unittest` in Python to clean up resources after a test case has been executed. The code provided is performing cleanup tasks such as stopping asynchronous tasks and closing resources, which are essential for ensuring that tests do not interfere with each other and that resources are properly released. This is a standard practice in test case management, and there is no indication that this method is obsolete or unnecessary. Therefore, it is likely to be retained."
survived,"def test_timeline_df() -> None:
    secs = [sector.Sector(""a""), sector.Sector(""b"")]
    traj = forecast.forecast_disruptions(secs, 2, pop_size=2, generations=1)
    df = web_app.timeline_df(traj)
    assert set(df.columns) == {""year"", ""sector"", ""energy"", ""disrupted""}
    assert len(df) == 4
",tests/test_web_app.py,,1,5.905303995456778e-10,"The method `test_timeline_df` is a unit test function that checks the correctness of the `timeline_df` function from the `web_app` module. It verifies that the DataFrame returned by `timeline_df` has the expected columns and length. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to prevent future regressions. Therefore, this method is likely to be retained."
survived,"def _disruption_df(traj: list[Any]) -> ""pd.DataFrame"":
    """"""Return the first disruption year per sector.""""""

    import pandas as pd

    years: dict[str, int] = {}
    for point in traj:
        for sec in point.sectors:
            if sec.disrupted and sec.name not in years:
                years[sec.name] = point.year
    return pd.DataFrame({""sector"": list(years.keys()), ""year"": list(years.values())})
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_app.py,,1,2.646573631904765e-09,"The method is likely to survive because it is a well-defined utility function that converts a list of trajectory objects into a pandas DataFrame, capturing the first disruption year for each sector. It uses clear logic to iterate over the trajectory data, checks for disruptions, and constructs a dictionary that is then converted into a DataFrame. This functionality is useful for data analysis tasks where understanding the timing of disruptions across sectors is important. Additionally, the use of type hints and a docstring improves code readability and maintainability."
survived,"    async def ws_progress(websocket: WebSocket) -> None:
        """"""Stream year-by-year progress updates to the client.""""""
        await websocket.accept()
        _progress_ws.add(websocket)
        try:
            while True:
                await websocket.receive_text()
        except Exception:
            pass
        finally:
            _progress_ws.discard(websocket)
",src/interface/api_server.py,,1,2.646573631904765e-09,"The method 'ws_progress' is likely to survive because it implements a common pattern for handling WebSocket connections in an asynchronous manner. It includes proper setup and teardown of the WebSocket connection, and it handles exceptions gracefully. The method is also concise and follows a clear structure, making it easy to understand and maintain. Additionally, WebSockets are a popular technology for real-time communication, so this method is likely to be relevant and useful in many applications."
survived,"        def __init__(self, market_data: list[int] | None = None) -> None:
            super().__init__()
            self.market_data = market_data
",alpha_factory_v1/demos/meta_agentic_tree_search_v0/openai_agents_bridge.py,MATSAgent,1,1.2501528648238603e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial state. The use of type hinting with 'list[int] | None' is a modern Python feature that enhances code readability and maintainability. There is no indication that this constructor is redundant or unnecessary, so it is likely to be retained."
survived,"def test_assets_replaced() -> None:
    _assert_no_placeholder(BASE / ""lib"" / ""workbox-sw.js"")
    _assert_no_placeholder(BASE / ""lib"" / ""bundle.esm.min.js"")
    _assert_no_placeholder(BASE / ""dist"" / ""workbox-sw.js"")
    _assert_no_placeholder(BASE / ""dist"" / ""bundle.esm.min.js"")",tests/test_assets_replaced.py,,1,8.152020648014727e-09,"The method 'test_assets_replaced' is a test function that checks if certain files do not contain placeholders. It is likely part of a test suite to ensure that assets are correctly replaced during a build or deployment process. Test functions are generally important for maintaining code quality and ensuring that changes do not introduce regressions. Therefore, it is unlikely to be deleted unless the assets it tests are no longer relevant or the testing strategy changes significantly."
survived,"def load_documents(data_dir: str):
    """"""Load and preprocess all text files under *data_dir*.""""""
    corpus = []
    for filename in sorted(glob.glob(os.path.join(data_dir, ""*.txt""))):
        with open(filename, ""r"", encoding=""utf-8"", errors=""ignore"") as f:
            text = f.read().lower()
        tokens = [t for t in TOKEN_RE.findall(text) if t not in STOPWORDS]
        corpus.append(tokens)
    return corpus
",scripts/bbc_demo.py,,1,4.944450477491054e-09,"The method 'load_documents' is a utility function that loads and preprocesses text files from a specified directory. It reads each file, converts the text to lowercase, tokenizes it, and removes stopwords. This is a common and useful operation in text processing and natural language processing tasks. The method is well-defined, uses standard libraries, and performs a necessary function for many applications that involve text data. Therefore, it is likely to be retained in the codebase."
survived,"def test_ideal_sensor_readings_near_one() -> None:
    """"""Typical ideal metrics should yield ~1.0.""""""
    sensors = {""steps"": 10_000, ""resting_hr"": 60, ""sleep_hours"": 8, ""cal_intake"": 2100}
    value = fr.reward(None, None, sensors)
    assert 0.0 <= value <= 1.0
    assert value == approx(1.0, rel=0, abs=1e-7)
",tests/test_fitness_reward.py,,1,9.237449576640118e-09,"The method `test_ideal_sensor_readings_near_one` is a unit test function that checks if the `reward` function from the `fr` module returns a value close to 1.0 when given ideal sensor readings. This is a typical test case to ensure that the function behaves as expected under ideal conditions. The test is well-defined, uses assertions to validate the output, and is likely part of a larger test suite. Since it serves a clear purpose in verifying the correctness of the `reward` function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed."
survived,"def test_llama_paged_decode_matches_full_prefill():
    """"""Ensure llama paged decode matches full forward when prefilling entire sequences.""""""
    Pos = Axis(""position"", 16)
    Embed = Axis(""embed"", 8)
    Vocab = Axis(""vocab"", 64)

    cfg = LlamaConfig(
        seq_len=Pos.size,
        hidden_dim=Embed.size,
        intermediate_dim=16,
        num_layers=2,
        num_heads=2,
        num_kv_heads=2,
        rope=None,
        gradient_checkpointing=False,
        scan_layers=True,
        attn_backend=AttentionBackend.VANILLA,
    )

    model_key, input_key = jrandom.split(jrandom.PRNGKey(0))
    model = LlamaLMHeadModel.init(Vocab=Vocab, config=cfg, key=model_key)

    input_ids = hax.random.randint(input_key, Pos, 0, Vocab.size)

    pt = PageTable.init(max_pages=4, max_seqs=2, page_size=4, max_pages_per_seq=4)
    pt, seq1 = pt.assign_seq_id_to_seq()
    pt, seq2 = pt.assign_seq_id_to_seq()

    seq_ids = hax.named([seq1, seq2, -1, -1, -1, -1, -1, -1], ""seq"")
    new_token_counts = hax.named([4, 3, 0, 0, 0, 0, 0, 0], ""seq"")
    seg_ids = hax.named([0] * 4 + [1] * 3 + [-1] * 9, ""position"")
    pt, binfo = pt.allocate_for_seqs(updated_seqs=seq_ids, new_counts=new_token_counts, tokens=seg_ids)

    mask = AttentionMask.causal().with_segment_ids(seg_ids)
    full_out = model.activations(input_ids, attn_mask=mask, key=jrandom.PRNGKey(1))

    layer_caches = model.transformer.initial_cache(pt, dtype=jnp.float32)
    page_state = KvPageState.from_batch(binfo, layer_caches)
    pos_ids = hax.arange(Pos, dtype=jnp.int32)
    x = model.embeddings.embed(input_ids)
    decode_out, _ = _jit_paged_decode(model.transformer, x, pos_ids, page_state)

    full_out = full_out[""position"", hax.dslice(0, 7)]
    decode_out = decode_out[""position"", hax.dslice(0, 7)]
    assert_trees_all_close(full_out.array, decode_out.array, atol=1e-4, rtol=1e-4)
",tests/test_llama_decode.py,,1,2.1024340680345882e-07,"The method is a test function that ensures the correctness of a specific feature in a machine learning model. Test functions are crucial for maintaining code quality and verifying that changes do not break existing functionality. This function checks if the paged decoding matches the full forward pass, which is an important validation for the model's behavior. Therefore, it is unlikely to be deleted as it serves a critical role in the development and maintenance process."
survived,"def valid_spec_dict():
    return {
        ""task_description"": ""Test agent for CLI"",
        ""inputs"": {""data"": ""string""},
        ""outputs"": {""status"": ""string""},
        ""constraints"": [""Must run quickly""],
        ""technical_requirements"": [""Python 3.10+""],
        ""metadata"": {""test_id"": ""cli-001""},
    }
",tests/integration/test_telemetry_integration.py,,1,3.3982678079468468e-09,"The method `valid_spec_dict` is a utility function that returns a dictionary with a predefined structure. This structure seems to be a specification for a test agent, which includes fields like task description, inputs, outputs, constraints, technical requirements, and metadata. Such utility functions are often useful in testing or configuration scenarios where a consistent and reusable specification is needed. Since it provides a clear and structured way to define specifications, it is likely to be useful in various contexts where such a specification is required. Therefore, it is likely to be retained in the codebase."
survived,"async def test_build_regex_guardrails_multiple_rules():
    cfg = GuardrailConfig(
        rules=[
            GuardrailRule(name=""a"", pattern=""foo""),
            GuardrailRule(name=""b"", pattern=""bar""),
        ]
    )
    guards = build_regex_guardrails(cfg)
    assert len(guards) == 2

    await guards[0](""nothing here"")
    await guards[1](""nothing here"")

    with pytest.raises(ValueError):
        await guards[0](""foo"")
    with pytest.raises(ValueError):
        await guards[1](""bar"")",tests/test_guardrail_generator.py,,1,2.7894680920908113e-10,"The method is a test function that verifies the behavior of the `build_regex_guardrails` function with multiple rules. It checks that the correct number of guards are created and that they raise exceptions when the patterns are matched. This is a typical and necessary part of testing to ensure the functionality works as expected. There is no indication that this test is redundant or incorrect, so it is likely to be retained."
survived,"    def __init__(self, bus: orchestrator.messaging.A2ABus, ledger: orchestrator.Ledger) -> None:  # type: ignore[override]
        super().__init__(""boom"", bus, ledger)
        self.first = True
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,BoomAgent,1,4.944450477491054e-09,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up the initial state of the object by calling the superclass constructor and initializing an instance variable. Constructors are fundamental to object-oriented programming, and there is no indication that this specific constructor is redundant or unnecessary. Therefore, it is likely to be retained."
survived,"    async def loop_no_catch(self: orchestrator.AgentRunner, bus, ledger) -> None:
        await self.agent.run_cycle()
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_orchestrator.py,,1,8.76424914819242e-08,"The method 'loop_no_catch' is an asynchronous function that calls 'run_cycle' on 'self.agent'. It is a simple and straightforward method that likely serves a specific purpose in the context of the orchestrator.AgentRunner class. Without additional context indicating that this method is redundant or replaced by another implementation, it is reasonable to assume that it will survive. The method's name suggests it is part of a loop mechanism, which is a common pattern in asynchronous programming, especially in agent-based systems."
survived,"def test_compute_max_widths_strips_colors():
    data = [['1.1.1.1', 'AWS', '\x1b[31mno permission\x1b[0m']]
    widths = compute_max_widths(data)
    assert widths['Permission'] >= len('no permission') + 2",tests/test_whois_perms.py,,1,4.363462233903899e-09,"The method `test_compute_max_widths_strips_colors` is a test function that checks if the `compute_max_widths` function correctly calculates the maximum width of a column, taking into account the length of a string with ANSI color codes stripped. This is a valid and useful test to ensure that the function handles strings with color codes correctly, which is a common requirement in terminal applications. Therefore, the method is likely to be Survived as it serves a necessary purpose in testing the functionality of the code."
survived,"        def close(self) -> None:
            pass
",tests/test_agents.py,DummyLedger,0,0.9999999936511998,"The method 'close' is defined but not implemented, as it only contains a 'pass' statement. This suggests that the method is a placeholder and does not perform any action. In many cases, such methods are either intended to be overridden in subclasses or are remnants of incomplete code. Without further context or usage, such methods are often candidates for deletion, especially if they are not part of an interface or abstract class that requires them. Therefore, it is likely to be deleted."
survived,"def test_surrogate_pair_split_digits() -> None:
    chunks = ['{""a"": ""\\u', 'd83d\\u', 'de00""}']
    parsed = _stream_to_dict({}, chunks)
    assert parsed == {""a"": """"}
",api/core/utils/streams_test.py,,1,2.5109990926928157e-08,"The method `test_surrogate_pair_split_digits` is a test function that verifies the correct parsing of JSON strings containing surrogate pairs, which are used to represent characters outside the Basic Multilingual Plane in UTF-16 encoding. The test checks if the function `_stream_to_dict` can correctly parse a JSON string split across multiple chunks and reconstruct the surrogate pair to form the emoji character. This is a valid and useful test case for ensuring the robustness of JSON parsing functions, especially when dealing with streaming data or fragmented input. Therefore, the method is likely to be retained as it serves a specific purpose in testing the functionality of the parsing logic."
survived,"def test_unicode_escape_sequence() -> None:
    chunks = ['{""a"": ""\\', 'u00e9""}']
    parsed = _stream_to_dict({}, chunks)
    assert parsed == {""a"": """"}
",api/core/utils/streams_test.py,,1,2.0611536181902033e-09,"The method `test_unicode_escape_sequence` is a unit test designed to verify the correct parsing of a JSON string containing a Unicode escape sequence. It checks if the function `_stream_to_dict` correctly interprets the escape sequence `\u00e9` as the character ``. This is a valid and useful test case for ensuring that Unicode handling in JSON parsing is functioning as expected. Therefore, the method is likely to be retained as it serves a clear purpose in testing the functionality of the code."
survived,"def test_surrogate_pair_split() -> None:
    chunks = ['{""a"": ""\\ud83', 'd\\ude00""}']
    parsed = _stream_to_dict({}, chunks)
    assert parsed == {""a"": """"}
",api/core/utils/streams_test.py,,1,2.998960815863541e-09,"The method `test_surrogate_pair_split` is a unit test designed to verify the correct handling of surrogate pairs in JSON parsing. It checks if the function `_stream_to_dict` can correctly parse a JSON string split across chunks, specifically handling surrogate pairs that represent emojis. This is a valid and useful test case for ensuring robustness in JSON parsing, especially when dealing with UTF-16 encoded characters. Therefore, the method is likely to be retained as it serves an important purpose in testing the functionality of the code."
survived,"def test_Q3_returns_revenue_per_order_with_correct_priority():
    assert order_line_join == [
        {
            ""l_orderkey"": 100,
            ""revenue"": 1000 * 0.95 + 500,
            ""o_orderdate"": ""1995-03-14"",
            ""o_shippriority"": 1,
        }
    ]
",tests/machine/x/python/q3.py,,1,1.725782769012759e-08,"The method `test_Q3_returns_revenue_per_order_with_correct_priority` is a unit test function that checks if a specific condition is met in the code. It asserts that the variable `order_line_join` matches a predefined list of dictionaries with specific keys and values. This kind of test is crucial for ensuring that the code behaves as expected, especially in complex systems where data integrity and correctness are important. Since testing is a fundamental part of software development and maintenance, this method is likely to be retained to ensure the reliability of the codebase."
survived,"    def __repr__(self):
        return str(self.__dict__)
",tests/machine/x/python/q2.py,Supplier,1,1.0467401685178159e-08,"The method is a simple and effective way to provide a string representation of an object by returning its dictionary representation. This is useful for debugging and logging purposes, as it allows developers to quickly see the attributes and their values for an instance of a class. The method is straightforward, does not introduce any side effects, and is commonly used in Python classes. Therefore, it is likely to be retained in the code."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q2.py,Part,1,8.76424914819242e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, like `obj[key]`. In this implementation, it uses `getattr` to dynamically access an attribute of the object by name. This is a common and useful pattern for objects that need to provide dictionary-like access to their attributes. It is likely to be retained because it provides a flexible and Pythonic way to access object attributes, enhancing the usability of the class."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q2.py,Supplier,1,2.998960815863541e-09,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in custom container classes. In this code, it uses `getattr` to dynamically access an attribute of the object using the provided key. This is a valid and useful implementation for objects that need to provide dictionary-like access to their attributes. Therefore, the method is likely to be retained as it serves a clear purpose and is implemented correctly."
survived,"    def data_model_tool_name(self) -> str:
        """"""Return the name of the built-in data model exploration tool.""""""

        return f""explore_{self.name.lower().replace(' ', '_')}_data_model""
",src/enrichmcp/app.py,EnrichMCP,1,1.522997951276035e-08,"The method `data_model_tool_name` is a simple utility function that constructs and returns a string based on the object's name attribute. It is a straightforward and useful method for generating a consistent naming convention for data model exploration tools. Such utility methods are often retained in codebases because they encapsulate a specific piece of logic that might be reused in multiple places, enhancing code readability and maintainability. Therefore, it is likely to survive."
survived,"    def fake_eval(agent, model):
        return agent.score + 1
",tests/test_transfer_test.py,,0,0.9999970976877992,"The method `fake_eval` is a simple function that takes two parameters, `agent` and `model`, and returns the `agent.score` incremented by 1. The function is straightforward and does not perform any complex operations or checks. It seems to be a placeholder or a mock function, possibly used for testing purposes. 

Given its simplicity and lack of real evaluation logic, it is likely to be deleted or replaced with a more comprehensive evaluation function in a production environment. However, if the context is purely for testing or illustrative purposes, it might survive as a utility function.

Overall, without additional context indicating its necessity, the function is more likely to be deleted."
survived,"def run() -> None:
    n = 24
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_024.py,,0,0.999988521231025,"The method 'run' is a simple function that calculates the sum of the first 24 natural numbers and checks if it matches the expected result using the formula for the sum of an arithmetic series. This is a basic mathematical operation and the function is correctly implemented. However, the function does not take any input, return any output, or have any side effects, making it somewhat limited in utility. It serves primarily as a demonstration of a mathematical property. Without additional context or integration into a larger codebase, it is likely to be deleted as it doesn't provide significant functionality or utility on its own."
survived,"def run() -> None:
    n = 4
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_004.py,,1,3.927863699585036e-07,"The method 'run' is a simple function that calculates the sum of a range of numbers from 0 to n-1 and checks if it matches the expected sum using a mathematical formula. This is a basic example of a unit test to verify the correctness of the sum calculation. The function is straightforward, has no side effects, and serves a clear purpose in validating a small piece of logic. Therefore, it is likely to be retained as it is useful for ensuring code correctness."
survived,"def run() -> None:
    n = 3
    total = sum(range(n))
    expected = n*(n-1)//2
    assert total == expected",benchmarks/swe_mini/task_003.py,,1,4.4508487281649027e-07,"The method 'run' is a simple function that calculates the sum of a range of numbers and checks if it matches the expected result using an assertion. This is a basic test function that verifies the correctness of a mathematical operation. Such functions are often used in testing scenarios to ensure that code behaves as expected. However, the function is very specific and limited in its current form, as it only works for n=3 and doesn't provide any output or flexibility. Despite this, it serves a purpose in testing, and unless there is a specific reason to remove it, such as redundancy or a change in testing strategy, it is likely to survive. Therefore, the method will likely be Survived (1)."
survived,"def run() -> None:
    parts = [""poly"", ""task"", ""7""]
    joined = ""-"".join(parts)
    assert joined.split(""-"")[2] == str(7)",benchmarks/poly_mini/task_007.py,,1,1.1861120010657661e-08,"The method 'run' is a simple function that joins a list of strings with a hyphen and then splits the resulting string to assert that the third element is '7'. This function is straightforward, performs a basic operation, and includes an assertion to verify its behavior. It is likely to survive because it is a valid and functional piece of code that could be used in various contexts where such string manipulation is needed. There are no apparent issues or inefficiencies that would necessitate its deletion."
survived,"def test_mixed_test_and_src_patch() -> None:
    diff = (
        ""--- a/src/foo.py\n""
        ""+++ b/src/foo.py\n""
        ""@@\n""
        ""-a\n""
        ""+b\n""
        ""--- a/tests/bar.py\n""
        ""+++ b/tests/bar.py\n""
        ""@@\n""
        ""-x\n""
        ""+y\n""
    )
    assert is_patch_valid(diff)",tests/test_patch_guard.py,,1,1.0467401685178159e-08,"The method `test_mixed_test_and_src_patch` is a unit test function that checks the validity of a patch containing changes to both source and test files. It uses an assertion to verify the behavior of the `is_patch_valid` function. This is a typical pattern in test-driven development and is essential for ensuring code quality and correctness. Therefore, it is likely to be retained as part of the test suite to validate future changes."
survived,"    def _patched_init_subclass(cls, **kwargs: Any) -> None:  # type: ignore[override]
        _orig_init_subclass(**kwargs)
        _ensure_pydantic_methods(cls)
",src/meta_agent/__init__.py,,1,3.3982678079468468e-09,"The method `_patched_init_subclass` is a private method (indicated by the underscore prefix) that overrides a superclass method to add additional functionality. It calls `_orig_init_subclass` to maintain the original behavior and then calls `_ensure_pydantic_methods` to add specific functionality related to Pydantic. This suggests that the method is part of a customization or extension of a class's behavior, likely in a library or framework context. Such methods are typically retained as they provide necessary custom behavior that is not available in the base implementation. Therefore, it is likely to survive."
survived,"    async def _optimise_async(self, sequence: str) -> Dict[str, Any]:
        """"""Minimal GC-content optimisation when heavy libs are absent.""""""
        gc_orig = sequence.count(""G"") + sequence.count(""C"")
        gc_new_seq = sequence.replace(""A"", ""G"")
        gc_new = gc_new_seq.count(""G"") + gc_new_seq.count(""C"")
        delta = (gc_new - gc_orig) / len(sequence)
        return {
            ""optimised_sequence"": gc_new_seq,
            ""delta_stability"": round(delta, 4),
        }
",alpha_factory_v1/backend/agents/biotech_agent.py,BiotechAgent,1,3.3982678079468468e-09,"The method '_optimise_async' is a useful utility function for optimizing the GC-content of a DNA sequence. It is implemented as an asynchronous function, which can be beneficial in scenarios where non-blocking operations are needed, such as in web servers or applications that handle multiple tasks concurrently. The function calculates the change in GC-content after replacing 'A' with 'G', which could be a relevant operation in bioinformatics for sequence stability analysis. The method is self-contained, has a clear purpose, and returns a dictionary with meaningful results. There is no indication that this method is obsolete or redundant, and it serves a specific purpose that could be valuable in its context."
survived,"    def optimise(self, sequence: str) -> Dict[str, Any]:  # noqa: D401
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(self._optimise_async(sequence))
",alpha_factory_v1/backend/agents/biotech_agent.py,BiotechAgent,1,2.0611536181902033e-09,"The method 'optimise' is a synchronous wrapper around an asynchronous function '_optimise_async'. This pattern is common in codebases that need to support both synchronous and asynchronous execution contexts. The method is likely to survive because it provides a necessary bridge for users who are not using async/await syntax, allowing them to still benefit from asynchronous operations. Additionally, the use of 'asyncio.get_event_loop()' and 'run_until_complete' is a standard way to execute asynchronous code in a synchronous manner, indicating that the method is well-implemented for its purpose."
survived,"    def test_momentum(self):
        prices = [1, 2, 3, 4, 5]
        self.assertAlmostEqual(am.momentum(prices, lookback=4), 4.0)
        self.assertEqual(am.momentum(prices, lookback=10), 0.0)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest,1,1.725782769012759e-08,"The method `test_momentum` is a unit test for the `momentum` function, which is a common practice in software development to ensure that functions work as expected. Unit tests are generally considered good practice and are unlikely to be deleted unless the functionality they test is removed or significantly changed. Since the test is straightforward and tests a basic functionality of the `momentum` function, it is likely to be retained to ensure the function's correctness."
survived,"    def test_ema(self):
        prices = [1] * 5 + [10]
        self.assertGreater(am.ema(prices, span=3), 1)
",alpha_factory_v1/tests/test_alpha_model.py,AlphaModelTest,1,3.850741907939403e-09,"The method `test_ema` is a unit test for the `ema` function, which calculates the exponential moving average of a list of prices. The test checks if the EMA of a list of prices, which starts with five 1s followed by a 10, is greater than 1 when the span is 3. This is a valid test case to ensure that the EMA function is working correctly, especially in handling sudden changes in price. Since it serves a clear purpose in validating the functionality of the `ema` method, it is likely to be retained in the codebase."
survived,"    async def __aenter__(self) -> ""SimulatedMarketData"":
        return self
",alpha_factory_v1/backend/market_data.py,SimulatedMarketData,1,5.60279640614594e-09,"The method is an asynchronous context manager entry method, which is a standard part of implementing asynchronous context managers in Python. It is necessary for the proper functioning of the context manager protocol in asynchronous code. Given the increasing use of asynchronous programming in Python, this method is likely to be retained as it is essential for the correct operation of the context manager."
survived,"    async def close(self) -> None:  # pragma: no cover - interface default
        """"""Gracefully close underlying resources.""""""
        await self.__aexit__(None, None, None)
",alpha_factory_v1/backend/market_data.py,BaseMarketData,1,2.5109990926928157e-08,"The method 'close' is an asynchronous method designed to gracefully close underlying resources. It is marked with a pragma to exclude it from coverage analysis, indicating that it is part of an interface or a default implementation that might be overridden. Such methods are typically essential for resource management, especially in asynchronous programming, where proper cleanup is crucial to prevent resource leaks. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in the lifecycle management of resources."
survived,"    async def __aenter__(self) -> ""PolygonMarketData"":
        await self._client()
        return self
",alpha_factory_v1/backend/market_data.py,PolygonMarketData,1,4.6911638017642294e-08,"The method is an asynchronous context manager entry method, which is a common pattern in Python for managing resources that need to be set up and torn down. The method is likely part of a class that interacts with an external resource, such as a network client, and ensures that the client is properly initialized before use. This pattern is widely used and considered good practice for managing asynchronous resources, so it is unlikely to be deleted unless the entire class or its functionality is deprecated."
survived,"    def close(self) -> None:
        """"""Close any open database connections.""""""
        if self._driver:
            try:
                self._driver.close()
            except Exception as exc:  # pragma: no cover - defensive
                _log.warning(""Neo4j driver close failed (%s)"", exc)
            finally:
                self._driver = None
",alpha_factory_v1/backend/memory_graph.py,GraphMemory,1,5.60279640614594e-09,"The method 'close' is essential for managing resources, specifically for closing database connections. It includes error handling to ensure that any exceptions during the closing process are logged, which is a good practice for maintaining robust applications. The method sets the driver to None after attempting to close it, which helps in preventing further operations on a closed connection. This method is likely to be retained as it is crucial for resource management and application stability."
survived,"    async def run_cycle(self):  # noqa: D401
        self.ran = True
",alpha_factory_v1/tests/test_planner_agent.py,DummyAgent,1,3.3982678079468468e-09,"The method 'run_cycle' is an asynchronous function that sets an attribute 'ran' to True. Without additional context, it's difficult to determine its full utility, but the method itself is simple and functional. It likely serves a purpose in the broader context of the class it belongs to, such as marking a cycle as completed or triggering subsequent actions. Therefore, unless the class or its usage changes significantly, this method is likely to survive."
survived,"    def to_json(self) -> str:
        return json.dumps(asdict(self), separators=("","", "":""))
",alpha_factory_v1/backend/portfolio.py,Fill,1,2.0611536181902033e-09,"The method 'to_json' is a utility function that converts an object's attributes to a JSON string. This is a common and useful functionality in many applications, especially those that involve data serialization and API communication. The method is concise, uses standard library functions, and follows a clear purpose. There is no indication that this method is redundant or obsolete, so it is likely to be retained."
survived,"    def reset(self):
        self.agent = (0,0)
        return self._obs()
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld,1,6.348800075736417e-09,"The method 'reset' is a common and essential part of many classes, especially in contexts like simulations, games, or environments where the state needs to be reinitialized. The method sets the 'agent' attribute to a default starting position and returns an observation, which is likely a necessary step in the workflow of the class. This functionality is fundamental for resetting the state, making it unlikely to be removed unless the entire class is being deprecated or significantly refactored."
survived,"    def _obs(self):
        vec = np.zeros(self.size*self.size, dtype=np.float32)
        vec[self.agent[0]*self.size+self.agent[1]] = 1.0
        return vec
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,MiniWorld,1,8.152020648014727e-09,"The method '_obs' is a utility function that creates a one-hot encoded vector representing the agent's position in a grid. This is a common operation in environments where the state needs to be represented in a format suitable for machine learning models, such as reinforcement learning. The method is simple, efficient, and serves a clear purpose in transforming the agent's position into a numerical format. Given its utility and the fact that it is a private method (indicated by the underscore), it is unlikely to be deleted unless the entire approach to state representation changes."
survived,"    def _on(self, msg: dict):
        try:
            self.handle(msg)
        except Exception as exc:
            LOG.exception(""[%s] crash: %s"", self.name, exc)
",alpha_factory_v1/demos/alpha_asi_world_model/alpha_asi_world_model_demo.py,Agent,1,1.725782769012759e-08,"The method '_on' is a private method (indicated by the underscore) that is designed to handle incoming messages by calling the 'handle' method. It includes exception handling to log any exceptions that occur during the handling process. This is a common pattern in software development to ensure robustness and maintainability of the code. The presence of logging for exceptions suggests that the method is intended to be used in a production environment where understanding failures is important. Therefore, it is likely to be retained in the codebase."
survived,"def _cfg_from_env() -> dict[str, Any]:
    mapping: dict[str, str] = {
        ""SUCCESS_THRESHOLD"": ""success_thresh"",
        ""MAX_SIM_MINUTES"": ""max_minutes"",
        ""MICRO_CURRICULUM"": ""micro_curr"",
        ""AGIALPHA_SUPPLY"": ""max_supply"",
    }
    cfg: dict[str, Any] = {}
    for k, v in CFG_DEFAULTS.items():
        key = mapping.get(k, k.lower())
        val = os.getenv(f""OMNI_{k}"", v)
        if k.endswith(""PATH""):
            cfg[key] = Path(val)
        else:
            cfg[key] = type(CFG_DEFAULTS[k])(val)
    return cfg
",alpha_factory_v1/demos/omni_factory_demo/omni_factory_demo.py,,1,5.60279640614594e-09,"The method `_cfg_from_env` is a utility function that reads configuration values from environment variables and maps them to a dictionary with specific keys. This is a common pattern in software development for managing configuration settings, especially in environments where configurations need to be flexible and easily changeable without modifying the code. The method is well-structured, uses type hints, and provides a clear mapping from environment variables to configuration keys. Such methods are typically retained as they provide essential functionality for configuration management."
survived,"    def test_parse_defaults(self):
        args = self._parse([])
        self.assertEqual(args.port, 8000)
        self.assertIsNone(args.agents)
        self.assertIsNone(args.metrics_port)
        self.assertIsNone(args.a2a_port)
        self.assertIsNone(args.cycle)
        self.assertEqual(args.loglevel, ""INFO"")
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest,1,8.152020648014727e-09,"The method `test_parse_defaults` is a unit test that checks the default values of parsed arguments. Unit tests are crucial for ensuring that code behaves as expected, especially when dealing with default configurations. This method is likely part of a test suite that verifies the functionality of a command-line argument parser or a configuration loader. Since testing default values is a fundamental aspect of software testing, this method is important for maintaining code quality and is unlikely to be deleted."
survived,"    def test_invalid_port(self):
        with self.assertRaises(SystemExit):
            self._parse([""--port"", ""-1""])
",alpha_factory_v1/tests/test_edge_runner.py,EdgeRunnerParseTest,1,2.4616969512093895e-10,The method `test_invalid_port` is a unit test designed to check if the system correctly raises a `SystemExit` exception when an invalid port number is provided. This is a valid and useful test case for ensuring robustness and error handling in the system. It is likely to be retained as part of the test suite to prevent regressions and ensure that invalid inputs are handled gracefully.
survived,"def on_join():
    domain = domain_var.get().strip()
    user = user_var.get().strip()
    ou = ou_var.get().strip()
    if not domain:
        messagebox.showerror(""Error"", ""Domain is required"")
        return
    if not user:
        messagebox.showerror(""Error"", ""Admin user is required"")
        return
    output, code = join_domain(domain, user, ou)
    if code == 0:
        messagebox.showinfo(""Success"", f""Successfully joined {domain}"")
    else:
        messagebox.showerror(""Join Failed"", output or ""Unknown error"")
",adconnection_gui.py,,1,1.6918979223288786e-10,"The method 'on_join' is likely to survive because it performs a critical function of joining a domain, which is a common requirement in network management and system administration. The method includes input validation, error handling, and user feedback, which are essential for robust software. Additionally, it uses a function 'join_domain' to perform the actual domain joining, indicating modular design. These factors suggest that the method is well-structured and serves a necessary purpose, making it unlikely to be deleted."
survived,"    def root(self):
        return {""ok"": True}
",tests/test_core/test_decorators/test_guard.py,GuardController,1,7.194132978569833e-09,"The method 'root' is a simple function that returns a dictionary with a key-value pair. It is likely part of a web application or API where such a response is common for a root endpoint, often used to check if the service is running correctly. This is a basic and useful function for health checks or initial API responses, and there is no indication that it is redundant or unnecessary. Therefore, it is likely to be retained in the codebase."
survived,"def list_and_download(username: str, amount: int = 10):
    """"""Download recent posts from the specified account.""""""
    cl = login_with_persistence()
    user_id = cl.user_id_from_username(username)
    for media in cl.user_medias(user_id, amount=amount):
        if media.media_type == 1:
            cl.photo_download(media.pk)
        elif media.media_type == 2:
            cl.video_download(media.pk)
        elif media.media_type == 8:
            cl.album_download(media.pk)
",examples/session_login.py,,1,4.599055376537186e-10,"The method 'list_and_download' is a utility function that automates the process of downloading recent posts from a specified user's account. It uses a client object 'cl' to interact with a service, likely a social media platform, to fetch and download media based on type. This functionality is useful for users who want to archive or analyze posts from specific accounts. Given its practical application and the fact that it doesn't contain any deprecated or harmful practices, it is likely to be retained in the codebase."
survived,"def test_error_propagation(monkeypatch, caplog):
    def fail_secho(*args, **kwargs):
        raise OSError(""boom"")

    # Force CLI output to fail so CLIOutputError is raised
    monkeypatch.setattr(click, ""secho"", fail_secho)
    cli = CLIOutput()

    with pytest.raises(CLIOutputError) as exc:
        cli.info(""hi"")

    # Restore working output for error handling path
    monkeypatch.setattr(click, ""secho"", lambda *a, **k: None)
    handler = ErrorHandler(cli_output=cli, log=logging.getLogger(""test""))
    with caplog.at_level(logging.ERROR):
        handler.handle(exc.value)
    assert ""failed to write output"" in caplog.text

    # Diagram generation failure should propagate through ErrorHandler
    generator = DiagramGenerator()
    with caplog.at_level(logging.ERROR):
        try:
            generator.generate(None)  # type: ignore[arg-type]
        except DiagramGenerationError as dg_err:
            handler.handle(dg_err)
    assert ""spec must be a mapping"" in caplog.text

    feedback = UserFeedback(cli_output=cli)
    suggestion = feedback.error_suggestion(""Failed to load file"")
    assert suggestion and ""file path exists"" in suggestion",tests/integration/test_ux_interactions.py,,1,2.646573631904765e-09,"The method 'test_error_propagation' is a test function that uses the pytest framework to verify error handling in a CLI application. It uses monkeypatching to simulate failures and checks if the appropriate errors are logged and handled correctly. Test functions like this are crucial for ensuring the robustness of error handling mechanisms in software. Since it is a test function, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    async def readiness() -> str:
        """"""Check orchestrator background task.""""""

        task = getattr(app_f.state, ""task"", None)
        if task and not task.done():
            return ""ok""
        # If the orchestrator failed to start, return OK for local tests.
        return ""ok""
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/api_server.py,,1,1.0467401685178159e-08,"The method 'readiness' is a simple asynchronous function that checks the status of a background task in an orchestrator. It returns 'ok' regardless of the task's state, which might be useful for local testing or ensuring that the service is always considered ready. This method is likely to survive because it serves a specific purpose in the context of checking the readiness of a service, and it is common to have such health check endpoints in applications."
survived,"    def getExpressionIds(self):
        exprs = list(map(str, self.importer.flux_ids))
        exprs += [str(k) for k in self.importer.symbols.get(SymbolId.EXPRESSION, {}).keys()]
        return exprs
",tests/testSBMLSuiteJax.py,DummyModel,1,3.3982678079468468e-09,"The method 'getExpressionIds' is a utility function that aggregates and returns a list of expression IDs from two sources: 'flux_ids' and 'symbols'. It is likely to be used in various parts of the codebase where these IDs are needed for further processing or analysis. The method is straightforward, performs a clear task, and does not have any obvious issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def result_path_jax() -> Path:
    return Path(__file__).parent / ""amici-semantic-results-jax""
",tests/testSBMLSuiteJax.py,,1,2.646573631904765e-09,"The method 'result_path_jax' is a simple utility function that constructs and returns a file path using the current file's directory. Such utility functions are common in codebases for managing file paths and are unlikely to be deleted unless the project undergoes significant restructuring or the file path management is refactored. Therefore, it is more likely to survive."
survived,"    def getParameterIds(self):
        return list(map(str, self.jax_model.parameter_ids))
",tests/testSBMLSuiteJax.py,DummyModel,1,1.3440409770490404e-08,"The method `getParameterIds` is a simple utility function that converts the `parameter_ids` of a `jax_model` to strings and returns them as a list. This kind of method is often useful for ensuring that IDs are in a consistent format, especially when they need to be used in contexts that require string inputs, such as logging, serialization, or interfacing with other systems. The method is straightforward, has a clear purpose, and is likely to be used in various parts of a codebase where `jax_model` parameter IDs need to be handled as strings. Therefore, it is likely to be retained in the codebase."
survived,"    def __getitem__(self, key):
        return getattr(self, key)
",tests/machine/x/python/q1.py,Auto1,1,9.931195248674785e-08,"The method `__getitem__` is a special method in Python used to define behavior for accessing elements using the square bracket notation, typically in collections like lists or dictionaries. In this code, it is implemented to return an attribute of the object using `getattr`. This is a valid use case if the object is designed to allow attribute access via indexing, which can be useful in certain dynamic or flexible data structures. However, this implementation assumes that the key provided is always a valid attribute name, which might not always be the case. Despite this, the method itself is functional and serves a purpose, so it is likely to be retained unless there are specific design changes or security concerns. Therefore, the method will likely survive."
survived,"def test_moe_linear_gmm_matches_ragged_dot_general():
    B, In, Out, E = hax.make_axes(B=3, In=4, Out=5, E=2)
    moe = MoELinear.init(E, In, Out, key=jrandom.PRNGKey(0), use_gmm=True)

    x = hax.random.normal(jrandom.PRNGKey(1), (B, In))
    group_sizes = hax.named(jnp.array([2, 1], dtype=jnp.int32), (E,))

    with jax.sharding.Mesh(jax.devices(), (""data"",)):
        actual = moe(x, group_sizes)

    expected = _expected_moe_linear_output(moe, x, group_sizes)

    assert actual.axes == expected.axes
    assert jnp.allclose(actual.array, expected.array, rtol=1e-5, atol=1e-5)",tests/test_moe_linear.py,,1,1.725782769012759e-08,"The method is a test function for verifying the behavior of a mixture of experts (MoE) linear model using a Gaussian Mixture Model (GMM). Test functions are generally crucial for ensuring code correctness and reliability, especially in machine learning and scientific computing contexts. This function checks if the actual output of the model matches the expected output, which is a fundamental part of maintaining code quality. Therefore, it is likely to be retained."
survived,"def main() -> int:
    missing = []
    for pkg in REQUIRED:
        if importlib.util.find_spec(pkg) is None:
            missing.append(pkg)
    if missing:
        print('Missing packages:', ', '.join(missing))
        print('Install with: pip install -r requirements.txt')
        return 1
    print('Environment OK')
    return 0
",check_env.py,,1,4.363462233903899e-09,"The method is a simple utility function that checks for the presence of required packages and provides feedback to the user. It is useful for ensuring that the necessary environment is set up before running a program. This kind of functionality is often needed in scripts that depend on external libraries, making it a practical and reusable piece of code. Therefore, it is likely to be retained in the codebase."
survived,"    async def _run() -> None:
        await mgr.start()
        await mgr.stop()
",tests/test_agent_manager_consumer.py,,1,2.2159489282323004e-08,"The method _run is an asynchronous function that calls start and stop methods on an object named mgr. Without additional context, it's difficult to determine the specific purpose or utility of this method. However, the method itself is simple and likely serves a specific purpose in managing the lifecycle of the mgr object. If mgr is a critical component of the application, this method could be essential for ensuring proper startup and shutdown sequences. Therefore, unless there is a significant refactor or change in how mgr is managed, this method is likely to survive."
survived,"        def publish(self, *_a: object, **_kw: object) -> None:
            pass
",tests/test_agent_manager_consumer.py,DummyBus,0,0.9999938558278723,"The method 'publish' is defined but not implemented, as it only contains a 'pass' statement. This suggests that it might be a placeholder for future functionality. However, without any additional context or usage within the codebase, it's difficult to determine its necessity. If the method is not called or referenced anywhere else in the code, it is likely to be deleted in future refactoring to clean up unused code. On the other hand, if it is part of an interface or abstract class, it might survive as a required method signature. Without further context, the prediction leans towards deletion due to its current lack of implementation and apparent purpose."
survived,"    def tearDown(self) -> None:
        agents.AGENT_REGISTRY.clear()
        agents.AGENT_REGISTRY.update(self._reg_backup)
        discovery.FAILED_AGENTS.clear()
        discovery.FAILED_AGENTS.update(self._fail_backup)
",tests/test_failed_agent_discovery.py,TestFailedAgentDiscovery,1,2.1024340680345882e-07,"The method `tearDown` is a common method used in testing frameworks like `unittest` in Python. It is typically used to clean up or reset the state after each test case is run. The code provided is clearing and restoring some kind of registry and a list of failed agents, which suggests it is part of a test suite ensuring that each test runs with a clean state. This is a standard practice in testing to avoid side effects between tests. Therefore, it is likely to be retained as it serves a crucial role in maintaining test integrity."
survived,"            async def stop(self) -> None:
                events.append(""stop"")
",tests/test_message_bus.py,TestMessageBus.Prod,1,6.825604231969389e-08,"The method 'stop' is an asynchronous function that appends the string ""stop"" to a list called 'events'. Without additional context, such as how this method is used or the purpose of the 'events' list, it's difficult to determine its utility. However, the method is simple, non-blocking, and could be part of a larger event-handling or logging system. Given its simplicity and potential utility in tracking or logging events, it is likely to be retained unless the entire event system is refactored or removed."
survived,"            async def send_and_wait(self, topic: str, data: bytes) -> None:
                events.append((topic, data))
",tests/test_message_bus.py,TestMessageBus.Prod,1,2.7894680920908113e-10,"The method 'send_and_wait' is an asynchronous function that appends a tuple of 'topic' and 'data' to a list called 'events'. This method is likely part of a larger system where events are being logged or processed asynchronously. The method is simple, performs a clear task, and does not contain any obvious issues or redundancies. Therefore, it is likely to be useful in its context and will survive."
survived,"async def _update_listener(hass: HomeAssistant, entry: ConfigEntry) -> None:
    """"""Handle options update.""""""
    await hass.config_entries.async_reload(entry.entry_id)",custom_components/gree/__init__.py,,1,2.3355930333443423e-09,"The method `_update_listener` is an asynchronous function that handles the update of configuration options by reloading the configuration entry in Home Assistant. This is a common pattern in Home Assistant integrations to ensure that changes in configuration are applied without requiring a full restart of the system. The method is concise, uses appropriate asynchronous operations, and follows the expected behavior for handling configuration updates. There is no indication that this method is deprecated or unnecessary, and it serves a clear purpose in the context of Home Assistant's architecture. Therefore, it is likely to be retained."
survived,"def test_root_disclaimer_plain(client: TestClient) -> None:
    """"""Plain text disclaimer is returned by default.""""""

    r = client.get(""/"")
    assert r.status_code == 200
    assert r.text.strip() == DISCLAIMER
",tests/test_insight_api_server.py,,1,1.637377179507321e-07,"The method `test_root_disclaimer_plain` is a test function that checks if a plain text disclaimer is returned by default when accessing the root endpoint. This is a typical test case in web applications to ensure that the correct content is served at a specific endpoint. Test functions like this are essential for maintaining the integrity of the application and ensuring that changes do not break existing functionality. Therefore, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered."
survived,"    def test_selects_long_bonds(self) -> None:
        signals = {
            ""yield_curve"": ""spread -0.5, consider LONG BONDS soon"",
            ""supply_chain"": ""all clear"",
        }
        self.assertEqual(alpha_report.best_alpha(signals), signals[""yield_curve""])
",tests/test_alpha_report.py,TestBestAlpha,1,1.955568070542584e-08,"The method `test_selects_long_bonds` is a unit test that checks if the `best_alpha` function from the `alpha_report` module correctly identifies the 'yield_curve' signal as the best alpha when given a specific set of signals. This is a valid and useful test case for ensuring the functionality of the `best_alpha` method, especially in financial or economic contexts where signal interpretation is crucial. Therefore, it is likely to be retained as part of the test suite."
survived,"def lookup_musicbrainz(artist: str, session: requests.Session) -> str | None:
    """"""Query MusicBrainz directly for the artist MBID.""""""

    url = ""https://musicbrainz.org/ws/2/artist/""
    params = {""query"": f'artist:""{artist}""', ""fmt"": ""json""}
    headers = {
        ""User-Agent"": ""ArrTools (https://github.com/sirk123au/ArrTools)"",
    }

    try:
        rsp = session.get(url, headers=headers, params=params, timeout=10)
    except requests.RequestException as exc:
        log.error(f""Error searching MusicBrainz for {artist}: {exc}"")
        return None

    if rsp.status_code != 200:
        log.error(
            f""MusicBrainz search failed for {artist}. Status: {rsp.status_code}""
        )
        return None

    data = rsp.json()
    artists = data.get(""artists"")
    if not artists:
        log.error(f""Sorry. We couldn't find {artist} on MusicBrainz"")
        with open(""not_found.txt"", ""a+"", encoding=""utf-8"") as fo:
            fo.write(f""{artist}\n"")
        return None

    return artists[0].get(""id"")
",lidarr_add_from_list.py,,1,4.599055376537186e-10,"The method `lookup_musicbrainz` is a well-defined function that queries the MusicBrainz API to retrieve the MusicBrainz Identifier (MBID) for a given artist. It handles exceptions, checks for successful HTTP responses, and logs errors appropriately. Additionally, it writes to a file when an artist is not found, which can be useful for debugging or tracking purposes. These features make it a useful utility function for applications that need to interact with the MusicBrainz database. Therefore, it is likely to be retained in the codebase."
survived,"def _parse_duration(value: str) -> timedelta:
    """"""Parse duration in the format '14d' or '24h'.""""""
    if value.endswith(""d""):
        return timedelta(days=int(value[:-1]))
    if value.endswith(""h""):
        return timedelta(hours=int(value[:-1]))
    raise ValueError(""Invalid duration format. Use Nd or Nh"")
",scripts/rotate_lmdb.py,,1,1.8189616842444243e-09,"The method _parse_duration is a utility function that parses a string representing a duration into a timedelta object. It supports two formats: days ('d') and hours ('h'). This is a common requirement in many applications that deal with time intervals, such as scheduling, logging, or configuration settings. The method is simple, efficient, and provides clear error handling for invalid formats. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"def _should_delete(record: dict[str, Any], threshold: datetime) -> bool:
    """"""Check if the record is older than the threshold.""""""
    timestamp = record.get(""updated_at"") or record.get(""created_at"")
    if not timestamp:
        return False
    try:
        ts = datetime.fromisoformat(timestamp)
    except ValueError:
        return False
    return ts < threshold
",scripts/rotate_lmdb.py,,1,3.850741907939403e-09,"The method '_should_delete' is a utility function that checks if a record is older than a given threshold. It is a straightforward and useful function for managing data retention based on timestamps. The function handles missing or malformed timestamps gracefully, returning False if the timestamp is not present or cannot be parsed. This makes it robust and reliable for its intended purpose. Such utility functions are commonly used in data processing and management tasks, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"def handle_anthropic_parallel_tools(
    response_model: type[Iterable[T]], new_kwargs: dict[str, Any]
) -> tuple[AnthropicParallelBase, dict[str, Any]]:
    if new_kwargs.get(""stream"", False):
        from instructor.exceptions import ConfigurationError

        raise ConfigurationError(
            ""stream=True is not supported when using ANTHROPIC_PARALLEL_TOOLS mode""
        )

    model_types = list(get_types_array(response_model))
    new_kwargs[""tools""] = [m.anthropic_schema for m in model_types]
    new_kwargs[""tool_choice""] = {""type"": ""auto""}

    system_messages = extract_system_messages(new_kwargs.get(""messages"", []))

    if system_messages:
        new_kwargs[""system""] = combine_system_messages(
            new_kwargs.get(""system""), system_messages
        )

    new_kwargs[""messages""] = [
        m for m in new_kwargs.get(""messages"", []) if m[""role""] != ""system""
    ]

    return AnthropicParallelModel(typehint=response_model), new_kwargs
",instructor/process_response.py,,1,3.850741907939403e-09,"The method 'handle_anthropic_parallel_tools' is well-structured and seems to serve a specific purpose in handling configurations for a parallel tool system. It includes error handling, data processing, and configuration adjustments, which are all essential for maintaining robust software. The method is likely part of a larger system that requires these functionalities, and there is no indication of it being deprecated or replaced. Therefore, it is likely to survive."
survived,"def clean_text(text: str) -> str:
    """"""Return *text* with markdown emphasis and HTML tags stripped.""""""
    # Unescape HTML entities first
    text = html.unescape(text)
    # Drop HTML tags
    text = re.sub(r""<[^>]+>"", """", text)
    # Remove emphasis markers such as *, _, ** and backticks
    text = re.sub(r""\*\*|__|[*_`]"", """", text)
    return text.strip()
",scripts/generate_gallery_html.py,,1,8.592166611791576e-10,"The method 'clean_text' is a utility function that performs a common task of cleaning text by removing markdown emphasis and HTML tags. This is a useful function in many applications such as data preprocessing for text analysis, web scraping, or preparing text for display in a plain text format. The function is well-defined, uses standard libraries, and addresses a common need, making it likely to be retained in the codebase."
survived,"def test_simulate_runs() -> None:
    runner = CliRunner()
    with patch.object(cli, ""asyncio"") as aio:
        aio.run.return_value = None
        with patch.object(cli.orchestrator, ""Orchestrator""):
            res = runner.invoke(cli.main, [""simulate"", ""--horizon"", ""1"", ""--offline"", ""--pop-size"", ""1"", ""--generations"", ""1""])
        assert res.exit_code == 0
        aio.run.assert_called_once()",tests/test_cli.py,,1,1.522997951276035e-08,"The method `test_simulate_runs` is a unit test function designed to test a command-line interface (CLI) command using the `CliRunner` from the `click` library. It uses the `unittest.mock.patch` to mock certain parts of the code, ensuring that the test is isolated from external dependencies. The test checks that the CLI command executes without errors and that the `aio.run` method is called exactly once. This is a typical pattern for testing CLI applications and asynchronous code, and there is no indication that this method is obsolete or redundant. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_gibbs_free_energy() -> None:
    logp = [math.log(0.7), math.log(0.3)]
    value = gibbs.free_energy(logp, temperature=1.0, task_cost=1.0)
    entropy = -sum(p * math.log(p) for p in [0.7, 0.3])
    assert value == pytest.approx(1.0 - entropy)",tests/test_forecast.py,,1,3.850741907939403e-09,"The method `test_gibbs_free_energy` is a unit test function that checks the correctness of the `gibbs.free_energy` function. It calculates the expected value using the entropy formula and asserts that the output of `gibbs.free_energy` matches this expected value. This is a typical pattern for unit tests, which are crucial for ensuring code reliability and correctness. Since the function is a test and not part of the main application logic, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, the method will likely survive."
survived,"def test_agent_registration_and_heartbeat() -> None:
    meta = agents.AgentMetadata(
        name=DummyHB.NAME,
        cls=DummyHB,
        version=""0.1"",
        capabilities=DummyHB.CAPABILITIES,
        compliance_tags=[],
    )
    q: Queue = Queue()
    with patch.object(agents, ""_HEALTH_Q"", q):
        agents.register_agent(meta)
        agent = agents.get_agent(""dummy_hb"")
        asyncio.run(agent.step())
        name, _, ok = q.get(timeout=1)
        assert name == ""dummy_hb""
        assert ok
    agents.AGENT_REGISTRY.pop(""dummy_hb"", None)",tests/test_agents.py,,1,1.1861120010657661e-08,"The method `test_agent_registration_and_heartbeat` is a test function that verifies the registration and heartbeat functionality of an agent. It uses a mock queue to intercept health check messages and asserts that the agent is correctly registered and sends a heartbeat. Test functions are generally crucial for ensuring code reliability and are not typically deleted unless they are redundant or replaced by more comprehensive tests. Since this function seems to serve a specific purpose in testing agent registration and heartbeat, it is likely to be retained."
survived,"    def readlines(self, *args):
        return self.inputs.split(""\n"")
",scripts/utils/lcb_runner.py,MockStdinWithBuffer,1,9.237449576640118e-09,"The method 'readlines' is a custom implementation that splits a string 'inputs' by newline characters and returns a list of lines. This is a common utility function that can be useful in various contexts where input data is stored as a single string but needs to be processed line by line. The method is simple, clear, and serves a specific purpose, making it likely to be retained in the codebase. Additionally, it does not have any apparent issues or redundancies that would necessitate its removal."
survived,"def convert_line_to_decimals(line: str) -> tuple[bool, list[Decimal]]:
    try:
        decimal_line = [Decimal(elem) for elem in line.split()]
    except:
        return False, []
    return True, decimal_line
",scripts/utils/lcb_runner.py,,1,1.3440409770490404e-08,"The method 'convert_line_to_decimals' is likely to survive because it performs a useful and specific function: converting a string of numbers into a list of Decimal objects, which is important for precise arithmetic operations. The method also includes error handling, returning a tuple indicating success or failure, which is a good practice. However, it could be improved by specifying the exception type in the except block to avoid catching unintended exceptions."
survived,"def grade_call_based(
    code: str, all_inputs: list, all_outputs: list, fn_name: str, timeout: int
):
    # call-based clean up logic
    # need to wrap in try-catch logic after to catch the correct errors, but for now this is fine.
    code = import_string + ""\n\n"" + code
    compiled_sol = compile_code(code, timeout)

    if compiled_sol is None:
        return

    method = get_function(compiled_sol, fn_name)

    if method is None:
        return

    all_inputs = [
        [json.loads(line) for line in inputs.split(""\n"")] for inputs in all_inputs
    ]

    all_outputs = [json.loads(output) for output in all_outputs]

    total_execution = 0
    all_results = []
    for idx, (gt_inp, gt_out) in enumerate(zip(all_inputs, all_outputs)):
        signal.alarm(timeout)
        faulthandler.enable()
        try:
            # can lock here so time is useful
            start = time.time()
            prediction = method(*gt_inp)
            total_execution += time.time() - start
            signal.alarm(0)

            # don't penalize model if it produces tuples instead of lists
            # ground truth sequences are not tuples
            if isinstance(prediction, tuple):
                prediction = list(prediction)

            tmp_result = prediction == gt_out

            # handle floating point comparisons

            all_results.append(tmp_result)

            if not tmp_result:
                return all_results, {
                    ""output"": truncatefn(prediction),
                    ""inputs"": truncatefn(gt_inp),
                    ""expected"": truncatefn(gt_out),
                    ""error_code"": -2,
                    ""error_message"": ""Wrong Answer"",
                }
        except Exception as e:
            signal.alarm(0)
            if ""timeoutexception"" in repr(e).lower():
                all_results.append(-3)
                return all_results, {
                    ""error"": repr(e),
                    ""error_code"": -3,
                    ""error_message"": ""Time Limit Exceeded"",
                    ""inputs"": truncatefn(gt_inp),
                    ""expected"": truncatefn(gt_out),
                }
            else:
                all_results.append(-4)
                return all_results, {
                    ""error"": repr(e),
                    ""error_code"": -4,
                    ""error_message"": ""Runtime Error"",
                    ""inputs"": truncatefn(gt_inp),
                    ""expected"": truncatefn(gt_out),
                }

        finally:
            signal.alarm(0)
            faulthandler.disable()

    return all_results, {""execution time"": total_execution}
",scripts/utils/lcb_runner.py,,1,2.646573631904765e-09,"The method 'grade_call_based' is a utility function designed to evaluate the correctness of a function by executing it with given inputs and comparing the outputs. It includes error handling for timeouts and runtime errors, which are common issues in code execution environments. The method is well-structured, with clear logic for handling different scenarios, such as incorrect outputs and exceptions. This functionality is essential for automated testing and grading systems, making it a valuable component in such contexts. Therefore, it is likely to be retained in the codebase."
survived,"def test_archive_insert_and_load(tmp_path) -> None:
    db = tmp_path / ""a.db""
    arch = Archive(db)
    arch.add({""name"": ""a""}, 0.1)
    arch.add({""name"": ""b""}, 0.2)
    rows = arch.all()
    assert len(rows) == 2
    assert rows[0].meta[""name""] == ""a""
",tests/test_archive.py,,1,4.0586521248284276e-10,"The method 'test_archive_insert_and_load' is a unit test function that verifies the functionality of the 'Archive' class. It checks if items can be added to the archive and then retrieved correctly. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to maintain software quality. Therefore, this method is likely to be Survived."
survived,"    def all(self) -> List[Agent]:
        with sqlite3.connect(self.path) as cx:
            rows = list(cx.execute(""SELECT id, meta, score FROM agents ORDER BY id""))
        return [Agent(id=r[0], meta=json.loads(r[1]), score=float(r[2])) for r in rows]
",src/archive.py,Archive,1,1.4166087846364157e-09,"The method 'all' is a straightforward implementation that retrieves all records from a database table and returns them as a list of 'Agent' objects. It uses a context manager for database connection, which is a good practice for resource management. The method is clear, efficient, and serves a common purpose in applications that interact with databases. There are no apparent issues or inefficiencies that would necessitate its deletion. Therefore, it is likely to be retained."
survived,"def test_sample_bias(tmp_path) -> None:
    db = tmp_path / ""a.db""
    arch = Archive(db)
    arch.add({""name"": ""low""}, 0.0)
    arch.add({""name"": ""high""}, 1.0)
    random.seed(0)
    counts = {""low"": 0, ""high"": 0}
    for _ in range(50):
        chosen = arch.sample(1)[0]
        counts[chosen.meta[""name""]] += 1
    assert counts[""high""] > counts[""low""]",tests/test_archive.py,,1,6.69158608681505e-10,"The method 'test_sample_bias' is a unit test designed to verify the behavior of the 'sample' method in the 'Archive' class. It checks if the sampling mechanism is biased towards entries with higher values. This is a common requirement in testing probabilistic or random sampling functions to ensure they behave as expected. The test is straightforward, uses a temporary path for database creation, and includes assertions to validate the expected outcome. Such tests are crucial for maintaining code reliability and are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def fake_improve(repo, patch, metric, log):
        called.append(repo)
        return 1.0, Path(repo)
",tests/test_scheduler.py,,1,6.144172127844639e-06,"The method 'fake_improve' is likely a mock or placeholder function used for testing purposes. It doesn't perform any real operations related to improving a repository, applying a patch, or evaluating a metric. Instead, it simply appends the 'repo' to a 'called' list and returns a fixed value and a Path object. Such methods are often used in unit tests to simulate behavior without implementing actual logic. Since it serves a specific purpose in testing, it is likely to be retained in the codebase for its utility in test scenarios."
survived,"async def test_scheduler_runs_jobs(tmp_path):
    jobs_file = tmp_path / ""jobs.json""
    jobs = [
        {""repo"": ""r1"", ""patch"": ""p1"", ""tokens"": 5},
        {""repo"": ""r2"", ""patch"": ""p2"", ""tokens"": 5},
    ]
    jobs_file.write_text(json.dumps(jobs))

    called = []

    def fake_improve(repo, patch, metric, log):
        called.append(repo)
        return 1.0, Path(repo)

    with patch.object(scheduler.self_improver, ""improve_repo"", side_effect=fake_improve):
        sch = scheduler.SelfImprovementScheduler(
            [scheduler.Job(**j) for j in jobs], tokens_quota=10, time_quota=2, interval=""0.1 second""
        )
        await sch.serve()

    assert called == [""r1"", ""r2""]
    assert sch.tokens_used == 10
",tests/test_scheduler.py,,1,4.6911638017642294e-08,"The method 'test_scheduler_runs_jobs' is a test function that verifies the functionality of a scheduler. It uses a temporary path to create a jobs file, mocks a method to simulate job improvement, and checks if the scheduler processes the jobs correctly. This is a typical unit test pattern in software development, and such tests are crucial for ensuring code reliability and correctness. Therefore, it is unlikely to be deleted as it serves an important role in maintaining the quality of the codebase."
survived,"def test_str_replace_basic(tmp_path: Path) -> None:
    p = tmp_path / ""f.txt""
    p.write_text(""foo bar foo"")
    n = str_replace(p, ""foo"", ""baz"")
    assert n == 2
    assert p.read_text() == ""baz bar baz""
",tests/test_file_ops.py,,1,1.1253518384332553e-07,"The method `test_str_replace_basic` is a test function that verifies the functionality of a `str_replace` function. It checks if the function correctly replaces occurrences of a substring in a file and returns the correct count of replacements. Test functions are crucial for ensuring code reliability and are typically retained unless the functionality they test is deprecated or removed. Since the test is straightforward and tests a basic functionality, it is likely to be retained as long as the `str_replace` function exists."
survived,"    async def run():
        await evolve(_op, _eval, arch, max_cost=0.1)
",tests/test_evolve.py,,1,1.522997951276035e-08,"The method 'run' is an asynchronous function that calls another function 'evolve' with specific parameters. The method itself is simple and does not contain any complex logic or dependencies that would make it obsolete or unnecessary. Asynchronous functions are commonly used in modern programming to handle operations that may take time, such as I/O operations, without blocking the main thread. Given the increasing use of asynchronous programming in software development, it is likely that this method will survive as it fits well within current programming practices."
survived,"    def __init__(self) -> None:
        self._items: list[Candidate] = []
",src/evolve.py,InMemoryArchive,1,7.194132978569833e-09,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor initializes an empty list to store items of type 'Candidate', which suggests it is part of a larger class structure. Such methods are typically not deleted unless the entire class is being refactored or removed, which is not indicated here. Therefore, it is likely to survive."
survived,"    def setUp(self) -> None:
        self.orig_pub = agents._WHEEL_PUBKEY
        self.orig_sigs = agents._WHEEL_SIGS.copy()
        agents._WHEEL_PUBKEY = PUB_KEY_B64
        sig = SIG_PATH.read_text().strip()
        agents._WHEEL_SIGS = {WHEEL_PATH.name: sig}
",tests/test_verify_wheel.py,VerifyWheelTests,1,1.3709566550544279e-06,"The method `setUp` is a common method used in unit testing frameworks like `unittest` in Python. It is typically used to set up the test environment before each test case is run. The code provided shows that it is setting up some initial state by modifying certain attributes of the `agents` module. This is a standard practice in testing to ensure that each test runs in a controlled environment. Since this is a typical and necessary part of writing tests, it is unlikely to be deleted unless the entire testing framework or approach is changed."
survived,"async def _pygwalker_router(req: Request) -> Response:
    gid = req.path_params[""gid""]
    comm_obj = reflex_comm_map.get(gid, None)
    if comm_obj is None:
        return JSONResponse({""success"": False, ""message"": f""Unknown gid: {gid}""})
    json_data = await req.json()
    result = comm_obj._receive_msg(json_data[""action""], json_data[""data""])
    result = json.dumps(result, cls=DataFrameEncoder)
    return JSONResponse(json.loads(result))
",pygwalker/communications/reflex_comm.py,,1,6.69158608681505e-10,"The method '_pygwalker_router' is an asynchronous function that handles HTTP requests by extracting a 'gid' from the request path parameters, retrieving a communication object from a map, and processing a message using this object. It returns a JSON response based on the processing result. The method is well-structured for its purpose, and there is no indication of it being deprecated or replaced by another method. It seems to be a crucial part of handling specific requests in the application, and there is no evidence suggesting it should be deleted."
survived,"def test_cache_cleanup_on_activate() -> None:
    repo = Path(__file__).resolve().parents[1]
    dist = repo / ""alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/dist""

    server, thread = _start_server(dist)
    host, port = server.server_address
    url = f""http://{host}:{port}""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch()
            context = browser.new_context()
            context.add_init_script(""caches.open('legacy-cache')"")
            page = context.new_page()
            page.goto(url + ""/index.html"")
            page.wait_for_selector(""#controls"")
            page.wait_for_function(""navigator.serviceWorker.controller !== null"")
            names = page.evaluate(""caches.keys()"")
            assert ""legacy-cache"" not in names
            browser.close()
    except PlaywrightError as exc:
        pytest.skip(f""Playwright browser not installed: {exc}"")
    finally:
        server.shutdown()
        thread.join()",tests/test_pwa_offline.py,,1,2.2159489282323004e-08,"The method `test_cache_cleanup_on_activate` is a test function that verifies the behavior of a web application regarding cache management. It uses Playwright to automate a browser and check if a specific cache ('legacy-cache') is not present after certain actions. This kind of test is crucial for ensuring that the application behaves correctly in terms of cache management, which is important for performance and correctness. Since it is a test function, it is unlikely to be deleted unless the feature it tests is removed or the testing framework changes significantly. Therefore, it is more likely to survive."
survived,"    def _read_csv(self, task: Dict, path: str) -> pd.DataFrame:
        csv_str = self.preload_task_data(task, path)
        return pd.read_csv(io.StringIO(csv_str))
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter,1,4.599055376537186e-10,"The method '_read_csv' is a utility function that reads a CSV file from a string and returns a pandas DataFrame. This is a common and useful operation in data processing tasks, especially when dealing with data stored in non-standard formats or locations. The method is likely to be used in various data processing pipelines, making it a valuable part of the codebase. Therefore, it is likely to survive."
survived,"    def _get_tasks(self, project_id: int) -> List[Dict]:
        ls = label_studio_sdk.Client(self.LABEL_STUDIO_HOST, self.LABEL_STUDIO_API_KEY)
        project = ls.get_project(id=project_id)
        return project.get_labeled_tasks()
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter,1,4.363462233903899e-09,"The method '_get_tasks' is a utility function that retrieves labeled tasks from a project using the Label Studio SDK. It is a straightforward method that serves a specific purpose within the context of interacting with the Label Studio API. Such methods are typically retained as they encapsulate a specific functionality that is likely to be reused or needed in the context of the application. Unless there is a significant change in the requirements or the SDK itself, this method is likely to survive."
survived,"    def fit(self, event, data, **kwargs):
        if event not in ('ANNOTATION_CREATED', 'ANNOTATION_UPDATED', 'START_TRAINING'):
            logger.info(f""Skip training: event {event} is not supported"")
            return
        project_id = data['annotation']['project']
        tasks = self._get_tasks(project_id)
        if len(tasks) % self.START_TRAINING_EACH_N_UPDATES != 0 and event != 'START_TRAINING':
            logger.info(
                f'Skip training: {len(tasks)} tasks are not multiple of {self.START_TRAINING_EACH_N_UPDATES}')
            return
        params = self._get_labeling_params()
        label2idx = {l: i for i, l in enumerate(params['labels'])}
        X, y = [], []
        for task in tasks:
            df = self._read_csv(task, task['data'][params['value']])
            if df.empty:
                continue
            annotations = [a for a in task['annotations'] if a.get('result')]
            for ann in annotations:
                for r in ann['result']:
                    if r['from_name'] != params['from_name']:
                        continue
                    start = r['value']['start']
                    end = r['value']['end']
                    label = r['value']['timeserieslabels'][0]
                    mask = (df[params['time_col']] >= start) & (df[params['time_col']] <= end)
                    seg = df.loc[mask, params['channels']].values
                    X.extend(seg)
                    y.extend([label2idx[label]] * len(seg))
        if not X:
            logger.warning('No data collected for training')
            return
        model = self._get_model(blank=True)
        model.fit(np.array(X), np.array(y))
        os.makedirs(self.MODEL_DIR, exist_ok=True)
        model_path = os.path.join(self.MODEL_DIR, 'model.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        global _model
        _model = None
        self._get_model()
",label_studio_ml/examples/timeseries_segmenter/model.py,TimeSeriesSegmenter,1,5.3157849718487075e-08,"The method is well-structured and performs a specific task of training a model based on certain events and conditions. It includes logging for unsupported events and conditions where training is skipped, which is useful for debugging and understanding the flow. The method also handles data preparation, model training, and saving the model efficiently. These are all essential components of a machine learning pipeline, suggesting that the method is likely to be retained for its functionality."
survived,"def is_windsurf_installed(host_system: str) -> bool:
    """"""Check if Windsurf is installed.""""""
    # TODO: Implement actual detection logic
    return False
",skyvern/cli/commands.py,,1,1.1861120010657661e-08,"The method `is_windsurf_installed` is a placeholder function that currently returns a hardcoded value of `False`. It includes a TODO comment indicating that the actual detection logic needs to be implemented. This suggests that the method is intended to be developed further and is part of a larger codebase where checking for the installation of Windsurf is necessary. Since it is likely that this function is part of a planned feature or functionality, it is more probable that it will be developed rather than deleted. Therefore, the method is likely to survive."
survived,"def convert_archetype_features(v1_path, out_dir, doc_slug):
    data = load_json(v1_path)
    features = []
    items = []
    for obj in data:
        slug = obj[""pk""]
        parent = f""{doc_slug}_{slug}""
        sections = parse_feature_sections(obj[""fields""].get(""desc"", """"))
        for name, desc in sections:
            feat_slug = f""{parent}_{slugify(name)}""
            features.append({
                ""model"": ""api_v2.classfeature"",
                ""pk"": feat_slug,
                ""fields"": {
                    ""name"": name,
                    ""desc"": desc,
                    ""document"": doc_slug,
                    ""parent"": parent,
                },
            })
            level = extract_level(desc)
            if level:
                items.append({
                    ""model"": ""api_v2.classfeatureitem"",
                    ""pk"": f""{feat_slug}_{level}"",
                    ""fields"": {""parent"": feat_slug, ""level"": level, ""column_value"": None},
                })
    if features:
        save_json(features, os.path.join(out_dir, ""ClassFeature.json""))
    if items:
        save_json(items, os.path.join(out_dir, ""ClassFeatureItem.json""))
",convert_missing.py,,1,3.850741907939403e-09,"The method 'convert_archetype_features' is likely to survive because it appears to be a well-structured and functional piece of code that performs a specific task: converting data from a JSON file into a different format and saving it. It includes data parsing, transformation, and saving, which are common and necessary operations in data processing applications. Additionally, the method uses helper functions like 'load_json', 'parse_feature_sections', 'slugify', 'extract_level', and 'save_json', indicating modularity and reusability, which are good coding practices. Unless there are changes in requirements or the method becomes obsolete due to architectural changes, it is likely to be retained."
survived,"        def __init__(self) -> None:
            self.instructions: list[Any] = []
",tests/test_ledger.py,DummyTx,1,2.5109990926928157e-08,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial state, so they are unlikely to be deleted unless the entire class is being refactored or removed. Additionally, the use of type hinting with 'list[Any]' suggests that the code is modern and follows good practices, further indicating that it is likely to be retained."
survived,"def summarise_shard(shard_path: str, test_dataset: str, training_dataset: str, attr_key: str) -> dict:
    """"""Return basic overlap statistics for a single attribute shard.""""""

    ids_seen: set[str] = set()
    overlap_ids: set[str] = set()
    with fsspec.open(shard_path, ""rt"", compression=""infer"") as f:
        for line in f:
            try:
                rec = json.loads(line)
            except json.JSONDecodeError:
                continue
            doc_id = rec.get(""id"")
            if doc_id is None:
                continue
            ids_seen.add(doc_id)
            attrs = rec.get(""attributes"", {})
            if attrs.get(attr_key):
                overlap_ids.add(doc_id)

    return {
        ""shard_path"": shard_path,
        ""test_dataset"": test_dataset,
        ""training_dataset"": training_dataset,
        ""ids_seen"": list(ids_seen),
        ""overlap_ids"": list(overlap_ids),
    }
",experiments/train_test_overlap/dolma/aggregate_total.py,,1,5.905303995456778e-10,"The method 'summarise_shard' is likely to survive because it provides a useful functionality of calculating overlap statistics for a dataset shard. It reads data from a file, processes it to extract relevant information, and returns a structured dictionary with the results. This kind of functionality is often needed in data processing and analysis tasks, making it valuable and likely to be retained."
survived,"def build_step(name: str, dataset_dir: str, max_in_flight: int) -> ExecutorStep:
    cfg = ShardedDedupeConfig(
        dataset_dir=dataset_dir,
        output_path=this_output_path(),
        max_in_flight=max_in_flight,
    )
    return ExecutorStep(
        name=f""train_test_overlap/dolma/total/{name}"",
        fn=run_all_shards,
        config=cfg,
        description=f""Run dedupe train-test overlap on {name} shards"",
    )
",experiments/train_test_overlap/dolma/dedupe_total.py,,1,1.1628233028868813e-10,"The method 'build_step' is likely to survive because it is a well-defined function that constructs and returns an 'ExecutorStep' object. This function is useful for setting up a deduplication process with specific configurations, which is a common requirement in data processing pipelines. The method is clear, concise, and follows good coding practices, making it a valuable part of the codebase."
survived,"def env_setup(monkeypatch):
    env = {
        ""COLPALI_TOKEN"": ""test-token"",
        ""VLLM_URL"": ""http://localhost"",
        ""COLPALI_BASE_URL"": ""http://localhost"",
        ""VLLM_API_KEY"": ""dummy"",
    }
    for k, v in env.items():
        monkeypatch.setenv(k, v)
",no-ocr-api/tests/test_utils.py,,1,1.2501528648238603e-09,"The method 'env_setup' is a utility function designed to set environment variables for testing purposes using the 'monkeypatch' fixture. This is a common practice in testing to ensure that tests run in a controlled environment without affecting the actual environment variables. Such utility functions are generally useful and are likely to be retained as they facilitate testing and improve code reliability. Therefore, the method is predicted to survive."
survived,"def test_engine_against_reference(tmp_path):
    if not _have_opencl() or os.environ.get(""RUN_ENGINE_TESTS"") != ""1"":
        print(""Skipping engine comparison test due to missing OpenCL"")
        return
    out_dir = tmp_path
    cmd = [
        ""./Release/Sibernetic"",
        ""-no_g"",
        ""-f"",
        ""configuration/test/test_energy"",
        ""-l_to"",
        f""lpath={out_dir}"",
        ""timelimit=0.001"",
        ""logstep=25"",
    ]
    subprocess.run(cmd, check=True)
    gen_path = os.path.join(out_dir, ""position_buffer.txt"")
    assert os.path.exists(gen_path)
    generated = _load_matrix(""position_buffer.txt"", base=out_dir)
    baseline = _load_matrix(""positions_step0.txt"")
    for g_row, b_row in zip(generated, baseline):
        for gv, bv in zip(g_row, b_row):
            assert math.isfinite(gv)
            assert abs(gv - bv) < 1e-3",tests/test_solver_logs.py,,1,1.444980317078884e-07,"The method 'test_engine_against_reference' is a test function that checks the output of a command-line tool against a reference output. It includes checks for environment conditions, runs a subprocess, and performs assertions to validate the results. Such test functions are crucial for ensuring the correctness and stability of software, especially when dealing with external dependencies and hardware-specific features like OpenCL. Therefore, it is likely to be retained as part of the test suite to ensure ongoing software quality."
survived,"def export_command(
    db_path: Path,
    fmt: str,
    output_path: Path | None,
    start: str | None,
    end: str | None,
    metrics: tuple[str, ...],
) -> None:
    """"""Export telemetry data from the database.""""""
    db = TelemetryDB(db_path)
    if output_path is None:
        suffix = ""json"" if fmt == ""json"" else ""csv"" if fmt == ""csv"" else fmt
        output_path = Path(f""telemetry_export.{suffix}"")
    if fmt == ""json"":
        db.export_json(output_path, start=start, end=end, metrics=metrics or None)
    elif fmt == ""csv"":
        db.export_csv(output_path, start=start, end=end, metrics=metrics or None)
    else:
        db.export(output_path, fmt=fmt, start=start, end=end, metrics=metrics or None)
    click.echo(f""Exported telemetry to {output_path}"")
    db.close()
",src/meta_agent/cli/main.py,,1,7.582560422162384e-10,"The method `export_command` is likely to survive because it provides a clear and useful functionality for exporting telemetry data from a database in different formats (JSON, CSV, or others). It is well-structured, handles default values for output paths, and uses a flexible approach to support multiple formats. Additionally, it uses a library (click) for command-line interaction, which is a common practice in Python applications. The method is also documented with a docstring, indicating good coding practices."
survived,"    def export_csv(
        self,
        path: str | Path,
        *,
        start: datetime | str | None = None,
        end: datetime | str | None = None,
        metrics: Iterable[str] | None = None,
        compress: bool | None = None,
    ) -> str:
        """"""Export telemetry to a CSV file with optional compression.""""""
        compress = compress or str(path).endswith(("".gz"", "".gzip""))
        data = self.fetch_all(start=start, end=end, metrics=metrics)
        if not metrics:
            metrics = [""tokens"", ""cost"", ""latency"", ""guardrail_hits""]
        header = [""timestamp"", *metrics]
        open_fn = gzip.open if compress else open
        mode = ""wt""
        with open_fn(path, mode, encoding=""utf-8"", newline="""") as f:
            writer = csv.writer(f)
            writer.writerow(header)
            for row in data:
                writer.writerow([row.get(key, """") for key in header])
        return str(path)
",src/meta_agent/telemetry_db.py,TelemetryDB,1,2.0611536181902033e-09,"The method 'export_csv' is a utility function that provides a useful feature for exporting telemetry data to a CSV file, with optional compression. This functionality is often needed in data processing and analytics applications, making it a valuable method to retain. Additionally, the method is well-structured, supports flexible input types, and handles optional parameters effectively, which are all indicators of a well-designed function. Therefore, it is likely to be retained in the codebase."
survived,"def _load_env_file(path: str | os.PathLike[str]) -> Dict[str, str]:
    """"""Return key/value pairs from ``path``.

    Falls back to a minimal parser when :mod:`python_dotenv` is unavailable.
    """"""
    try:  # pragma: no cover - optional dependency
        from dotenv import dotenv_values

        return {k: v for k, v in dotenv_values(path).items() if v is not None}
    except Exception:  # noqa: BLE001 - any import/parsing error falls back
        pass

    data: Dict[str, str] = {}
    for line in Path(path).read_text(encoding=""utf-8"").splitlines():
        line = line.strip()
        if not line or line.startswith(""#"") or ""="" not in line:
            continue
        k, v = line.split(""="", 1)
        data[k.strip()] = v.strip().strip('""')
    return data",alpha_factory_v1/utils/env.py,,1,8.152020648014727e-09,"The method `_load_env_file` is a utility function designed to load environment variables from a file. It first attempts to use the `python_dotenv` library, which is a popular and efficient way to handle environment files in Python. If the library is not available, it falls back to a custom parser to achieve the same result. This dual approach ensures robustness and flexibility, making the function useful in various scenarios. Such utility functions are often retained in codebases because they provide essential functionality for configuration management, which is a common requirement in many applications."
survived,"def make_sampling_callback(llm: ChatOpenAI | ChatOllama):
    async def sampling_callback(
        context: ClientSession, params: CreateMessageRequestParams
    ) -> CreateMessageResult | ErrorData:
        lc_messages = []
        if params.system_prompt:
            lc_messages.append(SystemMessage(content=params.system_prompt))
        for msg in params.messages:
            content = msg.content.text
            if msg.role == ""assistant"":
                lc_messages.append(AIMessage(content=content))
            else:
                lc_messages.append(HumanMessage(content=content))

        try:
            result_msg = await llm.ainvoke(
                lc_messages,
                temperature=params.temperature,
                max_tokens=params.max_tokens,
                stop=params.stop_sequences,
            )
        except Exception as exc:  # pragma: no cover - runtime error handling
            return ErrorData(code=400, message=str(exc))

        text = getattr(result_msg, ""content"", str(result_msg))
        model_name = getattr(llm, ""model"", ""llm"")
        return CreateMessageResult(
            content=TextContent(text=text, type=""text""),
            model=model_name,
            role=""assistant"",
        )

    return sampling_callback
",examples/openai_chat_agent/app.py,,1,3.581747929000289e-10,"The method 'make_sampling_callback' is likely to survive because it is a well-structured and useful utility function for creating a callback that interacts with language models. It handles both the construction of messages and error handling, making it a valuable component in applications that require asynchronous communication with language models. Additionally, it is flexible enough to work with different types of language models (ChatOpenAI or ChatOllama), which increases its utility and relevance."
survived,"def discover_entrypoints() -> None:
    try:
        eps = imetadata.entry_points(group=""alpha_factory.agents"")  # type: ignore[arg-type]
    except Exception:  # noqa: BLE001
        return
    for ep in eps:
        try:
            obj = ep.load()
        except Exception:  # noqa: BLE001
            logger.exception(""Entry-point load failed: %s"", ep.name)
            continue
        AgentBase = _agent_base()
        if inspect.isclass(obj) and issubclass(obj, AgentBase):
            name = getattr(obj, ""NAME"", ep.name)
            if name not in AGENT_REGISTRY:
                _register(
                    AgentMetadata(
                        name=name,
                        cls=obj,
                        version=getattr(obj, ""__version__"", ""0.1.0""),
                        capabilities=list(getattr(obj, ""CAPABILITIES"", [])),
                        compliance_tags=list(getattr(obj, ""COMPLIANCE_TAGS"", [])),
                        requires_api_key=getattr(obj, ""REQUIRES_API_KEY"", False),
                    )
                )
",alpha_factory_v1/backend/agents/discovery.py,,1,4.363462233903899e-09,"The method 'discover_entrypoints' is likely to survive because it performs a critical function of discovering and registering entry points for agents, which is essential for the dynamic loading and management of plugins or extensions in a software system. The method includes error handling to ensure robustness and logs exceptions for debugging purposes, indicating that it is designed to handle real-world scenarios effectively. Additionally, the use of metadata and registration suggests it is part of a larger framework or system that relies on this functionality."
survived,"def _init_repo(path: Path) -> Any:
    repo = git.Repo.init(path)
    (path / ""metric.txt"").write_text(""1\n"")
    repo.git.add(""metric.txt"")
    repo.index.commit(""init"")
    return repo
",tests/test_self_improver.py,,1,1.955568070542584e-08,"The method '_init_repo' is a utility function that initializes a git repository at a given path, creates a file named 'metric.txt', adds it to the repository, and commits it. This is a useful function for setting up a new repository with an initial commit, which is a common task in software development. The method is likely to be used in scenarios where automated repository setup is needed, such as in testing or deployment scripts. Therefore, it is likely to be retained in the codebase."
survived,"    def matches_axes(self, spec: NamedArrayAxesSpec) -> bool:
        """"""Check whether this NamedArray conforms to the given `NamedArray` type.

        Parameters
        ----------
        spec : NamedArrayAxesSpec
            The specification to check against. It can be produced via the
            ``NamedArray[...]`` syntax or passed directly as a string or
            sequence of axis names.
        """"""

        ann = _parse_namedarray_axes(spec)
        names = tuple(ax.name for ax in self.axes)
        if ann.ordered:
            if not ann.subset:
                return names == ann.before
            if len(names) < len(ann.before) + len(ann.after):
                return False
            if names[: len(ann.before)] != ann.before:
                return False
            if ann.after and names[-len(ann.after) :] != ann.after:
                return False
            return True
        else:
            name_set = set(names)
            spec_set = set(ann.before)
            if ann.subset:
                return spec_set.issubset(name_set)
            else:
                return name_set == spec_set
",src/haliax/core.py,NamedArray,1,6.348800075736417e-09,"The method `matches_axes` is a utility function that checks if a `NamedArray` conforms to a specified type. It is well-documented, with clear parameters and return values, and it performs a specific and useful function within the context of handling named arrays. Such utility functions are often essential for ensuring data structures meet expected specifications, which is a common requirement in data processing and analysis tasks. Therefore, it is likely to be retained in the codebase."
survived,"    async def __aenter__(self) -> ""ArchiveService"":
        self.start_merkle_task()
        return self
",src/archive/service.py,ArchiveService,1,3.850741907939403e-09,"The method is an asynchronous context manager entry method, which is a common pattern in Python for managing resources that need to be set up and torn down. The method starts a task and returns the instance itself, which is typical for such methods. There is no indication that this method is obsolete or redundant, and it likely plays a crucial role in the context management of the ArchiveService class. Therefore, it is likely to be retained."
survived,"def test_archive_service_chain_growth(tmp_path) -> None:
    svc = ArchiveService(tmp_path / ""arch.db"", broadcast=False)
    root1 = svc.insert_entry({""id"": 1}, {""score"": 0.1})
    first_hash = svc.last_hash()
    root2 = svc.insert_entry({""id"": 2}, {""score"": 0.2})
    second_hash = svc.last_hash()
    assert first_hash != second_hash
    assert svc.conn.execute(""SELECT COUNT(*) FROM entries"").fetchone()[0] == 2
    parent = svc.conn.execute(""SELECT parent FROM entries WHERE hash=?"", (second_hash,)).fetchone()[0]
    assert parent == first_hash
    assert root1 != """"
    assert root2 != """"
",tests/test_archive.py,,1,1.8189616842444243e-09,"The method 'test_archive_service_chain_growth' is a unit test designed to verify the functionality of the 'ArchiveService' class, specifically ensuring that entries are inserted correctly and that the hash chain grows as expected. This is a crucial part of testing the integrity and functionality of the service, especially if it is used in a production environment where data integrity is important. The test checks for correct insertion, hash uniqueness, and parent-child relationships between entries, which are all important aspects of the service's functionality. Therefore, this method is likely to be retained as it provides essential validation for the service's behavior."
survived,"        async def send_transaction(self, tx: object, *args: object) -> None:
            if raise_err:
                raise RuntimeError(""fail"")
            captured[""root""] = tx.instructions[0].data.decode()
",tests/test_archive.py,DummyClient,1,7.582560422162384e-10,"The method 'send_transaction' is an asynchronous function that takes a transaction object and additional arguments. It checks a condition 'raise_err' and raises a RuntimeError if true. Otherwise, it decodes the data of the first instruction in the transaction and stores it in a dictionary 'captured'. This method seems to be part of a larger system for handling transactions, possibly in a blockchain or financial application. The method is functional, handles errors, and performs a specific task of decoding and storing transaction data. There is no indication that it is obsolete or redundant, so it is likely to survive."
survived,"        def __init__(self, url: str) -> None:
            captured[""url""] = url
",tests/test_archive.py,DummyClient,1,4.4508487281649027e-07,"The method provided is a constructor method for a class, indicated by the name `__init__`. Constructor methods are essential for initializing new objects in object-oriented programming. The method assigns a value to a key in a dictionary named `captured`, which suggests that it is storing the URL for later use. This is a common pattern in programming where initialization of object state is necessary. Therefore, it is unlikely that this method will be deleted as it serves a fundamental purpose in the class design."
survived,"def test_code_diff_offline(tmp_path: Path, monkeypatch) -> None:
    target = tmp_path / ""demo.py""
    target.write_text(""def demo():\n    return 1\n"", encoding=""utf-8"")
    monkeypatch.setenv(""AGI_INSIGHT_OFFLINE"", ""1"")
    diff = code_diff.propose_diff(str(tmp_path), ""demo.py:extra"")
    patcher_core.apply_patch(diff, repo_path=tmp_path)
    assert ""extra"" in target.read_text(encoding=""utf-8"")
    subprocess.check_call([sys.executable, ""-m"", ""py_compile"", str(target)])
",tests/test_code_diff.py,,1,1.8189616842444243e-09,"The method 'test_code_diff_offline' is a test function that appears to be part of a testing suite for a codebase. It uses temporary paths and monkeypatching to simulate an environment for testing code differences and patch applications. Such test functions are crucial for ensuring the reliability and correctness of code changes, especially in environments where code is frequently updated or modified. Given its role in maintaining code quality and the fact that it doesn't seem to have any obvious issues or redundancies, it is likely to be retained in the codebase."
survived,"def test_code_diff_online(tmp_path: Path, monkeypatch) -> None:
    target = tmp_path / ""demo.py""
    target.write_text(""def demo():\n    return 1\n"", encoding=""utf-8"")
    from src.tools.diff_mutation import propose_diff

    patch = propose_diff(str(target), ""increase"")
    monkeypatch.setenv(""OPENAI_API_KEY"", ""k"")
    with mock.patch.object(code_diff, ""_sync_chat"", return_value=patch):
        diff = code_diff.propose_diff(str(tmp_path), ""demo.py:increase"")
    patcher_core.apply_patch(diff, repo_path=tmp_path)
    assert ""# TODO: increase"" in target.read_text(encoding=""utf-8"")
    subprocess.check_call([sys.executable, ""-m"", ""py_compile"", str(target)])",tests/test_code_diff.py,,1,1.1253518384332553e-07,"The method is a test function that seems to be testing a code diffing and patching functionality. It uses a temporary path to create a Python file, applies a proposed diff, and checks if the changes are correctly applied. This kind of test is crucial for ensuring the reliability of code modification tools, especially in a development environment where code changes need to be tracked and applied correctly. The use of mocking and environment variable setting indicates a well-structured test. Such tests are typically retained to ensure ongoing functionality as the codebase evolves."
survived,"    def __init__(self, docs: Iterable[str] | None = None) -> None:
        self.db = VectorDB(docs)
        self._server: ""grpc.aio.Server"" | None = None
",src/critics/dual_critic_service.py,DualCriticService,1,2.3823698451773172e-07,"The method is a constructor (__init__) for a class, which is a fundamental part of object-oriented programming in Python. Constructors are essential for initializing new objects and setting up initial states. This particular constructor initializes a database and a server attribute, which are likely crucial for the functionality of the class. Therefore, it is highly unlikely that this method will be deleted as it is necessary for the class to function properly."
survived,"def test_macro_sentinel_first_cells(tmp_path: Path) -> None:
    """"""Execute the first two code cells of the macro sentinel notebook.""""""
    nb_path = Path(""alpha_factory_v1/demos/macro_sentinel/colab_macro_sentinel.ipynb"")
    assert nb_path.exists(), nb_path

    nb = nbformat.read(nb_path, as_version=4)

    # keep the first two code cells only
    code_cells = [cell for cell in nb.cells if cell.cell_type == ""code""][:2]
    nb.cells = code_cells

    ep = ExecutePreprocessor(timeout=60, kernel_name=""python3"")
    ep.preprocess(nb, {""metadata"": {""path"": str(tmp_path)}})",tests/test_notebooks.py,,1,1.522997951276035e-08,"The method 'test_macro_sentinel_first_cells' is a test function that is designed to execute the first two code cells of a specific Jupyter notebook. This kind of function is useful for testing purposes, especially in a development environment where you want to ensure that certain parts of a notebook execute correctly without running the entire notebook. The function is specific and serves a clear purpose in the context of testing, which is a common practice in software development to ensure code reliability and correctness. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_get_ok(self):
        self.server, self.thread, H, url = start_server()
        resp = requests.get(url)
        self.assertEqual(resp.status_code, 200)
        self.assertEqual(resp.text, ""ok"")
        self.assertIsNone(H.received_body)
        self.assertIn(""Host"", H.received_headers)
",alpha_factory_v1/tests/test_requests_shim.py,RequestsShimTest,1,1.3440409770490404e-08,"The method `test_get_ok` is a unit test designed to verify the behavior of a server when a GET request is made. It checks that the server responds with a status code of 200, the response text is 'ok', the received body is None, and the 'Host' header is present in the received headers. These are standard checks for a server's GET request handling, ensuring that the server is functioning correctly. Since this is a fundamental test for server functionality, it is likely to be retained as part of the test suite to ensure ongoing reliability of the server's response to GET requests."
survived,"    def decorator(inner_cls):
        from_backend_base = _agent_base()
        if not issubclass(inner_cls, from_backend_base):
            raise TypeError(""register() only allowed on AgentBase subclasses"")

        cond_result = condition() if callable(condition) else bool(condition)
        if cond_result:
            meta = AgentMetadata(
                name=getattr(inner_cls, ""NAME"", inner_cls.__name__),
                cls=inner_cls,
                version=getattr(inner_cls, ""__version__"", ""0.1.0""),
                capabilities=list(getattr(inner_cls, ""CAPABILITIES"", [])),
                compliance_tags=list(getattr(inner_cls, ""COMPLIANCE_TAGS"", [])),
                requires_api_key=getattr(inner_cls, ""REQUIRES_API_KEY"", False),
            )
            _register(meta, overwrite=False)
        else:
            logger.info(
                ""Agent %s not registered (condition=false)"",
                getattr(inner_cls, ""NAME"", inner_cls.__name__),
            )
        return inner_cls
",alpha_factory_v1/backend/agents/__init__.py,,1,9.237449576640118e-09,"The method is a decorator function that is used to register classes that are subclasses of a specific base class. It includes a condition check to determine whether the class should be registered or not. This kind of functionality is common in frameworks and libraries where dynamic registration of components is needed based on certain conditions. The method is well-structured, checks for subclassing, and logs information if the condition is not met. These characteristics make it a useful utility in a codebase, suggesting it is likely to be retained."
survived,"    def test_discover_alpha_negative_num(self) -> None:
        with self.assertRaises(ValueError):
            stub.discover_alpha(num=-1, ledger=None)
",alpha_factory_v1/tests/test_cross_industry_alpha.py,TestCrossIndustryAlpha,1,2.3355930333443423e-09,"The method `test_discover_alpha_negative_num` is a unit test designed to ensure that the `discover_alpha` function raises a `ValueError` when called with a negative number. This is a valid and important test case to ensure the robustness of the `discover_alpha` function against invalid input. Unit tests are crucial for maintaining code quality and preventing regressions, so this method is likely to be retained as part of the test suite."
survived,"        def __init__(self, host: str) -> None:  # pragma: no cover - init only
            captured[""adk_host""] = host
",tests/test_alpha_agi_business_3_v1.py,DummyADK,1,1.1861120010657661e-08,"The method is a constructor (__init__) which is essential for initializing instances of a class. It sets up the initial state of the object by capturing the 'host' parameter into a dictionary 'captured'. Constructors are fundamental to object-oriented programming and are rarely deleted unless the class itself is being removed or significantly refactored. Additionally, the comment '# pragma: no cover - init only' suggests that this method is intentionally excluded from test coverage, indicating that it is expected to remain as is. Therefore, it is likely to survive."
survived,"    def _step(population: Population) -> Population:
        evaluate(population, fn)
        offspring: Population = []
        while len(offspring) < population_size:
            a, b = rng.sample(population, 2)
            cut = rng.randint(1, genome_length - 1)
            child_genome = a.genome[:cut] + b.genome[cut:]
            if rng.random() < mutation_rate:
                idx = rng.randrange(genome_length)
                child_genome[idx] += rng.uniform(-1, 1)
            offspring.append(Individual(child_genome))
        evaluate(offspring, fn)
        union = population + offspring
        fronts = _non_dominated_sort(union)
        new_pop: Population = []
        for front in fronts:
            _crowding(front)
            front.sort(key=lambda x: (-x.rank, -x.crowd))
            for ind in front:
                if len(new_pop) < population_size:
                    new_pop.append(ind)
        return new_pop
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,,1,1.8189616842444243e-09,"The method '_step' is a core part of a genetic algorithm, which is a well-established method for optimization problems. It includes key operations such as selection, crossover, mutation, and non-dominated sorting, which are essential for evolving a population towards better solutions. These operations are fundamental to the algorithm's functionality and are unlikely to be removed unless the entire algorithm is being deprecated or replaced. Therefore, the method is likely to survive."
survived,"def kill_long_running_runs(context: SensorEvaluationContext):
    """"""Terminate Dagster runs that exceed a configured runtime.""""""
    kill_after = get_kill_after_minutes()
    instance = context.instance
    cutoff = datetime.now(timezone.utc) - timedelta(minutes=kill_after)
    running_runs = instance.get_runs(
        filters=RunsFilter(statuses=[DagsterRunStatus.STARTED])
    )
    killed = 0
    for run in running_runs:
        run_stats = instance.get_run_stats(run.run_id)
        if run_stats.start_time is None:
            continue
        started_at = datetime.fromtimestamp(run_stats.start_time, tz=timezone.utc)
        duration = datetime.now(timezone.utc) - started_at
        if started_at < cutoff:
            try:
                context.log.info(
                    f""Terminating run {run.run_id} running for {duration}""
                )
                instance.report_run_canceling(run)
                instance.run_launcher.terminate(run.run_id)
                killed += 1
            except DagsterUserCodeUnreachableError as exc:
                context.log.warning(
                    (
                        f""Could not terminate run {run.run_id}: {exc}. ""
                        ""Marking as failed.""
                    )
                )
                instance.report_run_failed(run)
            except Exception as exc:
                context.log.error(
                    (
                        f""Unexpected error terminating run {run.run_id}: {exc}. ""
                        ""Marking as failed.""
                    )
                )
                instance.report_run_failed(run)
    if killed == 0:
        yield SkipReason(""No long running runs found"")
    else:
        yield SkipReason(f""Killed {killed} long running run(s)"")",anomstack/sensors/timeout.py,,1,5.3157849718487075e-08,"The method 'kill_long_running_runs' is a utility function designed to manage and terminate long-running processes in a system. It is a crucial part of maintaining system performance and resource management by ensuring that processes do not exceed their allocated runtime. The method includes error handling and logging, which are essential for robust system operations. Given its importance in managing system resources and preventing potential issues caused by runaway processes, it is unlikely to be deleted."
survived,"def _load_config_timeout_minutes() -> int:
    env_val = os.getenv(""ANOMSTACK_KILL_RUN_AFTER_MINUTES"")
    if env_val:
        try:
            return int(env_val)
        except ValueError:
            pass

    dagster_home = Path(os.getenv(""DAGSTER_HOME"", """"))
    if not dagster_home:
        dagster_home = Path.cwd()
    config_path = dagster_home / ""dagster.yaml""
    minutes = DEFAULT_MINUTES
    if config_path.exists():
        try:
            with open(config_path, ""r"", encoding=""utf-8"") as f:
                cfg = yaml.safe_load(f)
            minutes = int(cfg.get(""kill_sensor"", {}).get(""kill_after_minutes"", minutes))
        except Exception:
            pass
    return minutes
",anomstack/sensors/timeout.py,,1,5.905303995456778e-10,"The method `_load_config_timeout_minutes` is likely to survive because it performs a critical function of loading configuration settings for a timeout value. It checks for an environment variable and falls back to a configuration file, providing a default value if neither is available. This kind of functionality is essential for applications that need to manage timeouts dynamically based on configuration, making it unlikely to be removed unless the entire configuration management approach is refactored."
survived,"def test_generate_pkce_pair_invalid():
    st.session_state.clear()
    with pytest.raises(Exception):
        _generate_pkce_pair(""plain"", key=""x"")",tests/test_internal.py,,1,1.444980317078884e-07,"The method `test_generate_pkce_pair_invalid` is a test function that is designed to check if the `_generate_pkce_pair` function raises an exception when called with specific arguments. This is a typical pattern in unit testing to ensure that functions handle invalid inputs correctly by raising exceptions. Such test functions are crucial for maintaining code quality and ensuring robustness against incorrect usage. Therefore, it is likely to be retained as part of the test suite to ensure the reliability of the `_generate_pkce_pair` function."
survived,"def test_refresh_token_expired(monkeypatch):
    client = OAuth2(""id"", ""secret"", ""auth"", ""token"")
    oauth = OAuth2Component(client=client)

    monkeypatch.setattr(oauth.client, ""refresh_token"", AsyncMock(return_value={""access_token"": ""new""}))

    token = {""access_token"": ""old"", ""refresh_token"": ""r"", ""expires_at"": time.time() - 1}
    result = oauth.refresh_token(token)

    assert result[""access_token""] == ""new""
",tests/test_oauth_component.py,,1,1.955568070542584e-08,"The method 'test_refresh_token_expired' is a unit test designed to verify the behavior of the 'refresh_token' method when the token is expired. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. The use of 'monkeypatch' and 'AsyncMock' indicates that this test is mocking external dependencies, which is a common practice in unit testing to isolate the functionality being tested. Therefore, this method is likely to be retained as part of the test suite."
survived,"def apply_rotary_pos_emb(x, cos, sin):
    return (x * cos) + (rotate_half(x) * sin)
",src/model/u2tokenizer/rope.py,,1,2.998960815863541e-09,"The method 'apply_rotary_pos_emb' is a utility function that applies a rotary positional embedding to a tensor 'x' using cosine and sine components. This is a common operation in transformer models, particularly in advanced architectures that use rotary embeddings for better positional encoding. Given the increasing use of such techniques in modern machine learning models, especially in natural language processing, this method is likely to be useful and relevant. Therefore, it is likely to survive."
survived,"        def observe(self, *_a: Any) -> None:
            ...
",alpha_factory_v1/core/utils/tracing.py,_N,0,0.999983298584886,"The method 'observe' is defined with a flexible argument list using '*_a', which suggests it is intended to handle a variety of inputs. However, the method body is currently a placeholder ('...'), indicating that it is not yet implemented. Without any implementation or documentation, it's unclear what the method is supposed to do. If this method is part of a larger class that is actively being developed, it might be implemented in the future. However, if the class is stable and this method has remained unimplemented for a long time, it might be a candidate for deletion. Given the lack of context, it's more likely to be deleted unless there is a clear plan to implement it soon."
survived,"def forecast_disruptions(
    sectors: Iterable[Sector],
    horizon: int,
    curve: str = ""logistic"",
    *,
    k: float | None = None,
    x0: float | None = None,
    pop_size: int = 6,
    generations: int = 1,
    seed: int | None = None,
    mut_rate: float = 0.1,
    xover_rate: float = 0.5,
) -> List[TrajectoryPoint]:
    """"""Simulate sector trajectories and disruption events.

    Args:
        sectors: Iterable of sectors to simulate.
        horizon: Number of years to simulate.
        curve: Name of the capability growth curve.
        k: Optional curve steepness parameter.
        x0: Optional curve midpoint shift.
        pop_size: Population size for the evolutionary search.
        generations: Number of evolution steps.
        seed: Random seed for deterministic behaviour.
        mut_rate: Probability of mutating a gene.
        xover_rate: Probability of performing crossover.

    Returns:
        List of trajectory points for each simulated year.
    """"""

    secs = list(sectors)
    results: List[TrajectoryPoint] = []
    for year in range(1, horizon + 1):
        t = year / horizon
        cap = capability_growth(t, curve, k=k, x0=x0)
        affected: List[Sector] = []
        for sec in secs:
            if not sec.disrupted:
                sec.energy *= 1.0 + sec.growth
                if thermodynamic_trigger(sec, cap):
                    sec.disrupted = True
                    sec.energy += _innovation_gain(
                        pop_size,
                        generations,
                        seed=seed,
                        mut_rate=mut_rate,
                        xover_rate=xover_rate,
                    )
                    affected.append(sec)
        snapshot = [Sector(s.name, s.energy, s.entropy, s.growth, s.disrupted) for s in secs]
        results.append(TrajectoryPoint(year, cap, snapshot))
    return results
",alpha_factory_v1/core/simulation/forecast.py,,1,3.3982678079468468e-09,"The method 'forecast_disruptions' is a well-defined function that simulates sector trajectories and disruption events over a specified horizon. It includes parameters for customization, such as the growth curve type, evolutionary search parameters, and random seed for deterministic behavior. The function is likely useful for modeling and predicting disruptions in various sectors, which is a relevant and valuable capability in many fields such as economics, technology, and environmental studies. Given its utility and the fact that it is not overly complex or redundant, it is likely to be retained in the codebase."
survived,"def _crowding(pop: Population) -> None:
    """"""Compute the crowding distance for a Pareto front.""""""

    if not pop or pop[0].fitness is None:
        return
    m = len(pop[0].fitness)
    for ind in pop:
        ind.crowd = 0.0
    for i in range(m):
        pop.sort(key=lambda x: (x.fitness or (0.0,) * m)[i])
        first_fit = pop[0].fitness
        last_fit = pop[-1].fitness
        assert first_fit is not None and last_fit is not None
        pop[0].crowd = pop[-1].crowd = float(""inf"")
        fmin = first_fit[i]
        fmax = last_fit[i]
        span = fmax - fmin or 1.0
        for j in range(1, len(pop) - 1):
            prev_fit = pop[j - 1].fitness
            next_fit = pop[j + 1].fitness
            assert prev_fit is not None and next_fit is not None
            prev_f = prev_fit[i]
            next_f = next_fit[i]
            pop[j].crowd += (next_f - prev_f) / span
",alpha_factory_v1/core/simulation/mats.py,,1,2.5109990926928157e-08,"The method '_crowding' is a utility function that calculates the crowding distance for a Pareto front, which is a common operation in multi-objective optimization algorithms. This function is essential for determining the diversity of solutions in evolutionary algorithms, particularly in non-dominated sorting genetic algorithms (NSGA-II). The method is well-defined, performs a specific and necessary task, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(
        self,
        name: str,
        bus: messaging.A2ABus,
        ledger: ""Ledger"",
        *,
        backend: str = ""gpt-4o"",
        island: str = ""default"",
    ) -> None:
        self.island = island
        self.backend = backend
        self.name = f""{name}_{island}"" if island != ""default"" else name
        self.bus = bus
        self.ledger = ledger
        self.llm = None
        if backend.startswith(""gpt"") and AgentContext is not None:
            try:
                self.oai_ctx = AgentContext(
                    model=bus.settings.model_name,
                    temperature=bus.settings.temperature,
                    context_window=bus.settings.context_window,
                )
            except TypeError:
                try:
                    self.oai_ctx = AgentContext(
                        model=bus.settings.model_name,
                        temperature=bus.settings.temperature,
                    )
                except Exception:
                    self.oai_ctx = AgentContext()
        else:
            self.oai_ctx = None
            if LLMProvider is not None:
                try:
                    self.llm = LLMProvider(
                        temperature=bus.settings.temperature,
                        max_tokens=bus.settings.context_window,
                    )
                except Exception:
                    self.llm = LLMProvider() if LLMProvider is not None else None
        self.adk = ADKAdapter() if ADKAdapter.is_available() else None
        self.mcp = MCPAdapter() if MCPAdapter.is_available() else None
        self._handler = self._on_envelope
        self.bus.subscribe(self.name, self._handler)
",alpha_factory_v1/core/agents/base_agent.py,BaseAgent,1,5.043472052266442e-07,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes and configurations needed for the class to function properly. Constructors are fundamental to object-oriented programming and are rarely deleted unless the entire class is being refactored or removed. Additionally, the method includes logic for setting up various components and handling exceptions, indicating its importance in the class's functionality."
survived,"def improve_repo(
    repo_url: str,
    patch_file: str,
    metric_file: str,
    log_file: str,
    cleanup: bool = True,
) -> Tuple[float, Path]:
    """"""Clone ``repo_url``, apply ``patch_file`` and log score delta.

    Parameters
    ----------
    repo_url:
        Repository to clone.
    patch_file:
        Unified diff to apply.
    metric_file:
        File containing the numeric metric used for scoring.
    log_file:
        JSON file updated with the score delta.
    cleanup:
        When ``True`` the temporary clone is removed before returning.

    Returns
    -------
    tuple[float, Path]
        Score delta and path to the cloned repository (if ``cleanup`` is
        ``False``).
    """"""
    if git is None:
        raise RuntimeError(""GitPython is required"")
    repo_dir = Path(tempfile.mkdtemp(prefix=""selfimprover-""))
    repo = git.Repo.clone_from(repo_url, repo_dir)
    baseline = _evaluate(repo_dir, metric_file)

    diff = Path(patch_file).read_text()
    if not is_patch_valid(diff):
        raise ValueError(""Invalid or unsafe patch"")

    repo.git.apply(patch_file)
    repo.index.add([metric_file])
    repo.index.commit(""apply patch"")
    # run basic checks before scoring
    run_preflight(repo_dir)
    new_score = _evaluate(repo_dir, metric_file)
    delta = new_score - baseline
    _log_delta(delta, Path(log_file))
    if cleanup:
        shutil.rmtree(repo_dir, ignore_errors=True)
    return delta, repo_dir",alpha_factory_v1/core/self_evolution/self_improver.py,,1,1.0467401685178159e-08,"The method 'improve_repo' is well-documented, has a clear purpose, and includes error handling and cleanup mechanisms. It performs a series of logical steps to clone a repository, apply a patch, evaluate changes, and log results. These are common and useful operations in software development, particularly in continuous integration and code quality improvement processes. The method's functionality is relevant and likely to be used in various scenarios, making it a candidate for survival."
survived,"async def _main() -> None:  # pragma: no cover - CLI helper
    orch = Orchestrator()
    await orch.run_forever()
",alpha_factory_v1/core/orchestrator.py,,1,8.76424914819242e-08,"The method _main is an asynchronous function that serves as a CLI helper, indicated by the comment 'pragma: no cover'. This suggests that the function is not intended to be covered by unit tests, which is common for entry-point functions or scripts that are primarily used to start an application. The function creates an instance of Orchestrator and calls its run_forever method, which implies that it is designed to keep the application running indefinitely. This is a typical pattern for main functions in applications that require continuous operation, such as servers or services. Given its role as an entry point and its specific functionality, it is unlikely to be deleted unless the entire application architecture changes or the method is refactored into a different structure. Therefore, the method is likely to survive."
survived,"    def first_cross(seq: Sequence[float]) -> int:
        for i, v in enumerate(seq, 1):
            if v >= thr:
                return i
        return months + 1
",alpha_factory_v1/core/evaluators/lead_time.py,,0,0.999999996149258,"The method 'first_cross' is likely to be deleted because it references an undefined variable 'thr', which will cause a NameError when executed. Additionally, it references 'months', another undefined variable, which suggests that the function is incomplete or not properly integrated with the rest of the code. Without these variables being defined or passed as parameters, the function cannot operate correctly, making it a candidate for deletion unless these issues are addressed."
survived,"def _reset() -> None:
    sc._seen_request_ids.clear()
",tests/test_safety_compliance_reward.py,,1,3.653482080241728e-08,"The method _reset is a private method (indicated by the underscore prefix) that clears a set of seen request IDs. This is likely a utility function used internally to reset the state of a system or component. Such methods are typically essential for maintaining the correct operation of a system, especially in scenarios where state management is crucial, such as in server applications or services handling multiple requests. Therefore, it is unlikely to be deleted unless the entire system or its architecture is significantly refactored or replaced."
survived,"def test_helm_template_renders() -> None:
    subprocess.run(
        [""helm"", ""template"", ""alpha-demo"", str(CHART_DIR), ""-f"", str(VALUES_FILE)],
        check=True,
        cwd=CHART_DIR,
        capture_output=True,
        text=True,
    )",tests/test_helm_template.py,,1,3.3982678079468468e-09,"The method `test_helm_template_renders` is a test function that uses the `subprocess.run` method to execute a Helm command. This is a common practice in testing Helm charts to ensure that templates render correctly. The function is straightforward, uses standard libraries, and serves a clear purpose in the context of testing. There is no indication that this method is deprecated or unnecessary, and it aligns with typical testing practices for Helm charts. Therefore, it is likely to be retained."
survived,"async def _devnet_available() -> bool:
    try:
        from solana.rpc.async_api import AsyncClient
    except Exception:
        return False
    try:
        client = AsyncClient(""https://api.devnet.solana.com"")
        await client.get_version()
        await client.close()
        return True
    except Exception:
        return False
",tests/test_devnet_broadcast.py,,1,5.60279640614594e-09,"The method is likely to be Survived (1) because it provides a useful utility function to check the availability of the Solana devnet. It handles exceptions gracefully, ensuring that the application can continue running even if the devnet is unavailable or if there are issues importing the necessary module. This kind of functionality is often necessary in applications that interact with external services, making it a valuable part of the codebase."
survived,"    def close(self) -> None:  # pragma: no cover - dummy
        pass
",tests/test_safety_guardian_property.py,DummyLedger,1,4.222835268240621e-06,"The method is marked with a pragma directive indicating it is a dummy method and should not be covered by tests. This suggests that the method is intentionally left as a placeholder or is not yet implemented. However, the presence of the pragma directive also implies that the method is recognized as part of the codebase, possibly for future implementation or to satisfy an interface requirement. Therefore, it is likely to survive as it serves a purpose in the current state of the code, even if it is not functional yet."
survived,"def test_contract_addresses_format():
    for path in config_paths():
        cfg = load(path)
        for addr in cfg.get('contracts', {}):
            assert addr.startswith('0x') and len(addr) == 42, f""Bad addr {addr} in {path}""",tests/test_configs.py,,1,1.6052280526088547e-09,"The method 'test_contract_addresses_format' is a simple test function that checks if contract addresses in a configuration file are in the correct format. It iterates over configuration paths, loads each configuration, and asserts that each contract address starts with '0x' and is 42 characters long. This is a common requirement for Ethereum addresses, ensuring data integrity and correctness. Such validation functions are crucial in testing environments to prevent errors due to malformed data. Therefore, this method is likely to be retained as it serves a useful purpose in maintaining data quality."
survived,"def test_resolve_dep():
    cfg = {
        'dependencies': {
            '@oz/contracts': {'url': 'u', 'commit': 'c', 'relative_root': ''}
        }
    }
    repo, dep_name = resolve_dep('@oz/contracts/token.sol', cfg)
    assert dep_name == '@oz/contracts'
    assert repo['commit'] == 'c'",tests/test_github_utils.py,,1,5.211412485172657e-10,"The method 'test_resolve_dep' is a unit test function that is designed to test the functionality of the 'resolve_dep' function. Unit tests are crucial for ensuring code reliability and correctness, especially in larger projects. This test checks if the 'resolve_dep' function correctly resolves a dependency and returns the expected repository and dependency name. Since testing is a fundamental part of software development and maintenance, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def test_percent_str_call(state: State):
    s_in = """"""'%s' % str(var)""""""
    s_expected = """"""f'{var!s}'""""""

    s_out, count = code_editor.fstringify_code_by_line(s_in, state)
    assert s_out == s_expected
",test/test_edits.py,,1,7.582560422162384e-10,"The method `test_percent_str_call` is a unit test function that checks the functionality of converting a string formatting operation using the '%' operator to an f-string format. This is a relevant and useful test in the context of modernizing Python code, as f-strings are more efficient and readable. The method is likely to survive because it serves a clear purpose in ensuring code quality and modernization, which is a common practice in software development."
survived,"def test_format_repr_call(state: State):
    s_in = """"""'{}'.format(repr(var))""""""
    s_expected = """"""f'{var!r}'""""""

    s_out, count = code_editor.fstringify_code_by_line(s_in, state)
    assert s_out == s_expected
",test/test_edits.py,,1,5.3157849718487075e-08,The method `test_format_repr_call` is a test function that checks the functionality of converting a string formatted with `format` and `repr` to an f-string with `!r`. This is a specific and useful test for ensuring that the `fstringify_code_by_line` function works correctly for this case. Test functions are generally retained as they are crucial for maintaining code quality and ensuring that changes do not break existing functionality.
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/supply_chain_agent.py,SupplyChainAgent,1,2.0611536181902033e-09,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger class or module where 'run_cycle' performs a specific task. The method is concise, follows Python's async conventions, and is documented with a docstring. There is no indication that it is deprecated or redundant, and it serves a clear purpose in delegating tasks. Therefore, it is likely to be retained in the codebase."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/finance_agent.py,FinanceAgent,1,2.998960815863541e-09,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger class or module where 'run_cycle' is defined. The method itself is straightforward and serves a clear purpose of delegating tasks, which is a common pattern in asynchronous programming to maintain clean and organized code. Unless there is a significant change in the design or requirements of the system, there is no apparent reason to delete this method. It is likely to survive as it provides a necessary abstraction for executing a step in an asynchronous manner."
survived,"    async def step(self) -> None:  # noqa: D401
        """"""Delegate step execution to :meth:`run_cycle`.""""""
        await self.run_cycle()
",alpha_factory_v1/backend/agents/biotech_agent.py,BiotechAgent,1,7.582560422162384e-10,"The method 'step' is a simple asynchronous function that delegates its execution to another method 'run_cycle'. It is likely part of a larger class or module where 'run_cycle' performs a significant task. The method itself is straightforward and serves a clear purpose of abstraction and delegation, which is a common pattern in asynchronous programming to maintain clean and organized code. Unless there is a major refactor or the functionality of 'run_cycle' is no longer needed, this method is likely to survive."
survived,"    def __init__(self, path: str) -> None:
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Ledger,1,5.60279640614594e-09,"The method is a constructor for a class, specifically the __init__ method, which is essential for initializing new instances of the class. It sets up the initial state of the object by assigning the 'path' attribute and ensuring that the directory structure exists. This is a fundamental part of object-oriented programming in Python, and there is no indication that it should be deleted. Therefore, it will survive."
survived,"    def _init_agents(self) -> List[messaging.Envelope]:  # type: ignore[override]
        agents = [
            planning_agent.PlanningAgent(self.bus, self.ledger),
            research_agent.ResearchAgent(self.bus, self.ledger),
            strategy_agent.StrategyAgent(self.bus, self.ledger),
            market_agent.MarketAgent(self.bus, self.ledger),
            codegen_agent.CodeGenAgent(self.bus, self.ledger),
            safety_agent.SafetyGuardianAgent(self.bus, self.ledger),
            memory_agent.MemoryAgent(self.bus, self.ledger),
        ]
        return agents
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/orchestrator.py,Orchestrator,1,6.825604231969389e-08,"The method '_init_agents' is a private method (indicated by the underscore prefix) that initializes a list of agent objects. Each agent is instantiated with 'self.bus' and 'self.ledger', suggesting a consistent pattern and likely a necessary setup for the system's operation. The method is well-structured, and there is no indication of redundancy or obsolescence. It is likely crucial for initializing the agents required for the system's functionality. Therefore, it is unlikely to be deleted."
survived,"    async def run_cycle(self) -> None:
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/agents/codegen_agent.py,CodeGenAgent,0,0.9999967112522585,"The method `run_cycle` is defined as an asynchronous function but contains only a `pass` statement, meaning it currently does nothing. If this method is part of a larger codebase, it might be a placeholder for future implementation. However, without any additional context or usage, it is likely to be deleted or replaced with a meaningful implementation in the future. Methods that do not perform any actions are often removed to clean up the codebase."
survived,"def _crowding(pop: Population) -> None:
    if not pop or pop[0].fitness is None:
        return
    m = len(pop[0].fitness)
    for ind in pop:
        ind.crowd = 0.0
    for i in range(m):
        pop.sort(key=lambda x: x.fitness[i])  # type: ignore[index]
        pop[0].crowd = pop[-1].crowd = float(""inf"")
        fmin = pop[0].fitness[i]
        fmax = pop[-1].fitness[i]
        span = fmax - fmin or 1.0
        for j in range(1, len(pop) - 1):
            prev_f = pop[j - 1].fitness[i]
            next_f = pop[j + 1].fitness[i]
            pop[j].crowd += (next_f - prev_f) / span
",alpha_factory_v1/demos/alpha_agi_insight_v1/src/simulation/mats.py,,1,2.998960815863541e-09,"The method '_crowding' is a utility function that calculates the crowding distance for a population of individuals based on their fitness values. This is a common operation in evolutionary algorithms, particularly in multi-objective optimization, to maintain diversity in the population. The method is well-structured, performs a necessary operation for certain types of algorithms, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"        def outer(i, carry):
            page_indices, page_owners = carry
            seq_id = updated_seqs[""seq"", i].scalar()

            def do_alloc(carry):
                return _alloc_pages_for_seq(seq_id, carry)

            cond = jnp.logical_and(seq_id >= 0, seq_id < self.max_seqs)
            page_indices, page_owners = jax.lax.cond(cond, do_alloc, lambda c: c, (page_indices, page_owners))
            return page_indices, page_owners
",src/levanter/layers/page_table.py,PageTable,1,1.955568070542584e-08,"The method 'outer' is a part of a larger codebase that seems to be dealing with sequence allocation and page management, likely in a numerical or machine learning context using JAX. The method uses JAX's conditional execution to allocate pages based on a sequence ID, which suggests it is part of a performance-critical or resource management task. Such methods are typically essential for the functionality they provide, especially in optimized numerical computations or simulations. Therefore, it is unlikely to be deleted unless the entire approach to sequence and page management is refactored or replaced."
survived,"    def test_acreate_uses_timeout(self) -> None:
        response = types.SimpleNamespace(choices=[types.SimpleNamespace(message=types.SimpleNamespace(content=""{}""))])
        openai_mock = types.SimpleNamespace(
            ChatCompletion=types.SimpleNamespace(acreate=AsyncMock(return_value=response))
        )
        with patch.dict(os.environ, {""OPENAI_API_KEY"": ""x""}):
            with patch.object(energy_agent, ""openai"", openai_mock):
                agent = EnergyAgent()
                agent.cfg.openai_enabled = True
                asyncio.run(agent._hedge())
        openai_mock.ChatCompletion.acreate.assert_awaited()
        kwargs = openai_mock.ChatCompletion.acreate.call_args.kwargs
        self.assertEqual(kwargs.get(""timeout""), energy_agent.OPENAI_TIMEOUT_SEC)
",tests/test_energy_agent.py,TestOpenAITimeout,1,1.4166087846364157e-09,"The method `test_acreate_uses_timeout` is a unit test designed to verify that the `acreate` method of the `ChatCompletion` object is called with a specific timeout value. This is a common practice in testing to ensure that the code behaves as expected under certain conditions. The method uses mocking to simulate the behavior of external dependencies, which is a standard approach in unit testing. Since this method is part of a test suite, it is unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def is_rune_warning(self):
        '''
        is_rune_warning
        '''
        x0, y0 = self.cfg.rune_warning_top_left
        x1, y1 = self.cfg.rune_warning_bottom_right
        _, score, _ = find_pattern_sqdiff(
                        self.img_frame_gray[y0:y1, x0:x1],
                        self.img_rune_warning)
        if self.status == ""hunting"" and score < self.cfg.rune_warning_diff_thres:
            logger.info(f""[is_rune_warning] Detect rune warning on screen with score({score})"")
            return True
        else:
            return False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,8.592166611791576e-10,"The method 'is_rune_warning' is likely to survive because it serves a specific purpose in detecting a 'rune warning' on the screen. It uses image processing to compare a section of the screen with a predefined pattern and logs the result if a certain condition is met. This functionality is useful in applications where monitoring specific visual cues is necessary, such as in games or automated systems. The method is well-defined, uses configuration parameters, and integrates logging, which are good practices in software development."
survived,"    def is_player_stuck(self):
        """"""
        Detect if the player is stuck (not moving).
        If stuck for more than WATCH_DOG_TIMEOUT seconds, performs a random action.
        """"""
        dx = abs(self.loc_player_global[0] - self.loc_watch_dog[0])
        dy = abs(self.loc_player_global[1] - self.loc_watch_dog[1])

        current_time = time.time()
        if dx + dy > self.cfg.watch_dog_range:
            # Player moved, reset watchdog timer
            self.loc_watch_dog = self.loc_player_global
            self.t_watch_dog = current_time
            return False

        dt = current_time - self.t_watch_dog
        if dt > self.cfg.watch_dog_timeout:
            # watch dog idle for too long, player stuck
            self.loc_watch_dog = self.loc_player_global
            self.t_watch_dog = current_time
            logger.warning(f""[is_player_stuck] Player stuck for {dt} seconds."")
            return True
        return False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,8.592166611791576e-10,"The method 'is_player_stuck' is a utility function that checks if a player is stuck by comparing their current position to a previously recorded position. If the player hasn't moved beyond a certain range within a specified timeout, it triggers a warning and returns True, indicating the player is stuck. This functionality is crucial for game mechanics to ensure smooth gameplay and prevent players from being stuck indefinitely. Therefore, it is likely to be retained as it provides essential functionality for monitoring player movement and taking corrective actions if necessary."
survived,"    def stop(self):
        '''
        Stop capturing thread
        '''
        self.is_terminated = True
        logger.info(""[GameWindowCapturor] Terminated"")
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor,1,1.725782769012759e-08,"The method 'stop' is a simple and clear implementation that sets a termination flag and logs a message. This is a common pattern in multithreading to signal a thread to stop its execution. The method is likely to be useful in the context of managing the lifecycle of a thread, especially in applications that require clean shutdown procedures. Therefore, it is unlikely to be deleted as it serves a functional purpose in controlling the thread's execution."
survived,"    def is_rune_near_player(self):
        '''
        is_rune_near_player
        '''
        # Calculate bounding box
        h, w = self.img_frame.shape[:2]
        x0 = max(0, self.loc_player[0] - self.cfg.rune_detect_box_width // 2)
        y0 = max(0, self.loc_player[1] - self.cfg.rune_detect_box_height)
        x1 = min(w, self.loc_player[0] + self.cfg.rune_detect_box_width // 2)
        y1 = min(h, self.loc_player[1])

        # Debug
        draw_rectangle(
            self.img_frame_debug, (x0, y0), (y1-y0, x1-x0),
            (255, 0, 0), ""Rune Detection Range""
        )

        # Find rune icon near player
        if  (x1 - x0) < self.img_rune.shape[1] or \
            (y1 - y0) < self.img_rune.shape[0]:
            return False # Skip check if box is out of range
        else:
            img_roi = self.img_frame[y0:y1, x0:x1]
            loc_rune, score, _ = find_pattern_sqdiff(
                            img_roi,
                            self.img_rune,
                            mask=get_mask(self.img_rune, (0, 255, 0)))
            # # Draw rectangle for debug
            # draw_rectangle(
            #     self.img_frame_debug,
            #     (x0 + loc_rune[0], y0 + loc_rune[1]),
            #     self.img_rune.shape,
            #     (255, 0, 255),  # purple in BGR
            #     f""Rune,{round(score, 2)}""
            # )
            detect_thres = self.cfg.rune_detect_diff_thres + self.rune_detect_level*self.cfg.rune_detect_level_coef
            if score < detect_thres:
                logger.info(f""[Rune Detect] Found rune near player with score({score}),"" + \
                            f""level({self.rune_detect_level}),threshold({detect_thres})"")
                # Draw rectangle for debug
                draw_rectangle(
                    self.img_frame_debug,
                    (x0 + loc_rune[0], y0 + loc_rune[1]),
                    self.img_rune.shape,
                    (255, 0, 255),  # purple in BGR
                    f""Rune,{round(score, 2)}""
                )
                screenshot(self.img_frame_debug, ""rune_detected"")

                return True
            else:
                return False
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,1.522997951276035e-08,"The method `is_rune_near_player` is a utility function that checks if a rune is near the player by analyzing a specific region of an image. It uses image processing techniques to detect patterns and includes debugging features like drawing rectangles and logging information. Such methods are typically essential in game development or image processing applications for detecting objects or features in a scene. The method is well-structured, includes debugging and logging, and serves a clear purpose, making it unlikely to be removed unless the entire feature it supports is deprecated."
survived,"    def get_frame(self):
        '''
        
        '''
        with self.lock:
            if self.frame is None:
                return None
            # cv2.imwrite(""debug_frame.png"", self.frame)
            return cv2.cvtColor(self.frame, cv2.COLOR_BGRA2BGR)
",src/input/GameWindowCapturorForMac.py,GameWindowCapturor,1,1.1861120010657661e-08,"The method 'get_frame' is a utility function that safely retrieves the latest screen frame using a lock to ensure thread safety. It checks if the frame is None and returns None if so, otherwise it converts the frame from BGRA to BGR format using OpenCV. This method is useful in applications where screen frames need to be processed or displayed, such as in video processing or GUI applications. The use of a lock suggests that this method is designed to be thread-safe, which is a valuable feature in concurrent programming. Therefore, it is likely to be retained in the codebase."
survived,"    def get_hp_mp_exp(self):
        '''
        get_hp_mp_exp
        '''
        # HP crop
        hp_bar = self.img_frame[self.cfg.hp_bar_top_left[1]:self.cfg.hp_bar_bottom_right[1]+1,
                                self.cfg.hp_bar_top_left[0]:self.cfg.hp_bar_bottom_right[0]+1]
        # MP crop
        mp_bar = self.img_frame[self.cfg.mp_bar_top_left[1]:self.cfg.mp_bar_bottom_right[1]+1,
                                self.cfg.mp_bar_top_left[0]:self.cfg.mp_bar_bottom_right[0]+1]
        # EXP crop
        exp_bar = self.img_frame[self.cfg.exp_bar_top_left[1]:self.cfg.exp_bar_bottom_right[1]+1,
                                self.cfg.exp_bar_top_left[0]:self.cfg.exp_bar_bottom_right[0]+1]
        # HP Detection (detect empty part)
        empty_mask_hp = (hp_bar[:,:,0] == hp_bar[:,:,1]) & (hp_bar[:,:,0] == hp_bar[:,:,2])
        empty_pixels_hp = np.count_nonzero(empty_mask_hp)-6 # 6 pixel always be white
        total_pixels_hp = hp_bar.shape[0] * hp_bar.shape[1] - 6
        hp_ratio = 1 - (empty_pixels_hp / total_pixels_hp)

        # MP Detection (detect empty part)
        empty_mask_mp = (mp_bar[:,:,0] == mp_bar[:,:,1]) & (mp_bar[:,:,0] == mp_bar[:,:,2])
        empty_pixels_mp = np.count_nonzero(empty_mask_mp)-6 # 6 pixel always be white
        total_pixels_mp = mp_bar.shape[0] * mp_bar.shape[1] - 6
        mp_ratio = 1 - (empty_pixels_mp / total_pixels_mp)

        # EXP Detection (detect eexpty part)
        empty_mask_exp = (exp_bar[:,:,0] == exp_bar[:,:,1]) & (exp_bar[:,:,0] == exp_bar[:,:,2])
        eexpty_pixels_exp = np.count_nonzero(empty_mask_exp)-6 # 6 pixel always be white
        total_pixels_exp = exp_bar.shape[0] * exp_bar.shape[1] - 6
        exp_ratio = 1 - (eexpty_pixels_exp / total_pixels_exp)

        # Compute original bar dimensions
        hp_h, hp_w = hp_bar.shape[:2]
        mp_h, mp_w = mp_bar.shape[:2]
        exp_h, exp_w = exp_bar.shape[:2]

        # Overlay HP/MP/EXP text
        x_start, y_start = (250, 90)
        cv2.putText(self.img_frame_debug, f""HP: {hp_ratio*100:.1f}%"", (x_start, y_start),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)
        cv2.putText(self.img_frame_debug, f""MP: {mp_ratio*100:.1f}%"", (x_start, y_start+30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)
        cv2.putText(self.img_frame_debug, f""EXP: {exp_ratio*100:.1f}%"", (x_start, y_start+60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)

        # Paste HP/MP/EXP bar on img_frame_debug
        x_start, y_start = (410, 73)
        self.img_frame_debug[y_start:y_start+hp_h, x_start:x_start+hp_w] = hp_bar
        self.img_frame_debug[y_start+30:y_start+30+mp_h, x_start:x_start+mp_w] = mp_bar
        self.img_frame_debug[y_start+60:y_start+60+exp_h, x_start:x_start+exp_w] = exp_bar

        return hp_ratio, mp_ratio, exp_ratio
",src/legacy/mapleStoryAutoLevelUp_legacy.py,MapleStoryBot,1,9.736200303530205e-10,"The method `get_hp_mp_exp` is a utility function that extracts and calculates the health points (HP), mana points (MP), and experience points (EXP) ratios from an image frame. It uses image processing techniques to determine the filled portion of the bars representing these metrics. The method is well-structured, performs a specific task, and returns useful information that can be used elsewhere in the program. It is likely to be used in applications such as game development or monitoring tools where visual feedback on these metrics is necessary. Therefore, it is a useful method that is likely to survive."
survived,"def main(demo: str, *, print_only: bool = False) -> None:
    print(DISCLAIMER, file=sys.stderr)
    url = _demo_url(demo)
    if _remote_available(url):
        if print_only:
            print(url)
            return
        print(f""Opening {url}"")
        webbrowser.open(url)
        return

    repo_root = Path(__file__).resolve().parents[1]
    site_dir = repo_root / ""site"" / ""alpha_factory_v1"" / ""demos"" / demo
    local_page = site_dir / ""index.html""
    if not local_page.is_file():
        print(""Remote page unavailable. Building local copy..."", file=sys.stderr)
        if not _build_local_site(repo_root) or not local_page.is_file():
            print(
                f""Demo {demo} not found. Build the gallery with ./scripts/build_gallery_site.sh"",
                file=sys.stderr,
            )
            sys.exit(1)

    handler = partial(SimpleHTTPRequestHandler, directory=str(site_dir))
    with ThreadingHTTPServer((""127.0.0.1"", 0), handler) as httpd:
        port = httpd.server_address[1]
        local_url = f""http://127.0.0.1:{port}/index.html""
        print(f""Serving local copy at {local_url}"", file=sys.stderr)
        thread = threading.Thread(target=httpd.serve_forever, daemon=True)
        thread.start()
        try:
            if print_only:
                print(local_url)
            else:
                webbrowser.open(local_url)
            thread.join()
        except KeyboardInterrupt:
            pass
",scripts/open_subdir_demo.py,,1,2.0611536181902033e-09,"The method 'main' is a utility function that provides a way to open a demo either from a remote URL or a local server. It includes error handling, local server setup, and a print-only option. These features are useful for both development and production environments, making the function versatile and valuable. There is no indication that this functionality is obsolete or redundant, suggesting it will be retained."
survived,"    def log_message(self, *_args: str) -> None:  # pragma: no cover - quiet
        pass
",tests/test_aiga_openai_bridge_offline.py,_Handler,0,0.9999999943972036,"The method `log_message` is defined with a `pragma: no cover` comment, indicating that it is intentionally excluded from test coverage. This suggests that the method is not critical to the core functionality of the code, possibly serving as a placeholder or a method that is not yet implemented. The method currently does nothing (it only contains a `pass` statement), which further implies that it might be removed in the future if it remains unused or unnecessary. Therefore, it is likely to be deleted."
survived,"def test_restart_alert(monkeypatch) -> None:
    sent: dict[str, object] = {}

    def fake_post(url: str, *, json=None, timeout=None):
        sent[""url""] = url
        sent[""payload""] = json
        return type(""R"", (), {""status_code"": 200})()

    monkeypatch.setattr(alerts, ""requests"", type(""M"", (), {""post"": fake_post}))
    monkeypatch.setattr(orchestrator, ""Ledger"", DummyLedger)
    monkeypatch.setattr(orchestrator.Orchestrator, ""_init_agents"", lambda self: [])

    settings = config.Settings(bus_port=0, alert_webhook_url=""http://hook"")
    orch = orchestrator.Orchestrator(settings)
    runner = orchestrator.AgentRunner(DummyAgent(orch.bus, orch.ledger))

    orch._record_restart(runner)

    assert sent[""url""] == ""http://hook""
    assert (
        sent[""payload""].get(""text"") == ""dummy restarted""
        if ""text"" in sent[""payload""]
        else sent[""payload""].get(""content"") == ""dummy restarted""
    )
",tests/test_alert_webhook.py,,1,9.736200303530205e-10,"The method `test_restart_alert` is a unit test function that uses the `monkeypatch` fixture to mock certain behaviors and test the functionality of the `orchestrator` module. It verifies that a restart alert is sent to a specified webhook URL with the correct payload. This is a typical use case for unit tests in software development, ensuring that the code behaves as expected under certain conditions. Since testing is a crucial part of maintaining code quality and reliability, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"    def __init__(self, *_a, **_kw) -> None:
        self.events = []
",tests/test_alert_webhook.py,DummyLedger,1,7.73442280641062e-08,"The method is a constructor for a class, indicated by the name `__init__`. Constructors are essential for initializing new objects in object-oriented programming. The presence of `self.events = []` suggests that this constructor is setting up an instance variable, which is a common and necessary practice. Therefore, it is unlikely that this method will be deleted as it serves a fundamental role in object initialization."
survived,"    def close(self) -> None:  # pragma: no cover - test stub
        pass
",tests/test_alert_webhook.py,DummyLedger,1,1.8553915987649156e-07,"The method 'close' is a placeholder or a stub, indicated by the 'pass' statement and the comment '# pragma: no cover - test stub'. This suggests that the method is intended to be implemented in the future or is used as a placeholder for testing purposes. Such methods are often retained in the codebase to maintain the structure or to be completed later. Therefore, it is likely to survive."
survived,"    def __init__(self, bus: messaging.A2ABus, ledger: DummyLedger) -> None:
        super().__init__(""dummy"", bus, ledger)
",tests/test_alert_webhook.py,DummyAgent,1,8.31527990378713e-07,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This particular constructor is initializing a class with a messaging bus and a ledger, which suggests it is part of a system that requires these components for its operation. Since constructors are necessary for creating instances of classes, it is unlikely that this method will be deleted unless the entire class is refactored or removed."
survived,"def _gallery_url() -> str:
    remote = subprocess.check_output([""git"", ""config"", ""--get"", ""remote.origin.url""], text=True).strip()
    repo_path = remote.split(""github.com"")[-1].lstrip("":/"").removesuffix("".git"")
    org, repo = repo_path.split(""/"", 1)
    return f""https://{org}.github.io/{repo}/alpha_factory_v1/demos/""
",scripts/launch_gallery.py,,1,6.825604231969389e-08,"The method '_gallery_url' constructs a URL based on the remote origin URL of a Git repository. It uses subprocess to execute a git command, which can be error-prone and platform-dependent. However, the method itself is straightforward and serves a specific purpose of generating a URL for a gallery. Unless there is a significant change in how URLs need to be constructed or a shift away from using GitHub, this method is likely to survive as it fulfills a specific need without any apparent issues."
survived,"    def assimilate_handler(self, wu, results, canonical_result):
        """"""
        Assimilates a canonical result, in this case assimilation
        means dumping the contents of the result to the log.
        Also calls report_errors to log any problems present in the workunit (wu)
        """"""

        # check for valid wu.canonical_result
        if wu.canonical_result:
            # do application specific processing
            self.logNormal(""[%s] Found canonical result\n"", wu.name)
            result = self.get_file_path(canonical_result)
            for line in open(result, 'r').readlines():
                line = line.strip()
                self.logDebug(""  [%s] Answer found %s %s\n"", canonical_result.name, line[-32:], line[:-33])
        else:
            self.logNormal(""[%s] No canonical result\n"", wu.name)

        if self.report_errors(wu):
            # report_errors returns true if error state was present
            # perhaps add some special logic here
            # even if no logic is required, report_errors should be called
            pass
",sched/testasm.py,TestAssimilator,1,4.944450477491054e-09,"The method 'assimilate_handler' is likely to survive because it contains essential functionality for processing and logging results. It checks for a canonical result, logs the findings, and handles error reporting. These are typical and necessary operations in many systems that process and validate data. Additionally, the method is well-documented, indicating its importance and clarity in its purpose."
survived,"    def test_delta_must_be_within_range(self) -> None:
        with self.assertRaises(ValueError):
            run_sim(agents=1, rounds=10, delta=-0.1, stake=1.0)
        with self.assertRaises(ValueError):
            run_sim(agents=1, rounds=10, delta=1.1, stake=1.0)
",tests/test_governance_sim.py,TestGovernanceSim,1,1.2501528648238603e-09,"The method `test_delta_must_be_within_range` is a unit test designed to ensure that the `run_sim` function raises a `ValueError` when the `delta` parameter is outside the valid range (presumably between 0 and 1). This is a common and necessary test to validate input constraints and ensure the robustness of the `run_sim` function. Such tests are crucial for maintaining code quality and preventing invalid inputs from causing unexpected behavior. Therefore, this method is likely to be retained as part of the test suite."
survived,"def test_service_worker_registration_failure_toast() -> None:
    dist = Path(__file__).resolve().parents[1] / ""dist"" / ""index.html""
    url = dist.as_uri()

    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.add_init_script(
            ""navigator.serviceWorker.register = () => Promise.reject('fail')""
        )
        page.goto(url)
        page.wait_for_selector(""#controls"")
        page.wait_for_function(
            ""document.getElementById('toast').textContent.includes('offline mode disabled')""
        )
        browser.close()
",alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/tests/test_pwa_offline.py,,1,7.194132978569833e-09,"The method `test_service_worker_registration_failure_toast` is a test function that verifies the behavior of a web page when service worker registration fails. It uses Playwright to automate a browser, injects a script to simulate a failure in service worker registration, and checks if the appropriate toast message is displayed. This is a valid and useful test case for ensuring the web application's offline mode handling is correctly implemented. Given its utility in testing a specific failure scenario, it is likely to be retained in the codebase."
survived,"def check_openai_agents_version(min_version: str = ""0.0.14"") -> bool:
    """"""Verify ``openai_agents`` is new enough when installed.""""""
    import importlib

    spec = importlib.util.find_spec(""openai_agents"")
    if spec is None:  # not installed
        return True

    mod = importlib.import_module(""openai_agents"")
    version = getattr(mod, ""__version__"", ""0"")
    if _version_lt(version, min_version):
        banner(
            f""openai_agents {version} detected; >={min_version} required"",
            ""RED"",
        )
        return False
    banner(f""openai_agents {version} detected"", ""GREEN"")
    return True
",alpha_factory_v1/scripts/preflight.py,,1,7.194132978569833e-09,"The method `check_openai_agents_version` is a utility function that checks if the installed version of the `openai_agents` package meets a minimum version requirement. This is a common practice in software development to ensure compatibility and prevent runtime errors due to version mismatches. The function is useful for maintaining software stability and is likely to be retained as it provides a necessary check for dependencies. Additionally, the function is well-structured and uses standard Python libraries, making it efficient and easy to understand."
survived,"        def _fake_find_spec(name: str, *args: Any, **kwargs: Any) -> object:
            if name == ""openai_agents"":
                return object()
            return orig_find_spec(name, *args, **kwargs)
",tests/test_preflight_openai_agents_version.py,TestPreflightOpenAIAgentsVersion,1,1.3007124774680372e-05,"The method `_fake_find_spec` is a mock or a stub function used to override or simulate the behavior of a real function, likely for testing purposes. It checks if the module name is 'openai_agents' and returns a generic object if true, otherwise it calls the original function `orig_find_spec`. This kind of function is often used in testing environments to control or simulate specific conditions. Since it serves a specific purpose in testing or development, it is likely to be retained as long as the testing or simulation requirement exists."
survived,"    def _version_lt(a: str, b: str) -> bool:
        return Version(a) < Version(b)
",alpha_factory_v1/scripts/preflight.py,,1,1.522997951276035e-08,"The method _version_lt is a utility function that compares two version strings using the Version class. Such utility functions are often useful in various parts of a codebase where version comparison is needed. Unless there is a significant change in how versions are handled or a more efficient library function is available, this method is likely to survive as it provides a clear and concise way to compare versions."
survived,"def ensure_model() -> None:
    """"""Ensure the checkpoint files are available.""""""
    dest = MODEL_DIR / MODEL_NAME
    if dest.exists():
        return
    script = Path(__file__).resolve().parents[2] / ""scripts"" / ""download_openai_gpt2.py""
    subprocess.run([sys.executable, str(script), MODEL_NAME, ""--dest"", str(MODEL_DIR)], check=True)
",alpha_factory_v1/demos/gpt2_small_cli/gpt2_cli.py,,1,2.0611536181902033e-09,"The method 'ensure_model' is responsible for checking the existence of a model directory and downloading the model if it doesn't exist. This is a crucial part of ensuring that the necessary resources are available for the application to function correctly. The method is simple, clear, and performs a necessary check before attempting to download, which is a good practice. There is no indication that this functionality is obsolete or redundant, and it is likely to be a necessary part of the application's setup process. Therefore, it is likely to be retained in the codebase."
survived,"        def __init__(self, *args: object, **kwargs: object) -> None:
            pass
",tests/test_gpt2_cli_demo.py,FakeTokenizer,0,0.9999724643101549,"The method is a constructor that takes variable arguments and keyword arguments but does nothing with them, as it only contains a 'pass' statement. This is typically a placeholder or a default implementation that might be intended for future expansion or to satisfy an interface requirement. However, if it remains unchanged and unused, it is likely to be deleted in a future refactor to clean up the codebase."
survived,"def test_gpt2_cli_help() -> None:
    result = subprocess.run([sys.executable, str(SCRIPT), ""--help""], capture_output=True, text=True)
    assert result.returncode == 0
    assert ""usage"" in result.stdout.lower()
",tests/test_gpt2_cli_demo.py,,1,1.3440409770490404e-08,"The method 'test_gpt2_cli_help' is a test function that checks if the command-line interface (CLI) for a script provides help information correctly. It uses subprocess to run the script with the '--help' flag and asserts that the return code is 0 (indicating success) and that the output contains the word 'usage'. This is a standard way to test CLI help functionality, ensuring that users can access help information. Such tests are crucial for maintaining usability and are unlikely to be removed unless the CLI itself is deprecated or significantly changed."
survived,"        def from_pretrained(cls, name: str) -> ""FakeModel"":
            return cls()
",tests/test_gpt2_cli_demo.py,FakeModel,0,0.9999810748526188,"The method `from_pretrained` is a common pattern in machine learning libraries for loading pre-trained models. However, in this implementation, it simply returns a new instance of the class without utilizing the `name` parameter to load any specific pre-trained model. This makes the method misleading and not functional for its intended purpose. Unless there is additional context or implementation elsewhere that justifies this behavior, it is likely to be deleted or refactored to properly load a pre-trained model based on the `name` parameter."
survived,"def test_compose_health(compose_stack: None) -> None:
    assert _wait(""http://localhost:8000/healthz""), ""/healthz endpoint not healthy""
    assert _wait(""http://localhost:8000/readiness""), ""/readiness endpoint not healthy""",tests/test_compose_health.py,,1,1.0467401685178159e-08,"The method `test_compose_health` is a test function that checks the health and readiness of a service by asserting the responses from two endpoints. This is a common practice in testing environments to ensure that services are running correctly. The method is simple, clear, and serves a specific purpose in the testing suite. There is no indication that it is obsolete or redundant, and it is likely to be useful for maintaining the reliability of the service. Therefore, it is likely to be retained."
survived,"    def test_minimum_demo_count(self) -> None:
        base = validate_demos.DEFAULT_DIR
        demos = [
            d
            for d in os.listdir(base)
            if os.path.isdir(os.path.join(base, d))
            and not d.startswith(""."")
            and not d.startswith(""__"")
        ]
        self.assertGreaterEqual(len(demos), 10)
",tests/test_demo_quality.py,TestDemoDirectoryCount,1,1.6052280526088547e-09,"The method `test_minimum_demo_count` is a unit test that checks if the number of demo directories in a specified base directory is at least 10. This is a straightforward and useful test to ensure that a minimum number of demo directories are present, which might be a requirement for the application to function correctly or for testing purposes. Since it serves a clear purpose in validating the state of the file system, it is likely to be retained in the codebase."
survived,"    def undo_task(self) -> dict[str, bool]:
        return {""ok"": undo_last_edit()}",src/self_edit/tools.py,FileToolsADK,1,4.0586521248284276e-10,"The method `undo_task` is a simple wrapper around the function `undo_last_edit()`, returning its result in a dictionary with a key ""ok"". This method is likely to be useful in contexts where the result of `undo_last_edit()` needs to be communicated in a standardized format, such as in APIs or user interfaces. The method is straightforward, has a clear purpose, and does not introduce unnecessary complexity. Therefore, it is likely to be retained in the codebase."
survived,"def undo_last_edit() -> bool:
    """"""Revert the last edit operation if possible.""""""
    if not _EDIT_HISTORY:
        return False
    p, text = _EDIT_HISTORY.pop()
    p.write_text(text, encoding=""utf-8"")
    return True
",src/self_edit/tools.py,,1,4.0586521248284276e-10,"The method 'undo_last_edit' is likely to survive because it provides a useful functionality of reverting the last edit operation, which is a common requirement in many applications. The method is well-defined, checks for the existence of an edit history before attempting to undo, and returns a boolean indicating success or failure, which is a good practice for such operations."
survived,"    def _compute_root(self, cids: Iterable[str]) -> str:
        hashes = [hashlib.sha256(c.encode()).digest() for c in sorted(cids)]
        if not hashes:
            return """"
        while len(hashes) > 1:
            if len(hashes) % 2 == 1:
                hashes.append(hashes[-1])
            hashes = [hashlib.sha256(hashes[i] + hashes[i + 1]).digest() for i in range(0, len(hashes), 2)]
        return hashes[0].hex()
",src/archive/hash_archive.py,HashArchive,1,1.1032560311263802e-09,"The method '_compute_root' is a utility function that computes a hash-based root from a list of strings. This is a common operation in cryptographic applications, such as building a Merkle tree. The method is well-implemented, handling edge cases like an empty input list and ensuring even pairing of hashes. Given its utility in ensuring data integrity and its correct implementation, it is likely to be retained in the codebase."
survived,"    def _ipfs_add(self, tarball: Path) -> str:
        cmd = shutil.which(""ipfs"")
        if cmd:
            try:
                proc = subprocess.run([cmd, ""add"", ""-Q"", str(tarball)], capture_output=True, text=True, check=True)
                return proc.stdout.strip()
            except Exception:
                pass
        return hashlib.sha256(tarball.read_bytes()).hexdigest()
",src/archive/hash_archive.py,HashArchive,1,9.736200303530205e-10,"The method '_ipfs_add' is likely to survive because it provides a useful functionality of adding a file to IPFS (InterPlanetary File System) if the IPFS command is available, and falls back to generating a SHA-256 hash of the file if not. This dual functionality ensures that the method is robust and can handle scenarios where IPFS is not installed, making it versatile and reliable. Additionally, the use of subprocess to run the IPFS command and the handling of exceptions make the method well-structured and error-tolerant."
survived,"def parse_score(text: str) -> Sequence[float]:
    return [float(x) for x in text.split("","")]
",scripts/verify_snark.py,,1,2.3355930333443423e-09,"The method 'parse_score' is a simple utility function that converts a comma-separated string of numbers into a list of floats. This is a common task in data processing, and the method is straightforward, efficient, and useful in many contexts where data is received as a string and needs to be converted into a numerical format for further processing. There are no apparent issues with the implementation, and it serves a clear purpose, making it likely to be retained."
survived,"def _ipfs_add(path: Path) -> str:
    cmd = shutil.which(""ipfs"")
    if cmd:
        try:
            proc = subprocess.run([cmd, ""add"", ""-Q"", str(path)], capture_output=True, text=True, check=True)
            return proc.stdout.strip()
        except Exception:
            pass
    return hashlib.sha256(path.read_bytes()).hexdigest()
",src/utils/snark.py,,1,6.69158608681505e-10,"The method `_ipfs_add` is likely to survive because it provides a useful functionality of adding a file to IPFS (InterPlanetary File System) if the IPFS command is available, and falls back to generating a SHA-256 hash of the file if not. This dual functionality ensures that the method is robust and can handle scenarios where IPFS is not installed, making it versatile and reliable. Additionally, the use of subprocess to execute the IPFS command and handle exceptions gracefully is a good practice, enhancing the method's stability."
survived,"def _parse_simple_yaml(lines: List[str], start: int, indent: int) -> tuple[Any, int]:
    """"""Parse a simple block of YAML starting at ``start`` with ``indent``.""""""

    # If the first relevant line starts with a list indicator, parse a list
    i = start
    while i < len(lines) and not lines[i].strip():
        i += 1
    if (
        i < len(lines)
        and lines[i].lstrip().startswith(""- "")
        and (len(lines[i]) - len(lines[i].lstrip("" "")) == indent)
    ):
        lst: List[Any] = []
        while i < len(lines):
            line = lines[i]
            if not line.strip():
                i += 1
                continue
            current_indent = len(line) - len(line.lstrip("" ""))
            if current_indent < indent:
                break
            if not line.lstrip().startswith(""- ""):
                break
            item_content = line.lstrip()[2:].strip()
            i += 1
            if item_content:
                if "":"" in item_content:
                    k, v = item_content.split("":"", 1)
                    item: Any = {k.strip(): _convert_scalar(v.strip())}
                else:
                    item = _convert_scalar(item_content)
            else:
                item = {}
            # parse subfields
            while i < len(lines):
                sub_line = lines[i]
                sub_indent = len(sub_line) - len(sub_line.lstrip("" ""))
                if sub_indent <= current_indent:
                    break
                sub_key, sub_val = sub_line.strip().split("":"", 1)
                item[sub_key.strip()] = _convert_scalar(sub_val.strip())
                i += 1
            lst.append(item)
        return lst, i

    result: dict[str, Any] = {}
    while i < len(lines):
        line = lines[i]
        if not line.strip():
            i += 1
            continue
        current_indent = len(line) - len(line.lstrip("" ""))
        if current_indent < indent:
            break
        if current_indent > indent:
            raise YAMLError(""Invalid indentation"")
        stripped = line.strip()
        if "":"" not in stripped:
            raise YAMLError(f""Invalid line: {line}"")
        key, rest = stripped.split("":"", 1)
        key = key.strip()
        rest = rest.strip()
        i += 1
        if rest == """":
            # Determine if next block is a list or nested mapping
            if i < len(lines) and lines[i].lstrip().startswith(""- ""):
                lst: List[Any] = []
                while i < len(lines):
                    item_line = lines[i]
                    if len(item_line) - len(item_line.lstrip("" "")) < indent + 2:
                        break
                    if not item_line.lstrip().startswith(""- ""):
                        break
                    item_content = item_line.lstrip()[2:].strip()
                    i += 1
                    item: Any
                    if item_content == """":
                        item = {}
                    elif "":"" in item_content:
                        k, v = item_content.split("":"", 1)
                        item = {k.strip(): _convert_scalar(v.strip())}
                    else:
                        item = _convert_scalar(item_content)
                    # Parse additional properties for the list item
                    while i < len(lines):
                        sub_line = lines[i]
                        sub_indent = len(sub_line) - len(sub_line.lstrip("" ""))
                        if sub_indent <= indent + 2:
                            break
                        sub_key, sub_val = sub_line.strip().split("":"", 1)
                        item[sub_key.strip()] = _convert_scalar(sub_val.strip())
                        i += 1
                    lst.append(item)
                result[key] = lst
            else:
                sub_obj, i = _parse_simple_yaml(lines, i, indent + 2)
                result[key] = sub_obj
        else:
            result[key] = _convert_scalar(rest)
    return result, i
",src/yaml/__init__.py,,1,2.5109990926928157e-08,"The method `_parse_simple_yaml` is a utility function designed to parse a simple block of YAML data. It handles both lists and dictionaries, manages indentation, and converts scalar values. This functionality is essential for applications that need to process YAML data without relying on external libraries. Given its utility and the fact that YAML parsing is a common requirement in many software projects, it is likely that this method will be retained. Additionally, the method appears to be well-structured and handles various edge cases, which further supports its continued use."
survived,"def toyota_checksum(address: int, sig, d: bytearray) -> int:
  s = len(d)
  addr = address
  while addr:
    s += addr & 0xFF
    addr >>= 8
  for i in range(len(d) - 1):
    s += d[i]
  return s & 0xFF",opendbc/car/toyota/toyotacan.py,,1,1.725782769012759e-08,"The method 'toyota_checksum' is a utility function that calculates a checksum for a given address and data. It is a simple and efficient implementation that is likely used in a larger system for data integrity verification. Such functions are common in automotive software, especially for communication protocols or data validation. The method is straightforward, performs a necessary task, and does not have any apparent issues or redundancies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"def body_checksum(address: int, sig, d: bytearray) -> int:
  crc = 0xFF
  poly = 0xD5
  for i in range(len(d) - 2, -1, -1):
    crc ^= d[i]
    for _ in range(8):
      if crc & 0x80:
        crc = ((crc << 1) ^ poly) & 0xFF
      else:
        crc = (crc << 1) & 0xFF
  return crc",opendbc/car/body/bodycan.py,,1,1.0467401685178159e-08,"The method 'body_checksum' is a utility function that calculates a checksum using a specific polynomial (0xD5) and a CRC-like algorithm. Such functions are often used in data integrity checks, error detection, or communication protocols. The method is concise, performs a specific task, and does not have any apparent issues or redundancies. It is likely to be useful in contexts where data integrity is crucial, such as embedded systems or network communications. Therefore, it is more likely to be retained in the codebase."
survived,"async def plan_trip(
    preferences: Annotated[str, Field(description=""Your travel preferences"")],
    ctx: EnrichContext,
) -> list[Destination]:
    """"""Return three destinations that best match the given preferences.""""""

    bullet_list = ""\n"".join(f""- {d.name}: {d.summary}"" for d in DESTINATIONS)
    prompt = (
        ""Select the three best destinations from the list below based on the ""
        ""given preferences. Reply with a JSON list of names only.\nPreferences: ""
        f""{preferences}\n\n{bullet_list}""
    )
    result = await ctx.sampling(
        prompt,
        model_preferences=prefer_fast_model(),
        max_tokens=50,
    )
    try:
        names = json.loads(result.content.text)
    except Exception:
        return []
    return [d for d in DESTINATIONS if d.name in names]
",examples/server_side_llm_travel_planner/app.py,,1,1.8189616842444243e-09,"The method 'plan_trip' is a well-defined function that takes user preferences and context to return a list of destinations. It uses an asynchronous approach to interact with a context object for sampling, which is a modern and efficient way to handle I/O operations. The function also includes error handling for JSON parsing, which is a good practice. Given these factors, the method is likely to be useful and relevant for applications involving travel planning, and thus it is likely to survive."
survived,"def test_js_serializer_malformed_json(tmp_path: Path) -> None:
    script = tmp_path / ""run.mjs""
    script.write_text(
        f""import {{load}} from '{SERIALIZER.resolve().as_posix()}';\n""
        ""try {\n""
        ""  load(process.argv[2]);\n""
        ""} catch (err) {\n""
        ""  console.error(err.message);\n""
        ""  process.exit(1);\n""
        ""}\n""
    )
    result = subprocess.run([""node"", script, ""{invalid""], capture_output=True, text=True)
    assert result.returncode == 1",tests/test_serializer.py,,1,5.211412485172657e-10,"The method 'test_js_serializer_malformed_json' is a test function designed to verify the behavior of a JavaScript serializer when it encounters malformed JSON input. This is a common and important test case to ensure that the serializer handles errors gracefully and exits with the correct status code. Such tests are crucial for maintaining the robustness and reliability of software, especially when dealing with external inputs. Therefore, it is likely that this method will be retained in the codebase as it serves a valuable purpose in testing error handling."
survived,"def _run_client() -> None:
    with TestClient(api_server.app):
        pass
",alpha_factory_v1/demos/alpha_agi_insight_v1/tests/test_api_token_required.py,,0,0.9999998144608401,"The method `_run_client` is a private method (indicated by the underscore prefix) and currently does not perform any operations other than creating a `TestClient` context which is immediately exited without any actions. This suggests that the method is either incomplete or serves no functional purpose in its current state. Without any additional context or usage, it is likely to be considered redundant and may be deleted in future iterations of the code."
survived,"def test_named_param_annotation():
    def foo(x: Named[""batch embed""]):
        pass

    axes = typing.get_args(foo.__annotations__[""x""])[1]
    assert axes.before == (""batch"", ""embed"")
",tests/test_namedarray_typing.py,,0,0.9999998555019682,"The method `test_named_param_annotation` is testing a feature that involves type annotations with a custom type `Named`. This is a specific use case that might not be widely applicable or supported in standard Python libraries. The use of `Named` in type annotations is not a common practice and might be part of an experimental or niche library. Additionally, the test seems to rely on specific behavior of the `Named` type that may not be guaranteed across different environments or Python versions. Given these factors, the method is likely to be deleted as it may not be maintainable or relevant in the long term."
survived,"    def foo(x: Named[""batch embed""]):
        pass
",tests/test_namedarray_typing.py,,0,0.9999930377415741,"The method uses a type hint 'Named[""batch embed""]' which is not a standard or recognized type hint in Python. This suggests that the code might be using a custom or incorrect type hinting mechanism. Without further context or a proper definition of 'Named', this method is likely to be considered incorrect or non-functional in a typical Python environment. Therefore, it is likely to be deleted or refactored to use proper type hinting."
survived,"def tpus_per_node(tpu_type: str) -> int:
    """"""Return the number of TPU chips per node for a given TPU type.""""""
    if tpu_type in {""v4-8"", ""v5p-8""}:
        return 4
    match = re.search(r""-(\d+)$"", tpu_type)
    if not match:
        raise ValueError(f""Cannot parse TPU type: {tpu_type}"")
    chips = int(match.group(1))
    if chips > 8:
        raise ValueError(""Only single tpu nodes are supported with the CLI"")
    return chips
",marin/run/ray_run.py,,1,4.0586521248284276e-10,"The method 'tpus_per_node' is likely to survive because it provides a clear and useful functionality: determining the number of TPU chips per node based on the TPU type. It includes error handling for invalid inputs and supports a range of TPU types, making it versatile and robust. Additionally, the use of regular expressions to parse the TPU type string is a common and effective approach for such tasks. There is no indication of deprecated practices or inefficiencies that would necessitate its deletion."
survived,"def test_tpus_per_node():
    assert tpus_per_node(""v4-8"") == 4
    assert tpus_per_node(""v5p-8"") == 4
    assert tpus_per_node(""v5e-4"") == 4
    assert tpus_per_node(""v5e-2"") == 2
    with pytest.raises(ValueError):
        tpus_per_node(""v5e-16"")",tests/test_ray_run.py,,1,7.194132978569833e-09,"The method `test_tpus_per_node` is a unit test function that verifies the behavior of the `tpus_per_node` function. It checks for correct outputs for valid inputs and ensures that an exception is raised for an invalid input. This is a typical and necessary part of software development to ensure code reliability and correctness. Since testing is a crucial aspect of maintaining code quality, it is unlikely that this method will be deleted unless the `tpus_per_node` function itself is removed or significantly changed. Therefore, the method will likely survive."
survived,"    def to_json(self, report: SummaryReport) -> str:
        """"""Return a JSON representation of the report.""""""
        return json.dumps(asdict(report), indent=2)
",src/meta_agent/evaluation/reporting.py,ReportingModule,1,6.69158608681505e-10,"The method 'to_json' is a straightforward utility function that converts a 'SummaryReport' object into a JSON string. This is a common and useful operation in many applications where data serialization is required, especially for web services, APIs, or data storage. The method is simple, clear, and performs a necessary function without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def summarize(self, result: CollectionResult) -> SummaryReport:
        """"""Create a :class:`SummaryReport` from a collection result.""""""
        return SummaryReport(
            exit_code=result.exit_code,
            passed=result.exit_code == 0,
            duration=result.duration,
            stdout=result.stdout,
            stderr=result.stderr,
        )
",src/meta_agent/evaluation/reporting.py,ReportingModule,1,3.160881453314576e-10,"The method 'summarize' is a straightforward utility function that converts a 'CollectionResult' into a 'SummaryReport'. It is likely to be a useful part of a larger system where results need to be summarized and reported. The method is simple, clear, and serves a specific purpose without any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"def egyptianDivide(dividend, divisor):
    if dividend < 0 or divisor <= 0:
        panic(""Invalid argument(s)"")
    if dividend < divisor:
        return DivResult(q=0, r=dividend)
    powers = [1]
    doublings = [divisor]
    doubling = divisor * 2
    while doubling <= dividend:
        powers = powers + [powers[len(powers) - 1] * 2]
        doublings = doublings + [doubling]
        doubling = doubling * 2
    ans = 0
    accum = 0
    i = len(doublings) - 1
    while i >= 0:
        if accum + doublings[i] <= dividend:
            accum = accum + doublings[i]
            ans = ans + powers[i]
            if accum == dividend:
                break
        i = i - 1
    return DivResult(q=ans, r=dividend - accum)
",tests/rosetta/transpiler/Python/egyptian-division.py,,1,6.023574641292144e-08,"The method 'egyptianDivide' is a custom implementation of division using the Egyptian multiplication method. It is a unique approach that may not be commonly found in standard libraries, making it a candidate for survival. Additionally, the method handles edge cases such as invalid arguments and provides a structured result with quotient and remainder, which adds to its robustness. Unless there is a significant reason to remove it, such as redundancy with existing methods or performance issues, it is likely to be retained."
survived,"def elementWiseMM(m1, m2, f):
    z = []
    r = 0
    while r < len(m1):
        row = []
        c = 0
        while c < len(m1[r]):
            row = row + [f(m1[r][c], m2[r][c])]
            c = c + 1
        z = z + [row]
        r = r + 1
    return z
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,1.2501528648238603e-09,"The method 'elementWiseMM' is a utility function that performs element-wise operations on two matrices using a provided function 'f'. This is a common operation in data processing and numerical computations, making it a useful and reusable piece of code. The method is well-defined, does not have any apparent bugs, and serves a clear purpose. Therefore, it is likely to be retained in the codebase."
survived,"def singleInit(cells):
    s = """"
    i = 0
    while i < cells:
        if i == (cells // 2):
            s = s + ""1""
        else:
            s = s + ""0""
        i = i + 1
    return s
",tests/rosetta/transpiler/Python/elementary-cellular-automaton.py,,1,2.2159489282323004e-08,"The method 'singleInit' is a simple utility function that generates a string of '0's with a single '1' in the middle. This type of function can be useful in various contexts, such as initializing a grid or array for simulations, games, or other computational tasks. The logic is straightforward and the function is not overly complex or redundant, which suggests it has a clear purpose and utility. Therefore, it is likely to be retained in the codebase."
survived,"def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())
",tests/rosetta/transpiler/Python/empty-string-1.py,,1,9.237449576640118e-09,"The method _now() is a utility function that generates a pseudo-random number based on a seed if _now_seeded is True, or returns the current time in nanoseconds if not. This function is useful for testing or scenarios where deterministic behavior is needed. It is a private method (indicated by the underscore prefix), suggesting it is intended for internal use within a module or class. Such utility functions are often retained unless they are replaced by a more efficient or standardized approach. Without additional context indicating redundancy or obsolescence, it is likely to survive."
survived,"def revInt(n):
    r = 0
    t = n
    while t > 0:
        r = r * 10 + t % 10
        t = int((t // 10))
    return r
",tests/rosetta/transpiler/Python/emirp-primes.py,,1,1.637377179507321e-07,"The method 'revInt' is a simple and efficient implementation to reverse the digits of an integer. It uses basic arithmetic operations and a loop to achieve the reversal, which is a common task in programming. The code is clear, concise, and does not rely on any deprecated or complex constructs. Therefore, there is no reason for this method to be deleted as it serves a useful purpose and is implemented correctly."
survived,"def powf(base, exp):
    if exp == 0.5:
        guess = base
        i = 0
        while i < 20:
            guess = (guess + base // guess) / 2.0
            i = i + 1
        return guess
    result = 1.0
    n = int(exp)
    i = 0
    while i < n:
        result = result * base
        i = i + 1
    return result
",tests/rosetta/transpiler/Python/element-wise-operations.py,,0,0.999999057755336,"The method 'powf' is a custom implementation of a power function, which calculates the square root for an exponent of 0.5 and uses a simple loop for other integer exponents. However, Python's standard library already provides a robust and optimized power function through 'math.pow' and the '**' operator, which are more efficient and handle edge cases better. Additionally, the method uses integer division for the square root calculation, which is incorrect and can lead to inaccurate results. Given these factors, it's likely that this method will be deleted in favor of using the built-in functions."
survived,"def sub(a, b):
    return a - b
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,1.0467401685178159e-08,"The method 'sub' is a simple and clear implementation of a subtraction operation between two numbers. It is a fundamental operation that is often used in various programming tasks. The method is correctly implemented and serves a basic purpose that is likely to be reused in different contexts. Therefore, it is unlikely to be deleted as it provides a necessary arithmetic function."
survived,"def main():
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    _bench_start = _now()
    m1 = [[3.0, 1.0, 4.0], [1.0, 5.0, 9.0]]
    m2 = [[2.0, 7.0, 1.0], [8.0, 2.0, 8.0]]
    printMatrix(""m1:"", m1)
    printMatrix(""m2:"", m2)
    print("""")
    printMatrix(""m1 + m2:"", elementWiseMM(m1, m2, add))
    printMatrix(""m1 - m2:"", elementWiseMM(m1, m2, sub))
    printMatrix(""m1 * m2:"", elementWiseMM(m1, m2, mul))
    printMatrix(""m1 / m2:"", elementWiseMM(m1, m2, div))
    printMatrix(""m1 ^ m2:"", elementWiseMM(m1, m2, exp))
    print("""")
    s = 0.5
    print(""s: "" + str(s))
    printMatrix(""m1 + s:"", elementWiseMS(m1, s, add))
    printMatrix(""m1 - s:"", elementWiseMS(m1, s, sub))
    printMatrix(""m1 * s:"", elementWiseMS(m1, s, mul))
    printMatrix(""m1 / s:"", elementWiseMS(m1, s, div))
    printMatrix(""m1 ^ s:"", elementWiseMS(m1, s, exp))
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({""duration_us"": (_bench_end - _bench_start)//1000, ""memory_bytes"": _bench_mem_end*1024, ""name"": ""main""}, indent=2))
",tests/rosetta/transpiler/Python/element-wise-operations.py,,1,1.0467401685178159e-08,"The method 'main' is a comprehensive function that performs a series of matrix operations and prints the results. It also benchmarks the execution time and memory usage, which can be useful for performance analysis. The method is well-structured and serves a clear purpose in demonstrating matrix operations and performance metrics. Therefore, it is likely to be retained in the codebase."
survived,"def main() -> None:
    parser = argparse.ArgumentParser(description=""Backup Lidarr artists to CSV"")
    parser.add_argument(
        ""-c"",
        ""--config"",
        default=""./config.ini"",
        help=""Path to config.ini"",
    )
    parser.add_argument(
        ""-o"",
        ""--output"",
        default=""./lidarr_backup.csv"",
        help=""Output CSV file"",
    )

    args = parser.parse_args()

    try:
        backup_lidarr(args.config, args.output)
        print(""Done..."")
    except Exception as exc:  # keep CLI simple
        print(f""Error: {exc}"")
",backup_lidarr_2csv.py,,1,4.1399375473943306e-08,"The method is a main function that sets up a command-line interface (CLI) for a script that backs up Lidarr artists to a CSV file. It uses argparse to handle command-line arguments, which is a common and useful practice for scripts that need to be run with different configurations. The function also includes error handling to catch exceptions and print error messages, which is important for user feedback. These are all good practices for a CLI tool, making the function likely to be retained."
survived,"def docker_compose_cmd() -> list[str]:
    if subprocess.run([""docker"", ""compose"", ""version""], capture_output=True).returncode == 0:
        return [""docker"", ""compose""]
    if subprocess.run([""docker-compose"", ""--version""], capture_output=True).returncode == 0:
        return [""docker-compose""]
    sys.exit(""docker compose plugin not found"")
",alpha_factory_v1/demos/aiga_meta_evolution/start_aiga_demo.py,,1,9.237449576640118e-09,"The method `docker_compose_cmd` is designed to check for the availability of Docker Compose in two different formats: the newer 'docker compose' command and the older 'docker-compose' command. This is a practical approach given the transition from the standalone 'docker-compose' to the integrated 'docker compose' command in Docker CLI. The method ensures compatibility with both versions, which is crucial for maintaining functionality across different environments and setups. As Docker continues to evolve, having such a method helps in adapting to changes without breaking existing workflows. Therefore, this method is likely to survive as it provides necessary functionality for compatibility and transition management."
survived,"def main(argv: list[str] | None = None) -> None:  # pragma: no cover - CLI wrapper
    p = argparse.ArgumentParser(description=__doc__)
    p.add_argument(""--alpha"", default=""Generic opportunity"", help=""text description of the opportunity"")
    p.add_argument(""--ledger"", help=""path to ledger JSON file"")
    p.add_argument(""--model"", default=os.getenv(""ALPHA_CONVERSION_MODEL"", ""gpt-4o-mini""), help=""OpenAI model when API key present"")
    p.add_argument(""--no-log"", action=""store_true"", help=""do not write ledger file"")
    args = p.parse_args(argv)

    ledger = _ledger_path(args.ledger)
    plan = convert_alpha(args.alpha, ledger=None if args.no_log else ledger, model=args.model)
    if args.no_log:
        ledger.unlink(missing_ok=True)
    print(json.dumps(plan, indent=2))
    if not args.no_log:
        print(f""Logged to {ledger}"")
",alpha_factory_v1/demos/aiga_meta_evolution/alpha_conversion_stub.py,,1,1.0467401685178159e-08,"The method 'main' is a command-line interface (CLI) wrapper that uses argparse to parse command-line arguments and perform operations based on those arguments. It includes functionality for handling a ledger file, converting an alpha description using a specified model, and optionally logging the results. This kind of utility function is common in scripts that are intended to be run from the command line, and it provides useful functionality for users who need to automate tasks or integrate with other systems. The presence of features like environment variable defaults, optional logging, and JSON output make it versatile and practical for various use cases. Therefore, it is likely to be retained in the codebase."
survived,"def convert_alpha(alpha: str, *, ledger: Path | None = None, model: str = ""gpt-4o-mini"") -> Dict[str, object]:
    """"""Return a plan dictionary and log to *ledger*.""""""
    plan: Dict[str, object] = SAMPLE_PLAN
    if ""openai"" in globals() and os.getenv(""OPENAI_API_KEY""):
        prompt = (
            f""Given the opportunity: {alpha}\n""
            ""Provide a short JSON plan with three concise steps to realise value.""
        )
        try:
            resp = openai.ChatCompletion.create(
                model=model,
                messages=[{""role"": ""user"", ""content"": prompt}],
            )
            plan = json.loads(resp.choices[0].message.content)  # type: ignore[index]
            if not isinstance(plan, dict):
                plan = SAMPLE_PLAN
        except Exception:
            plan = SAMPLE_PLAN
    (_ledger_path(ledger)).write_text(json.dumps(plan, indent=2))
    return plan
",alpha_factory_v1/demos/aiga_meta_evolution/alpha_conversion_stub.py,,1,4.944450477491054e-09,"The method 'convert_alpha' is likely to survive because it provides a useful functionality of generating a plan based on a given input using an AI model. It also includes error handling to ensure that a default plan is returned in case of any issues, making it robust. Additionally, it logs the output to a specified ledger, which can be useful for tracking and auditing purposes. The use of environment variables and optional parameters makes it flexible and adaptable to different use cases."
survived,"            def add(self, instr: Any) -> ""DummyTx"":
                self.instructions.append(instr)
                return self
",tests/test_ledger_broadcast.py,DummyTx,1,4.0586521248284276e-10,"The method 'add' is a simple utility function that appends an instruction to a list and returns the instance itself, allowing for method chaining. This is a common pattern in Python and is useful for building up a sequence of operations in a fluent style. The method is straightforward, performs a clear function, and is likely to be used in contexts where instructions need to be dynamically added to a transaction or similar object. There is no indication that this method is redundant or unnecessary, so it is likely to be retained."
survived,"            async def send_transaction(self, tx: Any, *args: Any) -> None:
                captured[""root""] = tx.instructions[0].data.decode()
                raise RuntimeError(""fail"")
",tests/test_ledger_broadcast.py,DummyClient,0,0.9875683497413793,"The method 'send_transaction' is designed to capture and decode the first instruction's data from a transaction and then intentionally raise a RuntimeError. This suggests that the method is not meant to complete a transaction successfully but rather to test or debug the transaction handling process. The presence of the RuntimeError indicates that this method is not intended for production use in its current form. However, it might be useful for debugging or testing purposes, which could justify its survival if the context requires such functionality. Without additional context, it's challenging to definitively predict its fate, but the intentional failure suggests it might be a candidate for deletion unless it's specifically needed for testing."
survived,"        def __bool__(self):
            return False
",tests/test_statemachine.py,FalseyModel,1,1.1861120010657661e-08,"The method is a custom implementation of the __bool__ method in Python, which is used to define the truth value of an instance of a class. By returning False, it explicitly makes instances of the class evaluate to False in a boolean context. This can be useful in certain scenarios where you want to control the truthiness of objects. Since this is a valid and potentially useful implementation, it is likely to be retained."
survived,"    def visit_For(self, node):
        self.emit(f""for {self.expr(node.target)} in {self.expr(node.iter)} {{"")
        self.indent += 1
        for s in node.body:
            self.visit(s)
        self.indent -= 1
        self.emit(""}"")
",tools/any2mochi/py_simple.py,Conv,1,2.7894680920908113e-10,"The method `visit_For` is a part of a code generation or transpilation process, likely converting an abstract syntax tree (AST) representation of a Python `for` loop into another language's syntax, possibly a C-style language given the use of braces `{}`. This method is essential for the functionality of the tool or library it belongs to, as it handles a fundamental control structure in programming. Unless there is a significant change in the language or the tool's purpose, such methods are typically retained. Therefore, it is likely to survive."
survived,"async def test_as_proxy_with_server(fastmcp_server):
    """"""FastMCP.as_proxy should accept a FastMCP instance.""""""
    proxy = FastMCP.as_proxy(fastmcp_server)
    result = await proxy._mcp_call_tool(""greet"", {""name"": ""Test""})
    assert isinstance(result[0], mcp.types.TextContent)
    assert result[0].text == ""Hello, Test!""
",tests/server/test_proxy.py,,1,7.73442280641062e-08,"The method 'test_as_proxy_with_server' is a test function that verifies the behavior of the 'FastMCP.as_proxy' method. Test functions are crucial for ensuring code reliability and correctness, especially in asynchronous environments where bugs can be subtle and hard to detect. This function checks that the proxy correctly calls a tool and returns the expected result, which is essential for maintaining the integrity of the 'FastMCP' functionality. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def _scan_shell_commands(self, content: str) -> List[str]:
        issues: List[str] = []
        for pattern, desc in self._SHELL_PATTERNS:
            if re.search(pattern, content):
                issues.append(f""shell command detected: {desc}"")
        return issues
",src/meta_agent/template_validator.py,TemplateValidator,1,3.581747929000289e-10,"The method `_scan_shell_commands` is likely to survive because it serves a specific purpose of scanning a given content for shell command patterns and returning a list of issues if any are found. This functionality is useful for security checks or code analysis tools that need to identify potentially dangerous shell commands in code or scripts. The method is straightforward, performs a clear task, and is likely part of a larger system that requires such functionality."
survived,"def f1_score(truth: list[bool], pred: list[bool]) -> float:
    """"""Return the F1 score for ``pred`` against ``truth``.""""""
    tp = sum(t and p for t, p in zip(truth, pred))
    fp = sum((not t) and p for t, p in zip(truth, pred))
    fn = sum(t and (not p) for t, p in zip(truth, pred))
    denom = 2 * tp + fp + fn
    if denom == 0:
        # perfect prediction with no positive samples
        return 1.0
    return 2 * tp / denom
",src/simulation/replay.py,,1,1.8189616842444243e-09,"The method implements a standard calculation for the F1 score, which is a widely used metric in classification tasks to evaluate the balance between precision and recall. The code is clear, concise, and correctly handles edge cases, such as when there are no positive samples. Given its utility and correctness, it is likely to be retained in the codebase."
survived,"            def labels(self, *_a: Any, **_kw: Any) -> ""_N"":
                return self
",src/interface/api_server.py,_N,1,7.73442280641062e-08,"The method 'labels' is a simple function that returns the instance itself (self). This pattern is often used in fluent interfaces or builder patterns where methods return the object to allow method chaining. The method does not perform any operations or transformations, which might suggest it is a placeholder or part of a larger interface. Without additional context, it's difficult to determine its utility, but such methods are often retained for their role in a larger design pattern or interface. Therefore, it is likely to survive unless the design pattern changes or the method is deemed unnecessary."
survived,"            def observe(self, *_a: Any) -> None: ...
",src/interface/api_server.py,_N,1,7.889265051273362e-06,"The method 'observe' is defined with a flexible argument list, indicated by '*_a: Any', which suggests it is designed to handle a variety of inputs. This flexibility is often useful in methods that need to accommodate different types of data or varying numbers of arguments. The method is also part of a class (indicated by 'self'), which implies it might be an integral part of the class's functionality. Without additional context, such as the class's purpose or other methods, it's difficult to determine its exact role. However, the use of ellipsis ('...') suggests that the method is not yet implemented, which could mean it's a placeholder for future development. Given these factors, the method is likely to be retained for future use or implementation, rather than being deleted."
survived,"def test_safety_agent_emits_status() -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = safety_agent.SafetyGuardianAgent(bus, led)
    env = messaging.Envelope(""codegen"", ""safety"", {""code"": ""import os""}, 0.0)
    asyncio.run(agent.handle(env))
    assert bus.published[-1][1].payload[""status""] == ""blocked""
",tests/test_agent_handle_methods.py,,1,7.73442280641062e-08,"The method `test_safety_agent_emits_status` is a unit test designed to verify the behavior of the `SafetyGuardianAgent` when handling a specific message. It checks if the agent correctly identifies and blocks potentially unsafe code by asserting that the last published message on the bus has a status of ""blocked"". This is a crucial test for ensuring the safety mechanisms of the system are functioning as expected. Given its importance in validating the system's security features, it is unlikely to be deleted."
survived,"def test_log_and_tail(tmp_path):
    ledger = Ledger(str(tmp_path / ""ledger.db""), broadcast=False)
    e1 = messaging.Envelope(""a"", ""b"", {""v"": 1}, 0.0)
    e2 = messaging.Envelope(""b"", ""c"", {""v"": 2}, 1.0)
    ledger.log(e1)
    ledger.log(e2)
    tail = ledger.tail(2)
    assert tail[0][""payload""][""v""] == 1
    assert tail[1][""payload""][""v""] == 2",tests/test_ledger_basic.py,,1,4.363462233903899e-09,"The method 'test_log_and_tail' is a unit test designed to verify the functionality of the 'log' and 'tail' methods of a 'Ledger' class. Unit tests are crucial for ensuring code reliability and correctness, especially in systems that handle data logging and retrieval. This test checks that the 'log' method correctly records entries and that the 'tail' method retrieves the most recent entries in the correct order. Given the importance of testing in software development, this method is likely to be retained to ensure the integrity of the 'Ledger' class's functionality."
survived,"def test_planning_agent_handle_logs() -> None:
    cfg = config.Settings(bus_port=0)
    bus = DummyBus(cfg)
    led = DummyLedger()
    agent = planning_agent.PlanningAgent(bus, led)
    env = messaging.Envelope(""a"", ""planning"", {""plan"": ""x""}, 0.0)
    asyncio.run(agent.handle(env))
    assert led.logged and led.logged[0] is env
",tests/test_agent_handle_methods.py,,1,1.955568070542584e-08,"The method `test_planning_agent_handle_logs` is a unit test designed to verify the functionality of the `PlanningAgent` class, specifically its ability to handle messages and log them correctly. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to facilitate ongoing testing and development. Therefore, it is unlikely that this method will be deleted."
survived,"def local_gpt2_tokenizer(tmp_path_factory):
    """"""Load a GPT2 tokenizer from a local JSON file to avoid network downloads.""""""

    config_src = Path(__file__).parent / ""gpt2_tokenizer_config.json""
    tmpdir = tmp_path_factory.mktemp(""gpt2_tok"")
    shutil.copy(config_src, tmpdir / ""tokenizer.json"")
    shutil.copy(config_src, tmpdir / ""tokenizer_config.json"")
    (tmpdir / ""config.json"").write_text(json.dumps({""model_type"": ""gpt2"", ""vocab_size"": 5027}))
    return AutoTokenizer.from_pretrained(str(tmpdir))",tests/conftest.py,,1,8.592166611791576e-10,"The method 'local_gpt2_tokenizer' is likely to survive because it provides a useful functionality of loading a GPT2 tokenizer from a local JSON file, which can be crucial for environments where network access is restricted or to avoid unnecessary network calls. This method enhances efficiency and reliability by ensuring that the tokenizer can be loaded locally, which is a common requirement in many production and testing environments."
survived,"    def _append_memory_leak_analysis(self, snapshot_file):
        """"""
        
        """"""
        with open(snapshot_file, 'a', encoding='utf-8') as f:
            f.write(""\n"" + ""="" * 80 + ""\n"")
            f.write("":\n"")
            f.write(""-"" * 80 + ""\n"")
            
            # tracemalloc
            current, peak = tracemalloc.get_traced_memory()
            f.write(f""tracemalloc: {current / 1024 / 1024:.2f} MB\n"")
            f.write(f""tracemalloc: {peak / 1024 / 1024:.2f} MB\n"")
            
            # 
            try:
                stats = tracemalloc.get_traced_memory()
                f.write(f"": {stats}\n"")
                
                # 10
                snapshot = tracemalloc.take_snapshot()
                top_stats = snapshot.statistics('lineno')
                
                f.write(""\n (10):\n"")
                f.write(""-"" * 80 + ""\n"")
                for i, stat in enumerate(top_stats[:10], 1):
                    f.write(f""{i:2d}. {stat.count:>8} , {stat.size / 1024 / 1024:>8.2f} MB\n"")
                    f.write(f""    {stat.traceback.format()}\n"")
                    
            except Exception as e:
                f.write(f"": {e}\n"")
            
            # 
            f.write(""\n:\n"")
            f.write(""-"" * 80 + ""\n"")
            for i in range(3):
                count = gc.get_count()[i]
                f.write(f""GC {i}: {count} \n"")
            
            # 
            unreachable = len(gc.garbage)
            f.write(f"": {unreachable}\n"")
            
            f.flush()
        
        logger.debug("""")
",app/helper/memory.py,MemoryHelper,1,2.2159489282323004e-08,"The method '_append_memory_leak_analysis' is a utility function designed to analyze memory leaks and trends by writing detailed memory statistics to a file. It uses the 'tracemalloc' and 'gc' modules to gather memory allocation and garbage collection data, which are crucial for debugging and optimizing memory usage in applications. This functionality is valuable for developers who need to monitor and improve the performance of their applications, especially in environments where memory usage is critical. Therefore, the method is likely to be retained as it provides essential insights into memory management."
survived,"    async def rollout(self, client, model, prompt, answer, task=""default"", info={}, sampling_args={}, **kwargs):
        """"""Simple test rollout implementation.""""""
        response = await self.get_model_response(
            prompt=prompt,
            client=client,
            model=model,
            sampling_args=sampling_args
        )
        if self.message_type == 'chat':
            return [{'role': 'assistant', 'content': response}], {}
        return response, {}
",tests/test_environment.py,SimpleEnvironment,1,1.6918979223288786e-10,"The method 'rollout' is likely to survive because it is an asynchronous function that provides a clear and useful implementation for handling model responses. It is designed to work with different message types, such as 'chat', and returns the response in a structured format. This flexibility and clarity in handling model responses make it a valuable part of the codebase."
deleted,"    def _process_complex_signal_partition(self, signal_type: type) -> list[Column]:
        """"""Process complex signal types (DataModel subclasses) for partition_by.
        
        Args:
            signal_type: The DataModel type to process (e.g., File, Image)
            
        Returns:
            List of Column objects representing the unique identifier columns
            for the complex signal type.
        """"""
        if not (isinstance(signal_type, type) and issubclass(signal_type, DataModel)):
            raise ValueError(
                f""Complex signal type {signal_type} must be a DataModel subclass""
            )
        
        # Find the signal name in the schema that matches this type
        signal_name = None
        for name, schema_type in self.signals_schema.values.items():
            if schema_type == signal_type:
                signal_name = name
                break
        
        if signal_name is None:
            raise ValueError(
                f""Signal type {signal_type} not found in the current schema""
            )
        
        # Get the unique ID keys for this DataModel type
        unique_keys = getattr(signal_type, '_unique_id_keys', None)
        if unique_keys is None:
            # Fall back to using all columns of the signal if no unique keys defined
            unique_keys = list(signal_type._datachain_column_types.keys())
        
        # Generate column objects for each unique key
        partition_columns = []
        for key in unique_keys:
            col_name = f""{signal_name}.{key}""
            col_db_name = ColumnMeta.to_db_name(col_name)
            try:
                col_type = self.signals_schema.get_column_type(col_db_name)
                column = Column(col_db_name, python_to_sql(col_type))
                partition_columns.append(column)
            except Exception:
                # Skip columns that don't exist in the schema
                continue
        
        if not partition_columns:
            raise ValueError(
                f""No valid partition columns found for signal type {signal_type}""
            )
        
        return partition_columns
",src/datachain/lib/dc/datachain.py,DataChain,1,1.6052280526088547e-09,"The method '_process_complex_signal_partition' is well-defined and serves a specific purpose in processing complex signal types for partitioning. It includes error handling, checks for valid input, and processes data according to a schema. These characteristics suggest it is a useful and necessary part of the codebase, likely contributing to the functionality of a larger system. Therefore, it is unlikely to be deleted."
survived,"def ask_pkgx(import_id: str) -> str | None:
    """"""
    ask max's scraping work for the homepage of a package
    Homepage comes from the pkgxdev/www repo
    The API https://pkgx.dev/pkgs/{name}.json returns a blob which may contain
    the homepage field
    """"""
    response: Response = get(HOMEPAGE_URL.format(name=import_id))
    if response.status_code == 200:
        data: dict[str, str] = response.json()
        if ""homepage"" in data:
            return data[""homepage""]
",package_managers/pkgx/url.py,,0,0.9999970976874533,"The method is likely to be deleted because it is incomplete and contains several issues. Firstly, the function does not handle cases where the response status code is not 200, which could lead to unhandled exceptions. Secondly, the function does not import the necessary modules such as 'get' from 'requests' and 'Response', which would cause it to fail during execution. Lastly, the function lacks a return statement for cases where the 'homepage' is not found in the data, which would result in an implicit return of 'None'. These issues suggest that the method is either a work in progress or not maintained, increasing the likelihood of it being deleted."
survived,"    def test_sort_by_speed_index_asc(self):
        """"""Test sorting by speed index (lowest first).""""""
        models: list[ConciseModelResponse | ConciseLatestModelResponse] = [
            create_test_model(""model1"", speed_index=300),
            create_test_model(""model2"", speed_index=800),
            create_test_model(""model3"", speed_index=600),
        ]

        sorted_models = sort_models(models, ""speed_index"", ""asc"")

        assert [m.id for m in sorted_models] == [""model1"", ""model3"", ""model2""]
",api/api/routers/mcp/_utils/model_sorting_test.py,TestSortModels,1,3.2241866333029355e-08,"The method `test_sort_by_speed_index_asc` is a unit test that verifies the functionality of sorting models by their speed index in ascending order. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with sorting algorithms or any logic that can have multiple outcomes. This test is well-defined, checks a specific functionality, and is likely part of a larger test suite. Therefore, it is important for maintaining code quality and is unlikely to be deleted."
survived,"    def test_perplexity_reasoning_models_support_reasoning(self):
        """"""
        Test that Perplexity Sonar reasoning models are correctly identified as supporting reasoning
        """"""
        from litellm.utils import supports_reasoning
        
        # Set up local model cost map
        os.environ[""LITELLM_LOCAL_MODEL_COST_MAP""] = ""True""
        litellm.model_cost = litellm.get_model_cost_map(url="""")
        
        reasoning_models = [
            ""perplexity/sonar-reasoning"",
            ""perplexity/sonar-reasoning-pro"",
        ]
        
        for model in reasoning_models:
            assert supports_reasoning(model, None), f""{model} should support reasoning""
",tests/llm_translation/test_perplexity_reasoning.py,TestPerplexityReasoning,1,1.4166087846364157e-09,"The method is a test function that checks if certain models are correctly identified as supporting reasoning. It uses an assertion to verify the expected behavior of the 'supports_reasoning' function. This is a typical unit test pattern and is useful for ensuring code correctness. There is no indication that this method is obsolete or unnecessary, so it is likely to be retained."
survived,"def test_perplexity_config():
    """"""Test Perplexity config and supported parameters""""""
    print(""Testing Perplexity configuration..."")
    
    from litellm.llms.perplexity.chat.transformation import PerplexityChatConfig
    
    config = PerplexityChatConfig()
    
    # Test API base configuration
    api_base, api_key = config._get_openai_compatible_provider_info(
        api_base=None, api_key=""test-key""
    )
    
    expected_api_base = ""https://api.perplexity.ai""
    print(f""API Base: {api_base}"")
    assert api_base == expected_api_base, f""API base should be {expected_api_base}""
    
    # Test supported parameters
    supported_params = config.get_supported_openai_params(model=""perplexity/sonar-reasoning"")
    print(f""Supported params: {supported_params}"")
    
    assert ""reasoning_effort"" in supported_params, ""reasoning_effort should be in supported params""
    
    print("" Perplexity configuration test passed!\n"")
",verify_perplexity_reasoning.py,,1,8.152020648014727e-09,"The method 'test_perplexity_config' is a test function that verifies the configuration and supported parameters of the PerplexityChatConfig class. It includes assertions to ensure the API base URL and supported parameters are as expected. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite."
survived,"def main():
    """"""Run all verification tests""""""
    print(""=== Perplexity Reasoning Effort Verification ===\n"")
    
    try:
        test_perplexity_reasoning_models_in_model_cost()
        test_reasoning_effort_parameter_mapping()
        test_perplexity_reasoning_support()
        test_perplexity_config()
        
        print("" All tests passed! Perplexity reasoning effort functionality is working correctly."")
        
    except Exception as e:
        print(f"" Test failed with error: {e}"")
        import traceback
        traceback.print_exc()
        sys.exit(1)
",verify_perplexity_reasoning.py,,1,1.2501528648238603e-09,"The method 'main' is a typical entry point for running a series of tests, which is a common practice in software development to ensure code quality and functionality. It includes exception handling to catch and report errors, which is crucial for debugging and maintaining the code. The method is well-structured and serves a clear purpose, making it unlikely to be deleted unless the entire testing framework is being removed or significantly refactored. Therefore, it is more likely to survive."
survived,"def update_preset_column_config(
    preset_id: uuid.UUID,
    body: ColumnConfigurationDto,
    authenticated_entity: AuthenticatedEntity = Depends(
        IdentityManagerFactory.get_auth_verifier([""write:presets""])
    ),
    session: Session = Depends(get_session),
) -> PresetDto:
    tenant_id = authenticated_entity.tenant_id
    logger.info(""Updating preset column configuration"", extra={""preset_id"": preset_id})
    
    statement = (
        select(Preset)
        .where(Preset.tenant_id == tenant_id)
        .where(Preset.id == preset_id)
    )
    preset = session.exec(statement).first()
    if not preset:
        raise HTTPException(404, ""Preset not found"")

    # Get current options and remove any existing column config options
    current_options = [
        option for option in preset.options 
        if option.get(""label"", """").lower() not in [
            ""column_visibility"", 
            ""column_order"", 
            ""column_rename_mapping"", 
            ""column_time_formats"", 
            ""column_list_formats""
        ]
    ]

    # Add new column configuration options
    if body.column_visibility:
        current_options.append({
            ""label"": ""column_visibility"",
            ""value"": body.column_visibility
        })
    
    if body.column_order:
        current_options.append({
            ""label"": ""column_order"", 
            ""value"": body.column_order
        })
    
    if body.column_rename_mapping:
        current_options.append({
            ""label"": ""column_rename_mapping"",
            ""value"": body.column_rename_mapping
        })
    
    if body.column_time_formats:
        current_options.append({
            ""label"": ""column_time_formats"",
            ""value"": body.column_time_formats
        })
    
    if body.column_list_formats:
        current_options.append({
            ""label"": ""column_list_formats"",
            ""value"": body.column_list_formats
        })

    # Update the preset options
    preset.options = current_options
    session.commit()
    session.refresh(preset)
    
    logger.info(""Updated preset column configuration"", extra={""preset_id"": preset_id})
    return PresetDto(**preset.to_dict())
",keep/api/routes/preset.py,,1,2.7894680920908113e-10,"The method `update_preset_column_config` is likely to survive because it performs a crucial function of updating the configuration of preset columns, which is a common requirement in applications that manage user settings or preferences. The method is well-structured, uses dependency injection for authentication and session management, and handles exceptions appropriately. It also logs important actions, which is useful for monitoring and debugging. These factors indicate that the method is well-implemented and serves a necessary purpose, making it unlikely to be deleted."
survived,"    def column_time_formats(self) -> Dict[str, str]:
        """"""Get column time formats from preset options""""""
        config = [
            option
            for option in self.options
            if option.get(""label"", """").lower() == ""column_time_formats""
        ]
        if not config:
            return {}
        return config[0].get(""value"", {})
",keep/api/models/db/preset.py,PresetDto,1,1.6052280526088547e-09,"The method 'column_time_formats' is a utility function that retrieves specific configuration settings related to time formats from a list of options. It is straightforward, performs a clear task, and is likely part of a larger system that relies on configuration management. Such methods are generally useful for maintaining flexibility and adaptability in software systems, allowing for easy updates and changes to configuration without altering the core logic. Therefore, it is unlikely to be deleted unless the entire configuration management approach is overhauled."
survived,"    def column_order(self) -> List[str]:
        """"""Get column order configuration from preset options""""""
        config = [
            option
            for option in self.options
            if option.get(""label"", """").lower() == ""column_order""
        ]
        if not config:
            return []
        return config[0].get(""value"", [])
",keep/api/models/db/preset.py,PresetDto,1,5.905303995456778e-10,"The method 'column_order' is likely to survive because it serves a specific purpose of retrieving a configuration related to column order from a list of options. It is a utility function that abstracts the logic of filtering and extracting the desired configuration, which can be reused in different parts of the codebase. Additionally, the method is concise, clear, and follows good coding practices, making it a valuable part of the code."
survived,"def test_chained_split_gather_workflow():
    """"""Test a realistic workflow combining split and gather operations.""""""
    # Start with a document
    df = pd.DataFrame({
        ""document"": [
            ""This is the first paragraph of a long document. "" * 5 + 
            ""This is the second paragraph with different content. "" * 5 +
            ""This is the third and final paragraph. "" * 5
        ],
        ""doc_id"": [""doc1""]
    })
    
    # Split the document into chunks
    split_result = df.semantic.split(
        split_key=""document"",
        method=""token_count"",
        method_kwargs={""num_tokens"": 20}
    )
    
    # Gather context for each chunk
    gather_result = split_result.semantic.gather(
        content_key=""document_chunk"",
        doc_id_key=""semantic_split_0_id"",
        order_key=""semantic_split_0_chunk_num"",
        peripheral_chunks={
            ""previous"": {""head"": {""count"": 1}},
            ""next"": {""head"": {""count"": 1}}
        }
    )
    
    assert len(gather_result) >= len(df)  # Should have multiple chunks
    assert ""document_chunk_rendered"" in gather_result.columns
    assert len(gather_result.semantic.history) == 2
    assert gather_result.semantic.history[0].op_type == ""split""
    assert gather_result.semantic.history[1].op_type == ""gather"" ",tests/test_pandas_accessors.py,,1,6.825604231969389e-08,"The method 'test_chained_split_gather_workflow' is a test function that validates a specific workflow involving split and gather operations on a document. Test functions are crucial for ensuring code reliability and correctness, especially in data processing workflows. This function checks the integrity of the operations by asserting the expected outcomes, such as the number of chunks and the presence of specific columns. Given its role in maintaining code quality and its specificity to a particular workflow, it is likely to be retained for future testing and development purposes."
survived,"    def test_private_fields_accepts_task_input_and_task_output(self):
        """"""Test that private_fields accepts both 'task_input' and 'task_output' as valid literal values.

        This test ensures that the private_fields type annotation correctly includes both
        'task_input' and 'task_output' (not a duplicate 'task_input').
        """"""
        # This should work - task_input is valid
        request_with_task_input = RunRequest.model_validate(
            {
                ""task_input"": {""test"": ""data""},
                ""version"": 1,
                ""private_fields"": [""task_input""],
            }
        )
        assert ""task_input"" in request_with_task_input.private_fields

        # This should also work - task_output should be valid
        request_with_task_output = RunRequest.model_validate(
            {
                ""task_input"": {""test"": ""data""},
                ""version"": 1,
                ""private_fields"": [""task_output""],
            }
        )
        assert ""task_output"" in request_with_task_output.private_fields

        # Both should work together
        request_with_both = RunRequest.model_validate(
            {
                ""task_input"": {""test"": ""data""},
                ""version"": 1,
                ""private_fields"": [""task_input"", ""task_output""],
            }
        )
        assert ""task_input"" in request_with_both.private_fields
        assert ""task_output"" in request_with_both.private_fields

        # Custom string fields should also work
        request_with_custom = RunRequest.model_validate(
            {
                ""task_input"": {""test"": ""data""},
                ""version"": 1,
                ""private_fields"": [""task_input.image"", ""metadata.secret""],
            }
        )
        assert ""task_input.image"" in request_with_custom.private_fields
        assert ""metadata.secret"" in request_with_custom.private_fields",api/api/routers/run_test.py,TestRunRequestValidation,1,1.0467401685178159e-08,"The method is a unit test that verifies the functionality of a model's validation process. It checks that the 'private_fields' attribute can accept specific values ('task_input' and 'task_output') and custom string fields. This is a crucial part of ensuring the integrity and correctness of the model's behavior, especially if these fields are important for the application's logic. Such tests are essential for maintaining code quality and preventing regressions, so it is likely to be retained."
survived,"def test_severity_preprocessing_cel_utils_integration(
    db_session, workflow_manager, create_workflow, create_alert
):
    """"""
    Test that the cel_utils.preprocess_cel_expression function is properly integrated
    into the workflow manager to fix the lexicographic comparison bug
    """"""
    
    # This test specifically validates that lexicographic issues are resolved
    # Before fix: 'high' < 'info' lexicographically (h comes before i in alphabet)
    # After fix: high (4) > info (2) numerically
    
    workflow = create_workflow(
        ""test-preprocessing-integration"", 
        ""severity > 'info'""
    )

    # Create a 'high' severity alert - this is the key test case
    # that would fail with lexicographic comparison but should pass with numeric
    high_alert = create_alert(
        severity=AlertSeverity.HIGH,
        source=[""test""], 
        fingerprint=""fp-high-severity""
    )

    workflows_to_run_before = len(workflow_manager.scheduler.workflows_to_run)
    workflow_manager.insert_events(SINGLE_TENANT_UUID, [high_alert])
    
    # This assertion would fail before the fix, but should pass after
    assert len(workflow_manager.scheduler.workflows_to_run) == workflows_to_run_before + 1, \
        ""HIGH severity alert should match 'severity > info' expression after preprocessing fix""
    assert workflow_manager.scheduler.workflows_to_run[-1][""workflow_id""] == workflow.id",tests/test_workflow_severity_comparisons.py,,1,2.1024340680345882e-07,"The method is a test function that verifies the integration of a specific utility function into a workflow manager. It checks for a specific bug fix related to lexicographic comparison, which is a critical aspect of the system's functionality. Test functions like this are essential for ensuring that the system behaves as expected after changes or updates. Therefore, it is unlikely to be deleted as it serves an important role in maintaining code quality and reliability."
survived,"def parse_packages_file(file_path: str) -> dict[str, str | None]:
    """"""
    Parse the packages file and return a mapping of package_name -> source_name.

    Args:
        file_path: Path to the packages file

    Returns:
        Dictionary mapping package names to their source package names (None if not specified)
    """"""
    package_source_map = {}

    with open(file_path, encoding=""utf-8"") as f:
        current_package = None
        current_source = None

        for line in f:
            line = line.strip()

            if line.startswith(""Package: ""):
                # Save previous package if exists
                if current_package:
                    package_source_map[current_package] = current_source

                # Start new package
                current_package = line[9:].strip()
                current_source = None

            elif line.startswith(""Source: ""):
                # Extract source name (may include version info in parentheses)
                source_str = line[8:].strip()
                # Remove version info if present: ""source (version)"" -> ""source""
                if ""("" in source_str:
                    current_source = source_str.split(""("")[0].strip()
                else:
                    current_source = source_str

            elif line == """" and current_package:
                # End of current package entry
                package_source_map[current_package] = current_source
                current_package = None
                current_source = None

        # Handle last package if file doesn't end with blank line
        if current_package:
            package_source_map[current_package] = current_source

    return package_source_map
",package_managers/debian/scripts/investigate_sources.py,,1,3.3982678079468468e-09,"The method `parse_packages_file` is well-defined and serves a clear purpose: parsing a file to map package names to their source names. It handles edge cases, such as files not ending with a blank line, and uses Python's type hinting for clarity. The method is useful for applications dealing with package management or dependency resolution, and there are no apparent issues or redundancies that would necessitate its removal. Therefore, it is likely to be retained in the codebase."
survived,"def create_debian_package(
    package: str = ""test-package"",
    description: str = ""Test package"",
    homepage: str = """",
    vcs_git: str = """",
    vcs_browser: str = """",
    directory: str = """",
    filename: str = """",
    depends: list[str] | None = None,
    build_depends: list[str] | None = None,
    recommends: list[str] | None = None,
    suggests: list[str] | None = None,
) -> DebianData:
    """"""Helper to create DebianData instances for testing""""""

    debian_data = DebianData()
    debian_data.package = package
    debian_data.description = description
    debian_data.homepage = homepage
    debian_data.vcs_git = vcs_git
    debian_data.vcs_browser = vcs_browser
    debian_data.directory = directory
    debian_data.filename = filename

    # Convert string dependencies to Depends objects
    if depends:
        debian_data.depends = [Depends(package=dep, semver=""*"") for dep in depends]
    if build_depends:
        # build_depends is now list[Depends] like other dependency fields
        debian_data.build_depends = [
            Depends(package=dep, semver=""*"") for dep in build_depends
        ]
    if recommends:
        debian_data.recommends = [
            Depends(package=dep, semver=""*"") for dep in recommends
        ]
    if suggests:
        debian_data.suggests = [Depends(package=dep, semver=""*"") for dep in suggests]

    return debian_data",tests/package_managers/debian/conftest.py,,1,6.348800075736417e-09,"The method `create_debian_package` is a utility function designed to create instances of `DebianData` for testing purposes. It is well-structured, with clear parameter definitions and default values, making it easy to use and understand. The method also includes type hints, which improve code readability and maintainability. Additionally, it handles optional parameters gracefully and converts string dependencies into `Depends` objects, which is a common pattern in package management. These characteristics suggest that the method is useful and likely to be retained in the codebase for testing and development purposes."
survived,"    def test_dependency_type_change_build_to_runtime(
        self, mock_config, mock_logger, mock_db
    ):
        """"""
        Scenario:
          - p1 has build dependency to p2 in cache
          - p1 has runtime dependency to p2 in parsed data.

        Expect removed build dependency and new runtime dependency
        """"""

        p1_id = uuid4()
        p2_id = uuid4()

        p1_pkg = Package(id=p1_id, derived_id=""debian/p1"", name=""p1"", import_id=""p1"")
        p2_pkg = Package(id=p2_id, derived_id=""debian/p2"", name=""p2"", import_id=""p2"")

        # Existing build dependency
        existing_build_dep = LegacyDependency(
            package_id=p1_id,
            dependency_id=p2_id,
            dependency_type_id=mock_config.dependency_types.build,
        )

        cache = Cache(
            package_map={""debian/p1"": p1_pkg, ""debian/p2"": p2_pkg},
            url_map={},
            package_urls={},
            dependencies={p1_id: {existing_build_dep}},
        )

        # Parsed data only has runtime dependency
        new_pkg_data = create_debian_package(
            package=""p1"",
            depends=[""p2""],  # runtime
            build_depends=[],  # no build deps
        )

        diff = DebianDiff(mock_config, cache, mock_db, mock_logger)
        new_deps, removed_deps = diff.diff_deps(""debian/p1"", new_pkg_data)

        # Should remove build and add runtime
        assert len(removed_deps) == 1
        assert removed_deps[0].dependency_id == p2_id
        assert removed_deps[0].dependency_type_id == mock_config.dependency_types.build

        assert len(new_deps) == 1
        assert new_deps[0].dependency_id == p2_id
        assert new_deps[0].dependency_type_id == mock_config.dependency_types.runtime
",tests/package_managers/debian/test_debian_diff.py,TestDebianDifferentialLoading,1,2.2159489282323004e-08,"The method is a well-defined test case that checks the functionality of changing a dependency type from build to runtime. It is useful for ensuring that the system correctly updates dependencies based on new data. The test is clear, concise, and follows a logical structure, making it valuable for maintaining code quality. Therefore, it is likely to be retained."
survived,"    def diff_pkg_url(
        self, pkg_id: UUID, resolved_urls: dict[UUID, UUID]
    ) -> tuple[list[PackageURL], list[dict]]:
        """"""Takes in a package_id and resolved URLs from diff_url, and generates
        new PackageURL objects as well as a list of changes to existing ones""""""

        new_links: list[PackageURL] = []
        updates: list[dict] = []

        # what are the existing links?
        existing: set[UUID] = {
            pu.url_id for pu in self.caches.package_urls.get(pkg_id, set())
        }

        # for each URL type/URL for this package:
        for _url_type, url_id in resolved_urls.items():
            if url_id not in existing:
                # new link!
                new_links.append(
                    PackageURL(
                        id=uuid4(),
                        package_id=pkg_id,
                        url_id=url_id,
                        created_at=self.now,
                        updated_at=self.now,
                    )
                )
            else:
                # existing link - update timestamp
                existing_pu = next(
                    pu for pu in self.caches.package_urls[pkg_id] if pu.url_id == url_id
                )
                existing_pu.updated_at = self.now
                updates.append({""id"": existing_pu.id, ""updated_at"": self.now})

        return new_links, updates
",package_managers/debian/diff.py,DebianDiff,1,2.646573631904765e-09,"The method 'diff_pkg_url' is well-defined and serves a clear purpose in the context of managing package URLs. It efficiently handles the creation of new PackageURL objects and updates existing ones based on the input data. The method is likely part of a larger system that deals with package management or URL tracking, and its functionality is essential for maintaining accurate and up-to-date records. There is no indication that this method is redundant or obsolete, and it appears to be a necessary component of the system it belongs to. Therefore, it is likely to be retained."
survived,"def test_binutils(binutils):
    m = mock_open(read_data=binutils)

    with patch(""builtins.open"", m):
        result = parse_sources_file(""dummy"")

    assert result == {
        ""binutils"": {
            ""binutils-for-host"",
            ""binutils-for-build"",
            ""binutils-ia64-linux-gnu-dbg"",
            ""binutils-m68k-linux-gnu"",
            ""binutils-mips64el-linux-gnuabin32-dbg"",
            ""binutils-mipsisa64r6-linux-gnuabin32"",
            ""binutils-mipsisa64r6el-linux-gnuabi64-dbg"",
        }
    }
",package_managers/debian/scripts/test_investigate_sources.py,,1,2.998960815863541e-09,"The method `test_binutils` is a unit test function that uses mocking to test the `parse_sources_file` function. It is a well-structured test that checks if the `parse_sources_file` function correctly parses a file and returns the expected dictionary structure. Unit tests are crucial for ensuring code reliability and are typically maintained as long as the functionality they test is relevant. Therefore, this method is likely to be retained as long as the `parse_sources_file` function exists and requires testing."
survived,"def get_task_status(task_id):
    """"""Get the status of a specific task""""""
    if task_id not in tasks:
        logger.warning(f"" Frontend polling for unknown task: {task_id}"")
        return jsonify({'error': 'Task not found'}), 404
    
    task = tasks[task_id]
    logger.info(f"" Frontend polling task {task_id}: status={task['status']}"")
    
    return jsonify({
        'status': 'success',
        'task': {
            'id': task['id'],
            'status': task['status'],
            'prompt': task['prompt'],
            'repo_url': task['repo_url'],
            'branch': task['branch'],
            'model': task.get('model', 'claude'),  # Include model in response
            'commit_hash': task.get('commit_hash'),
            'changed_files': task.get('changed_files', []),
            'error': task.get('error'),
            'created_at': task['created_at']
        }
    })
",server/tasks.py,,1,3.160881453314576e-10,"The method `get_task_status` is well-structured and serves a clear purpose in the application by retrieving the status of a specific task. It includes logging for both successful and unsuccessful attempts to access task information, which is useful for debugging and monitoring. The method also provides a detailed JSON response with relevant task information, which is likely important for the frontend or other services that consume this API. Additionally, the method handles errors gracefully by returning a 404 status code when a task is not found. These factors suggest that the method is functional, useful, and aligns with good coding practices, making it likely to survive."
survived,"def home():
    """"""Root endpoint""""""
    return jsonify({
        'status': 'success',
        'message': 'Claude Code Automation API',
        'endpoints': ['/ping', '/start-task', '/task-status', '/git-diff', '/create-pr']
    })",server/health.py,,1,8.592166611791576e-10,"The method 'home' is a simple and clear implementation of a root endpoint for an API. It provides a JSON response with a status message and a list of available endpoints, which is a common practice in API design to help users understand the available functionalities. There is no indication of deprecated practices or security issues in the code. Therefore, it is likely to be retained in the codebase."
survived,"def get_git_diff(task_id):
    """"""Get the git diff for a completed task""""""
    if task_id not in tasks:
        return jsonify({'error': 'Task not found'}), 404
    
    task = tasks[task_id]
    logger.info(f"" Frontend requesting git diff for task {task_id} (status: {task['status']})"")
    
    if task['status'] != TaskStatus.COMPLETED:
        logger.warning(f"" Git diff requested for incomplete task {task_id}"")
        return jsonify({'error': 'Task not completed yet'}), 400
    
    diff_length = len(task.get('git_diff', ''))
    logger.info(f"" Returning git diff: {diff_length} characters"")
    
    return jsonify({
        'status': 'success',
        'git_diff': task.get('git_diff', ''),
        'commit_hash': task.get('commit_hash')
    })",server/git_operations.py,,1,5.905303995456778e-10,"The method 'get_git_diff' is well-structured and serves a clear purpose: to retrieve the git diff for a completed task. It includes error handling for cases where the task is not found or not completed, and logs relevant information for debugging. These are good practices in software development. Additionally, the method returns a JSON response, which is a common requirement for web APIs. There is no indication that this method is obsolete or redundant, so it is likely to be retained."
survived,"def migrate_legacy_tasks():
    """"""Migrate tasks from legacy JSON storage to Supabase""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        # This would be called manually to migrate existing tasks
        # Load legacy tasks from file if it exists
        import json
        import os
        
        legacy_file = 'tasks_backup.json'
        if not os.path.exists(legacy_file):
            return jsonify({
                'status': 'success',
                'message': 'No legacy tasks file found',
                'migrated': 0
            })
        
        with open(legacy_file, 'r') as f:
            legacy_tasks = json.load(f)
        
        migrated_count = 0
        for task_id, task_data in legacy_tasks.items():
            try:
                # Check if already migrated
                existing = DatabaseOperations.get_task_by_legacy_id(task_id)
                if existing:
                    continue
                
                # Migrate task
                DatabaseOperations.migrate_legacy_task(task_data, user_id)
                migrated_count += 1
            except Exception as e:
                logger.warning(f""Failed to migrate task {task_id}: {e}"")
        
        return jsonify({
            'status': 'success',
            'message': f'Migrated {migrated_count} tasks',
            'migrated': migrated_count
        })
        
    except Exception as e:
        logger.error(f""Error migrating legacy tasks: {str(e)}"")
        return jsonify({'error': str(e)}), 500",server/tasks.py,,0,0.9999998724809324,"The method 'migrate_legacy_tasks' is likely to be deleted in the future because it serves a specific transitional purpose: migrating tasks from a legacy JSON storage to a new system (Supabase). Once the migration is complete and all tasks have been successfully transferred, the need for this function will diminish. Additionally, the presence of a manual trigger and the handling of a legacy file suggest that this is a temporary utility function, not intended for long-term use."
survived,"def validate_github_token():
    """"""Validate GitHub token and check permissions""""""
    try:
        data = request.get_json()
        github_token = data.get('github_token')
        repo_url = data.get('repo_url', '')
        
        if not github_token:
            return jsonify({'error': 'github_token is required'}), 400
        
        # Create GitHub client
        g = Github(github_token)
        
        # Test basic authentication
        user = g.get_user()
        logger.info(f"" Token belongs to user: {user.login}"")
        
        # Test token scopes
        rate_limit = g.get_rate_limit()
        logger.info(f"" Rate limit info: {rate_limit.core.remaining}/{rate_limit.core.limit}"")
        
        # If repo URL provided, test repo access
        repo_info = {}
        if repo_url:
            try:
                repo_parts = repo_url.replace('https://github.com/', '').replace('.git', '')
                repo = g.get_repo(repo_parts)
                
                # Test various permissions
                permissions = {
                    'read': True,  # If we got here, we can read
                    'write': False,
                    'admin': False
                }
                
                try:
                    # Test if we can read branches
                    branches = list(repo.get_branches())
                    permissions['read_branches'] = True
                    logger.info(f"" Can read branches ({len(branches)} found)"")
                    
                    # Test if we can create branches
                    test_branch_name = f""test-permissions-{int(time.time())}""
                    try:
                        # Try to create a test branch
                        main_branch = repo.get_branch(repo.default_branch)
                        test_ref = repo.create_git_ref(f""refs/heads/{test_branch_name}"", main_branch.commit.sha)
                        permissions['create_branches'] = True
                        logger.info(f"" Can create branches - test successful"")
                        
                        # Clean up test branch immediately
                        test_ref.delete()
                        logger.info(f"" Cleaned up test branch"")
                        
                    except Exception as branch_error:
                        permissions['create_branches'] = False
                        logger.warning(f"" Cannot create branches: {branch_error}"")
                        
                except Exception as e:
                    permissions['read_branches'] = False
                    permissions['create_branches'] = False
                    logger.warning(f"" Cannot read branches: {e}"")
                
                try:
                    # Check if we can write (without actually writing)
                    repo_perms = repo.permissions
                    permissions['write'] = repo_perms.push
                    permissions['admin'] = repo_perms.admin
                    logger.info(f"" Repo permissions: push={repo_perms.push}, admin={repo_perms.admin}"")
                except Exception as e:
                    logger.warning(f"" Could not check repo permissions: {e}"")
                
                repo_info = {
                    'name': repo.full_name,
                    'private': repo.private,
                    'permissions': permissions,
                    'default_branch': repo.default_branch
                }
                
            except Exception as repo_error:
                return jsonify({
                    'error': f'Cannot access repository: {str(repo_error)}',
                    'user': user.login
                }), 403
        
        return jsonify({
            'status': 'success',
            'user': user.login,
            'repo': repo_info,
            'message': 'Token is valid and has repository access'
        })
        
    except Exception as e:
        logger.error(f""Token validation error: {str(e)}"")
        return jsonify({'error': f'Token validation failed: {str(e)}'}), 401
",server/tasks.py,,1,3.850741907939403e-09,"The method `validate_github_token` is a comprehensive function that validates a GitHub token by checking its permissions and access to a specified repository. It includes error handling, logging, and returns detailed JSON responses based on the validation results. This functionality is crucial for applications that need to interact with GitHub APIs securely and ensure proper access control. Given its utility in managing authentication and permissions, it is likely to be retained in the codebase."
survived,"def create_pull_request(task_id):
    """"""Create a pull request by applying the saved patch to a fresh repo clone""""""
    try:
        user_id = request.headers.get('X-User-ID')
        if not user_id:
            return jsonify({'error': 'User ID required'}), 400
        
        logger.info(f"" PR creation requested for task: {task_id}"")
        
        task = DatabaseOperations.get_task_by_id(task_id, user_id)
        if not task:
            logger.error(f"" Task {task_id} not found"")
            return jsonify({'error': 'Task not found'}), 404
        
        if task['status'] != 'completed':
            return jsonify({'error': 'Task not completed yet'}), 400
            
        if not task.get('git_patch'):
            return jsonify({'error': 'No patch data available for this task'}), 400
        
        data = request.get_json() or {}
        
        # Get prompt from chat messages
        prompt = """"
        if task.get('chat_messages'):
            for msg in task['chat_messages']:
                if msg.get('role') == 'user':
                    prompt = msg.get('content', '')
                    break
        
        pr_title = data.get('title', f""Claude Code: {prompt[:50]}..."")
        pr_body = data.get('body', f""Automated changes generated by Claude Code.\n\nPrompt: {prompt}\n\nChanged files:\n"" + '\n'.join(f""- {f}"" for f in task.get('changed_files', [])))
        github_token = data.get('github_token')
        
        if not github_token:
            return jsonify({'error': 'github_token is required'}), 400
        
        logger.info(f"" Creating PR for task {task_id}"")
        
        # Extract repo info from URL
        repo_parts = task['repo_url'].replace('https://github.com/', '').replace('.git', '')
        
        # Create GitHub client
        g = Github(github_token)
        repo = g.get_repo(repo_parts)
        
        # Determine branch strategy
        base_branch = task['target_branch']
        pr_branch = f""claude-code-{task_id}""
        
        logger.info(f"" Creating PR branch '{pr_branch}' from base '{base_branch}'"")
        
        # Get the latest commit from the base branch
        base_branch_obj = repo.get_branch(base_branch)
        base_sha = base_branch_obj.commit.sha
        
        # Create new branch for the PR
        try:
            # Check if branch already exists
            try:
                existing_branch = repo.get_branch(pr_branch)
                logger.warning(f"" Branch '{pr_branch}' already exists, deleting it first..."")
                repo.get_git_ref(f""heads/{pr_branch}"").delete()
                logger.info(f"" Deleted existing branch '{pr_branch}'"")
            except:
                pass  # Branch doesn't exist, which is what we want
            
            # Create the new branch
            new_ref = repo.create_git_ref(f""refs/heads/{pr_branch}"", base_sha)
            logger.info(f"" Created branch '{pr_branch}' from {base_sha[:8]}"")
            
        except Exception as branch_error:
            logger.error(f"" Failed to create branch '{pr_branch}': {str(branch_error)}"")
            
            # Provide specific error messages based on the error
            error_msg = str(branch_error).lower()
            if ""resource not accessible"" in error_msg:
                detailed_error = (
                    f""GitHub token lacks permission to create branches. ""
                    f""Please ensure your token has 'repo' scope (not just 'public_repo'). ""
                    f""Error: {branch_error}""
                )
            elif ""already exists"" in error_msg:
                detailed_error = f""Branch '{pr_branch}' already exists. Please try again or use a different task.""
            else:
                detailed_error = f""Failed to create branch '{pr_branch}': {branch_error}""
                
            return jsonify({'error': detailed_error}), 403
        
        # Apply the patch by creating/updating files
        logger.info(f"" Applying patch with {len(task.get('changed_files', []))} changed files..."")
        
        # For now, we'll use a simple approach to apply changes
        # In a real implementation, you'd want a more sophisticated patch parser
        patch_content = task['git_patch']
        files_updated = []
        
        # Simple file update based on changed_files list
        for file_path in task.get('changed_files', []):
            try:
                # This is a simplified approach - in reality you'd parse the patch properly
                logger.info(f"" Updating file: {file_path}"")
                files_updated.append(file_path)
            except Exception as e:
                logger.warning(f""Failed to update {file_path}: {e}"")
        
        # Create pull request
        pr = repo.create_pull(
            title=pr_title,
            body=pr_body,
            head=pr_branch,
            base=base_branch
        )
        
        # Update task with PR information
        DatabaseOperations.update_task(task_id, user_id, {
            'pr_branch': pr_branch,
            'pr_number': pr.number,
            'pr_url': pr.html_url
        })
        
        logger.info(f"" Created PR #{pr.number}: {pr.html_url}"")
        
        return jsonify({
            'status': 'success',
            'pr_url': pr.html_url,
            'pr_number': pr.number,
            'branch': pr_branch,
            'files_updated': len(files_updated)
        })
        
    except Exception as e:
        logger.error(f""Error creating PR: {str(e)}"")
        return jsonify({'error': str(e)}), 500
",server/tasks.py,,1,5.3157849718487075e-08,"The method 'create_pull_request' is a comprehensive function that handles the creation of a pull request by interacting with GitHub's API. It includes error handling, logging, and validation of inputs, which are essential for robust software development. The method is well-structured, with clear steps for checking task status, extracting necessary information, and creating a pull request. It also provides detailed error messages, which are crucial for debugging and user feedback. Given its functionality and the fact that it addresses a common need in software development (automating pull request creation), it is likely to be retained in the codebase."
survived,"def find_metadata_files(decrypted_dir: str) -> Dict[str, Any]:
    """"""
    Find all metadata.json files and categorize them by type.
    
    Args:
        decrypted_dir: Path to the decrypted_overrides directory
        
    Returns:
        Dictionary with categories as keys and lists of file paths as values
    """"""
    files = {
        ""global"": [],
        ""regions"": defaultdict(list),
        ""locales"": defaultdict(list)
    }
    
    # Walk through all directories
    for root, dirs, filenames in os.walk(decrypted_dir):
        if ""metadata.json"" in filenames:
            metadata_path = os.path.join(root, ""metadata.json"")
            
            # Check if this is a region-specific file
            if ""/region/"" in metadata_path:
                region_match = re.search(r'/region/([^/]+)/', metadata_path)
                if region_match:
                    region = region_match.group(1)
                    files[""regions""][region].append(metadata_path)
            
            # Check if this is a locale-specific file  
            elif ""/locale/"" in metadata_path:
                locale_match = re.search(r'/locale/([^/]+)/', metadata_path)
                if locale_match:
                    locale = locale_match.group(1)
                    files[""locales""][locale].append(metadata_path)
            
            # Check if this is a global file (directly in AssetData/)
            elif metadata_path.endswith(""/AssetData/metadata.json""):
                files[""global""].append(metadata_path)
    
    return files
",combine_metadata.py,,1,2.3355930333443423e-09,"The method `find_metadata_files` is a utility function that serves a clear purpose: it categorizes metadata files based on their directory structure. This is a common requirement in file management and data organization tasks, especially when dealing with large datasets that need to be processed or analyzed differently based on their categorization. The function is well-documented, uses standard libraries, and follows a logical structure. There is no indication that this functionality is obsolete or redundant, and it is likely to be useful in various applications that involve file system operations. Therefore, it is likely to be retained."
deleted,"        def create_flow_tool(graph_obj: Graph, flow_name: str, flow_desc: str):
            """"""Create a tool function for a specific flow.""""""
            
            @mcp.tool()
            def flow_tool(input_data: FlowInput) -> FlowOutput:
                f""""""Execute the {flow_name} flow.
                
                {flow_desc}
                """"""
                try:
                    # Import here to avoid circular imports
                    import time
                    
                    start_time = time.time()
                    
                    # Execute the flow
                    # Note: This follows the same pattern as the REST API execution
                    result = graph_obj.run(
                        inputs={""input_value"": input_data.input_value},
                        tweaks=input_data.tweaks or {}
                    )
                    
                    execution_time = time.time() - start_time
                    
                    return FlowOutput(
                        result=result,
                        execution_time=execution_time
                    )
                    
                except Exception as e:
                    return FlowOutput(
                        result=None,
                        error=str(e)
                    )
            
            # Dynamically set the function name to match the flow
            flow_tool.__name__ = f""execute_{flow_name.replace(' ', '_').replace('-', '_').lower()}""
            return flow_tool
",src/backend/base/langflow/cli/mcp_server.py,,1,3.850741907939403e-09,"The method 'create_flow_tool' is a utility function that dynamically creates and returns a tool function for executing a specific flow. It is designed to be flexible and reusable, allowing for the creation of multiple flow tools with different names and descriptions. The method is well-structured, handles exceptions, and provides useful output, making it a valuable part of a codebase that deals with flow execution. There is no indication that it is obsolete or redundant, and it seems to serve a clear purpose in the context of the application."
survived,"    async def test_transfer_traces_fails_with_non_existent_project_id(
        self,
        gql_client: AsyncGraphQLClient,
        trace_transfer_fixture: dict[str, int],
        db: DbSessionFactory,
    ) -> None:
        trace1_id = trace_transfer_fixture[""trace1_id""]
        trace2_id = trace_transfer_fixture[""trace2_id""]

        async with db() as session:
            traces = (
                await session.scalars(
                    select(models.Trace).where(models.Trace.id.in_([trace1_id, trace2_id]))
                )
            ).all()
            assert len(traces) == 2

        result = await gql_client.execute(
            self.TRANSFER_TRACES_MUTATION,
            variables={
                ""traceIds"": [
                    str(GlobalID(""Trace"", str(trace1_id))),
                    str(GlobalID(""Trace"", str(trace2_id))),
                ],
                ""projectId"": str(GlobalID(""Project"", ""99999"")),
            },
        )
        assert result.errors

        async with db() as session:
            traces = (
                await session.scalars(
                    select(models.Trace).where(models.Trace.id.in_([trace1_id, trace2_id]))
                )
            ).all()
            assert len(traces) == 2
            source_project_id = trace_transfer_fixture[""source_project_id""]
            assert all(trace.project_rowid == source_project_id for trace in traces)
",tests/unit/server/api/mutations/test_trace_transfer_mutations.py,TestTraceTransferMutationMixin,1,8.76424914819242e-08,"The method is a test function that verifies the behavior of a system when attempting to transfer traces with a non-existent project ID. It is a part of a test suite, likely for a larger application, and is crucial for ensuring the robustness and correctness of the trace transfer functionality. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function is specific in its purpose and checks for a particular edge case, making it valuable for maintaining software quality."
survived,"    def test_env_group_mismatched_names_fails(self, mock_openai_client):
        """"""Test that EnvGroup fails when env_names length doesn't match envs.""""""
        env1 = SingleTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""q1""], ""answer"": [""a1""]}),
            rubric=Rubric()
        )
        
        with pytest.raises(ValueError, match=""Number of env_names must match number of envs""):
            EnvGroup(envs=[env1], env_names=[""math"", ""code""])
",tests/test_env_group.py,TestEnvGroup,1,5.60279640614594e-09,"The method is a unit test designed to ensure that the EnvGroup class correctly raises a ValueError when the number of environment names does not match the number of environments. This is a valid and necessary test to ensure the robustness of the EnvGroup class, as it checks for proper error handling in case of user input errors. Such tests are crucial for maintaining code quality and preventing bugs, especially in larger systems. Therefore, this method is likely to be retained in the codebase."
survived,"        def mock_encode(text, **kwargs):
            # Return tokens based on the text content
            if ""assistant: Hi there!"" in text:
                # Prompt + completion: return extended tokens
                return [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
            elif ""user: Hello"" in text:
                # Just prompt: return base tokens
                return [1, 2, 3, 4, 5]
            else:
                # Default case
                return [1, 2, 3]
",tests/test_environment.py,TestEnvironmentBase,1,1.1032560311263802e-09,"The method 'mock_encode' is a utility function that simulates encoding text into tokens based on specific conditions. It is useful for testing and development purposes, especially in scenarios where actual encoding is not necessary or available. Such mock functions are often retained in codebases for testing, debugging, or as placeholders until a more sophisticated solution is implemented. Therefore, it is likely to survive."
survived,"    async def test_rollout_state_structure(self, mock_singleturn_env):
        """"""Test that rollout creates proper state structure.""""""
        prompt = [{""role"": ""user"", ""content"": ""Hello""}]
        answer = ""Hi""
        task = ""greeting""
        info = {""context"": ""test""}
        
        completion, state = await mock_singleturn_env.rollout(
            client=mock_singleturn_env.client,
            model=""test-model"",
            prompt=prompt,
            answer=answer,
            task=task,
            info=info
        )
        
        # Check all expected state fields
        assert state[""prompt""] == prompt
        # state[""completion""] is initialized to [] but not updated during rollout
        assert state[""completion""] == []
        assert state[""answer""] == answer
        assert state[""task""] == task
        assert state[""info""] == info
        assert ""responses"" in state
        assert isinstance(state[""responses""], list)
        assert len(state[""responses""]) == 1
",tests/test_singleturn_env.py,TestSingleTurnEnv,1,1.275190675769241e-07,"The method `test_rollout_state_structure` is a unit test designed to verify the structure of the state object returned by the `rollout` function. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks that the state object contains all expected fields and that they are correctly initialized. Such tests are typically retained to maintain code quality and prevent regressions, making it unlikely that this method will be deleted."
survived,"            def is_completed(self, messages, state, **kwargs):
                return ""DONE"" in messages
",tests/test_multiturn_env.py,TestMultiTurnEnv.CompletionMultiTurnEnv,1,2.3355930333443423e-09,"The method `is_completed` is a simple utility function that checks if the string ""DONE"" is present in the `messages` list. This kind of method is often useful in various contexts where a process or task needs to be marked as complete based on certain conditions. The method is straightforward, easy to understand, and likely serves a specific purpose in the codebase. Unless the functionality it provides is no longer needed or has been replaced by a more comprehensive solution, it is likely to survive."
survived,"    async def test_completion_format_multiturn(self, mock_openai_client):
        """"""Test MultiTurnEnv with completion format.""""""
        class CompletionMultiTurnEnv(MultiTurnEnv):
            def __init__(self, **kwargs):
                super().__init__(message_type=""completion"", **kwargs)
                
            def is_completed(self, messages, state, **kwargs):
                return ""DONE"" in messages
            
            def env_response(self, messages, state, **kwargs):
                return "" Continue."", state
        
        completion_dataset = Dataset.from_dict({
            ""prompt"": [""Start:""],
            ""answer"": [""Done""]
        })
        
        env = CompletionMultiTurnEnv(
            client=mock_openai_client,
            model=""test-model"",
            dataset=completion_dataset,
            max_turns=3
        )
        
        mock_openai_client.add_text_response(""Start:"", ""First response"")
        mock_openai_client.add_text_response(""Start:First response Continue."", ""Final DONE"")
        
        prompt = ""Start:""
        completion, state = await env.rollout(
            client=mock_openai_client,
            model=""test-model"",
            prompt=prompt,
            answer=""Done""
        )
        
        assert isinstance(completion, str)
        assert ""First response"" in completion
        assert ""DONE"" in completion
        assert len(state[""responses""]) == 2
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.8189616842444243e-09,"The method is a test function for a specific feature (MultiTurnEnv with completion format) and is likely part of a test suite. Test methods are generally not deleted unless the feature they are testing is removed or significantly changed. Since this method is testing a specific functionality and there is no indication that the feature is deprecated or removed, it is likely to survive."
survived,"    def test_mcp_json_saas_mode(self):
        with override_settings(SENTRY_MODE=""saas""):
            response = self.client.get(""/.well-known/mcp.json"")

        assert response.status_code == 200
        assert response[""Content-Type""] == ""application/json""
        
        data = json.loads(response.content)
        assert data[""name""] == ""Sentry""
        assert data[""description""] == ""Connect to Sentry, debug faster.""
        assert data[""endpoint""] == ""https://mcp.sentry.dev/mcp""
",tests/sentry/web/test_api.py,McpJsonTest,1,4.0586521248284276e-10,"The method `test_mcp_json_saas_mode` is a unit test that verifies the behavior of a specific endpoint in a SaaS mode setting. It checks the response status, content type, and specific JSON content, which are crucial for ensuring the endpoint's correct functionality. Such tests are essential for maintaining software quality and are unlikely to be removed unless the endpoint itself is deprecated or the testing framework changes significantly. Therefore, the method is likely to survive."
survived,"    def __init__(self, runner, console: Console):
        self.runner = runner
        self.console = console
        self.default_lm_api_base = runner.config.get(""default_lm_api_base"", None)
",docetl/operations/utils/api.py,LLMCallHandler,1,1.522997951276035e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects with specific attributes and are unlikely to be removed unless the class itself is being deprecated or refactored significantly. Since this method is performing a basic and necessary function of setting up initial state for an object, it is likely to survive."
deleted,"    def _handle_model_error(self, model: str, error: Exception) -> None:
        """"""Handle model-specific errors.""""""
        if model not in BASIC_MODELS and ""/"" not in model:
            raise ValueError(
                f""Note: You may also need to prefix your model name with the provider, ""
                f""e.g. 'openai/gpt-4o-mini' or 'gemini/gemini-1.5-flash' to conform to ""
                f""LiteLLM API standards. Original error: {error}""
            )
        raise error
",docetl/operations/utils/api.py,LLMCallHandler,1,3.3982678079468468e-09,"The method '_handle_model_error' is designed to handle errors related to model names, specifically checking if the model name is correctly prefixed with a provider. This is a useful utility function for ensuring that model names conform to expected standards, which is important for maintaining compatibility with the LiteLLM API. The method provides a clear error message to guide users in correcting their input, which is a valuable feature for debugging and user experience. Given its utility in error handling and user guidance, it is likely to be retained in the codebase."
deleted,"    def _build_scratchpad_instructions(self) -> str:
        """"""Build instructions for scratchpad usage.""""""
        return """"""

You are incrementally processing data across multiple batches. You will see:
1. The current batch of data to process
2. The intermediate output so far (what you returned last time)
3. A scratchpad for tracking additional state

IMPORTANT: Only use the scratchpad if your task specifically requires tracking items that appear multiple times across batches. If you only need to track distinct/unique items, leave the scratchpad empty and set updated_scratchpad to null.

The intermediate output contains the result that directly answers the user's task, for **all** the data processed so far, including the current batch. You must return this via the send_output function.

Example task that NEEDS scratchpad - counting words that appear >2 times:
- Call send_output with: {""frequent_words"": [""the"", ""and""]} # Words seen 3+ times - this is your actual result
- Set updated_scratchpad to: {""pending"": {""cat"": 2, ""dog"": 1}} # Must track words seen 1-2 times

Example task that does NOT need scratchpad - collecting unique locations:
- Call send_output with: {""locations"": [""New York"", ""Paris""]} # Just the unique items
- Set updated_scratchpad to: null # No need to track counts since we only want distinct items

As you process each batch:
1. Use both the previous output and scratchpad (if needed) to inform your processing
2. Call send_output with your result that combines the current batch with previous output
3. Set updated_scratchpad only if you need to track counts/frequencies between batches

If you use the scratchpad, keep it concise (~500 chars) and easily parsable using:
- Key-value pairs
- JSON-like format
- Simple counters/tallies

Your main result must be sent via send_output. The updated_scratchpad is only for tracking state between batches, and should be null unless you specifically need to track frequencies.""""""
",docetl/operations/utils/api.py,LLMCallHandler,1,7.73442280641062e-08,"The method '_build_scratchpad_instructions' is a utility function that provides detailed instructions on how to use a scratchpad for processing data in batches. It is well-documented and serves a specific purpose in guiding users on when and how to use the scratchpad effectively. Such methods are typically retained in codebases because they encapsulate important logic or guidelines that are crucial for the correct functioning of a system. Additionally, the method is not overly complex or redundant, and it provides clear examples and instructions, which are valuable for users or developers interacting with the system."
survived,"        def func1(completion, **kwargs):
            return 1.0
",tests/test_rubric_group.py,TestRubricGroup,0,0.9999995549151272,"The method `func1` is very simple and returns a constant value of 1.0 regardless of the input parameters. This makes it not very useful in most practical scenarios unless it is specifically designed to be a placeholder or a stub for testing purposes. Without additional context or functionality, such a method is likely to be deleted or replaced with more meaningful logic in a real-world application."
survived,"    def test_format_reward_function(self, xml_parser):
        """"""Test the format reward function.""""""
        reward_func = xml_parser.get_format_reward_func()
        
        # Well-formatted completion
        good_completion = [
            {""role"": ""assistant"", ""content"": ""<reasoning>Good reasoning</reasoning><answer>42</answer>""}
        ]
        good_reward = reward_func(good_completion)
        assert 0.0 <= good_reward <= 1.0
        
        # Poorly formatted completion - gets partial credit for proper spacing
        bad_completion = [
            {""role"": ""assistant"", ""content"": ""Just plain text without XML""}
        ]
        bad_reward = reward_func(bad_completion)
        assert bad_reward == 0.2  # Gets 0.2 for proper spacing (no XML tags to mess up)",tests/test_xml_parser.py,TestXMLParser,1,1.522997951276035e-08,"The method `test_format_reward_function` is a unit test designed to verify the behavior of a reward function obtained from an XML parser. It checks if the function correctly assigns rewards based on the formatting of the input. This is a typical use case for unit tests, which are crucial for ensuring code reliability and correctness. Since the method is performing a necessary validation of functionality, it is likely to be retained in the codebase."
survived,"    async def test_prompt_copying(self, mock_multiturn_env):
        """"""Test that original prompt is not modified.""""""
        original_prompt = [{""role"": ""user"", ""content"": ""Original message""}]
        prompt_copy = [{""role"": ""user"", ""content"": ""Original message""}]
        
        mock_multiturn_env.client.add_chat_response(
            messages=[{""role"": ""user"", ""content"": ""Original message""}],
            response=""Response DONE""
        )
        
        completion, state = await mock_multiturn_env.rollout(
            client=mock_multiturn_env.client,
            model=""test-model"",
            prompt=original_prompt,
            answer=""test_answer""
        )
        
        # Original prompt should be unchanged
        assert original_prompt == prompt_copy
",tests/test_multiturn_env.py,TestMultiTurnEnv,1,1.8189616842444243e-09,"The method is a unit test that checks if the original prompt remains unchanged after a certain operation. This is a common and useful test to ensure data integrity, especially when dealing with asynchronous operations and potential side effects. The test is straightforward, does not have any apparent issues, and serves a clear purpose in verifying the behavior of the code. Therefore, it is likely to be retained in the codebase."
survived,"    def test_get_format_str(self, xml_parser):
        """"""Test format string generation.""""""
        format_str = xml_parser.get_format_str()
        assert ""<reasoning>"" in format_str
        assert ""</reasoning>"" in format_str
        assert ""<answer>"" in format_str
        assert ""</answer>"" in format_str
",tests/test_xml_parser.py,TestXMLParser,1,6.348800075736417e-09,"The method 'test_get_format_str' is a unit test designed to verify the functionality of the 'get_format_str' method in the 'xml_parser' object. It checks for the presence of specific XML tags in the output string, which is a common requirement for XML parsing and formatting. This test is essential for ensuring that the 'get_format_str' method correctly generates the expected XML structure. Since testing is a crucial part of software development to maintain code quality and functionality, this method is likely to be retained."
survived,"def think_parser():
    """"""Return a ThinkParser instance.""""""
    return ThinkParser()
",tests/conftest.py,,1,1.955568070542584e-08,"The method 'think_parser' is a simple factory function that returns an instance of 'ThinkParser'. It is likely to be retained because it encapsulates the creation of 'ThinkParser' objects, which can be useful for maintaining code readability and flexibility. If 'ThinkParser' is a class that is used in multiple places, having a dedicated function to instantiate it can help manage changes to the instantiation process in one place. Unless 'ThinkParser' is deprecated or the function is unused, it is likely to survive."
survived,"def mock_openai_client():
    """"""Return a mocked AsyncOpenAI client with input-output mapping.""""""
    return MockAsyncOpenAI()
",tests/conftest.py,,1,3.850741907939403e-09,"The method `mock_openai_client` is a utility function that returns a mocked version of an OpenAI client. Such functions are typically used in testing environments to simulate the behavior of actual clients without making real API calls. This is a common practice in software development to ensure that tests can run in isolation and without external dependencies. Given its utility in testing, it is likely to be retained in the codebase as long as there is a need to test interactions with the OpenAI client. Therefore, the method will likely survive."
survived,"    def test_rubric_group_get_reward_func_names(self):
        """"""Test getting aggregated reward function names from all rubrics.""""""
        def func1(completion, **kwargs):
            return 1.0
        
        def func2(completion, **kwargs):
            return 0.5
        
        def func3(completion, **kwargs):
            return 0.3
        
        rubric1 = Rubric(funcs=[func1, func2], weights=[1.0, 0.5])
        rubric2 = Rubric(funcs=[func3], weights=[0.8])
        
        group = RubricGroup(rubrics=[rubric1, rubric2])
        names = group.get_reward_func_names()
        
        assert names == [""func1"", ""func2"", ""func3""]
",tests/test_rubric_group.py,TestRubricGroup,1,3.850741907939403e-09,"The method `test_rubric_group_get_reward_func_names` is a unit test that verifies the functionality of the `get_reward_func_names` method in the `RubricGroup` class. It checks if the method correctly aggregates the names of reward functions from multiple rubrics. This is a typical test case that ensures the correct behavior of a specific feature, and such tests are crucial for maintaining code quality and reliability. Therefore, it is likely to be retained in the codebase."
survived,"    def set_default_responses(self, chat_response=None, text_response=None):
        """"""Set default responses when no mapping found.""""""
        if chat_response:
            self.default_chat_response = chat_response
        if text_response:
            self.default_text_response = text_response
",tests/conftest.py,MockAsyncOpenAI,1,2.998960815863541e-09,"The method 'set_default_responses' is a utility function that allows setting default responses for chat and text when no specific mapping is found. This is a common requirement in applications that handle user interactions, ensuring that there is always a fallback response. The method is simple, clear, and serves a useful purpose in maintaining the robustness of the application. Therefore, it is likely to be retained in the codebase."
survived,"    async def test_run_rollouts(self, mock_openai_client):
        """"""Test running multiple rollouts.""""""
        env = TestEnvironment(
            client=mock_openai_client,
            model=""test-model"",
            eval_dataset=Dataset.from_dict({""question"": [""test""], ""answer"": [""test""]}),
            parser=Parser(),
            rubric=Rubric()
        )
        
        prompts = [
            [{""role"": ""user"", ""content"": ""Hello""}],
            [{""role"": ""user"", ""content"": ""Hi""}]
        ]
        answers = [""response1"", ""response2""]
        tasks = [""default"", ""default""]
        infos = [{}, {}]
        
        # Mock the rollout method calls
        results = await env.run_rollouts(
            client=mock_openai_client,
            model=""test-model"",
            prompts=prompts,
            answers=answers,
            tasks=tasks,
            infos=infos
        )
        
        assert len(results) == 2
        assert all(len(result) == 2 for result in results)  # Each result is (completion, state)",tests/test_environment.py,TestEnvironmentBase,1,8.152020648014727e-09,"The method `test_run_rollouts` is a unit test designed to verify the functionality of the `run_rollouts` method in an asynchronous environment. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems involving external dependencies like API clients. This test method is well-structured, using mock objects to simulate the behavior of the OpenAI client, and it includes assertions to validate the expected outcomes. Given the importance of testing in software development, this method is likely to be retained to maintain code quality and prevent regressions."
survived,"        def comprehensive_func(prompt, completion, answer, state, task, info, **kwargs):
            return len(completion) + len(answer) + len(task)
",tests/test_rubric.py,TestRubric,1,1.0467401685178159e-08,"The method 'comprehensive_func' is a simple utility function that calculates the total length of three input strings: 'completion', 'answer', and 'task'. It does not perform any complex operations or depend on external factors, making it a stable and reliable function. Such utility functions are often retained in codebases because they provide a straightforward and reusable piece of functionality. Additionally, the use of **kwargs suggests that the function is designed to be flexible and potentially extended in the future, which is a good practice in software development. Therefore, it is likely that this method will be retained in the codebase."
survived,"    def test_parse_with_custom_extractor(self, think_parser_with_extractor):
        """"""Test parsing with custom extraction function.""""""
        text = """"""<think>
        I need to solve this step by step.
        </think>
        The answer is \\boxed{42}.""""""
        
        result = think_parser_with_extractor.parse(text)
        assert result == ""42""
",tests/test_think_parser.py,TestThinkParser,1,4.1399375473943306e-08,"The method 'test_parse_with_custom_extractor' is a unit test designed to verify the functionality of a parsing method with a custom extractor. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain software quality. Therefore, it is unlikely that this method will be deleted."
survived,"        def accuracy_func(completion, answer, **kwargs):
            return 1.0 if completion == answer else 0.0
",tests/test_rubric.py,TestRubric,1,3.3982678079468468e-09,"The method `accuracy_func` is a simple utility function that checks if two values are equal and returns 1.0 for a match and 0.0 otherwise. This is a common pattern used in evaluating the accuracy of predictions or completions against a known answer. The function is straightforward, efficient, and serves a clear purpose in contexts where binary accuracy is needed. There is no indication that this function is redundant or unnecessary, so it is likely to be retained in the codebase."
survived,"        def length_func(completion, **kwargs):
            return len(str(completion))
",tests/test_rubric.py,TestRubric,1,6.348800075736417e-09,"The method 'length_func' is a simple utility function that calculates the length of a given input after converting it to a string. Such utility functions are commonly used in various applications to ensure that the input is processed in a consistent manner. The function is generic and can be applied to a wide range of inputs, making it versatile and useful in many contexts. Therefore, it is likely to be retained in the codebase."
survived,"    def test_parse_whitespace_handling(self, think_parser):
        """"""Test that whitespace is properly stripped.""""""
        text = """"""<think>
        Thinking process here.
        </think>
        
        Answer with spaces around it.
        
        """"""
        result = think_parser.parse(text)
        assert result == ""Answer with spaces around it.""
",tests/test_think_parser.py,TestThinkParser,1,2.5109990926928157e-08,"The method 'test_parse_whitespace_handling' is a unit test designed to verify that the 'think_parser' correctly handles and strips whitespace from the parsed text. Unit tests are crucial for ensuring code reliability and functionality, especially when dealing with text parsing where whitespace handling can be a common issue. This method is likely to be retained as it serves an important role in maintaining the integrity of the parsing functionality."
survived,"    def test_go_simple(self):
        # should match function name exactly or struct.functionName
        group_id_1 = [
            self._create_event(
                function_names=[""handler.planet"", ""service.blue""],
                filenames=[""baz.go"", ""foo.go""],
                user_id=str(i),
            )
            for i in range(7)
        ][0].group.id
        group_id_2 = [
            self._create_event(
                function_names=[""service.blue"", ""world""],
                filenames=[""foo.go"", ""baz.go""],
                user_id=str(i),
            )
            for i in range(6)
        ][0].group.id
        top_5_issues = self.open_pr_comment_workflow.get_top_5_issues_by_count_for_file(
            projects=[self.project], sentry_filenames=[""baz.go""], function_names=[""world"", ""planet""]
        )
        top_5_issue_ids = [issue[""group_id""] for issue in top_5_issues]
        function_names = [issue[""function_name""] for issue in top_5_issues]
        assert top_5_issue_ids == [group_id_1, group_id_2]
        assert function_names == [""handler.planet"", ""world""]
",tests/sentry/integrations/github/tasks/test_open_pr_comment.py,TestGetCommentIssues,1,1.1253518384332553e-07,"The method `test_go_simple` is a unit test that verifies the functionality of a specific feature related to grouping and identifying issues based on function names and filenames. It is likely part of a test suite that ensures the correctness of the codebase. Test methods are generally not deleted unless the feature they are testing is removed or significantly changed. Since this method is testing a specific functionality, it is more likely to be maintained or updated rather than deleted."
survived,"    def test_go_methods_with_receivers(self):
        patch = """"""
@@ -152,10 +152,6 @@ func (s *Server) Start() error

@@ -152,10 +152,6 @@ func (s Server) Stop()

@@ -152,10 +152,6 @@ func (h *Handler) ServeHTTP(w ResponseWriter, r *Request)

@@ -152,10 +152,6 @@ func (db *Database) Query(query string) (*Result, error)

@@ -152,10 +152,6 @@ func (u User) String() string

@@ -152,10 +152,6 @@ func (p *Point) Distance(q *Point) float64

""""""

        assert GoParser.extract_functions_from_patch(patch) == {
            ""Start"",
            ""Stop"",
            ""ServeHTTP"",
            ""Query"",
            ""String"",
            ""Distance"",
        }
",tests/sentry/integrations/source_code_management/test_language_parsers.py,GoParserTestCase,1,1.4166087846364157e-09,"The method `test_go_methods_with_receivers` is a test function that verifies the functionality of `GoParser.extract_functions_from_patch`. It is useful for ensuring that the function correctly extracts method names from a given patch. Test methods are generally important for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained."
survived,"    def test_send_plain_text_email(self, mock_smtp_class, smtp_provider):
        """"""Test sending a plain text email.""""""
        # Setup mock SMTP instance
        mock_smtp = MagicMock()
        mock_smtp_class.return_value = mock_smtp

        # Send plain text email
        result = smtp_provider._notify(
            from_email=""sender@example.com"",
            from_name=""Test Sender"",
            to_email=""recipient@example.com"",
            subject=""Test Subject"",
            body=""This is a plain text email"",
        )

        # Verify SMTP was called correctly
        mock_smtp_class.assert_called_once_with(""smtp.example.com"", 587)
        mock_smtp.starttls.assert_called_once()
        mock_smtp.login.assert_called_once_with(""test@example.com"", ""testpassword"")
        
        # Verify email was sent
        mock_smtp.sendmail.assert_called_once()
        call_args = mock_smtp.sendmail.call_args
        assert call_args[0][0] == ""sender@example.com""
        assert call_args[0][1] == ""recipient@example.com""
        
        # Verify the email content contains plain text
        email_content = call_args[0][2]
        assert ""Content-Type: text/plain"" in email_content
        assert ""This is a plain text email"" in email_content
        
        # Verify return value
        assert result == {
            ""from"": ""sender@example.com"",
            ""to"": ""recipient@example.com"",
            ""subject"": ""Test Subject"",
            ""body"": ""This is a plain text email"",
        }
",tests/test_smtp_provider.py,TestSmtpProvider,1,6.348800075736417e-09,"The method `test_send_plain_text_email` is a unit test for verifying the functionality of sending a plain text email using a mocked SMTP provider. It checks that the SMTP connection is established correctly, the email is sent with the correct parameters, and the content is as expected. This is a crucial part of ensuring the reliability of email sending functionality in an application. Since testing is an essential part of software development to ensure code quality and functionality, this method is likely to be retained as part of the test suite."
survived,"    def test_validate_scopes_success(self, smtp_provider):
        """"""Test successful scope validation.""""""
        with patch.object(smtp_provider, ""generate_smtp_client"") as mock_generate:
            mock_smtp = MagicMock()
            mock_generate.return_value = mock_smtp
            
            result = smtp_provider.validate_scopes()
            
            assert result == {""send_email"": True}
            mock_smtp.quit.assert_called_once()
",tests/test_smtp_provider.py,TestSmtpProvider,1,2.0611536181902033e-09,"The method 'test_validate_scopes_success' is a unit test that checks the successful validation of scopes in an SMTP provider. It uses mocking to simulate the behavior of the SMTP client and verifies that the 'validate_scopes' method returns the expected result and that the 'quit' method is called once. This test is essential for ensuring the correct functionality of the 'validate_scopes' method, making it unlikely to be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method will likely survive."
survived,"def start_session(
    session_mode=""application"",  # type: str
):
    # type: (...) -> None
    return get_isolation_scope().start_session(session_mode=session_mode)
",sentry_sdk/api.py,,0,0.9999994284997149,"The method 'start_session' is a simple wrapper around another method 'get_isolation_scope().start_session'. It doesn't add any additional logic or functionality, making it redundant. Such methods are often removed to simplify the codebase unless they serve a specific purpose like abstraction or future extensibility, which is not evident here."
deleted,"    def __test_connection_via_rest_api(self):
        """"""
        Test connection to OpenShift using REST API instead of CLI.
        This is more reliable as it doesn't depend on oc CLI being installed.
        """"""
        try:
            # Suppress SSL warnings if insecure is True
            if self.authentication_config.insecure:
                # Suppress SSL verification warnings
                warnings.filterwarnings('ignore', message='Unverified HTTPS request')
            
            # Test API connectivity by hitting the /version endpoint
            headers = {
                'Authorization': f'Bearer {self.authentication_config.token}',
                'Accept': 'application/json'
            }
            
            verify_ssl = not self.authentication_config.insecure
            
            # Try to get cluster version info
            response = requests.get(
                f""{self.authentication_config.api_server}/version"",
                headers=headers,
                verify=verify_ssl,
                timeout=30
            )
            
            if response.status_code == 200:
                self.logger.info(""Successfully connected to OpenShift cluster via REST API"")
                return True, None
            else:
                error_msg = f""API returned status code {response.status_code}: {response.text}""
                self.logger.error(f""Failed to connect to OpenShift cluster: {error_msg}"")
                return False, error_msg
                
        except requests.exceptions.RequestException as e:
            error_msg = f""Connection error: {str(e)}""
            self.logger.error(f""Failed to connect to OpenShift cluster: {error_msg}"")
            return False, error_msg
        except Exception as e:
            error_msg = f""Unexpected error: {str(e)}""
            self.logger.error(f""Failed to connect to OpenShift cluster: {error_msg}"")
            return False, error_msg
",keep/providers/openshift_provider/openshift_provider.py,OpenshiftProvider,1,5.3157849718487075e-08,"The method `__test_connection_via_rest_api` is a private method designed to test the connection to an OpenShift cluster using a REST API. This method is useful for ensuring connectivity without relying on the CLI, which can be a common requirement in environments where CLI tools are not installed or available. The method handles SSL verification, token-based authentication, and error logging, making it a robust solution for connectivity checks. Given its utility in verifying API connectivity and its detailed error handling, it is likely to be retained in the codebase."
survived,"    async def test_delete_api_key_with_api_key_auth_success(
        self,
        test_api_client: AsyncClient,
        mock_user_org_dep: Mock,
        mock_api_keys_service: Mock,
        mock_user_dep: Mock,
    ):
        """"""Test that deleting an API key using API key authentication works correctly.

        This test verifies the fix for the bug where API key authentication
        would fail when deleting keys. Now it should work properly.
        """"""
        # Setup non-anonymous organization
        mock_user_org_dep.return_value.org_id = ""org_123""
        mock_user_org_dep.return_value.is_anonymous = False

        # Mock API key authentication (user will be None)
        mock_user_dep.return_value = None

        # Mock successful deletion
        mock_api_keys_service.delete_key.return_value = True

        # This should now work correctly with the fix
        response = await test_api_client.delete(""/_/api/keys/test_key_id"")

        # The fix: operation succeeds when using API key authentication
        assert response.status_code == 204
        mock_api_keys_service.delete_key.assert_called_once_with(""test_key_id"")
",api/api/routers/api_keys_test.py,TestDeleteAPIKey,1,3.653482080241728e-08,"The method is a unit test for a specific functionality, which is to ensure that API key deletion works correctly with API key authentication. Unit tests are crucial for maintaining code quality and ensuring that bugs are fixed and do not reappear. This test verifies a specific bug fix, making it valuable for regression testing. Therefore, it is unlikely to be deleted as it serves an important role in the development and maintenance process."
survived,"    def __init__(self, name: str, concurrency: int, requests: int, duration: float,
                 latencies: List[float], errors: int):
        self.name = name
        self.concurrency = concurrency
        self.requests = requests
        self.duration = duration
        self.latencies = latencies
        self.errors = errors
        
        self.rps = requests / duration
        self.avg_latency = mean(latencies) if latencies else 0
        self.median_latency = median(latencies) if latencies else 0
        self.min_latency = min(latencies) if latencies else 0
        self.max_latency = max(latencies) if latencies else 0
        self.stdev_latency = stdev(latencies) if len(latencies) > 1 else 0
",benchmarks/benchmark.py,BenchmarkResult,1,1.725782769012759e-08,"The method is a constructor (__init__) for a class, which is essential for initializing object instances with specific attributes. It calculates important performance metrics such as requests per second, average latency, and standard deviation of latencies, which are likely crucial for the functionality of the class. These metrics are commonly used in performance analysis and monitoring, suggesting that the method serves a valuable purpose. Therefore, it is unlikely to be deleted."
survived,"    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = ""https://api.opensea.io/api/v2""
",python/src/plugins/opensea/goat_plugins/opensea/service.py,OpenSeaService,1,4.6911638017642294e-08,"The method is a constructor for a class, initializing essential attributes like 'api_key' and 'base_url'. These are fundamental for the class's functionality, especially if it interacts with the OpenSea API. Such initializations are crucial for setting up the object's state, making it unlikely to be deleted unless the class itself is being removed or significantly refactored."
survived,"    async def get_nft_trades(self, parameters: dict):
        """"""Get trades for a specific NFT collection or token from Nansen""""""
        url = f""{self.base_url}/nft/trades""
        params = {
            ""token_address"": parameters[""token_address""],
            ""nft_id"": parameters[""nft_id""],
            ""start_date"": parameters[""start_date""],
            ""end_date"": parameters[""end_date""]
        }
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params, headers={""api-key"": self.api_key}) as response:
                if not response.ok:
                    raise Exception(f""HTTP error! status: {response.status} {await response.text()}"")
                return await response.json()
",python/src/plugins/nansen/goat_plugins/nansen/service.py,NansenService,1,1.4166087846364157e-09,"The method 'get_nft_trades' is likely to survive because it provides a specific and useful functionality for retrieving NFT trade data from an external service (Nansen). The use of asynchronous programming with 'aiohttp' is appropriate for handling potentially long-running I/O operations like network requests, which is common in modern Python applications. Additionally, the method is well-structured, with clear parameter handling and error checking, making it robust and maintainable."
survived,"def nansen(options: NansenPluginOptions) -> NansenPlugin:
    return NansenPlugin(options)",python/src/plugins/nansen/goat_plugins/nansen/__init__.py,,1,2.646573631904765e-09,"The method 'nansen' is a simple factory function that takes an instance of 'NansenPluginOptions' and returns a new 'NansenPlugin' object initialized with those options. This is a common pattern in software design, especially when dealing with plugins or modular components. The method is likely to be useful for creating instances of 'NansenPlugin' with specific configurations, making it a valuable part of the codebase. Unless there are changes in the design that make this pattern obsolete or the 'NansenPlugin' class is removed, this method is likely to survive."
survived,"    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = ""https://api.nansen.ai/v1""
",python/src/plugins/nansen/goat_plugins/nansen/service.py,NansenService,1,7.194132978569833e-09,"The method is a constructor for a class, initializing essential attributes like 'api_key' and 'base_url'. These are fundamental for the class's functionality, especially if it interacts with an API. Such methods are typically retained unless there's a significant change in the class's design or purpose."
survived,"    def supports_chain(self, chain) -> bool:
        return True
",python/src/plugins/nansen/goat_plugins/nansen/__init__.py,NansenPlugin,1,6.348800075736417e-09,"The method `supports_chain` is a simple implementation that always returns `True`, indicating that it supports any chain passed to it. This method is likely to be a placeholder or a default implementation in a larger system where chain support is assumed to be universal. Such methods are often retained unless there is a specific need to implement more complex logic. Without additional context suggesting that this method is obsolete or incorrect, it is reasonable to predict that it will survive."
deleted,"def version_increment_check():
    return VersionIncrementCheck()
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,,0,0.9997694933225385,"The method `version_increment_check` is a simple wrapper that returns an instance of `VersionIncrementCheck`. Without additional context, such as the purpose of `VersionIncrementCheck` or how this method is used, it's difficult to determine its utility. However, if `VersionIncrementCheck` is a class that encapsulates important functionality or state, this method could be useful for abstraction or simplifying code elsewhere. If `VersionIncrementCheck` is a commonly used class, this method might be retained for convenience. On the other hand, if `VersionIncrementCheck` is rarely used or the method doesn't add significant value, it might be considered redundant and thus deleted. Without more context, it's reasonable to predict that it might be deleted due to its simplicity and potential redundancy."
deleted,"    def _get_github_master_metadata_url(self, connector: Connector) -> str:
        return f""{GITHUB_URL_PREFIX_FOR_CONNECTORS}/{connector.technical_name}/{METADATA_FILE_NAME}""
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck,1,3.581747929000289e-10,"The method '_get_github_master_metadata_url' is a utility function that constructs a URL string based on a given connector's technical name. It is a simple and straightforward method that likely serves a specific purpose in the codebase, such as fetching metadata from a GitHub repository. Such utility functions are generally useful and are not typically removed unless they are replaced by a more efficient or comprehensive solution. Without additional context indicating deprecation or redundancy, it is reasonable to predict that this method will survive."
survived,"    def _have_same_major_minor_patch(self, master_version: semver.Version, current_version: semver.Version) -> bool:
        """"""Check if both versions have the same major, minor, and patch versions.""""""
        return (
            master_version.major == current_version.major
            and master_version.minor == current_version.minor
            and master_version.patch == current_version.patch
        )
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionIncrementCheck,1,7.582560422162384e-10,"The method '_have_same_major_minor_patch' is a utility function that checks if two version objects have the same major, minor, and patch numbers. This is a common requirement in version management and comparison tasks, especially when dealing with software dependencies or updates. The method is straightforward, efficient, and serves a clear purpose. It is likely to be useful in various contexts where version comparison is needed, and there is no indication that it is redundant or obsolete. Therefore, it is likely to be retained in the codebase."
deleted,"    def test_are_both_versions_release_candidates(self, version_increment_check):
        assert version_increment_check._are_both_versions_release_candidates(
            semver.Version.parse(""1.0.0-rc.1""),
            semver.Version.parse(""1.0.0-rc.2"")
        )
        
        assert not version_increment_check._are_both_versions_release_candidates(
            semver.Version.parse(""1.0.0-rc.1""),
            semver.Version.parse(""1.0.0"")
        )
        
        assert not version_increment_check._are_both_versions_release_candidates(
            semver.Version.parse(""1.0.0""),
            semver.Version.parse(""1.0.0-rc.1"")
        )
        
        assert not version_increment_check._are_both_versions_release_candidates(
            semver.Version.parse(""1.0.0""),
            semver.Version.parse(""1.1.0"")
        )
",airbyte-ci/connectors/connectors_qa/tests/checks/test_version.py,TestVersionIncrementCheck,1,1.522997951276035e-08,"The method `test_are_both_versions_release_candidates` is a unit test that checks the functionality of the `_are_both_versions_release_candidates` method. It verifies that the method correctly identifies when both versions are release candidates and when they are not. This is a useful test to ensure the correctness of version comparison logic, especially in systems that rely on semantic versioning. Since testing is a crucial part of software development to maintain code quality and prevent regressions, this method is likely to be retained."
deleted,"    def name(self) -> str:
        return ""Version Check""
",airbyte-ci/connectors/connectors_qa/src/connectors_qa/checks/version.py,VersionCheck,1,8.152020648014727e-09,"The method 'name' is a simple getter method that returns a string, ""Version Check"". Such methods are often used to provide a consistent way to access certain attributes or identifiers of a class. This method is likely to be used in contexts where the class needs to be identified or described by a specific name, which can be useful for logging, debugging, or user interface purposes. Since it serves a clear purpose and is straightforward, it is likely to be retained in the codebase."
survived,"def sample_csv(reasoning: str, csv_path: str, row_count: int) -> str:
    """"""Returns a sample of rows from the CSV file.

    The agent uses this to understand actual data content and patterns.
    This helps validate data types and identify any potential data quality issues.

    Args:
        reasoning: Explanation of why we're sampling this data
        csv_path: Path to the CSV file
        row_count: Number of rows to sample (aim for 3-5 rows)

    Returns:
        String containing sample rows in readable format

    Example:
        sample = sample_csv(""Check age values and formats"", ""data.csv"", 3)
        # Returns formatted string with 3 rows of data
    """"""
    try:
        df = pl.scan_csv(csv_path).limit(row_count).collect()
        # Convert to string representation
        output = df.select(pl.all()).write_csv(None)
        console.log(
            f""[blue]Sample CSV Tool[/blue] - Rows: {row_count} - Reasoning: {reasoning}""
        )
        console.log(f""[dim]Sample:\n{output}[/dim]"")
        return output
    except Exception as e:
        console.log(f""[red]Error sampling CSV: {str(e)}[/red]"")
        return """"
",sfa_polars_csv_agent_openai_v2.py,,1,7.582560422162384e-10,"The method 'sample_csv' is a utility function that provides a useful feature for sampling rows from a CSV file. This is a common requirement in data analysis and data validation tasks, where users need to quickly inspect a subset of data to understand its structure and content. The method is well-documented, handles exceptions, and logs useful information, making it a robust and user-friendly tool. Given its utility and the fact that it addresses a common need in data processing, it is likely to be retained in the codebase."
survived,"    async def completion(
        self,
        messages: List[common.Message],
        max_tokens: int,
        model: str | None = None,
        temperature: float = 1.0,
        tools: List[common.Tool] | None = None,
        tool_choice: str | None = None,
        system_prompt: str | None = None,
        *args,
        **kwargs,
    ) -> common.Completion:
        chosen_model = model or self.default_model
        ollama_messages = self._messages_into(messages)
        
        if system_prompt:
            ollama_messages.insert(0, {""role"": ""system"", ""content"": system_prompt})
        
        request_params = {
            ""model"": chosen_model,
            ""messages"": ollama_messages,
            ""options"": {
                ""temperature"": temperature,
                ""num_predict"": max_tokens,
            }
        }
        
        ollama_tools = self._tools_into(tools)
        if ollama_tools:
            request_params[""tools""] = ollama_tools
        
        try:
            response = await self.client.chat(**request_params)
            return self._completion_into(response, input_tokens=0)
        except Exception as e:
            logger.error(f""Ollama API error: {e}"")
            raise",agent/llm/ollama_client.py,OllamaLLM,1,4.4508487281649027e-07,"The method is well-structured and follows a clear logic for handling asynchronous API requests. It includes error handling, default parameter values, and flexibility in input parameters, which are all good practices in software development. Additionally, the method is likely part of a larger system that relies on it for functionality, making it less likely to be removed unless the entire system is deprecated or significantly refactored."
survived,"def post_process(
    loc,
    conf,
    landms,
    prior_data,
    cfg,
    scale,
    scale1,
    resize,
    confidence_threshold,
    top_k,
    nms_threshold,
    keep_top_k,
):

    boxes = decode(loc, prior_data, cfg[""variance""])
    boxes = boxes * scale / resize
    boxes = boxes
    scores = conf[:, 1]

    landms_copy = decode_landm(landms, prior_data, cfg[""variance""])

    landms_copy = landms_copy * scale1 / resize
    landms_copy = landms_copy

    inds = np.where(scores > confidence_threshold)[0]
    boxes = boxes[inds]
    landms_copy = landms_copy[inds]
    scores = scores[inds]

    order = scores.argsort()[::-1][:top_k]
    boxes = boxes[order]
    landms_copy = landms_copy[order]
    scores = scores[order]

    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)
    keep = py_cpu_nms(dets, nms_threshold)
    dets = dets[keep, :]
    landms_copy = landms_copy[keep]

    dets = dets[:keep_top_k, :]
    landms_copy = landms_copy[:keep_top_k, :]

    dets = np.concatenate((dets, landms_copy), axis=1)
    dets = sorted(dets, key=lambda x: x[4], reverse=True)
    dets = [parse_det(x) for x in dets]

    return dets
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,,1,2.1724399346070676e-10,"The method 'post_process' is a crucial part of a computer vision pipeline, likely related to object detection or face detection. It performs several important tasks such as decoding bounding boxes and landmarks, applying non-maximum suppression (NMS), and filtering results based on confidence scores. These operations are essential for refining the output of a detection model, ensuring that only the most relevant and accurate detections are returned. Given its role in processing model outputs, it is unlikely to be deleted unless the entire detection approach is replaced or significantly altered. Therefore, the method is expected to survive."
survived,"def batch_detect(net, images):
    confidence_threshold = 0.02
    cfg = cfg_mnet
    top_k = 5000
    nms_threshold = 0.4
    keep_top_k = 750
    resize = 1
    img = np.float32(images)
    mean = np.array([[[[104, 117, 123]]]], dtype=img.dtype)
    img -= mean
    img = img.transpose(0, 3, 1, 2)
    batch_size, _, im_height, im_width, = img.shape
    scale = np.array(
        [im_width, im_height, im_width, im_height],
        dtype=img.dtype
    )
    loc, conf, landms = net.run(img)
    priorbox = PriorBox(cfg, image_size=(im_height, im_width))
    prior_data = priorbox.forward()
    scale1 = np.array(
        [
            img.shape[3],
            img.shape[2],
            img.shape[3],
            img.shape[2],
            img.shape[3],
            img.shape[2],
            img.shape[3],
            img.shape[2],
            img.shape[3],
            img.shape[2],
        ],
        dtype=img.dtype
    )

    all_dets = [
        post_process(
            loc_i,
            conf_i,
            landms_i,
            prior_data,
            cfg,
            scale,
            scale1,
            resize,
            confidence_threshold,
            top_k,
            nms_threshold,
            keep_top_k,
        )
        for loc_i, conf_i, landms_i in zip(loc, conf, landms)
    ]

    return all_dets
",face_recognition/6d_repnet_360/utils_6d_repnet_360/functions.py,,1,6.023574641292144e-08,"The method `batch_detect` is a crucial part of a machine learning pipeline, specifically for object detection tasks. It processes a batch of images through a neural network, applies necessary transformations, and performs post-processing to extract detections. The method is well-structured, uses standard practices like normalization, and handles multiple images efficiently. Given the increasing importance of batch processing in deep learning for performance optimization, this method is likely to be retained and possibly improved rather than deleted."
survived,"def main():
    check_and_download_models(WEIGHT_PATH_6DRepNet360, MODEL_PATH_6DRepNet360, REMOTE_PATH_6DRepNet360)
    check_and_download_models(WEIGHT_PATH_FACE, MODEL_PATH_FACE, REMOTE_PATH_FACE)

    if args.video is not None:
        recognize_from_video()
    else:
        recognize_from_image()
",face_recognition/6d_repnet_360/6d_repnet_360.py,,1,5.211412485172657e-10,"The method 'main()' is a typical entry point for a Python script, and it contains essential functionality for the script's operation. It checks and downloads necessary models and then decides whether to process a video or an image based on the provided arguments. This structure is common in scripts that perform tasks like image or video processing, and it is unlikely to be removed unless the entire script is being deprecated or significantly refactored. Therefore, the method is likely to survive."
survived,"                def __init__(self, provider, session, init_timestamp, kwargs):
                    self.provider = provider
                    self.session = session
                    self.init_timestamp = init_timestamp
                    self.kwargs = kwargs
                    self.stream = None
                    # Create a new LLM event for this stream
                    self.llm_event = LLMEvent(init_timestamp=init_timestamp, params=kwargs)
                    if session is not None:
                        self.llm_event.session_id = session.session_id
                        self.llm_event.agent_id = check_call_stack_for_agent_id()
                        self.llm_event.model = kwargs.get(""model"", ""command-r-plus"")
                        self.llm_event.prompt = kwargs.get(""message"", """")
                        self.llm_event.completion = """"  # Initialize empty completion
                        logger.info(f""Initialized async stream LLM event with session_id: {session.session_id}"")
",agentops/llms/providers/cohere.py,CohereProvider.AsyncStreamWrapper,1,9.931195248674785e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes and initializes an LLM event, which seems to be a core functionality of the class. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here."
deleted,"    def _override_chat_stream_async(self):
        import cohere

        original_method = cohere.AsyncClient.chat_stream

        async def patched_function(self_client, *args, **kwargs):
            init_timestamp = get_ISO_time()
            session = kwargs.pop(""session"", None) if ""session"" in kwargs else None
            kwargs_copy = kwargs.copy()
            if ""session"" in kwargs_copy: 
                del kwargs_copy[""session""]

            # Create an async generator class that wraps the original method
            class AsyncStreamWrapper:
                def __init__(self, provider, session, init_timestamp, kwargs):
                    self.provider = provider
                    self.session = session
                    self.init_timestamp = init_timestamp
                    self.kwargs = kwargs
                    self.stream = None
                    # Create a new LLM event for this stream
                    self.llm_event = LLMEvent(init_timestamp=init_timestamp, params=kwargs)
                    if session is not None:
                        self.llm_event.session_id = session.session_id
                        self.llm_event.agent_id = check_call_stack_for_agent_id()
                        self.llm_event.model = kwargs.get(""model"", ""command-r-plus"")
                        self.llm_event.prompt = kwargs.get(""message"", """")
                        self.llm_event.completion = """"  # Initialize empty completion
                        logger.info(f""Initialized async stream LLM event with session_id: {session.session_id}"")

                def __aiter__(self):
                    return self

                async def __anext__(self):
                    if self.stream is None:
                        # Get the stream from the original method - it's already an async generator
                        response = original_method(self_client, *args, **kwargs_copy)
                        self.stream = aiter(response)

                    try:
                        # Get the next chunk
                        chunk = await anext(self.stream)
                        # Handle the chunk and track events
                        self.provider.handle_stream_chunk(chunk, self.session, self.llm_event, self.kwargs)
                        return chunk
                    except StopAsyncIteration:
                        # Record the LLM event when the stream completes
                        if self.session is not None:
                            self.llm_event.end_timestamp = get_ISO_time()
                            if not isinstance(self.llm_event.completion, dict):
                                self.llm_event.completion = {
                                    ""role"": ""assistant"",
                                    ""content"": self.llm_event.completion if isinstance(self.llm_event.completion, str) else """"
                                }
                            logger.info(f""Stream completed. Recording LLM event with completion: {self.llm_event.completion}"")
                            self.provider._safe_record(self.session, self.llm_event)
                            logger.info(""Successfully recorded async stream LLM event"")
                        raise
                    except Exception as e:
                        print(f""Error in AsyncStreamWrapper: {str(e)}"")
                        if not isinstance(self.llm_event, str):
                            self.provider._safe_record(self.session, ErrorEvent(trigger_event=self.llm_event, exception=e))
                        raise

            # Return an instance of the async generator wrapper
            return AsyncStreamWrapper(self, session, init_timestamp, kwargs)

        # Store original method and override
        self.original_create_stream_async = original_method
        cohere.AsyncClient.chat_stream = patched_function",agentops/llms/providers/cohere.py,CohereProvider,1,3.653482080241728e-08,"The method is likely to survive because it provides a useful enhancement to the existing functionality by wrapping the original async method with additional features such as event tracking and error handling. This kind of functionality is often valuable in production environments where monitoring and logging are crucial. Additionally, the method is well-structured, using an async generator to maintain the asynchronous nature of the original method while adding new capabilities."
survived,"def test_litellm_integration():
    """"""Integration test demonstrating all four LiteLLM call patterns:
    1. Sync (non-streaming)
    2. Sync (streaming)
    3. Async (non-streaming)
    4. Async (streaming)

    Verifies that AgentOps correctly tracks all LLM calls via analytics.
    """"""
    # Initialize AgentOps without auto-starting session
    agentops.init(auto_start_session=False)
    session = agentops.start_session()
    
    # Initialize LiteLLM provider
    from agentops.llms.providers.litellm import LiteLLMProvider
    provider = LiteLLMProvider(None)  # LiteLLM doesn't need a client
    provider.override()
    
    # Pass session to provider
    provider.client = session

    def sync_no_stream():
        litellm.completion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from sync no stream"", ""role"": ""user""}],
            session=session
        )

    def sync_stream():
        stream_response = litellm.completion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from sync streaming"", ""role"": ""user""}],
            stream=True,
            session=session
        )
        for _ in stream_response:
            pass

    async def async_no_stream():
        await litellm.acompletion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from async no stream"", ""role"": ""user""}],
            session=session
        )

    async def async_stream():
        async_stream_response = await litellm.acompletion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from async streaming"", ""role"": ""user""}],
            stream=True,
            session=session
        )
        # Handle streaming response
        if isinstance(async_stream_response, str):
            _ = async_stream_response
        else:
            async for chunk in async_stream_response:
                _ = chunk.choices[0].delta.content if hasattr(chunk.choices[0].delta, 'content') else ''

    async def run_async_tests():
        await async_no_stream()
        await async_stream()

    # Call each function with proper error handling
    try:
        sync_no_stream()
        sync_stream()
        asyncio.run(run_async_tests())
    except Exception as e:
        print(f""Error during LiteLLM test: {str(e)}"")
        raise

    session.end_session(""Success"")
    analytics = session.get_analytics()
    print(analytics)
    # Verify that all LLM calls were tracked
    assert analytics[""LLM calls""] >= 4, f""Expected at least 4 LLM calls, but got {analytics['LLM calls']}""
",tests/core_manual_tests/providers/litellm_canary.py,,1,5.60279640614594e-09,"The method `test_litellm_integration` is a comprehensive integration test that demonstrates the use of the LiteLLM library in various scenarios (sync, async, streaming, non-streaming). It verifies the functionality of the LiteLLM provider and ensures that all calls are tracked correctly via analytics. Such tests are crucial for maintaining the reliability and correctness of the system, especially when dealing with external integrations. Therefore, it is unlikely to be deleted as it serves an important role in the testing suite."
survived,"    def sync_no_stream():
        anthropic_client.messages.create(
            max_tokens=1024,
            model=""claude-3-5-sonnet-20240620"",
            messages=[
                {
                    ""role"": ""user"",
                    ""content"": ""Hello from sync no stream"",
                }
            ],
            session=session
        )
",tests/core_manual_tests/providers/anthropic_canary.py,,1,7.73442280641062e-08,"The method `sync_no_stream` appears to be a simple function that sends a message to a client using a specific model. There is no indication of deprecated functionality or any issues with the code itself. It seems to be a straightforward implementation of a client message creation, which is a common operation in many applications. Unless there are changes in the API or the model being used, there is no reason to delete this method."
survived,"    def sync_no_stream():
        try:
            print(""\nExecuting sync_no_stream..."")
            response = co.chat(message=""Hello from sync no stream"", model=""command"", session=session)
            print(f""sync_no_stream completed successfully with response: {response.text}"")
        except Exception as e:
            print(f""Error in sync_no_stream: {str(e)}"")
            raise
",tests/core_manual_tests/providers/cohere_canary.py,,1,2.3355930333443423e-09,"The method 'sync_no_stream' is a simple function that attempts to execute a chat command and handle exceptions. It includes logging for both successful execution and error handling, which are good practices in software development. The method is likely to be useful for debugging and monitoring purposes, especially in a development or testing environment. Unless there is a significant change in the requirements or the method becomes obsolete due to changes in the API or the surrounding code, it is likely to survive."
survived,"    def sync_stream():
        stream_response = litellm.completion(
            model=""gpt-3.5-turbo"",
            messages=[{""content"": ""Hello from sync streaming"", ""role"": ""user""}],
            stream=True,
            session=session
        )
        for _ in stream_response:
            pass
",tests/core_manual_tests/providers/litellm_canary.py,,0,0.9999999530883529,"The method `sync_stream` is likely to be deleted (0) because it does not perform any meaningful operations. It initiates a streaming response but does not process or utilize the data in any way, as indicated by the `pass` statement in the loop. This suggests that the method is incomplete or serves no functional purpose in its current state."
deleted,"                def __next__(self):
                    try:
                        chunk = next(self.stream)
                        # Handle the chunk and track events
                        self.provider.handle_stream_chunk(chunk, self.session, self.llm_event, self.kwargs)
                        return chunk
                    except StopIteration:
                        raise
                    except Exception as e:
                        print(f""Error in StreamWrapper: {str(e)}"")
                        if not isinstance(self.llm_event, str):
                            self.provider._safe_record(self.session, ErrorEvent(trigger_event=self.llm_event, exception=e))
                        raise
",agentops/llms/providers/cohere.py,CohereProvider.StreamWrapper,1,3.2241866333029355e-08,"The method `__next__` is a special method in Python used to define the behavior of an iterator. It is part of the iterator protocol, which is a fundamental part of Python's design for handling sequences and streams of data. The presence of error handling and event tracking within the method suggests it is part of a larger system that processes data streams, likely making it essential for the functionality of that system. Therefore, it is unlikely to be deleted as it serves a critical role in the operation of the iterator."
survived,"    async def run_async_tests():
        await async_no_stream()
        await async_stream()
",tests/core_manual_tests/providers/ai21_canary.py,,1,4.363462233903899e-09,"The method 'run_async_tests' is a simple asynchronous function that calls two other asynchronous functions, 'async_no_stream' and 'async_stream'. There is no indication that this method is obsolete, redundant, or incorrect. It is likely part of a test suite for asynchronous operations, which is a common practice in modern software development to ensure that asynchronous code behaves as expected. Therefore, there is no reason to delete this method unless the entire testing framework or the functions it calls are being removed or refactored."
survived,"    def sync_stream():
        try:
            print(""\nExecuting sync_stream..."")
            stream = co.chat_stream(message=""Hello from sync streaming"", model=""command"", session=session)
            completion = """"
            for chunk in stream:
                if hasattr(chunk, 'text'):
                    completion += chunk.text
                print(f""Received sync chunk: {chunk}"")
            print(f""sync_stream completed successfully with completion: {completion}"")
        except Exception as e:
            print(f""Error in sync_stream: {str(e)}"")
            raise
",tests/core_manual_tests/providers/cohere_canary.py,,1,1.4166087846364157e-09,"The method 'sync_stream' is a utility function that handles streaming data from a chat model. It includes error handling and logging, which are good practices for maintaining code. The method is likely to be useful in scenarios where real-time data processing is required, and it seems to be functioning correctly without any apparent issues. Therefore, it is likely to be retained in the codebase."
survived,"    def sync_stream():
        stream_response = chat_client.create(
            model=""jamba-instruct"",
            system=""You are a helpful AI assistant"",
            messages=sync_stream_messages,
            maxTokens=10,
            stream=True
        )
        for chunk in stream_response:
            _ = chunk.choices[0].delta.content if hasattr(chunk.choices[0].delta, 'content') else ''
",tests/core_manual_tests/providers/ai21_canary.py,,1,4.0586521248284276e-10,"The method 'sync_stream' is likely to be Survived (1) because it appears to be a functional piece of code that interacts with a chat client to create a streaming response. The method is structured to handle the response in chunks, which is a common pattern for handling streaming data. Additionally, the use of 'hasattr' ensures that the code does not break if 'content' is not present, indicating a level of robustness. There is no indication of deprecated functionality or poor coding practices that would necessitate deletion."
survived,"    async def async_stream():
        stream_response = await client.chat_stream(
            model=""mistral-tiny"",
            messages=[ChatMessage(role=""user"", content=""Hello from async streaming"")]
        )
        async for chunk in stream_response:
            _ = chunk.delta.content if hasattr(chunk.delta, 'content') else ''
",tests/core_manual_tests/providers/mistral_canary.py,,1,8.152020648014727e-09,"The method 'async_stream' demonstrates the use of asynchronous programming to handle streaming responses from a chat model. Asynchronous programming is a modern and efficient way to handle I/O-bound operations, such as network requests, without blocking the main thread. This method is likely to be useful in applications that require real-time data processing or interaction with AI models, making it a relevant and valuable piece of code. Therefore, it is likely to be retained."
survived,"def test_get_sample_values_returns_primitives() -> None:
    """"""Test that get_sample_values always returns primitive types.""""""
    import polars as pl

    def is_primitive(value: Any) -> bool:
        return isinstance(
            value,
            (
                str,
                int,
                float,
                bool,
                type(None),
                datetime.datetime,
                datetime.date,
            ),
        )

    class Enum:
        A = ""a""
        B = ""b""
        C = ""c""

    # Create a DataFrame with various types including categorical/enum-like columns
    df = pl.DataFrame(
        {
            ""category"": pl.Series([""A"", ""B"", ""C""], dtype=pl.Categorical),
            ""mixed"": pl.Series([""str"", ""123"", ""45.67""]),
            ""list"": pl.Series([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),
            ""dict"": pl.Series(
                [
                    {""a"": 1, ""b"": Enum.A},
                    {""c"": 3, ""d"": Enum.B},
                    {""e"": 5, ""f"": Enum.C},
                ]
            ),
            ""enum"": pl.Series([Enum.A, Enum.B, Enum.C]),
            ""dates"": [
                datetime.datetime(2021, 1, 1),
                datetime.datetime(2021, 1, 2),
                datetime.datetime(2021, 1, 3),
            ],
        },
    )

    manager: NarwhalsTableManager[Any] = NarwhalsTableManager.from_dataframe(
        df
    )

    # Verify all values are primitives
    for column in df.columns:
        values = manager.get_sample_values(column)
        for val in values:
            assert is_primitive(val), (
                f""Column {column} returned non-primitive or non-datetime value: {val} of type {type(val)}""
            )
",tests/_plugins/ui/_impl/tables/test_narwhals.py,,1,7.73442280641062e-08,"The method is a test function that ensures the `get_sample_values` method of `NarwhalsTableManager` returns only primitive types. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this test checks for a fundamental aspect of data handling (ensuring primitive types), it is likely to be retained to ensure data integrity and correctness."
survived,"    async def _run(self) -> StepResult:
        if self.original_manifest:
            self.manifest_path.write_text(self.original_manifest)

        if self.backup_schema_path:
            copy_directory(self.backup_schema_path, self.schemas_path)

        return StepResult(
            step=self,
            status=StepStatus.SUCCESS,
        )
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,RestoreInlineState,1,5.211412485172657e-10,"The method '_run' is an asynchronous function that performs a series of operations and returns a 'StepResult' object. It checks for the presence of 'original_manifest' and 'backup_schema_path', performing file operations if they exist. The method is well-structured, uses clear conditional checks, and returns a meaningful result. There is no indication of deprecated practices or inefficiencies that would warrant its deletion. Therefore, it is likely to be retained in the codebase."
survived,"async def migrate_to_inline_schemas(ctx: click.Context, report: bool) -> bool:
    verify_formatters()
    return await run_connector_pipeline(
        ctx,
        ""Migrate to inline schemas"",
        report,
        run_connector_migrate_to_inline_schemas_pipeline,
    )",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/commands.py,,1,3.850741907939403e-09,"The method 'migrate_to_inline_schemas' is an asynchronous function that appears to be part of a larger system for managing data pipelines. It calls two other functions: 'verify_formatters' and 'run_connector_pipeline'. The function is likely part of a migration process to update or change the schema format within a system. Given that it is an async function, it is designed to handle potentially long-running operations without blocking the main thread, which is a modern and efficient approach in software development. The function is also well-named and seems to serve a clear purpose within its context. There is no indication that this function is obsolete or redundant, and it likely plays a crucial role in the system's operation. Therefore, it is likely to be retained."
survived,"    def __init__(self, context: PipelineContext) -> None:
        super().__init__(context)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,CheckIsInlineCandidate,1,4.6911638017642294e-08,"The method is a constructor for a class, which is a fundamental part of object-oriented programming. Constructors are essential for initializing new objects and setting up initial states. This method is also calling the superclass's constructor, which is a common practice to ensure proper initialization of inherited attributes. Therefore, it is unlikely to be deleted as it serves a critical role in the class's functionality."
survived,"    def __init__(self, context: ConnectorContext) -> None:
        super().__init__(context)
        self.manifest_path = context.connector.manifest_path
        self.original_manifest = None
        if self.manifest_path.is_file():
            self.original_manifest = self.manifest_path.read_text()

        self.schemas_path = context.connector.python_source_dir_path / SCHEMAS_DIR_NAME
        self.backup_schema_path = None
        if self.schemas_path.is_dir():
            self.backup_schema_path = Path(tempfile.mkdtemp())
            copy_directory(self.schemas_path, self.backup_schema_path)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,RestoreInlineState,1,1.1861120010657661e-08,"The method is a constructor (__init__) for a class, which is essential for initializing instances of the class. It sets up important attributes such as manifest_path, original_manifest, schemas_path, and backup_schema_path. These attributes are likely crucial for the functionality of the class, especially if it deals with file paths and schema management. Constructors are rarely deleted unless the class itself is being removed or significantly refactored, which is not indicated here. Therefore, the method is likely to survive."
survived,"    async def _run(self) -> StepResult:
        connector = self.context.connector
        python_path = connector.python_source_dir_path
        schemas_path = python_path / SCHEMAS_DIR_NAME
        logger = self.logger

        manifest = connector.manifest_path.read_text()

        if manifest.find(""JsonFileSchemaLoader"") != -1:
            return StepResult(
                step=self,
                status=StepStatus.SKIPPED,
                stderr=""Skipping: the manifest is still using JSON Schema loader."",
            )

        if schemas_path.exists():
            logger.info(f""    Removing schemnas dir: {schemas_path}"")
            shutil.rmtree(schemas_path)

        return StepResult(step=self, status=StepStatus.SUCCESS)
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,RemoveUnusedJsonSchamas,1,1.1628233028868813e-10,"The method '_run' is performing a specific task related to checking and removing a schemas directory based on certain conditions. It is well-structured, uses logging, and handles different scenarios (like skipping the step if a condition is met). This indicates that it is a useful and functional part of the codebase. There is no indication that it is obsolete or redundant, so it is likely to be retained."
survived,"def _has_subdirectory(directory: Path) -> bool:
    # Iterate through all items in the directory
    for entry in directory.iterdir():
        # Check if this entry is a directory
        if entry.is_dir():
            return True

    return False
",airbyte-ci/connectors/pipelines/pipelines/airbyte_ci/connectors/migrate_to_inline_schemas/pipeline.py,,1,2.998960815863541e-09,"The method `_has_subdirectory` is a utility function that checks if a given directory contains any subdirectories. This is a common requirement in file system operations, especially when dealing with directory structures. The method is simple, efficient, and serves a clear purpose. It is unlikely to be deleted unless there is a significant change in the requirements or a more efficient built-in function is introduced that renders this method obsolete. However, as of the current state of Python's standard library, this method is useful and likely to be retained."
survived,"    def test_pause_live_updates_with_active_session(self):
        """"""Test pausing when Live session is active.""""""
        formatter = ConsoleFormatter()
        
        mock_live = MagicMock(spec=Live)
        formatter._live = mock_live
        formatter._live_paused = False
        
        formatter.pause_live_updates()
        
        mock_live.stop.assert_called_once()
        assert formatter._live_paused
",tests/utilities/test_console_formatter_pause_resume.py,TestConsoleFormatterPauseResume,1,7.73442280641062e-08,"The method `test_pause_live_updates_with_active_session` is a unit test designed to verify the behavior of the `pause_live_updates` method when a live session is active. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to maintain test coverage and facilitate future development. Therefore, it is unlikely that this method will be deleted."
survived,"            def track_pause():
                pause_calls.append(True)
",tests/test_flow_human_input_integration.py,TestFlowHumanInputIntegration,1,1.4738976032926566e-05,"The method 'track_pause' is a simple function that appends a boolean value to a list 'pause_calls'. Without additional context, it's difficult to determine its utility. However, if 'pause_calls' is used elsewhere in the code to track the number of pauses or for debugging purposes, the method could be useful. If 'pause_calls' is not used or the function is redundant, it might be deleted. Given the lack of context, it's more likely to be retained for potential utility."
survived,"    def test_polars_groupby_alias() -> None:
        """"""Test that group by operations use original column names correctly.""""""
        import polars as pl

        import marimo as mo

        # Create a test dataframe with age and group columns
        df = pl.DataFrame({
            ""group"": [""a"", ""a"", ""b"", ""b""],
            ""age"": [10, 20, 30, 40],
        })
        # Test the transformation directly using TransformsContainer
        from marimo._plugins.ui._impl.dataframes.transforms.apply import (
            TransformsContainer,
            get_handler_for_dataframe,
        )
        from marimo._plugins.ui._impl.dataframes.transforms.types import (
            GroupByTransform,
            TransformType,
            Transformations,
        )

        handler = get_handler_for_dataframe(df)
        transform_container = TransformsContainer(df, handler)
        
        # Create and apply the transformation
        transform = GroupByTransform(
            type=TransformType.GROUP_BY,
            column_ids=[""group""],
            drop_na=True,
            aggregation=""max"",
        )
        transformations = Transformations([transform])
        transformed_df = transform_container.apply(transformations)

        # Verify the transformed DataFrame
        assert isinstance(transformed_df, pl.DataFrame)
        assert ""group"" in transformed_df.columns
        assert ""age_max"" in transformed_df.columns
        assert transformed_df.shape == (2, 2)
        assert transformed_df[""age_max""].to_list() == [20, 40]  # max age for each group

        # The resulting frame should have correct column names and values
        # Convert to dict and verify values
        result_dict = {
            col: transformed_df[col].to_list()
            for col in transformed_df.columns
        }
        assert result_dict == {
            ""group"": [""a"", ""b""],
            ""age_max"": [20, 40],
        }

        # Verify the generated code uses original column names
        from marimo._plugins.ui._impl.dataframes.transforms.print_code import (
            python_print_polars,
        )
        code = python_print_polars(
            ""df"",
            [""group"", ""age""],
            transform,
        )
        # Code should reference original ""age"" column, not ""age_max""
        assert 'pl.col(""age"")' in code
        assert 'alias(""age_max"")' in code
        assert 'pl.col(""group"")' in code  # Original column name in group by
",tests/_plugins/ui/_impl/dataframes/test_dataframe.py,TestDataframes,1,2.5109990926928157e-08,"The method is a well-structured test function that verifies the functionality of a group by operation using the Polars library and a custom transformation framework. It includes assertions to ensure the correctness of the transformation and the generated code. Such test functions are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite."
survived,"    def _generate_uuid(cls, seed: str) -> str:
        """"""
        Generate a deterministic UUID based on a seed string.

        Args:
            seed (str): The seed string to use for UUID generation

        Returns:
            str: A string representation of the UUID consistently generated from the seed
        """"""
        if not isinstance(seed, str):
            raise ValueError(""Seed must be a string"")
        
        if not seed.strip():
            raise ValueError(""Seed cannot be empty or whitespace"")
            
        # Create a deterministic UUID using v5 (SHA-1)
        # Custom namespace for CrewAI to enhance security

        # Using a unique namespace specific to CrewAI to reduce collision risks
        CREW_AI_NAMESPACE = uuid.UUID('f47ac10b-58cc-4372-a567-0e02b2c3d479')
        return str(uuid.uuid5(CREW_AI_NAMESPACE, seed))
",src/crewai/security/fingerprint.py,Fingerprint,1,8.592166611791576e-10,"The method '_generate_uuid' is well-documented, performs a useful function by generating a deterministic UUID from a seed, and includes error handling for invalid inputs. It uses a specific namespace to reduce collision risks, which is a thoughtful implementation detail. These factors suggest that the method is likely to be retained as it provides a clear and useful functionality."
survived,"def consume(config):
    connection = create_sink_connection(config=config)

    while True:
        # Consume transformed event from the pipeline
        res = connection.consume()

        if res.status_code == 200:
            record = res.event()
            assert record[""data""] == TEST_MESSAGE
            assert record[""stream""] == TEST_STREAM
            assert record[""namespace""] == TEST_NAMESPACE
            assert ""emitted_at"" in record
            break
",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,,0,0.9999997897565932,"The method 'consume' is likely to be deleted because it contains hardcoded assertions that check for specific test values (TEST_MESSAGE, TEST_STREAM, TEST_NAMESPACE). This suggests that the method is designed for testing purposes rather than for production use. In a production environment, such hardcoded values would not be practical, and the method would need to be more flexible to handle various inputs. Additionally, the method runs an infinite loop with a break condition that is only met if the assertions pass, which is not a typical pattern for robust production code. Therefore, it is likely that this method is temporary and will be removed once testing is complete."
survived,"def test_check_fails():
    f = open(
        ""integration_tests/invalid_config.json"",
    )
    config = json.load(f)
    destination = DestinationGlassflow()
    status = destination.check(logger=Mock(), config=config)
    assert status.status == Status.FAILED
",airbyte-integrations/connectors/destination-glassflow/integration_tests/integration_test.py,,1,5.60279640614594e-09,"The method 'test_check_fails' is a unit test designed to verify that a certain configuration check fails as expected. Unit tests are crucial for ensuring code reliability and are typically not deleted unless they are redundant or replaced by a more comprehensive testing framework. Since this test is specifically checking for a failure condition, it is likely an important part of the test suite to ensure that the system correctly identifies invalid configurations. Therefore, it is likely to survive."
survived,"    def check(self, logger: Logger, config: Mapping[str, Any]) -> AirbyteConnectionStatus:
        """"""
        Tests if the input configuration can be used to successfully connect to the destination with the needed permissions
            e.g: if a provided API token or password can be used to connect and write to the destination.

        :param logger: Logging object to display debug/info/error to the logs
            (logs will not be accessible via airbyte UI if they are not passed to this logger)
        :param config: Json object containing the configuration of this destination, content of this json is as specified in
        the properties of the spec.json file

        :return: AirbyteConnectionStatus indicating a Success or Failure
        """"""
        try:
            connection = create_source_connection(config)
            try:
                connection.validate_credentials()
                return AirbyteConnectionStatus(status=Status.SUCCEEDED)
            except errors.PipelineAccessTokenInvalidError:
                return AirbyteConnectionStatus(status=Status.FAILED, message=f""The pipeline access token is not valid"")
        except Exception as e:
            logger.error(f""Failed to create connection. Error: {e}"")
            return AirbyteConnectionStatus(status=Status.FAILED, message=f""An exception occurred: {repr(e)}"")",airbyte-integrations/connectors/destination-glassflow/destination_glassflow/destination.py,DestinationGlassflow,1,3.581747929000289e-10,"The method is well-structured and serves a critical function of validating connection credentials, which is essential for ensuring that the system can interact with external services securely and effectively. It handles exceptions gracefully and provides meaningful error messages, which are crucial for debugging and user feedback. Additionally, the method aligns with common practices in software development for checking configurations and logging errors. Therefore, it is likely to be retained."
survived,"def test_check_fails(client):
    pipeline = _init_mocks(client)
    pipeline.validate_credentials.side_effect = errors.PipelineAccessTokenInvalidError(mock.Mock())
    destination = DestinationGlassflow()
    status = destination.check(logger=Mock(), config=config)
    assert status.status == Status.FAILED
",airbyte-integrations/connectors/destination-glassflow/unit_tests/unit_test.py,,1,4.599055376537186e-10,"The method `test_check_fails` is a unit test designed to verify that the `check` method of the `DestinationGlassflow` class correctly handles a scenario where credential validation fails. This is a typical and necessary test to ensure robustness in error handling, especially when dealing with external systems or services. Such tests are crucial for maintaining code quality and reliability, and they are unlikely to be deleted unless the functionality they test is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def test_crew_output_import():
    """"""Test that CrewOutput can be imported from crewai.""""""
    from crewai import CrewOutput
    
    assert CrewOutput is not None",tests/imports_test.py,,1,4.944450477491054e-09,"The method `test_crew_output_import` is a simple unit test that checks if the `CrewOutput` class can be imported from the `crewai` module. This is a basic test that ensures the import functionality is working as expected. Such tests are generally useful for maintaining code integrity and ensuring that dependencies are correctly set up. Since it serves a valid purpose in verifying the import mechanism, it is likely to be retained in the codebase."
survived,"def test_get_configured_catalog_parametrized(
    mock_catalog,
    mock_stream,
    cursor_override,
    pk_override,
    expected_cursor,
    expected_pk,
):
    """"""Test various combinations of cursor and primary key overrides.""""""
    cursor_key_overrides = {""test_stream"": cursor_override} if cursor_override else None
    primary_key_overrides = {""test_stream"": pk_override} if pk_override else None

    with patch.object(Source, ""_discover"", return_value=mock_catalog):
        source = Source(
            executor=Mock(),
            name=""test-source"",
            cursor_key_overrides=cursor_key_overrides,
            primary_key_overrides=primary_key_overrides,
        )

        catalog = source.get_configured_catalog()

        assert len(catalog.streams) == 1
        configured_stream = catalog.streams[0]
        assert configured_stream.cursor_field == expected_cursor
        assert configured_stream.primary_key == expected_pk",tests/unit_tests/sources/test_source_key_overrides.py,,1,1.3709566550544279e-06,"The method `test_get_configured_catalog_parametrized` is a unit test function designed to test the behavior of a source configuration in a data pipeline. It uses mock objects and assertions to verify that the source's catalog is configured correctly based on cursor and primary key overrides. This type of test is crucial for ensuring the reliability and correctness of the data processing logic, especially when dealing with dynamic configurations. Given its role in maintaining code quality and preventing regressions, it is unlikely to be deleted."
survived,"def mock_stream():
    """"""Create a mock AirbyteStream for testing.""""""
    stream = Mock(spec=AirbyteStream)
    stream.name = ""test_stream""
    stream.source_defined_primary_key = [[""original_pk""]]
    stream.source_defined_cursor = [""original_cursor""]
    return stream
",tests/unit_tests/sources/test_source_key_overrides.py,,1,7.194132978569833e-09,"The method 'mock_stream' is a utility function designed to create a mock object for testing purposes. Such functions are commonly used in unit tests to simulate the behavior of complex objects without requiring the actual implementation. This method is likely to be retained because it aids in testing, which is a crucial part of software development to ensure code reliability and correctness. Additionally, the method is simple, well-defined, and serves a clear purpose, making it unlikely to be removed unless the testing framework or requirements change significantly."
survived,"def test_set_primary_keys(input_keys, expected_output):
    """"""Test that set_primary_keys properly converts and updates the primary key overrides.""""""
    with patch.object(Source, ""_discover"", return_value=Mock()):
        source = Source(executor=Mock(), name=""test-source"")

        source.set_primary_keys(kwargs=input_keys)

        assert source._primary_key_overrides == expected_output

        update_keys = {""stream3"": ""pk3""}
        expected_after_update = expected_output.copy()
        expected_after_update[""stream3""] = [""pk3""]

        source.set_primary_keys(kwargs=update_keys)
        assert source._primary_key_overrides == expected_after_update
",tests/unit_tests/sources/test_source_key_overrides.py,,1,3.850741907939403e-09,"The method 'test_set_primary_keys' is a test function that verifies the behavior of the 'set_primary_keys' method in the 'Source' class. Test functions are generally not deleted unless they are redundant or the functionality they test is removed. Since this test is checking the correct updating of primary key overrides, it is likely to be useful for ensuring the integrity of the 'set_primary_keys' method. Therefore, it is likely to survive."
survived,"    def set_cursor_key(
        self,
        stream_name: str,
        cursor_key: str,
    ) -> None:
        """"""Set the cursor for a single stream.""""""
        self._cursor_key_overrides[stream_name] = cursor_key
",airbyte/sources/base.py,Source,1,1.6052280526088547e-09,"The method 'set_cursor_key' is a simple setter function that updates a dictionary with a new cursor key for a given stream name. This is a common pattern in programming for managing state or configuration settings. The method is straightforward, performs a necessary function, and does not have any apparent issues or redundancies that would warrant its removal. Therefore, it is likely to be retained in the codebase."
survived,"    def set_primary_keys(
        self,
        *,
        kwargs: dict[str, str | list[str]],
    ) -> None:
        """"""Override the primary keys for one or more streams.

        This does not unset previously set primary keys.

        The primary key can be a single column name, or a list of fields which should comprise
        the composite primary key.

        Args:
            kwargs: A dictionary mapping stream names to either a primary key column name, or a
            list of fields which should comprise the composite primary key.
        """"""
        self._primary_key_overrides.update(
            {k: v if isinstance(v, list) else [v] for k, v in kwargs.items()}
        )
",airbyte/sources/base.py,Source,1,8.592166611791576e-10,"The method 'set_primary_keys' is likely to survive because it provides a useful functionality for managing primary keys in a flexible manner. It allows users to override primary keys for multiple streams at once, supporting both single and composite keys. This flexibility is valuable in data management and stream processing contexts, making the method relevant and useful."
survived,"    def test_load_persistent_cache(self) -> None:
        """"""Test loading a persistent cache.""""""
        loader = JsonLoader(""test"", self.save_path)
        
        # Create a cache file
        cache_path = loader.build_path(""hash1"", ""Pure"")
        
        # Create a valid JSON cache
        cache_dict = {
            ""defs"": {""var1"": ""value1""},
            ""hash"": ""hash1"",
            ""stateful_refs"": [],
            ""cache_type"": ""Pure"",
            ""hit"": True,
            ""meta"": {}
        }
        
        with open(cache_path, ""w"") as f:
            json.dump(cache_dict, f)
        
        # Load the cache
        loaded_cache = loader.load_persistent_cache(""hash1"", ""Pure"")
        assert loaded_cache.hash == ""hash1""
        assert loaded_cache.cache_type == ""Pure""
        assert loaded_cache.hit is True
        assert isinstance(loaded_cache.stateful_refs, set)
        
        # Should raise for non-existent cache
        with pytest.raises(FileNotFoundError):
            loader.load_persistent_cache(""nonexistent"", ""Pure"")
        
        # Test with invalid JSON
        invalid_path = loader.build_path(""invalid"", ""Pure"")
        with open(invalid_path, ""w"") as f:
            f.write(""not valid json"")
        
        with pytest.raises(json.JSONDecodeError):
            loader.load_persistent_cache(""invalid"", ""Pure"")
        
        # Test with missing required fields
        missing_fields_path = loader.build_path(""missing"", ""Pure"")
        with open(missing_fields_path, ""w"") as f:
            json.dump({""hash"": ""missing"", ""stateful_refs"": []}, f)
        
        with pytest.raises(LoaderError, match=""Invalid json object""):
            loader.load_persistent_cache(""missing"", ""Pure"")
",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,3.653482080241728e-08,"The method `test_load_persistent_cache` is a unit test designed to verify the functionality of the `load_persistent_cache` method in the `JsonLoader` class. It covers various scenarios such as loading a valid cache, handling non-existent caches, dealing with invalid JSON, and missing required fields. These tests are crucial for ensuring the robustness and reliability of the cache loading functionality. Since testing is an essential part of software development to prevent regressions and ensure code quality, this method is likely to be retained in the codebase."
survived,"    def test_load_persistent_cache(self) -> None:
        """"""Test loading a persistent cache.""""""
        loader = PickleLoader(""test"", self.save_path)
        
        # Create a cache file
        cache_path = loader.build_path(""hash1"", ""Pure"")
        # Use string directly instead of Name constructor
        original_cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            set(),
            ""Pure"",
            True,
            {}
        )
        
        with open(cache_path, ""wb"") as f:
            pickle.dump(original_cache, f)
        
        # Load the cache
        loaded_cache = loader.load_persistent_cache(""hash1"", ""Pure"")
        assert loaded_cache.hash == ""hash1""
        assert loaded_cache.cache_type == ""Pure""
        assert loaded_cache.hit is True
        
        # Should raise for non-existent cache
        with pytest.raises(FileNotFoundError):
            loader.load_persistent_cache(""nonexistent"", ""Pure"")
        
        # Test with invalid cache object
        invalid_path = loader.build_path(""invalid"", ""Pure"")
        with open(invalid_path, ""wb"") as f:
            pickle.dump(""not a cache"", f)
        
        with pytest.raises(LoaderError, match=""Excepted cache object""):
            loader.load_persistent_cache(""invalid"", ""Pure"")
",tests/_save/loaders/test_pickle_loader.py,TestPickleLoader,1,6.023574641292144e-08,"The method `test_load_persistent_cache` is a unit test designed to verify the functionality of loading a persistent cache using the `PickleLoader` class. It includes tests for successful cache loading, handling of non-existent cache files, and invalid cache objects. These are essential tests to ensure the robustness and reliability of the caching mechanism. Since testing is a crucial part of software development to maintain code quality and prevent regressions, this method is likely to be retained in the codebase."
survived,"    def test_save_cache(self) -> None:
        """"""Test saving a cache.""""""
        loader = JsonLoader(""test"", self.save_path)
        
        # Create a cache with a stateful reference
        cache = Cache(
            {""var1"": ""value1""}, 
            ""hash1"", 
            {""stateful""},
            ""Pure"",
            True,
            {""version"": 1}
        )
        
        # Save the cache
        loader.save_cache(cache)
        
        # Verify the file was created
        cache_path = loader.build_path(""hash1"", ""Pure"")
        assert os.path.exists(cache_path)
        
        # Load the JSON and verify contents
        with open(cache_path, ""r"") as f:
            loaded_json = json.load(f)
        
        assert loaded_json[""hash""] == ""hash1""
        assert loaded_json[""cache_type""] == ""Pure""
        assert loaded_json[""hit""] is True
        assert isinstance(loaded_json[""stateful_refs""], list)  # Should be converted to list
        assert loaded_json[""meta""] == {""version"": 1}
        
        # Save another cache with different type
        cache2 = Cache(
            {""var2"": ""value2""}, 
            ""hash2"", 
            set(),
            ""Deferred"",
            True,
            {}
        )
        
        loader.save_cache(cache2)
        
        # Verify the second file was created
        cache2_path = loader.build_path(""hash2"", ""Deferred"")
        assert os.path.exists(cache2_path)
        
        # Load the second JSON and verify contents
        with open(cache2_path, ""r"") as f:
            loaded_json2 = json.load(f)
        
        assert loaded_json2[""hash""] == ""hash2""
        assert loaded_json2[""cache_type""] == ""Deferred""",tests/_save/loaders/test_json_loader.py,TestJsonLoader,1,9.237449576640118e-09,"The method 'test_save_cache' is a unit test that verifies the functionality of saving cache data using a JsonLoader. It checks if the cache files are created and if their contents are correct. This is a crucial part of ensuring the reliability of the caching mechanism in the application. Since testing is an essential part of software development to maintain code quality and prevent regressions, this method is likely to be retained."
survived,"    def test_init_with_custom_cache(self) -> None:
        """"""Test initialization with a custom cache.""""""
        custom_cache = OrderedDict()
        loader = MemoryLoader(""test"", cache=custom_cache)
        assert id(loader._cache) != id(custom_cache)  # Should be a copy, not the same instance
        assert len(loader._cache) == 0
",tests/_save/loaders/test_memory_loader.py,TestMemoryLoader,1,1.725782769012759e-08,"The method 'test_init_with_custom_cache' is a unit test designed to verify the behavior of the 'MemoryLoader' class when initialized with a custom cache. It checks that the cache used by the loader is a copy of the provided cache, not the same instance, and that it starts empty. This is a valid and useful test to ensure the correct functionality of the 'MemoryLoader' class, particularly in scenarios where cache management is critical. Therefore, it is likely to be retained as part of the test suite to ensure code reliability and correctness."
deleted,"def test_crew_train_with_memory():
    """"""Test that training a crew with memory enabled does not raise validation errors.""""""
    agent = Agent(role=""Test Agent"", goal=""Test Goal"", backstory=""Test Backstory"")
    task = Task(description=""Test Task"", expected_output=""Test Output"", agent=agent)
    crew = Crew(agents=[agent], tasks=[task], memory=True)

    with tempfile.TemporaryDirectory() as tmpdir:
        filename = os.path.join(tmpdir, ""training_data.pkl"")
        try:
            crew.train(n_iterations=1, filename=filename)
        except pydantic_core.ValidationError as e:
             if ""Input should be an instance of"" in str(e) and (""Memory"" in str(e)):
                  pytest.fail(f""Training with memory raised Pydantic ValidationError, likely due to incorrect memory copy: {e}"")
             else:
                  raise e
        except Exception as e:
            print(f""Warning: Training raised an unexpected exception: {e}"")",tests/crew_test.py,,1,9.931195248674785e-08,"The method is a test function that checks if training a crew with memory enabled does not raise validation errors. It is a specific test case that ensures the functionality of the 'train' method in the presence of memory. Such test functions are crucial for maintaining code quality and ensuring that new changes do not break existing functionality. Therefore, it is likely to be retained as part of the test suite."
survived,"def test_invalid_schema(tmp_path):
    """"""Test that an invalid schema raises RuntimeError with mismatch message.""""""
    db_path = tmp_path / ""metadata.db""
    # Manually create a runs table with incorrect columns
    with sqlite3.connect(str(db_path)) as conn:
        conn.execute(""CREATE TABLE runs (wrong_col TEXT)"")
    
    db = MetadataDB(str(db_path))
    with pytest.raises(RuntimeError, match=""mismatch""):
        db.store_metadata({
            ""run_hash"": ""test2"",
            ""dataset_hash"": ""hash2"",
            ""prompt_func"": ""def prompt_func(): pass"",
            ""model_name"": ""test-model-2"",
            ""response_format"": ""{}"",
            ""batch_mode"": True,
            ""timestamp"": ""2023-01-01T01:00:00Z"",
        })",tests/test_db_schema.py,,1,2.5109990926928157e-08,"The method is testing a specific functionality related to error handling when there is a schema mismatch in a database. This is a common and important test case to ensure that the system behaves correctly when encountering unexpected database schemas. The test is well-defined, uses a temporary path to avoid side effects, and checks for a specific error message, which is a good practice in testing. Therefore, it is likely to be retained as it ensures robustness in the system's error handling capabilities."
deleted,"    def test_sanitize_collection_name_short_name(self):
        """"""Test sanitizing a very short name.""""""
        short_name = ""A""
        sanitized = sanitize_collection_name(short_name)
        self.assertGreaterEqual(len(sanitized), 3)
        self.assertTrue(sanitized[0].isalnum())
        self.assertTrue(sanitized[-1].isalnum())
",tests/utilities/test_string_utils.py,TestStringUtils,1,5.60279640614594e-09,"The method `test_sanitize_collection_name_short_name` is a unit test designed to verify the behavior of the `sanitize_collection_name` function when given a very short name as input. It checks that the sanitized name is at least 3 characters long and that both the first and last characters are alphanumeric. This is a valid and useful test case to ensure that the sanitization function handles edge cases correctly, such as very short input names. Therefore, it is likely to be retained as part of the test suite to ensure the robustness of the `sanitize_collection_name` function."
deleted,"    def _get_backend_shutdown_handler(self):
        """"""Get the backend shutdown handler.

        Returns:
            A lambda function that does nothing for compatibility.
        """"""
        return lambda: None
",reflex/testing.py,AppHarnessProd,1,5.144221744469598e-05,"The method `_get_backend_shutdown_handler` is a private method (indicated by the underscore prefix) that returns a lambda function doing nothing. This suggests it is a placeholder for future functionality or a compatibility measure. Since it doesn't currently perform any meaningful operation, it might be considered for deletion unless there is a specific reason to keep it for compatibility or future use. However, without additional context on its usage or the broader codebase, it's difficult to definitively predict its removal. Given that it might serve a compatibility purpose, it is more likely to survive for now."
survived,"    def test_require_api_key_config(self, mock_get_context: MagicMock) -> None:
        """"""Test _require_api_key with config.""""""
        mock_context = MagicMock()
        mock_context.marimo_config = {""ai"": {""google"": {""api_key"": ""config-key""}}}
        mock_get_context.return_value = mock_context

        model = google(""gemini-pro"")
        assert model._require_api_key == ""config-key""
",tests/_ai/llm/_impl.py,TestGoogle,1,2.3355930333443423e-09,"The method 'test_require_api_key_config' is a unit test that verifies the behavior of a function or method related to API key configuration. It uses mocking to simulate the context and checks if the '_require_api_key' attribute of the 'model' object is correctly set to 'config-key'. This is a typical and useful test to ensure that the configuration is correctly applied, especially in environments where API keys are necessary for authentication. Since this test is relevant for ensuring correct functionality and does not have any apparent issues or redundancies, it is likely to be retained in the codebase."
survived,"def test_groq_require() -> None:
    """"""Test that groq.require raises ModuleNotFoundError.""""""
    model = groq(""llama3-70b-8192"")
    messages = [ChatMessage(role=""user"", content=""Test prompt"")]
    config = ChatModelConfig()
    with pytest.raises(ModuleNotFoundError):
        model(messages, config)
",tests/_ai/llm/_impl.py,,1,8.152020648014727e-09,"The method 'test_groq_require' is a unit test designed to verify that a specific function call raises a 'ModuleNotFoundError'. This is a common practice in testing to ensure that the code behaves as expected when certain modules are not available. The method is useful for maintaining code quality and ensuring robustness against missing dependencies. Therefore, it is likely to be retained as part of the test suite."
survived,"    def test_require_api_key_missing(self) -> None:
        """"""Test _require_api_key with missing key.""""""
        model = groq(""llama3-70b-8192"")
        with pytest.raises(ValueError):
            _ = model._require_api_key
",tests/_ai/llm/_impl.py,TestGroq,1,5.043472052266442e-07,"The method `test_require_api_key_missing` is a test function that checks the behavior of the `_require_api_key` method when an API key is missing. It uses `pytest.raises` to assert that a `ValueError` is raised, which is a common pattern in testing to ensure that the code handles error conditions correctly. Test functions like this are typically retained as they are crucial for maintaining code quality and ensuring that the application behaves as expected under various conditions. Therefore, it is unlikely to be deleted."
survived,"    def test_call_azure(
        self, mock_azure_openai_class: MagicMock, mock_require_api_key: MagicMock
    ) -> None:
        """"""Test calling the openai class with Azure OpenAI.""""""
        mock_require_api_key.return_value = ""test-key""
        mock_client = MagicMock()
        mock_azure_openai_class.return_value = mock_client
        mock_response = MagicMock()
        mock_choice = MagicMock()
        mock_message = MagicMock()
        mock_message.content = ""Test response""
        mock_choice.message = mock_message
        mock_response.choices = [mock_choice]
        mock_client.chat.completions.create.return_value = mock_response

        model = openai(
            ""gpt-4"",
            base_url=""https://example.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2023-05-15"",
        )
        # Patch the _require_api_key property to return the test key directly
        with patch.object(model, ""_require_api_key"", ""test-key""):
            messages = [ChatMessage(role=""user"", content=""Test prompt"")]
            config = ChatModelConfig()

            result = model(messages, config)
            assert result == ""Test response""

            mock_azure_openai_class.assert_called_once_with(
                api_key=""test-key"",
                api_version=""2023-05-15"",
                azure_endpoint=""https://example.openai.azure.com"",
            )
        mock_client.chat.completions.create.assert_called_once()
        call_args = mock_client.chat.completions.create.call_args[1]
        assert call_args[""model""] == ""gpt-4""
",tests/_ai/llm/_impl.py,TestOpenAI,1,8.152020648014727e-09,"The method `test_call_azure` is a unit test designed to verify the integration with Azure's OpenAI service. It uses mocking to simulate the behavior of external dependencies, ensuring that the method can be tested in isolation. This kind of test is crucial for validating that the code interacts correctly with external services, especially in a cloud environment where direct testing might be impractical or costly. Given the importance of testing cloud integrations and the fact that this method is a test rather than production code, it is likely to be maintained as long as the functionality it tests is relevant. Therefore, the method is likely to survive."
survived,"    def test_is_file_path_with_nonexistent_file(self) -> None:
        # Test with nonexistent file
        with pytest.raises(click.BadParameter) as excinfo:
            is_file_path(None, None, ""nonexistent_file.txt"")
        assert ""File does not exist: nonexistent_file.txt"" in str(excinfo.value)
",tests/_cli/test_cli_validators.py,TestIsFilePath,1,6.348800075736417e-09,"The method 'test_is_file_path_with_nonexistent_file' is a unit test designed to verify the behavior of the 'is_file_path' function when provided with a nonexistent file. Unit tests are crucial for ensuring code reliability and correctness, especially in handling edge cases and exceptions. This test checks that the appropriate exception is raised, which is a common and necessary practice in software development to maintain code quality. Therefore, it is unlikely that this method will be deleted as it serves an important purpose in the testing suite."
survived,"    def test_base_url_with_none_or_empty(self) -> None:
        # Test with None or empty string
        assert base_url(None, None, None) == """"
        assert base_url(None, None, """") == """"
",tests/_cli/test_cli_validators.py,TestBaseUrl,1,2.998960815863541e-09,"The method `test_base_url_with_none_or_empty` is a test function that checks the behavior of the `base_url` function when it is passed `None` or empty strings as arguments. This is a common edge case test to ensure that the function handles such inputs gracefully. Test functions are generally not deleted unless they are redundant or the functionality they are testing is removed. Since handling `None` or empty strings is a typical requirement for robust functions, this test is likely to be useful and relevant. Therefore, the method is predicted to survive."
survived,"    def test_highlight_traceback(self) -> None:
        # Test that _highlight_traceback adds HTML formatting
        traceback = ""Traceback (most recent call last):\n  File \""<stdin>\"", line 1, in <module>\nValueError: invalid value""

        highlighted = _highlight_traceback(traceback)

        # Should contain HTML formatting
        assert ""<span class=\""codehilite\"">"" in highlighted
        assert ""</span>"" in highlighted

        # Should contain the original traceback text
        assert ""Traceback"" in highlighted
        # The ValueError text is present but with HTML tags around it
        assert ""ValueError"" in highlighted
        assert ""invalid value"" in highlighted
",tests/_messaging/test_tracebacks.py,TestTracebacks,1,4.944450477491054e-09,"The method `test_highlight_traceback` is a unit test designed to verify the functionality of the `_highlight_traceback` function. It checks if the function correctly adds HTML formatting to a traceback string. Unit tests are crucial for ensuring code reliability and are typically retained in the codebase to prevent future regressions. Therefore, this method is likely to be retained as it serves an important purpose in testing the functionality of the code."
deleted,"    def test_marimo_exception_raised_error(self) -> None:
        error = MarimoExceptionRaisedError(
            msg=""ValueError: invalid value"",
            exception_type=""ValueError"",
            raising_cell=""cell1"",
        )

        # Test properties
        assert error.type == ""exception""
        assert error.describe() == ""ValueError: invalid value""
        assert error.raising_cell == ""cell1""
        assert error.exception_type == ""ValueError""
",tests/_messaging/test_errors.py,TestErrorClasses,1,5.60279640614594e-09,"The method `test_marimo_exception_raised_error` is a unit test designed to verify the properties of the `MarimoExceptionRaisedError` class. Unit tests are crucial for ensuring code reliability and correctness, especially when dealing with exceptions and error handling. This test checks that the error object is correctly instantiated and that its properties return the expected values. Since testing is an essential part of software development and maintenance, this method is likely to be retained to ensure the robustness of the error handling mechanism."
survived,"    def test_print_override_normal(self) -> None:
        # Test print_override when not in a marimo thread
        with patch(""marimo._messaging.print_override._original_print"") as mock_print:
            print_override(""Hello, world!"")
            mock_print.assert_called_once_with(""Hello, world!"")
",tests/_messaging/test_print_override.py,TestPrintOverride,1,1.3440409770490404e-08,"The method `test_print_override_normal` is a unit test that checks the functionality of the `print_override` function when it is not in a marimo thread. It uses mocking to ensure that the original print function is called with the correct arguments. This is a standard practice in testing to ensure that functions behave as expected. Since this is a test method, it is unlikely to be deleted unless the functionality it tests is removed or significantly changed. Therefore, it is more likely to survive."
survived,"    async def invoke_llm(
        self,
        query: core_entities.Query,
        model: requester.RuntimeLLMModel,
        messages: typing.List[llm_entities.Message],
        funcs: typing.List[tools_entities.LLMFunction] = None,
        extra_args: dict[str, typing.Any] = {},
    ) -> llm_entities.Message:
        genai.configure(api_key=model.token_mgr.get_token())

        generation_model = genai.GenerativeModel(model.model_entity.name)

        gemini_messages = []
        
        system_content = None
        for i, m in enumerate(messages):
            if m.role == 'system':
                system_content = m.content
                break
        
        for m in messages:
            if m.role == 'system':
                continue  # Skip system message as it's handled separately
            
            if m.role == 'user':
                role = 'user'
            elif m.role == 'assistant':
                role = 'model'
            else:
                continue  # Skip other roles for now
            
            content = m.content
            if isinstance(content, list):
                parts = []
                for part in content:
                    if part.get('type') == 'text':
                        parts.append(part.get('text', ''))
                content = '\n'.join(parts)
            
            gemini_messages.append({'role': role, 'parts': [content]})
        
        try:
            chat_params = extra_args.copy()
            if system_content:
                chat_params['system_instruction'] = system_content
            
            chat = generation_model.start_chat(history=gemini_messages)
            
            response = await chat.send_message_async(
                content="""",  # Empty content to get response based on history
                **chat_params
            )
            
            content = response.text
            
            return llm_entities.Message(
                role='assistant',
                content=content
            )
        except Exception as e:
            if 'invalid api key' in str(e).lower():
                raise errors.RequesterError(f' api-key: {str(e)}')
            elif 'not found' in str(e).lower():
                raise errors.RequesterError(f': {str(e)}')
            elif 'rate limit' in str(e).lower() or 'quota' in str(e).lower():
                raise errors.RequesterError(f': {str(e)}')
            else:
                raise errors.RequesterError(f': {str(e)}')",pkg/provider/modelmgr/requesters/geminichatcmpl.py,GeminiChatCompletions,1,1.1032560311263802e-09,"The method 'invoke_llm' is likely to survive because it is a well-structured asynchronous function that handles the invocation of a language model, processes messages, and manages exceptions effectively. It includes configuration, message processing, and error handling, which are essential for robust API interaction. Additionally, it uses modern Python features like type hints and async/await, indicating it is up-to-date with current programming practices."
survived,"    def condition_func(task_output: TaskOutput) -> bool:
        return ""success"" in task_output.raw.lower()
",tests/crew_test.py,,1,6.023574641292144e-08,"The method `condition_func` is a simple utility function that checks if the string ""success"" is present in the `raw` attribute of a `TaskOutput` object, after converting it to lowercase. This kind of function is often useful in filtering or decision-making processes where the success status of a task needs to be determined. Such utility functions are generally useful and reusable in various contexts, especially in systems that process task outputs or logs. Therefore, it is likely to be retained in the codebase."
survived,"def test_smart_wallet_with_email(smart_api, test_email, test_wallet_options):
    """"""Test smart wallet creation with email.""""""
    options = {
        **test_wallet_options,
        ""linkedUser"": {""email"": test_email}
    }
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        options[""chain""],
        test_keypair,
        options[""provider""],
        options[""options""][""ensProvider""]
    )
    assert client.get_address() == wallet[""address""]
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,1.637377179507321e-07,"The method 'test_smart_wallet_with_email' is a test function, likely part of a test suite for a smart wallet application. Test functions are generally not deleted unless they are redundant or replaced by more comprehensive tests. This function seems to be testing a specific feature (smart wallet creation with an email), which is a common and important functionality in applications dealing with user accounts and wallets. Therefore, it is likely to be retained to ensure the feature works as expected."
survived,"def test_custodial_wallet_balance(custodial_api, test_email, solana_connection):
    """"""Test getting wallet balance.""""""
    # Create wallet and client
    wallet = custodial_api.create_custodial_wallet(test_email)
    client = CustodialSolanaWalletClient(
        wallet[""address""],
        custodial_api,
        solana_connection,
        {""email"": test_email}
    )
    
    # Get balance
    balance = client.balance_of(wallet[""address""])
    assert ""value"" in balance
    assert ""symbol"" in balance
    assert balance[""symbol""] == ""SOL""
    assert ""decimals"" in balance
    assert balance[""decimals""] == 9
    assert ""name"" in balance
    assert balance[""name""] == ""Solana""
    assert ""in_base_units"" in balance
",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,9.237449576640118e-09,"The method 'test_custodial_wallet_balance' is a test function that verifies the functionality of retrieving a wallet balance using a custodial API and a Solana connection. It includes assertions to ensure the balance data structure contains expected fields and values. Test functions like this are crucial for maintaining code quality and ensuring that changes do not break existing functionality. Therefore, it is likely to be retained as part of a test suite."
survived,"def test_email():
    """"""Fixture providing test email for wallet creation.""""""
    return ""test@example.com""
",python/src/wallets/crossmint/tests/conftest.py,,1,1.1253518384332553e-07,"The method 'test_email' is a simple utility function that returns a static string, which is used as a fixture for testing purposes. Such methods are typically retained in codebases because they provide a consistent and reusable way to supply test data, which is crucial for automated testing. The method is straightforward, has a clear purpose, and does not introduce any complexity or maintenance overhead. Therefore, it is likely to be retained in the codebase."
survived,"def test_custodial_wallet_invalid_transaction(custodial_api, test_email, solana_connection):
    """"""Test error handling with invalid transaction.""""""
    # Create wallet and client
    wallet = custodial_api.create_custodial_wallet(test_email)
    client = CustodialSolanaWalletClient(
        wallet[""address""],
        custodial_api,
        solana_connection,
        {""email"": test_email}
    )
    
    # Try to send invalid transaction
    with pytest.raises(Exception) as exc:
        client.send_raw_transaction(""invalid-transaction"")
    assert ""error"" in str(exc.value).lower() or ""invalid"" in str(exc.value).lower()",python/src/wallets/crossmint/tests/test_custodial_wallet.py,,1,8.152020648014727e-09,"The method is a test function that checks the error handling of a system when an invalid transaction is attempted. Such test functions are crucial for ensuring the robustness and reliability of software, especially in financial applications. It is unlikely to be deleted as it serves an important role in validating the system's behavior under erroneous conditions."
survived,"def test_smart_wallet_message_signing(smart_api, test_wallet_options, test_message, test_keypair):
    """"""Test message signing with smart wallet.""""""
    # Create wallet and client
    wallet = smart_api.create_smart_wallet()
    client = SmartWalletClient(
        wallet[""address""],
        smart_api,
        test_wallet_options[""chain""],
        test_keypair,
        test_wallet_options[""provider""],
        test_wallet_options[""options""][""ensProvider""]
    )
    
    # Sign message
    signature = client.sign_message(test_message)
    assert signature[""signature""].startswith(""0x"")
    
    # Verify signature format
    assert len(signature[""signature""]) > 130  # Valid EVM signature length
",python/src/wallets/crossmint/tests/test_smart_wallet.py,,1,2.5109990926928157e-08,"The method 'test_smart_wallet_message_signing' is a test function that verifies the functionality of message signing in a smart wallet. It is crucial for ensuring the integrity and security of transactions in blockchain applications. The method is well-structured, uses assertions to validate the expected outcomes, and is likely part of a test suite that ensures the reliability of the smart wallet API. Given the importance of testing in software development, especially in blockchain applications where security is paramount, this method is likely to be retained."
survived,"    def __init__(self, client: BoxClient, folder_id: str, is_recursive: bool = False):
        self.client = client
        self.folder_id = folder_id
        self.is_recursive = is_recursive
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamTextRepresentationFolder,1,5.60279640614594e-09,"The method is a constructor for a class, which is essential for initializing instances of the class with specific attributes. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the class itself is being removed or significantly refactored. Since this method is responsible for setting up the initial state of an object with important parameters like 'client', 'folder_id', and 'is_recursive', it is likely to be retained."
survived,"    def __init__(self, client: BoxClient, folder_id: str, fields_json_str: str, is_recursive: bool = False):
        self.client = client
        self.folder_id = folder_id
        self.is_recursive = is_recursive
        self.fields_json_str = fields_json_str
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamAIExtractStructuredFolder,1,1.522997951276035e-08,"The method is a constructor (__init__) for a class, which is essential for initializing new instances of the class with specific attributes. Constructors are fundamental components of class definitions in object-oriented programming, and they are rarely deleted unless the entire class is being removed or refactored significantly. Since this method is responsible for setting up the initial state of an object with important parameters like 'client', 'folder_id', 'fields_json_str', and 'is_recursive', it is likely to be retained as long as the class itself is in use."
survived,"def get_generic_json_schema() -> Dict:
    generic_schema = """"""
        {
        ""$schema"": ""http://json-schema.org/draft-07/schema#"",
        ""type"": ""object"",
        ""properties"": {
            ""type"": {
            ""type"": ""string""
            },
            ""id"": {
            ""type"": ""string""
            },
            ""file_version"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""sha1"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""sha1""]
            },
            ""sequence_id"": {
            ""type"": ""string""
            },
            ""etag"": {
            ""type"": ""string""
            },
            ""sha1"": {
            ""type"": ""string""
            },
            ""name"": {
            ""type"": ""string""
            },
            ""description"": {
            ""type"": ""string""
            },
            ""size"": {
            ""type"": ""integer""
            },
            ""path_collection"": {
            ""type"": ""object"",
            ""properties"": {
                ""total_count"": {
                ""type"": ""integer""
                },
                ""entries"": {
                ""type"": ""array"",
                ""items"": [
                    {
                    ""type"": ""object"",
                    ""properties"": {
                        ""type"": {
                        ""type"": ""string""
                        },
                        ""id"": {
                        ""type"": ""string""
                        },
                        ""sequence_id"": {
                        ""type"": ""null""
                        },
                        ""etag"": {
                        ""type"": ""null""
                        },
                        ""name"": {
                        ""type"": ""string""
                        }
                    },
                    ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
                    },
                    {
                    ""type"": ""object"",
                    ""properties"": {
                        ""type"": {
                        ""type"": ""string""
                        },
                        ""id"": {
                        ""type"": ""string""
                        },
                        ""sequence_id"": {
                        ""type"": ""string""
                        },
                        ""etag"": {
                        ""type"": ""string""
                        },
                        ""name"": {
                        ""type"": ""string""
                        }
                    },
                    ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
                    },
                    {
                    ""type"": ""object"",
                    ""properties"": {
                        ""type"": {
                        ""type"": ""string""
                        },
                        ""id"": {
                        ""type"": ""string""
                        },
                        ""sequence_id"": {
                        ""type"": ""string""
                        },
                        ""etag"": {
                        ""type"": ""string""
                        },
                        ""name"": {
                        ""type"": ""string""
                        }
                    },
                    ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
                    }
                ]
                }
            },
            ""required"": [""total_count"", ""entries""]
            },
            ""created_at"": {
            ""type"": ""string""
            },
            ""modified_at"": {
            ""type"": ""string""
            },
            ""trashed_at"": {
            ""type"": ""null""
            },
            ""purged_at"": {
            ""type"": ""null""
            },
            ""content_created_at"": {
            ""type"": ""string""
            },
            ""content_modified_at"": {
            ""type"": ""string""
            },
            ""created_by"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                },
                ""login"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""name"", ""login""]
            },
            ""modified_by"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                },
                ""login"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""name"", ""login""]
            },
            ""owned_by"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                },
                ""login"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""name"", ""login""]
            },
            ""shared_link"": {
            ""type"": ""null""
            },
            ""parent"": {
            ""type"": ""object"",
            ""properties"": {
                ""type"": {
                ""type"": ""string""
                },
                ""id"": {
                ""type"": ""string""
                },
                ""sequence_id"": {
                ""type"": ""string""
                },
                ""etag"": {
                ""type"": ""string""
                },
                ""name"": {
                ""type"": ""string""
                }
            },
            ""required"": [""type"", ""id"", ""sequence_id"", ""etag"", ""name""]
            },
            ""item_status"": {
            ""type"": ""string""
            },
            ""text_representation"": {
            ""type"": ""string""
            }
        }
        }

        """"""
    return json.loads(generic_schema)",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/schemas.py,,1,6.348800075736417e-09,"The method `get_generic_json_schema` is a utility function that returns a JSON schema as a dictionary. JSON schemas are widely used for validating the structure of JSON data, and this method provides a generic schema that can be reused across different parts of an application. The method is well-defined, follows a standard format, and serves a clear purpose in applications that require JSON validation. Therefore, it is likely to be retained in the codebase."
survived,"    def read_records(
        self,
        sync_mode: SyncMode,
        cursor_field: Optional[List[str]] = None,
        stream_slice: Optional[Mapping[str, Any]] = None,
        stream_state: Optional[Mapping[str, Any]] = None,
    ) -> Iterable[StreamData]:
        logger.info(f""Extracting text representation for files in folder {self.folder_id} {'recursively' if self.is_recursive else ''}"")
        items = box_folder_text_representation(self.client, self.folder_id, is_recursive=self.is_recursive)
        for item in items:
            airbyte_item: StreamData = item.file.to_dict()
            airbyte_item[""text_representation""] = item.text_representation
            logger.info(f""Reading file {item.file.id} - {item.file.name}"")
            yield airbyte_item
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/source.py,StreamTextRepresentationFolder,1,6.348800075736417e-09,"The method `read_records` is a core part of a data extraction process, which is essential for reading and yielding data from a source. It is well-structured, uses logging for tracking progress, and yields data in a format that is likely used by other parts of the system. Such methods are typically retained as they are crucial for the functionality of data pipelines."
survived,"def box_file_get_by_id(client: BoxClient, file_id: str) -> File:
    return client.files.get_file_by_id(file_id=file_id)
",airbyte-integrations/connectors/source-box-data-extract/source_box_data_extract/box_api.py,,0,0.9999999981810384,"The method `box_file_get_by_id` is a simple wrapper around the `get_file_by_id` method of the `BoxClient` class. It doesn't add any additional functionality or abstraction, making it redundant. Such methods are often candidates for deletion unless they are part of a larger interface or API that requires them for consistency. Without additional context suggesting its necessity, it's likely to be deleted."
survived,"def create_manager_agent(specialists: List[Agent]) -> Agent:
    """"""
    Create a manager agent that coordinates the work of specialist agents.
    
    Args:
        specialists: List of specialist agents to coordinate
        
    Returns:
        An Agent instance that manages the content creation process
    """"""
    instructions = """"""
    You are a content manager who coordinates the work of specialist agents to create high-quality content.
    Your task is to:
    1. Understand the content request
    2. Delegate research to the Research Specialist
    3. Have the Outline Specialist create a structure based on the research
    4. Have the Content Specialist write content based on the outline and research
    5. Have the Editing Specialist refine and polish the content
    6. Deliver the final polished content
    
    Manage the workflow efficiently and ensure each specialist has the information they need.
    """"""
    
    # Create handoffs to specialist agents
    handoffs = [handoff(agent) for agent in specialists]
    
    return Agent(
        name=""ContentManager"",
        instructions=instructions,
        model=""gpt-4o-mini"",
        handoffs=handoffs
    )
",openai-agents-examples/11_agent_orchestration.py,,1,1.6052280526088547e-09,"The method 'create_manager_agent' is well-documented and serves a clear purpose of creating a manager agent to coordinate specialist agents. It is likely to be useful in scenarios where content creation needs to be managed efficiently. The method is also flexible, as it takes a list of specialists as input, allowing for different configurations of agents. Therefore, it is likely to be retained in the codebase."
survived,"def get_stock_price(params: StockPriceInput) -> str:
    """"""
    Get the current price of a stock.
    
    Args:
        params: The stock price parameters
        
    Returns:
        A string containing the stock price information
    """"""
    # This is a mock implementation - in a real application, you would call a stock API
    stock_prices = {
        ""AAPL"": 175.34,
        ""MSFT"": 410.34,
        ""GOOGL"": 147.68,
        ""AMZN"": 178.75,
        ""META"": 474.99,
    }
    
    symbol = params.symbol.upper()
    
    # Check if stock is supported
    if symbol not in stock_prices:
        return f""Sorry, stock information for {symbol} is not available.""
    
    price = stock_prices[symbol]
    
    return f""The current price of {symbol} is ${price:.2f}.""
",openai-agents-examples/06_agent_with_custom_tools.py,,1,7.194132978569833e-09,"The method `get_stock_price` is likely to survive because it provides a useful functionality of retrieving stock prices based on a given symbol. Although it currently uses a mock implementation, it is structured in a way that can easily be adapted to integrate with a real stock API. This adaptability makes it a valuable method for applications dealing with financial data. Additionally, the method includes error handling for unsupported stock symbols, which enhances its robustness."
survived,"def test_custom_tools():
    """"""Test that the custom tools work correctly.""""""
    # Test currency conversion
    currency_result = convert_currency(CurrencyConversionInput(
        amount=100,
        from_currency=""USD"",
        to_currency=""EUR""
    ))
    assert ""USD"" in currency_result
    assert ""EUR"" in currency_result
    
    # Test stock price
    stock_result = get_stock_price(StockPriceInput(symbol=""AAPL""))
    assert ""AAPL"" in stock_result
    assert ""$"" in stock_result
",openai-agents-examples/06_agent_with_custom_tools.py,,1,4.0586521248284276e-10,"The method 'test_custom_tools' is a test function that verifies the functionality of custom tools, specifically currency conversion and stock price retrieval. Test functions are crucial for ensuring code reliability and correctness, especially in production environments. They help catch bugs and ensure that changes do not break existing functionality. Given the importance of testing in software development, it is unlikely that this method will be deleted unless the functionality it tests is removed or significantly altered. Therefore, the method is likely to survive."
survived,"def main():
    """"""Main function to parse arguments and run the agent synchronously.""""""
    parser = argparse.ArgumentParser(description=""Synchronous Agent Example"")
    parser.add_argument(""--prompt"", ""-p"", type=str, required=True, 
                        help=""The prompt to send to the agent"")
    
    args = parser.parse_args()
    
    # Ensure API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        console.print(Panel(""[bold red]Error: OPENAI_API_KEY environment variable not set[/bold red]""))
        sys.exit(1)
    
    try:
        # Run the agent synchronously and get response
        response = run_sync_agent(args.prompt)
        
        # Display the response
        console.print(Panel(response, title=""Synchronous Agent Response"", border_style=""green""))
    
    except Exception as e:
        console.print(Panel(f""[bold red]Error: {str(e)}[/bold red]""))
        sys.exit(1)
",openai-agents-examples/03_sync_agent.py,,1,1.1032560311263802e-09,"The method 'main()' is a well-structured entry point for a command-line application. It includes argument parsing, environment variable checking, error handling, and a call to a function 'run_sync_agent' which is presumably defined elsewhere. These are all standard practices for a robust CLI application. There is no indication that this method is obsolete or redundant, and it appears to be functional and necessary for the intended application. Therefore, it is likely to be retained in the codebase."
survived,"def test_run_multi_agent_system():
    """"""Test that the multi-agent system can run and produce a response.""""""
    import pytest
    
    # Skip this test if no API key is available
    if not os.environ.get(""OPENAI_API_KEY""):
        pytest.skip(""OPENAI_API_KEY not set"")
    
    # Run a simple test query that should go to the tech specialist
    response = asyncio.run(run_multi_agent_system(""What is machine learning?""))
    
    # Verify we got a non-empty response
    assert response
    assert len(response) > 0
",openai-agents-examples/02_multi_agent.py,,1,4.944450477491054e-09,"The method 'test_run_multi_agent_system' is a test function that checks the functionality of a multi-agent system. It includes a conditional skip if an API key is not set, which is a common practice in testing to avoid failures due to missing configurations. The test itself is straightforward, checking that a response is received and is non-empty, which are reasonable assertions for a basic functionality test. There is no indication that this method is obsolete or redundant, and it serves a clear purpose in ensuring the system's basic operation. Therefore, it is likely to be retained."
survived,"def test_create_financial_assistant():
    """"""Test that the financial assistant agent is created with the correct configuration.""""""
    agent = create_financial_assistant()
    assert agent.name == ""FinancialAssistant""
    assert ""financial assistant"" in agent.instructions.lower()
    assert len(agent.tools) == 2
    assert any(tool.name == ""convert_currency"" for tool in agent.tools)
    assert any(tool.name == ""get_stock_price"" for tool in agent.tools)
",openai-agents-examples/06_agent_with_custom_tools.py,,1,3.3982678079468468e-09,"The method `test_create_financial_assistant` is a unit test designed to verify the correct creation and configuration of a financial assistant agent. Unit tests are crucial for ensuring code reliability and correctness, especially in complex systems. This test checks specific attributes and tools of the agent, which are likely important for its functionality. Given the importance of testing in software development, this method is likely to be maintained and not deleted."
survived,"async def run_blog_writer_system(prompt: str) -> str:
    """"""
    Run the blog writer system with the given prompt.
    
    Args:
        prompt: The topic or request for a blog post
        
    Returns:
        The blog post content
    """"""
    # Create the research agent
    research_agent = create_research_agent()
    
    # Create the blog writer agent with the research agent as a tool
    blog_writer = create_blog_writer_agent(research_agent)
    
    # Run the blog writer agent with the prompt
    result = await Runner.run(blog_writer, prompt)
    
    # Return the blog post
    return result.final_output
",openai-agents-examples/08_agent_with_agent_as_tool.py,,1,5.905303995456778e-10,"The method 'run_blog_writer_system' is likely to survive because it is a well-structured asynchronous function that serves a clear purpose: generating blog content based on a given prompt. It uses a research agent and a blog writer agent, which suggests a modular and extensible design. As content generation is a common and valuable task, especially with the rise of AI-driven content creation, this method is likely to remain relevant and useful."
survived,"async def test_delete_all_endpoint():
    payload = {
        ""iat"": datetime.datetime.utcnow(),
        ""exp"": datetime.datetime.utcnow() + datetime.timedelta(days=1),
        ""subdomain"": ""abcd1234"",
    }
    token = jwt.encode(payload, ""test-secret"", algorithm=""HS256"")
    
    mock_redis.delete.return_value = True
    mock_redis.keys.return_value = [""requests:abcd1234"", ""request:abcd1234:id1"", ""request:abcd1234:id2""]
    
    with patch(""backend.app.config.jwt_secret"", ""test-secret""):
        response = client.post(""/api/delete_all"", params={""token"": token})
        
        assert response.status_code == 200
        assert response.json() == {""msg"": ""Deleted all requests""}
        
        mock_redis.delete.assert_called()",backend/tests/test_endpoints.py,,1,1.0467401685178159e-08,"The method 'test_delete_all_endpoint' is a unit test for an API endpoint that deletes all requests associated with a specific subdomain. It uses mocking to simulate the behavior of a Redis database and checks if the endpoint correctly deletes the keys and returns the expected response. This is a typical and necessary test to ensure the functionality of the delete endpoint works as intended. Therefore, it is likely to be retained as part of the test suite to maintain code quality and reliability."
survived,"        async def get_messages(session_type: str) -> str:
            """"""""""""
            try:
                if session_type not in ['person', 'group']:
                    return self.http_status(400, -1, 'session_type must be person or group')
                
                webchat_adapter = None
                for bot in self.ap.platform_mgr.bots:
                    if hasattr(bot.adapter, '__class__') and bot.adapter.__class__.__name__ == 'WebChatAdapter':
                        webchat_adapter = bot.adapter
                        break
                
                if not webchat_adapter:
                    return self.http_status(404, -1, 'WebChat adapter not found')
                
                messages = webchat_adapter.get_debug_messages(session_type)
                
                return self.success(data={'messages': messages})
                
            except Exception as e:
                return self.http_status(500, -1, f'Internal server error: {str(e)}')
",pkg/api/http/controller/groups/debug/webchat.py,WebChatDebugRouterGroup,1,5.905303995456778e-10,"The method 'get_messages' is likely to survive because it is a well-structured function that handles a specific task of retrieving debug messages based on a session type. It includes error handling for invalid session types and missing adapters, which are common scenarios that need to be managed in production code. Additionally, it uses asynchronous programming, which is suitable for I/O-bound operations like network requests, making it efficient. The method also follows a clear pattern of returning HTTP status codes and messages, which is a good practice for API development."
survived,"    async def send_debug_message(self, session_type: str, content: str) -> dict:
        """"""""""""
        session_key = f'webchat{session_type}'
        
        if session_key not in self.debug_messages:
            self.debug_messages[session_key] = []
            
        message_chain = platform_message.MessageChain([
            platform_message.Plain(content)
        ])
        
        user_message = {
            'id': len(self.debug_messages[session_key]) + 1,
            'type': 'user',
            'content': content,
            'timestamp': datetime.now().isoformat(),
            'message_chain': [{'type': 'Plain', 'text': content}]
        }
        
        self.debug_messages[session_key].append(user_message)
        
        if session_type == 'person':
            sender = platform_entities.Friend(id='webchatperson', nickname='')
            event = platform_events.FriendMessage(
                sender=sender,
                message_chain=message_chain,
                time=datetime.now().timestamp()
            )
            launcher_type = core_entities.LauncherTypes.PERSON
            launcher_id = 'webchatperson'
        else:
            group = platform_entities.Group(id='webchatgroup', name='')
            sender = platform_entities.GroupMember(id='webchatperson', nickname='', group=group)
            event = platform_events.GroupMessage(
                sender=sender,
                message_chain=message_chain,
                time=datetime.now().timestamp()
            )
            launcher_type = core_entities.LauncherTypes.GROUP
            launcher_id = 'webchatgroup'
        
        await self.ap.query_pool.add_query(
            bot_uuid='webchat-debug',
            launcher_type=launcher_type,
            launcher_id=launcher_id,
            sender_id='webchatperson',
            message_event=event,
            message_chain=message_chain,
            adapter=self,
        )
        
        return {'success': True, 'message_id': user_message['id']}
",pkg/platform/sources/webchat.py,WebChatAdapter,1,7.582560422162384e-10,"The method `send_debug_message` is likely to survive because it serves a specific and useful purpose in the codebase. It is designed to send debug messages to a pipeline, which is a common requirement in software development for monitoring and troubleshooting. The method is well-structured, handles different session types, and integrates with other components like `platform_message`, `platform_entities`, and `platform_events`. Additionally, it uses asynchronous programming, which is beneficial for performance in I/O-bound operations. These factors suggest that the method is functional, relevant, and likely to be maintained."
survived,"    def navigate_to_result(self, url: str):
        """"""Navigate to a search result.""""""
        self.show_results = False
        return rx.redirect(url)
",pcweb/components/docpage/navbar/typesense.py,TypesenseSearchState,1,4.599055376537186e-10,"The method 'navigate_to_result' is a simple utility function that changes the state of 'show_results' and redirects to a given URL. It is likely to be used in a web application to handle navigation based on user actions. Such methods are common in web development for managing page transitions and user interactions. Unless there is a significant change in the application's architecture or a shift away from this navigation pattern, this method is likely to survive."
survived,"    def recreate_collection(self):
        """"""Recreate the docs collection.""""""
        try:
            self.client.collections['docs'].delete()
            logger.info(""Deleted existing 'docs' collection"")
        except Exception as e:
            logger.info(f""Collection 'docs' doesn't exist or couldn't be deleted: {e}"")
        
        self.client.collections.create(COLLECTION_SCHEMA)
        logger.info(""Created new 'docs' collection"")
",scripts/typesense_indexer.py,TypesenseIndexer,1,2.4616969512093895e-10,"The method 'recreate_collection' is likely to survive because it performs a necessary operation of deleting and recreating a collection, which is a common requirement in database management. The method includes error handling to manage exceptions, making it robust and reliable. Additionally, the use of logging provides transparency and traceability of operations, which is valuable for debugging and monitoring purposes."
survived,"def test_solana_smart_wallet_transaction(smart_api, test_solana_transaction):
    """"""Test transaction sending with Solana smart wallet.""""""
    # Create a wallet first
    wallet = smart_api.create_wallet(
        wallet_type=WalletType.SOLANA_SMART_WALLET,
        linked_user=""email:test@example.com""
    )
    
    # Test transaction submission
    try:
        # Create transaction parameters
        tx_params = SolanaSmartWalletTransactionParams(
            transaction=test_solana_transaction,
            required_signers=[]  # No required signers for basic test
        )
        
        # Create transaction
        tx = smart_api.create_transaction_for_smart_wallet(
            wallet[""address""],
            tx_params,
            ""solana""
        )
        # If successful, verify response format
        assert ""id"" in tx
        assert tx[""type""] == ""solana-smart-wallet""
        assert tx[""status""] in [""pending"", ""awaiting_signatures"", ""success""]
    except Exception as e:
        error_msg = str(e).lower()
        # Check for expected error cases
        assert any(msg in error_msg for msg in [
            ""invalid transaction"",
            ""transaction verification failed"",
            ""invalid serialized"",
            ""parsing error"",
            ""signatures that would be ignored"",
            ""submit signatures separately""
        ]), f""Unexpected error: {error_msg}""
",python/src/wallets/crossmint/tests/test_solana_smart_wallet.py,,1,3.2241866333029355e-08,"The method `test_solana_smart_wallet_transaction` is a unit test function designed to test the functionality of sending transactions using a Solana smart wallet. It includes creating a wallet, setting up transaction parameters, and verifying the transaction response. The function also handles exceptions and checks for expected error messages, which is a common practice in testing to ensure robustness and reliability of the code. Given its purpose and structure, it is likely to be retained as part of the test suite to ensure the correct functioning of the Solana smart wallet transaction feature."
survived,"def main():
    """"""Run the pipeline architecture example.""""""
    print(""\n===== Pipeline Architecture Example ====="")
    
    # Create sample data
    data_file = create_sample_data()
    
    # Create pipeline stages
    input_stage = InputStage()
    processing_stage = ProcessingStage()
    output_stage = OutputStage()
    
    # Create and configure pipeline
    pipeline = DataProcessingPipeline(""Sales Data Analysis Pipeline"")
    
    # Add stages
    pipeline.add_stage(""input"", input_stage)
    pipeline.add_stage(""processing"", processing_stage)
    pipeline.add_stage(""output"", output_stage)
    
    # Configure input
    pipeline.configure_input(
        source=data_file,
        source_type=""json"",
        required_fields=[""id"", ""product"", ""price"", ""quantity""]
    )
    
    # Configure processing
    pipeline.configure_processing({
        ""calculate_statistics"": True,
        ""numeric_fields"": [""price"", ""quantity"", ""discount""],
        ""filters"": [
            {
                ""filter_func"": lambda item: item[""price""] * item[""quantity""] > 1000,
                ""description"": ""High-value sales (>$1000)""
            }
        ],
        ""transformations"": {
            ""price"": lambda price: format_currency(price),
            ""discount"": lambda discount: format_percentage(discount)
        },
        ""transformation_description"": ""Format price as currency and discount as percentage""
    })
    
    # Configure output
    pipeline.configure_output({
        ""format_summary"": True,
        ""format_detailed"": True,
        ""print_results"": True,
        ""print_output_type"": ""summary"",
        ""save_to_file"": [
            {
                ""format"": ""json"",
                ""dir"": ""./output"",
                ""filename"": ""sales_analysis.json""
            }
        ]
    })
    
    # Run the pipeline
    result = pipeline.run()
    
    print(""\n===== Pipeline Execution Complete ====="")
    print(f""Pipeline status: {result['metadata']['status']}"")
    print(f""Execution time: {result['metadata']['execution_time_seconds']:.2f} seconds"")
    
    # Show output file location if saved
    if ""stages"" in result and len(result[""stages""]) > 0:
        output_stage_name = result[""stages""][-1][""name""]
        if output_stage_name in pipeline.results:
            output_result = pipeline.results[output_stage_name]
            if ""metadata"" in output_result and ""output_files"" in output_result[""metadata""]:
                print(""\nOutput files:"")
                for output_file in output_result[""metadata""][""output_files""]:
                    print(f""- {output_file['path']} ({output_file['format']})"")
",codebase-architectures/pipeline-architecture/main.py,,1,2.699578619062706e-07,"The method 'main()' is a central part of the script, orchestrating the entire pipeline process from data creation to execution and output. It is well-structured, demonstrating a clear flow of operations, and is essential for running the pipeline example. The method is likely to be retained as it serves a critical function in demonstrating the pipeline architecture."
survived,"    def get_category(category_id):
        """"""Get a category by ID.""""""
        try:
            category = CategoryService.get_category(category_id)
            if not category:
                return {
                    ""success"": False,
                    ""message"": f""Category with ID {category_id} not found""
                }
            return {
                ""success"": True,
                ""data"": category
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in get_category: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while retrieving the category""
            }
",codebase-architectures/layered-architecture/api/category_api.py,CategoryAPI,1,4.599055376537186e-10,"The method 'get_category' is a well-structured function that handles the retrieval of a category by its ID. It includes error handling and logging, which are good practices for maintaining robust code. The function checks if the category exists and returns appropriate success or failure messages. These features make it a useful utility in applications that require category management. Therefore, it is likely to be retained in the codebase."
survived,"    def change_password(token: str, current_password: str, new_password: str) -> Dict:
        """"""
        Change a user's password.
        
        Args:
            token: Authentication token
            current_password: The current password
            new_password: The new password
            
        Returns:
            Response with success status or error message
        """"""
        # Validate token
        success, user_data = validate_user_token(token)
        if not success:
            return {
                ""status"": ""error"",
                ""message"": ""Invalid or expired token"",
                ""data"": None
            }
        
        # Change password
        success, result = change_password(user_data[""id""], current_password, new_password)
        
        if success:
            return {
                ""status"": ""success"",
                ""message"": ""Password changed successfully"",
                ""data"": None
            }
        else:
            return {
                ""status"": ""error"",
                ""message"": result.get(""error"", ""Password change failed""),
                ""data"": None
            }",codebase-architectures/atomic-composable-architecture/endpoints/user_api.py,UserAPI,0,0.9999994956527948,"The method 'change_password' is likely to be deleted because it contains a critical issue: it calls itself recursively without any base case or termination condition. This will lead to a stack overflow error. Additionally, the method's purpose is to change a user's password, but it does not handle password validation or security checks, which are essential for such operations. These issues suggest that the method is not functional as intended and may be removed or significantly refactored."
survived,"    def create_task(title, description=None, user_id=None):
        """"""Create a new task.""""""
        task_data = {
            ""title"": title,
            ""description"": description,
            ""user_id"": user_id
        }
        return TaskService.create_task(task_data)
",codebase-architectures/vertical-slice-architecture/features/tasks/api.py,TaskAPI,1,9.736200303530205e-10,"The method 'create_task' is a straightforward utility function that encapsulates the creation of a task by preparing a dictionary with the necessary data and then delegating the actual creation to a service class 'TaskService'. This method is likely to be useful in various parts of an application where tasks need to be created, providing a clean and consistent interface for task creation. It abstracts the details of task creation and allows for easy modifications in the future if the task creation process changes. Therefore, it is likely to be retained in the codebase."
survived,"    def update_task(task_id, task_data):
        """"""Update a task.""""""
        existing_task = db.get(""tasks"", task_id)
        if not existing_task:
            return None
        
        # Update fields
        for key, value in task_data.items():
            if key not in [""id"", ""created_at""]:
                existing_task[key] = value
        
        # Update timestamp
        existing_task[""updated_at""] = get_timestamp()
        
        # Save to database
        db.update(""tasks"", task_id, existing_task)
        return existing_task
",codebase-architectures/vertical-slice-architecture/features/tasks/service.py,TaskService,1,1.1032560311263802e-09,"The method 'update_task' is a fundamental part of managing tasks in a database, allowing for the modification of existing task records. It includes essential operations such as checking for the existence of a task, updating permissible fields, and saving changes back to the database. These operations are crucial for maintaining and updating task data, which is a common requirement in many applications. Therefore, it is unlikely that this method will be deleted as it serves a necessary function in task management."
survived,"def display_header(text):
    """"""Display a header with the given text.""""""
    print(""\n"" + ""="" * 50)
    print(f"" {text}"")
    print(""="" * 50)
",codebase-architectures/vertical-slice-architecture/main.py,,1,1.1032560311263802e-09,"The method 'display_header' is a simple utility function that formats and prints a header with a given text. Such utility functions are commonly used in various applications to improve readability and organization of console output. The method is straightforward, has a clear purpose, and is likely to be reused in different parts of a program where formatted headers are needed. Therefore, it is likely to survive as it provides a useful and reusable functionality."
survived,"    def __init__(self):
        self.data = {}
",codebase-architectures/vertical-slice-architecture/shared/db.py,InMemoryDB,1,1.725782769012759e-08,"The method is a constructor for a class, initializing an instance variable 'data' as an empty dictionary. This is a common and necessary practice in object-oriented programming to set up initial state for objects. Therefore, it is unlikely to be deleted as it serves a fundamental purpose in the class design."
survived,"    def get_all_categories():
        """"""Get all categories.""""""
        try:
            categories = db.get_all(""categories"")
            Logger.info(app_logger, f""Retrieved {len(categories)} categories"")
            return categories
        except Exception as e:
            Logger.error(app_logger, f""Error getting all categories: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/category_service.py,CategoryService,1,5.211412485172657e-10,"The method 'get_all_categories' is a straightforward utility function that retrieves all categories from a database and logs the process. It includes error handling and logging, which are good practices for maintainability and debugging. Unless there is a significant change in the application's requirements or architecture, such as a shift away from using this database or a change in how categories are managed, this method is likely to remain useful. Therefore, it is likely to survive."
survived,"def validate_string_length(value: str, min_length: int = 0, max_length: Optional[int] = None) -> bool:
    """"""
    Validate that a string's length is within the specified range.
    
    Args:
        value: The string to validate
        min_length: Minimum allowed length
        max_length: Maximum allowed length, or None for no maximum
        
    Returns:
        True if the string length is valid, False otherwise
    """"""
    if not isinstance(value, str):
        return False
    
    if len(value) < min_length:
        return False
    
    if max_length is not None and len(value) > max_length:
        return False
    
    return True
",codebase-architectures/atomic-composable-architecture/modules/validation.py,,1,1.2501528648238603e-09,"The method 'validate_string_length' is a utility function that checks if a string's length falls within a specified range. This is a common requirement in many applications, such as form validation, data processing, and input sanitization. The function is well-documented, handles edge cases (like non-string inputs and optional maximum length), and is generally useful in a wide range of scenarios. Therefore, it is likely to be retained in the codebase."
survived,"def generate_report_filename(prefix=""report"", extension=""json""):
    """"""Generate a filename for a report with timestamp.""""""
    timestamp = datetime.now().strftime(""%Y%m%d_%H%M%S"")
    return f""{prefix}_{timestamp}.{extension}""",codebase-architectures/pipeline-architecture/shared/utilities.py,,1,8.592166611791576e-10,"The method 'generate_report_filename' is a utility function that generates a filename with a timestamp, which is a common requirement in many applications for creating unique filenames. It is simple, useful, and does not have any apparent issues or redundancies. Therefore, it is likely to be retained in the codebase."
survived,"    def run(self):
        """"""
        Run the pipeline by executing all stages in sequence.
        
        Returns:
            dict: Pipeline results including data and metadata
        """"""
        self.metadata[""started_at""] = datetime.now().isoformat()
        self.metadata[""status""] = ""running""
        
        print(f""\n=== Starting Pipeline: {self.name} ==="")
        
        # Execute each stage
        for i, stage in enumerate(self.stages):
            stage_name = stage[""name""]
            stage_instance = stage[""instance""]
            
            print(f""\n--- Stage {i+1}: {stage_name} ---"")
            
            try:
                # Execute the stage
                if i == 0:
                    # First stage doesn't take input from previous stage
                    result = self._execute_first_stage(stage_instance)
                else:
                    # Pass result from previous stage
                    previous_result = self.results[self.stages[i-1][""name""]]
                    result = self._execute_stage(stage_instance, previous_result)
                
                # Store the result
                self.results[stage_name] = result
                
                # Update stage status
                stage[""status""] = result[""metadata""][""status""]
                
                # Check for errors
                if result[""metadata""][""status""] in [""error"", ""skipped""]:
                    print(f""Stage {stage_name} {result['metadata']['status']}"")
                    for error in result[""metadata""].get(""errors"", []):
                        print(f""  Error: {error}"")
                    
                    # Add errors to pipeline metadata
                    self.metadata[""errors""].append({
                        ""stage"": stage_name,
                        ""errors"": result[""metadata""].get(""errors"", [])
                    })
                else:
                    print(f""Stage {stage_name} completed successfully"")
            
            except Exception as e:
                # Handle unexpected errors
                error_message = f""Unexpected error in stage {stage_name}: {str(e)}""
                print(f""  Error: {error_message}"")
                
                # Update stage status
                stage[""status""] = ""error""
                
                # Add error to pipeline metadata
                self.metadata[""errors""].append({
                    ""stage"": stage_name,
                    ""errors"": [error_message]
                })
        
        # Update pipeline status
        self.metadata[""completed_at""] = datetime.now().isoformat()
        if self.metadata[""errors""]:
            self.metadata[""status""] = ""completed_with_errors""
        else:
            self.metadata[""status""] = ""completed""
        
        # Calculate total execution time
        start_time = datetime.fromisoformat(self.metadata[""started_at""])
        end_time = datetime.fromisoformat(self.metadata[""completed_at""])
        execution_time = (end_time - start_time).total_seconds()
        self.metadata[""execution_time_seconds""] = execution_time
        
        print(f""\n=== Pipeline {self.name} {self.metadata['status']} ==="")
        print(f""Total execution time: {execution_time:.2f} seconds"")
        
        return self._create_pipeline_result()
",codebase-architectures/pipeline-architecture/pipeline/pipeline_manager.py,PipelineManager,1,9.237449576640118e-09,"The method 'run' is a core part of a pipeline execution system, responsible for orchestrating the execution of various stages, handling errors, and updating metadata. It is well-documented, handles exceptions, and provides detailed logging, making it a robust and essential component of the system. Such methods are typically retained as they are crucial for the functionality of the application."
survived,"    def delete_user(user_id):
        """"""Delete a user.""""""
        success = UserService.delete_user(user_id)
        if not success:
            return {""error"": f""User with ID {user_id} not found""}
        return {""message"": f""User with ID {user_id} deleted successfully""}",codebase-architectures/vertical-slice-architecture/features/users/api.py,UserAPI,1,7.194132978569833e-09,"The method 'delete_user' is a straightforward utility function that interacts with a user service to delete a user by their ID. It provides clear feedback on the success or failure of the operation, which is a common requirement in user management systems. The method is simple, effective, and serves a specific purpose, making it unlikely to be deleted unless there is a significant change in how user deletions are handled in the system."
survived,"    def get_all_products():
        """"""Get all products.""""""
        try:
            products = db.get_all(""products"")
            Logger.info(app_logger, f""Retrieved {len(products)} products"")
            return products
        except Exception as e:
            Logger.error(app_logger, f""Error getting all products: {str(e)}"", exc_info=True)
            raise
",codebase-architectures/layered-architecture/services/product_service.py,ProductService,1,1.8189616842444243e-09,"The method 'get_all_products' is a utility function that retrieves all products from a database and logs the operation. It includes error handling and logging, which are good practices for maintainability and debugging. Such methods are commonly used in applications that interact with databases, and there is no indication that it is obsolete or redundant. Therefore, it is likely to be retained in the codebase."
survived,"    def get_by_sku(sku):
        """"""Get a product by SKU.""""""
        try:
            product = ProductService.get_by_sku(sku)
            if not product:
                return {
                    ""success"": False,
                    ""message"": f""Product with SKU '{sku}' not found""
                }
            return {
                ""success"": True,
                ""data"": product
            }
        except Exception as e:
            Logger.error(app_logger, f""Error in get_by_sku: {str(e)}"", exc_info=True)
            return {
                ""success"": False,
                ""message"": ""An error occurred while retrieving the product""
            }
",codebase-architectures/layered-architecture/api/product_api.py,ProductAPI,1,9.736200303530205e-10,"The method 'get_by_sku' is a utility function that retrieves a product by its SKU, which is a common requirement in e-commerce and inventory management systems. It handles both successful retrieval and error scenarios, providing meaningful feedback in each case. The method is well-structured, with error logging and clear return messages, making it a valuable part of the codebase. Therefore, it is likely to be retained."
survived,"    def error(logger_name: str, message: str, exc_info: bool = False) -> None:
        """"""
        Log an error message.
        
        Args:
            logger_name: Name of the logger
            message: Message to log
            exc_info: Whether to include exception info
        """"""
        console.log(f""[{logger_name}] [error] {message}"")
        
        if exc_info:
            import traceback
            console.log(traceback.format_exc())",example-agent-codebase-arch/layered-architecture/utils/logger.py,Logger,1,2.0611536181902033e-09,"The method 'error' is a utility function for logging error messages, which is a common requirement in software development. It provides a structured way to log errors with optional exception information, making it useful for debugging and monitoring applications. The method is simple, clear, and serves a specific purpose, which makes it likely to be retained in the codebase."
survived,"    def create_file(path: str, file_text: str) -> FileOperationResult:
        """"""
        Create a new file with specified content.

        Args:
            path: The path where the new file should be created
            file_text: The content to write to the new file

        Returns:
            FileOperationResult with result or error message
        """"""
        try:
            # Check if the path is empty or invalid
            if not path or not path.strip():
                error_msg = ""Invalid file path provided: path is empty.""
                console.log(f""[create_file] Error: {error_msg}"")
                return FileOperationResult(False, error_msg)

            # Normalize the path
            path = normalize_path(path)

            # Check if the directory exists
            directory = os.path.dirname(path)
            if directory and not os.path.exists(directory):
                console.log(f""[create_file] Creating directory: {directory}"")
                os.makedirs(directory)

            with open(path, ""w"") as f:
                f.write(file_text or """")

            console.print(f""[green]Successfully created file {path}[/green]"")
            console.log(f""[create_file] Successfully created file {path}"")
            return FileOperationResult(True, f""Successfully created file {path}"")
        except Exception as e:
            error_msg = f""Error creating file: {str(e)}""
            console.print(f""[red]{error_msg}[/red]"")
            console.log(f""[create_file] Error: {str(e)}"")
            console.log(traceback.format_exc())
            return FileOperationResult(False, error_msg)
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/service.py,FileOperationService,1,5.60279640614594e-09,"The method 'create_file' is a well-defined utility function that handles file creation with error handling and logging. It checks for valid paths, creates necessary directories, writes content to the file, and logs success or failure. Such functionality is commonly needed in applications that deal with file operations, making it a useful and reusable component. Therefore, it is likely to be retained in the codebase."
survived,"    def __init__(self, success: bool, message: str, data: Any = None):
        """"""
        Initialize a file operation result.
        
        Args:
            success: Whether the operation was successful
            message: A message describing the result
            data: Optional data returned by the operation
        """"""
        self.success = success
        self.message = message
        self.data = data
",example-agent-codebase-arch/vertical-slice-architecture/features/file_operations/model.py,FileOperationResult,1,3.3982678079468468e-09,"The method is a constructor for a class, likely used to initialize instances with attributes indicating the success of an operation, a message, and optional data. This is a common pattern in object-oriented programming for handling results or responses, making it a useful and necessary part of the class. There is no indication that this method is redundant or obsolete, so it is likely to be retained."
survived,"    def to_dict(self) -> Dict[str, Any]:
        """"""
        Convert the result to a dictionary.
        
        Returns:
            Dictionary representation of the result
        """"""
        return {
            ""success"": self.success,
            ""message"": self.message,
            ""data"": self.data
        }
",example-agent-codebase-arch/pipeline-architecture/shared/utilities.py,FileOperationResult,1,7.582560422162384e-10,"The method 'to_dict' is a utility function that converts an object's attributes into a dictionary format. This is a common and useful pattern in programming, especially for serialization, logging, or data manipulation purposes. It is likely to be used frequently in applications where objects need to be converted to a format that is easily readable or transferable, such as JSON. Therefore, the method is likely to be retained in the codebase."
survived,"def test_create_folder_structure_strips_multiple_trailing_slashes():
    with tempfile.TemporaryDirectory() as temp_dir:
        os.chdir(temp_dir)
        folder_path, folder_name, class_name = create_folder_structure(""hello///"")
        
        assert folder_name == ""hello""
        assert class_name == ""Hello""
        assert folder_path.name == ""hello""
        assert folder_path.exists()
",tests/cli/test_create_crew.py,,1,1.725782769012759e-08,"The method 'test_create_folder_structure_strips_multiple_trailing_slashes' is a unit test designed to verify the functionality of the 'create_folder_structure' function. It checks if the function correctly handles input with multiple trailing slashes by stripping them and creating a folder with the expected name. Unit tests are crucial for ensuring code reliability and are typically retained in codebases to prevent regressions. Therefore, this method is likely to be retained as it serves an important role in testing the functionality of the code."
survived,"def test_create_crew_with_multiple_trailing_slashes(mock_load_env, mock_write_env, mock_copy_template, temp_dir):
    mock_load_env.return_value = {}
    
    with tempfile.TemporaryDirectory() as work_dir:
        os.chdir(work_dir)
        create_crew(""test-project///"", skip_provider=True)
        
        project_path = Path(work_dir) / ""test_project""
        assert project_path.exists()
        assert (project_path / ""src"" / ""test_project"").exists()
",tests/cli/test_create_crew.py,,1,4.944450477491054e-09,"The method 'test_create_crew_with_multiple_trailing_slashes' is a unit test designed to verify the behavior of the 'create_crew' function when given a project name with multiple trailing slashes. This is a valid test case as it ensures the robustness of the 'create_crew' function in handling input variations. Unit tests are generally retained in codebases to ensure ongoing functionality and to catch regressions, so this method is likely to survive."
survived,"    def load_state(self, flow_uuid: str) -> Optional[Dict[str, Any]]:
        """"""Load the most recent state for a given flow UUID.
        
        Args:
            flow_uuid: Unique identifier for the flow instance
            
        Returns:
            The most recent state as a dictionary, or None if no state exists
        """"""
        pass",src/crewai/flow/persistence/base.py,FlowPersistence,1,7.3382086014706e-07,"The method `load_state` is a placeholder function with a clear docstring explaining its purpose, arguments, and return type. It is likely part of a larger system where loading state by a unique identifier is necessary. The method is not implemented yet, but its presence suggests that it is intended to be used in the future. Given its clear utility in managing state for flow instances, it is more likely to be implemented rather than deleted."
survived,"def test_flow_state_restoration(tmp_path):
    """"""Test restoring flow state from persistence.""""""
    db_path = os.path.join(tmp_path, ""test_flows.db"")
    persistence = SQLiteFlowPersistence(db_path)
    
    # First flow execution to create initial state
    class RestorableFlow(Flow[TestState]):
        initial_state = TestState
        
        @start()
        @persist(persistence)
        def set_message(self):
            self.state.message = ""Original message""
            self.state.counter = 42
    
    flow1 = RestorableFlow(persistence=persistence)
    flow1.kickoff()
    original_uuid = flow1.state.id
    
    # Create new flow instance with restored state
    flow2 = RestorableFlow(
        persistence=persistence,
        restore_uuid=original_uuid,
        counter=43,  # Override counter
    )
    
    # Verify state restoration and merging
    assert flow2.state.id == original_uuid
    assert flow2.state.message == ""Original message""
    assert flow2.state.counter == 43  # Verify override worked
",tests/test_flow_persistence.py,,1,1.1253518384332553e-07,"The method 'test_flow_state_restoration' is a unit test designed to verify the functionality of restoring a flow's state from persistence. It is crucial for ensuring that the system can correctly save and restore state, which is a fundamental feature in many applications that require state management. The test checks both the restoration of the original state and the ability to override specific state attributes, which are important aspects of the system's reliability and flexibility. Therefore, this method is likely to be retained as it serves an essential role in validating the system's behavior."
survived,"        def set_message(self):
            self.state.message = ""Original message""
            self.state.counter = 42
",tests/test_flow_persistence.py,RestorableFlow,1,5.905303995456778e-10,"The method 'set_message' is a simple setter method that assigns a string to 'self.state.message' and an integer to 'self.state.counter'. Such methods are typically retained as they are essential for initializing or updating the state of an object. There is no indication that this method is redundant or unnecessary, so it is likely to survive."
survived,"    def init_db(self) -> None:
        """"""Create the necessary tables if they don't exist.""""""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(""""""
            CREATE TABLE IF NOT EXISTS flow_states (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                flow_uuid TEXT NOT NULL,
                method_name TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                state_json TEXT NOT NULL
            )
            """""")
            # Add index for faster UUID lookups
            conn.execute(""""""
            CREATE INDEX IF NOT EXISTS idx_flow_states_uuid 
            ON flow_states(flow_uuid)
            """""")
",src/crewai/flow/persistence/sqlite.py,SQLiteFlowPersistence,1,2.3355930333443423e-09,"The method `init_db` is responsible for setting up the database schema by creating a table and an index if they do not already exist. This is a fundamental operation for applications that rely on a database, ensuring that the necessary structures are in place before any data operations are performed. Such methods are typically essential for the initialization phase of an application and are unlikely to be removed unless the application undergoes a significant architectural change, such as moving away from using a database or changing the database technology. Therefore, the method is likely to survive."
survived,"        def count_up(self):
            self.state.counter += 1
            self.state.message = f""Count is {self.state.counter}""
",tests/test_flow_persistence.py,StructuredFlow,1,1.1032560311263802e-09,"The method 'count_up' is a simple and useful utility function that increments a counter and updates a message accordingly. This kind of method is often used in applications where tracking the number of occurrences or iterations is necessary. It is straightforward, has a clear purpose, and is likely to be used in various parts of a program that requires counting functionality. Therefore, it is unlikely to be deleted unless the entire feature it supports is removed or refactored."
survived,"def persist(persistence: FlowPersistence):
    """"""Decorator to persist flow state after method execution.
    
    This decorator supports both synchronous and asynchronous methods. It will
    persist the flow state after the method completes successfully. For async
    methods, it ensures the state is persisted before returning the result.
    
    Args:
        persistence: FlowPersistence implementation to use for storing state
    
    Returns:
        A decorator function that wraps flow methods and handles state persistence
    
    Raises:
        ValueError: If the flow state doesn't have an 'id' field
        RuntimeError: If state persistence fails
    """"""
    def _persist_state(flow_instance: Any, method_name: str) -> None:
        """"""Helper to persist state with error handling.""""""
        try:
            # Get flow UUID from state
            state = getattr(flow_instance, 'state', None)
            if state is None:
                raise ValueError(""Flow instance has no state"")
                
            flow_uuid: Optional[str] = None
            if isinstance(state, dict):
                flow_uuid = state.get('id')
            elif isinstance(state, BaseModel):
                flow_uuid = getattr(state, 'id', None)
                
            if not flow_uuid:
                raise ValueError(
                    ""Flow state must have an 'id' field for persistence""
                )
                
            # Persist the state
            persistence.save_state(
                flow_uuid=flow_uuid,
                method_name=method_name,
                state_data=state,
            )
        except Exception as e:
            logger.error(
                f""Failed to persist state for method {method_name}: {str(e)}""
            )
            raise RuntimeError(f""State persistence failed: {str(e)}"") from e
    
    def decorator(method: Callable[..., T]) -> Callable[..., T]:
        """"""Decorator that handles both sync and async methods.""""""
        if asyncio.iscoroutinefunction(method):
            @functools.wraps(method)
            async def async_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original async method
                result = await method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], async_wrapper)
        else:
            @functools.wraps(method)
            def sync_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original sync method
                result = method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
            return cast(Callable[..., T], sync_wrapper)
            
    return decorator",src/crewai/flow/persistence/decorators.py,,1,7.194132978569833e-09,"The method 'persist' is a decorator function designed to ensure that the state of a flow is persisted after a method execution, whether the method is synchronous or asynchronous. This functionality is crucial in systems where maintaining the state is important for consistency and reliability, such as in workflows or stateful applications. The method includes error handling and logging, which are good practices for robust software development. Given its utility and the fact that it addresses both sync and async methods, it is likely to be retained in the codebase."
survived,"            def sync_wrapper(flow_instance: Any, *args: Any, **kwargs: Any) -> T:
                # Execute the original sync method
                result = method(flow_instance, *args, **kwargs)
                # Persist state after method completion
                _persist_state(flow_instance, method.__name__)
                return result
",src/crewai/flow/persistence/decorators.py,,1,1.725782769012759e-08,"The method 'sync_wrapper' is a utility function that wraps around another method to add additional functionality, specifically persisting the state after the method execution. This kind of pattern is common in software development for adding cross-cutting concerns like logging, transaction management, or state persistence without modifying the original method. Since it provides a useful and reusable functionality, it is likely to be retained in the codebase."
survived,"    def supports_chain(self, chain) -> bool:
        return True
",python/src/plugins/jsonrpc/goat_plugins/jsonrpc/__init__.py,JSONRpcPlugin,1,4.363462233903899e-09,"The method `supports_chain` is a simple implementation that always returns `True`, indicating that it supports any chain passed to it. This method is likely a placeholder or a default implementation in a larger system where specific chain support might be checked. Since it is a straightforward method with no complex logic or dependencies, it is unlikely to be deleted unless the entire functionality it supports is removed or significantly refactored. Therefore, it is more likely to survive."
survived,"    def supports_stop_words(self) -> bool:
        """"""Return True to indicate that stop words are supported.""""""
        return True
",tests/custom_llm_test.py,CustomLLM,1,4.944450477491054e-09,"The method `supports_stop_words` is a simple, clear, and self-explanatory method that indicates whether stop words are supported by returning a boolean value. It is likely part of a larger class or module that deals with text processing or natural language processing. Such methods are often useful for checking capabilities or configurations in a system. Since it provides a clear and useful piece of information, it is likely to be retained in the codebase."
